var Rb = Object.defineProperty;
var Bb = (e, n, t) => n in e ? Rb(e, n, { enumerable: !0, configurable: !0, writable: !0, value: t }) : e[n] = t;
var Ce = (e, n, t) => (Bb(e, typeof n != "symbol" ? n + "" : n, t), t);
function zb(e, n) {
  for (var t = 0; t < n.length; t++) {
    const i = n[t];
    if (typeof i != "string" && !Array.isArray(i)) {
      for (const r in i)
        if (r !== "default" && !(r in e)) {
          const a = Object.getOwnPropertyDescriptor(i, r);
          a && Object.defineProperty(e, r, a.get ? a : {
            enumerable: !0,
            get: () => i[r]
          });
        }
    }
  }
  return Object.freeze(Object.defineProperty(e, Symbol.toStringTag, { value: "Module" }));
}
Number.EPSILON === void 0 && (Number.EPSILON = Math.pow(2, -52));
Number.isInteger === void 0 && (Number.isInteger = function(e) {
  return typeof e == "number" && isFinite(e) && Math.floor(e) === e;
});
Math.sign === void 0 && (Math.sign = function(e) {
  return e < 0 ? -1 : e > 0 ? 1 : +e;
});
"name" in Function.prototype || Object.defineProperty(Function.prototype, "name", {
  get: function() {
    return this.toString().match(/^\s*function\s*([^\(\s]*)/)[1];
  }
});
Object.assign === void 0 && (Object.assign = function(e) {
  if (e == null)
    throw new TypeError("Cannot convert undefined or null to object");
  const n = Object(e);
  for (let t = 1; t < arguments.length; t++) {
    const i = arguments[t];
    if (i != null)
      for (const r in i)
        Object.prototype.hasOwnProperty.call(i, r) && (n[r] = i[r]);
  }
  return n;
});
const $b = "119", Nb = 0, H0 = 1, Ub = 2, Lx = 1, Gb = 2, ym = 3, cg = 0, hi = 1, Fy = 2, Dx = 1, co = 0, xm = 1, q0 = 2, K0 = 3, X0 = 4, Vb = 5, Xc = 100, jb = 101, Wb = 102, Y0 = 103, J0 = 104, Hb = 200, qb = 201, Kb = 202, Xb = 203, kx = 204, Ox = 205, Yb = 206, Jb = 207, Qb = 208, Zb = 209, eM = 210, tM = 0, nM = 1, iM = 2, Ov = 3, sM = 4, rM = 5, oM = 6, aM = 7, Ry = 0, lM = 1, cM = 2, su = 0, uM = 1, dM = 2, hM = 3, fM = 4, pM = 5, I0 = 300, L0 = 301, D0 = 302, Fx = 303, k0 = 304, ug = 306, By = 307, X_ = 1e3, qi = 1001, Y_ = 1002, _i = 1003, Fv = 1004, Rv = 1005, Li = 1006, Rx = 1007, zy = 1008, dg = 1009, mM = 1010, gM = 1011, J_ = 1012, _M = 1013, j_ = 1014, oo = 1015, Q_ = 1016, yM = 1017, vM = 1018, wM = 1019, bm = 1020, xM = 1021, pa = 1022, ws = 1023, bM = 1024, MM = 1025, TM = ws, ru = 1026, Pm = 1027, EM = 1028, SM = 1029, PM = 1030, AM = 1031, CM = 1032, IM = 1033, Q0 = 33776, Z0 = 33777, ew = 33778, tw = 33779, nw = 35840, iw = 35841, sw = 35842, rw = 35843, LM = 36196, ow = 37492, aw = 37496, DM = 37808, kM = 37809, OM = 37810, FM = 37811, RM = 37812, BM = 37813, zM = 37814, $M = 37815, NM = 37816, UM = 37817, GM = 37818, VM = 37819, jM = 37820, WM = 37821, HM = 36492, qM = 37840, KM = 37841, XM = 37842, YM = 37843, JM = 37844, QM = 37845, ZM = 37846, e1 = 37847, t1 = 37848, n1 = 37849, i1 = 37850, s1 = 37851, r1 = 37852, o1 = 37853, a1 = 2200, l1 = 2201, c1 = 2202, Z_ = 2300, W_ = 2301, ev = 2302, au = 2400, Qc = 2401, ey = 2402, O0 = 2500, Bx = 2501, u1 = 0, Ki = 3e3, $y = 3001, F0 = 3007, R0 = 3002, d1 = 3003, zx = 3004, $x = 3005, Nx = 3006, h1 = 3200, f1 = 3201, Su = 0, p1 = 1, tv = 7680, m1 = 519, Ny = 35044, Am = 35048;
function Fr() {
}
Object.assign(Fr.prototype, {
  addEventListener: function(e, n) {
    this._listeners === void 0 && (this._listeners = {});
    const t = this._listeners;
    t[e] === void 0 && (t[e] = []), t[e].indexOf(n) === -1 && t[e].push(n);
  },
  hasEventListener: function(e, n) {
    if (this._listeners === void 0)
      return !1;
    const t = this._listeners;
    return t[e] !== void 0 && t[e].indexOf(n) !== -1;
  },
  removeEventListener: function(e, n) {
    if (this._listeners === void 0)
      return;
    const i = this._listeners[e];
    if (i !== void 0) {
      const r = i.indexOf(n);
      r !== -1 && i.splice(r, 1);
    }
  },
  dispatchEvent: function(e) {
    if (this._listeners === void 0)
      return;
    const t = this._listeners[e.type];
    if (t !== void 0) {
      e.target = this;
      const i = t.slice(0);
      for (let r = 0, a = i.length; r < a; r++)
        i[r].call(this, e);
    }
  }
});
const Ti = [];
for (let e = 0; e < 256; e++)
  Ti[e] = (e < 16 ? "0" : "") + e.toString(16);
let s_ = 1234567;
const un = {
  DEG2RAD: Math.PI / 180,
  RAD2DEG: 180 / Math.PI,
  generateUUID: function() {
    const e = Math.random() * 4294967295 | 0, n = Math.random() * 4294967295 | 0, t = Math.random() * 4294967295 | 0, i = Math.random() * 4294967295 | 0;
    return (Ti[e & 255] + Ti[e >> 8 & 255] + Ti[e >> 16 & 255] + Ti[e >> 24 & 255] + "-" + Ti[n & 255] + Ti[n >> 8 & 255] + "-" + Ti[n >> 16 & 15 | 64] + Ti[n >> 24 & 255] + "-" + Ti[t & 63 | 128] + Ti[t >> 8 & 255] + "-" + Ti[t >> 16 & 255] + Ti[t >> 24 & 255] + Ti[i & 255] + Ti[i >> 8 & 255] + Ti[i >> 16 & 255] + Ti[i >> 24 & 255]).toUpperCase();
  },
  clamp: function(e, n, t) {
    return Math.max(n, Math.min(t, e));
  },
  // compute euclidian modulo of m % n
  // https://en.wikipedia.org/wiki/Modulo_operation
  euclideanModulo: function(e, n) {
    return (e % n + n) % n;
  },
  // Linear mapping from range <a1, a2> to range <b1, b2>
  mapLinear: function(e, n, t, i, r) {
    return i + (e - n) * (r - i) / (t - n);
  },
  // https://en.wikipedia.org/wiki/Linear_interpolation
  lerp: function(e, n, t) {
    return (1 - t) * e + t * n;
  },
  // http://en.wikipedia.org/wiki/Smoothstep
  smoothstep: function(e, n, t) {
    return e <= n ? 0 : e >= t ? 1 : (e = (e - n) / (t - n), e * e * (3 - 2 * e));
  },
  smootherstep: function(e, n, t) {
    return e <= n ? 0 : e >= t ? 1 : (e = (e - n) / (t - n), e * e * e * (e * (e * 6 - 15) + 10));
  },
  // Random integer from <low, high> interval
  randInt: function(e, n) {
    return e + Math.floor(Math.random() * (n - e + 1));
  },
  // Random float from <low, high> interval
  randFloat: function(e, n) {
    return e + Math.random() * (n - e);
  },
  // Random float from <-range/2, range/2> interval
  randFloatSpread: function(e) {
    return e * (0.5 - Math.random());
  },
  // Deterministic pseudo-random float in the interval [ 0, 1 ]
  seededRandom: function(e) {
    return e !== void 0 && (s_ = e % 2147483647), s_ = s_ * 16807 % 2147483647, (s_ - 1) / 2147483646;
  },
  degToRad: function(e) {
    return e * un.DEG2RAD;
  },
  radToDeg: function(e) {
    return e * un.RAD2DEG;
  },
  isPowerOfTwo: function(e) {
    return (e & e - 1) === 0 && e !== 0;
  },
  ceilPowerOfTwo: function(e) {
    return Math.pow(2, Math.ceil(Math.log(e) / Math.LN2));
  },
  floorPowerOfTwo: function(e) {
    return Math.pow(2, Math.floor(Math.log(e) / Math.LN2));
  },
  setQuaternionFromProperEuler: function(e, n, t, i, r) {
    const a = Math.cos, c = Math.sin, u = a(t / 2), l = c(t / 2), f = a((n + i) / 2), m = c((n + i) / 2), h = a((n - i) / 2), p = c((n - i) / 2), _ = a((i - n) / 2), v = c((i - n) / 2);
    switch (r) {
      case "XYX":
        e.set(u * m, l * h, l * p, u * f);
        break;
      case "YZY":
        e.set(l * p, u * m, l * h, u * f);
        break;
      case "ZXZ":
        e.set(l * h, l * p, u * m, u * f);
        break;
      case "XZX":
        e.set(u * m, l * v, l * _, u * f);
        break;
      case "YXY":
        e.set(l * _, u * m, l * v, u * f);
        break;
      case "ZYZ":
        e.set(l * v, l * _, u * m, u * f);
        break;
      default:
        console.warn("THREE.MathUtils: .setQuaternionFromProperEuler() encountered an unknown order: " + r);
    }
  }
};
function vt(e = 0, n = 0) {
  this.x = e, this.y = n;
}
Object.defineProperties(vt.prototype, {
  width: {
    get: function() {
      return this.x;
    },
    set: function(e) {
      this.x = e;
    }
  },
  height: {
    get: function() {
      return this.y;
    },
    set: function(e) {
      this.y = e;
    }
  }
});
Object.assign(vt.prototype, {
  isVector2: !0,
  set: function(e, n) {
    return this.x = e, this.y = n, this;
  },
  setScalar: function(e) {
    return this.x = e, this.y = e, this;
  },
  setX: function(e) {
    return this.x = e, this;
  },
  setY: function(e) {
    return this.y = e, this;
  },
  setComponent: function(e, n) {
    switch (e) {
      case 0:
        this.x = n;
        break;
      case 1:
        this.y = n;
        break;
      default:
        throw new Error("index is out of range: " + e);
    }
    return this;
  },
  getComponent: function(e) {
    switch (e) {
      case 0:
        return this.x;
      case 1:
        return this.y;
      default:
        throw new Error("index is out of range: " + e);
    }
  },
  clone: function() {
    return new this.constructor(this.x, this.y);
  },
  copy: function(e) {
    return this.x = e.x, this.y = e.y, this;
  },
  add: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector2: .add() now only accepts one argument. Use .addVectors( a, b ) instead."), this.addVectors(e, n)) : (this.x += e.x, this.y += e.y, this);
  },
  addScalar: function(e) {
    return this.x += e, this.y += e, this;
  },
  addVectors: function(e, n) {
    return this.x = e.x + n.x, this.y = e.y + n.y, this;
  },
  addScaledVector: function(e, n) {
    return this.x += e.x * n, this.y += e.y * n, this;
  },
  sub: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector2: .sub() now only accepts one argument. Use .subVectors( a, b ) instead."), this.subVectors(e, n)) : (this.x -= e.x, this.y -= e.y, this);
  },
  subScalar: function(e) {
    return this.x -= e, this.y -= e, this;
  },
  subVectors: function(e, n) {
    return this.x = e.x - n.x, this.y = e.y - n.y, this;
  },
  multiply: function(e) {
    return this.x *= e.x, this.y *= e.y, this;
  },
  multiplyScalar: function(e) {
    return this.x *= e, this.y *= e, this;
  },
  divide: function(e) {
    return this.x /= e.x, this.y /= e.y, this;
  },
  divideScalar: function(e) {
    return this.multiplyScalar(1 / e);
  },
  applyMatrix3: function(e) {
    const n = this.x, t = this.y, i = e.elements;
    return this.x = i[0] * n + i[3] * t + i[6], this.y = i[1] * n + i[4] * t + i[7], this;
  },
  min: function(e) {
    return this.x = Math.min(this.x, e.x), this.y = Math.min(this.y, e.y), this;
  },
  max: function(e) {
    return this.x = Math.max(this.x, e.x), this.y = Math.max(this.y, e.y), this;
  },
  clamp: function(e, n) {
    return this.x = Math.max(e.x, Math.min(n.x, this.x)), this.y = Math.max(e.y, Math.min(n.y, this.y)), this;
  },
  clampScalar: function(e, n) {
    return this.x = Math.max(e, Math.min(n, this.x)), this.y = Math.max(e, Math.min(n, this.y)), this;
  },
  clampLength: function(e, n) {
    const t = this.length();
    return this.divideScalar(t || 1).multiplyScalar(Math.max(e, Math.min(n, t)));
  },
  floor: function() {
    return this.x = Math.floor(this.x), this.y = Math.floor(this.y), this;
  },
  ceil: function() {
    return this.x = Math.ceil(this.x), this.y = Math.ceil(this.y), this;
  },
  round: function() {
    return this.x = Math.round(this.x), this.y = Math.round(this.y), this;
  },
  roundToZero: function() {
    return this.x = this.x < 0 ? Math.ceil(this.x) : Math.floor(this.x), this.y = this.y < 0 ? Math.ceil(this.y) : Math.floor(this.y), this;
  },
  negate: function() {
    return this.x = -this.x, this.y = -this.y, this;
  },
  dot: function(e) {
    return this.x * e.x + this.y * e.y;
  },
  cross: function(e) {
    return this.x * e.y - this.y * e.x;
  },
  lengthSq: function() {
    return this.x * this.x + this.y * this.y;
  },
  length: function() {
    return Math.sqrt(this.x * this.x + this.y * this.y);
  },
  manhattanLength: function() {
    return Math.abs(this.x) + Math.abs(this.y);
  },
  normalize: function() {
    return this.divideScalar(this.length() || 1);
  },
  angle: function() {
    return Math.atan2(-this.y, -this.x) + Math.PI;
  },
  distanceTo: function(e) {
    return Math.sqrt(this.distanceToSquared(e));
  },
  distanceToSquared: function(e) {
    const n = this.x - e.x, t = this.y - e.y;
    return n * n + t * t;
  },
  manhattanDistanceTo: function(e) {
    return Math.abs(this.x - e.x) + Math.abs(this.y - e.y);
  },
  setLength: function(e) {
    return this.normalize().multiplyScalar(e);
  },
  lerp: function(e, n) {
    return this.x += (e.x - this.x) * n, this.y += (e.y - this.y) * n, this;
  },
  lerpVectors: function(e, n, t) {
    return this.x = e.x + (n.x - e.x) * t, this.y = e.y + (n.y - e.y) * t, this;
  },
  equals: function(e) {
    return e.x === this.x && e.y === this.y;
  },
  fromArray: function(e, n) {
    return n === void 0 && (n = 0), this.x = e[n], this.y = e[n + 1], this;
  },
  toArray: function(e, n) {
    return e === void 0 && (e = []), n === void 0 && (n = 0), e[n] = this.x, e[n + 1] = this.y, e;
  },
  fromBufferAttribute: function(e, n, t) {
    return t !== void 0 && console.warn("THREE.Vector2: offset has been removed from .fromBufferAttribute()."), this.x = e.getX(n), this.y = e.getY(n), this;
  },
  rotateAround: function(e, n) {
    const t = Math.cos(n), i = Math.sin(n), r = this.x - e.x, a = this.y - e.y;
    return this.x = r * t - a * i + e.x, this.y = r * i + a * t + e.y, this;
  },
  random: function() {
    return this.x = Math.random(), this.y = Math.random(), this;
  }
});
function Bi() {
  this.elements = [
    1,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    1
  ], arguments.length > 0 && console.error("THREE.Matrix3: the constructor no longer reads arguments. use .set() instead.");
}
Object.assign(Bi.prototype, {
  isMatrix3: !0,
  set: function(e, n, t, i, r, a, c, u, l) {
    const f = this.elements;
    return f[0] = e, f[1] = i, f[2] = c, f[3] = n, f[4] = r, f[5] = u, f[6] = t, f[7] = a, f[8] = l, this;
  },
  identity: function() {
    return this.set(
      1,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      1
    ), this;
  },
  clone: function() {
    return new this.constructor().fromArray(this.elements);
  },
  copy: function(e) {
    const n = this.elements, t = e.elements;
    return n[0] = t[0], n[1] = t[1], n[2] = t[2], n[3] = t[3], n[4] = t[4], n[5] = t[5], n[6] = t[6], n[7] = t[7], n[8] = t[8], this;
  },
  extractBasis: function(e, n, t) {
    return e.setFromMatrix3Column(this, 0), n.setFromMatrix3Column(this, 1), t.setFromMatrix3Column(this, 2), this;
  },
  setFromMatrix4: function(e) {
    const n = e.elements;
    return this.set(
      n[0],
      n[4],
      n[8],
      n[1],
      n[5],
      n[9],
      n[2],
      n[6],
      n[10]
    ), this;
  },
  multiply: function(e) {
    return this.multiplyMatrices(this, e);
  },
  premultiply: function(e) {
    return this.multiplyMatrices(e, this);
  },
  multiplyMatrices: function(e, n) {
    const t = e.elements, i = n.elements, r = this.elements, a = t[0], c = t[3], u = t[6], l = t[1], f = t[4], m = t[7], h = t[2], p = t[5], _ = t[8], v = i[0], S = i[3], D = i[6], w = i[1], T = i[4], F = i[7], E = i[2], A = i[5], L = i[8];
    return r[0] = a * v + c * w + u * E, r[3] = a * S + c * T + u * A, r[6] = a * D + c * F + u * L, r[1] = l * v + f * w + m * E, r[4] = l * S + f * T + m * A, r[7] = l * D + f * F + m * L, r[2] = h * v + p * w + _ * E, r[5] = h * S + p * T + _ * A, r[8] = h * D + p * F + _ * L, this;
  },
  multiplyScalar: function(e) {
    const n = this.elements;
    return n[0] *= e, n[3] *= e, n[6] *= e, n[1] *= e, n[4] *= e, n[7] *= e, n[2] *= e, n[5] *= e, n[8] *= e, this;
  },
  determinant: function() {
    const e = this.elements, n = e[0], t = e[1], i = e[2], r = e[3], a = e[4], c = e[5], u = e[6], l = e[7], f = e[8];
    return n * a * f - n * c * l - t * r * f + t * c * u + i * r * l - i * a * u;
  },
  getInverse: function(e, n) {
    n !== void 0 && console.warn("THREE.Matrix3: .getInverse() can no longer be configured to throw on degenerate.");
    const t = e.elements, i = this.elements, r = t[0], a = t[1], c = t[2], u = t[3], l = t[4], f = t[5], m = t[6], h = t[7], p = t[8], _ = p * l - f * h, v = f * m - p * u, S = h * u - l * m, D = r * _ + a * v + c * S;
    if (D === 0)
      return this.set(0, 0, 0, 0, 0, 0, 0, 0, 0);
    const w = 1 / D;
    return i[0] = _ * w, i[1] = (c * h - p * a) * w, i[2] = (f * a - c * l) * w, i[3] = v * w, i[4] = (p * r - c * m) * w, i[5] = (c * u - f * r) * w, i[6] = S * w, i[7] = (a * m - h * r) * w, i[8] = (l * r - a * u) * w, this;
  },
  transpose: function() {
    let e;
    const n = this.elements;
    return e = n[1], n[1] = n[3], n[3] = e, e = n[2], n[2] = n[6], n[6] = e, e = n[5], n[5] = n[7], n[7] = e, this;
  },
  getNormalMatrix: function(e) {
    return this.setFromMatrix4(e).getInverse(this).transpose();
  },
  transposeIntoArray: function(e) {
    const n = this.elements;
    return e[0] = n[0], e[1] = n[3], e[2] = n[6], e[3] = n[1], e[4] = n[4], e[5] = n[7], e[6] = n[2], e[7] = n[5], e[8] = n[8], this;
  },
  setUvTransform: function(e, n, t, i, r, a, c) {
    const u = Math.cos(r), l = Math.sin(r);
    this.set(
      t * u,
      t * l,
      -t * (u * a + l * c) + a + e,
      -i * l,
      i * u,
      -i * (-l * a + u * c) + c + n,
      0,
      0,
      1
    );
  },
  scale: function(e, n) {
    const t = this.elements;
    return t[0] *= e, t[3] *= e, t[6] *= e, t[1] *= n, t[4] *= n, t[7] *= n, this;
  },
  rotate: function(e) {
    const n = Math.cos(e), t = Math.sin(e), i = this.elements, r = i[0], a = i[3], c = i[6], u = i[1], l = i[4], f = i[7];
    return i[0] = n * r + t * u, i[3] = n * a + t * l, i[6] = n * c + t * f, i[1] = -t * r + n * u, i[4] = -t * a + n * l, i[7] = -t * c + n * f, this;
  },
  translate: function(e, n) {
    const t = this.elements;
    return t[0] += e * t[2], t[3] += e * t[5], t[6] += e * t[8], t[1] += n * t[2], t[4] += n * t[5], t[7] += n * t[8], this;
  },
  equals: function(e) {
    const n = this.elements, t = e.elements;
    for (let i = 0; i < 9; i++)
      if (n[i] !== t[i])
        return !1;
    return !0;
  },
  fromArray: function(e, n) {
    n === void 0 && (n = 0);
    for (let t = 0; t < 9; t++)
      this.elements[t] = e[t + n];
    return this;
  },
  toArray: function(e, n) {
    e === void 0 && (e = []), n === void 0 && (n = 0);
    const t = this.elements;
    return e[n] = t[0], e[n + 1] = t[1], e[n + 2] = t[2], e[n + 3] = t[3], e[n + 4] = t[4], e[n + 5] = t[5], e[n + 6] = t[6], e[n + 7] = t[7], e[n + 8] = t[8], e;
  }
});
let Lc;
const ga = {
  getDataURL: function(e) {
    if (/^data:/i.test(e.src) || typeof HTMLCanvasElement > "u")
      return e.src;
    let n;
    if (e instanceof HTMLCanvasElement)
      n = e;
    else {
      Lc === void 0 && (Lc = document.createElementNS("http://www.w3.org/1999/xhtml", "canvas")), Lc.width = e.width, Lc.height = e.height;
      const t = Lc.getContext("2d");
      e instanceof ImageData ? t.putImageData(e, 0, 0) : t.drawImage(e, 0, 0, e.width, e.height), n = Lc;
    }
    return n.width > 2048 || n.height > 2048 ? n.toDataURL("image/jpeg", 0.6) : n.toDataURL("image/png");
  }
};
let g1 = 0;
function Fn(e, n, t, i, r, a, c, u, l, f) {
  Object.defineProperty(this, "id", { value: g1++ }), this.uuid = un.generateUUID(), this.name = "", this.image = e !== void 0 ? e : Fn.DEFAULT_IMAGE, this.mipmaps = [], this.mapping = n !== void 0 ? n : Fn.DEFAULT_MAPPING, this.wrapS = t !== void 0 ? t : qi, this.wrapT = i !== void 0 ? i : qi, this.magFilter = r !== void 0 ? r : Li, this.minFilter = a !== void 0 ? a : zy, this.anisotropy = l !== void 0 ? l : 1, this.format = c !== void 0 ? c : ws, this.internalFormat = null, this.type = u !== void 0 ? u : dg, this.offset = new vt(0, 0), this.repeat = new vt(1, 1), this.center = new vt(0, 0), this.rotation = 0, this.matrixAutoUpdate = !0, this.matrix = new Bi(), this.generateMipmaps = !0, this.premultiplyAlpha = !1, this.flipY = !0, this.unpackAlignment = 4, this.encoding = f !== void 0 ? f : Ki, this.version = 0, this.onUpdate = null;
}
Fn.DEFAULT_IMAGE = void 0;
Fn.DEFAULT_MAPPING = I0;
Fn.prototype = Object.assign(Object.create(Fr.prototype), {
  constructor: Fn,
  isTexture: !0,
  updateMatrix: function() {
    this.matrix.setUvTransform(this.offset.x, this.offset.y, this.repeat.x, this.repeat.y, this.rotation, this.center.x, this.center.y);
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.name = e.name, this.image = e.image, this.mipmaps = e.mipmaps.slice(0), this.mapping = e.mapping, this.wrapS = e.wrapS, this.wrapT = e.wrapT, this.magFilter = e.magFilter, this.minFilter = e.minFilter, this.anisotropy = e.anisotropy, this.format = e.format, this.internalFormat = e.internalFormat, this.type = e.type, this.offset.copy(e.offset), this.repeat.copy(e.repeat), this.center.copy(e.center), this.rotation = e.rotation, this.matrixAutoUpdate = e.matrixAutoUpdate, this.matrix.copy(e.matrix), this.generateMipmaps = e.generateMipmaps, this.premultiplyAlpha = e.premultiplyAlpha, this.flipY = e.flipY, this.unpackAlignment = e.unpackAlignment, this.encoding = e.encoding, this;
  },
  toJSON: function(e) {
    const n = e === void 0 || typeof e == "string";
    if (!n && e.textures[this.uuid] !== void 0)
      return e.textures[this.uuid];
    const t = {
      metadata: {
        version: 4.5,
        type: "Texture",
        generator: "Texture.toJSON"
      },
      uuid: this.uuid,
      name: this.name,
      mapping: this.mapping,
      repeat: [this.repeat.x, this.repeat.y],
      offset: [this.offset.x, this.offset.y],
      center: [this.center.x, this.center.y],
      rotation: this.rotation,
      wrap: [this.wrapS, this.wrapT],
      format: this.format,
      type: this.type,
      encoding: this.encoding,
      minFilter: this.minFilter,
      magFilter: this.magFilter,
      anisotropy: this.anisotropy,
      flipY: this.flipY,
      premultiplyAlpha: this.premultiplyAlpha,
      unpackAlignment: this.unpackAlignment
    };
    if (this.image !== void 0) {
      const i = this.image;
      if (i.uuid === void 0 && (i.uuid = un.generateUUID()), !n && e.images[i.uuid] === void 0) {
        let r;
        if (Array.isArray(i)) {
          r = [];
          for (let a = 0, c = i.length; a < c; a++)
            r.push(ga.getDataURL(i[a]));
        } else
          r = ga.getDataURL(i);
        e.images[i.uuid] = {
          uuid: i.uuid,
          url: r
        };
      }
      t.image = i.uuid;
    }
    return n || (e.textures[this.uuid] = t), t;
  },
  dispose: function() {
    this.dispatchEvent({ type: "dispose" });
  },
  transformUv: function(e) {
    if (this.mapping !== I0)
      return e;
    if (e.applyMatrix3(this.matrix), e.x < 0 || e.x > 1)
      switch (this.wrapS) {
        case X_:
          e.x = e.x - Math.floor(e.x);
          break;
        case qi:
          e.x = e.x < 0 ? 0 : 1;
          break;
        case Y_:
          Math.abs(Math.floor(e.x) % 2) === 1 ? e.x = Math.ceil(e.x) - e.x : e.x = e.x - Math.floor(e.x);
          break;
      }
    if (e.y < 0 || e.y > 1)
      switch (this.wrapT) {
        case X_:
          e.y = e.y - Math.floor(e.y);
          break;
        case qi:
          e.y = e.y < 0 ? 0 : 1;
          break;
        case Y_:
          Math.abs(Math.floor(e.y) % 2) === 1 ? e.y = Math.ceil(e.y) - e.y : e.y = e.y - Math.floor(e.y);
          break;
      }
    return this.flipY && (e.y = 1 - e.y), e;
  }
});
Object.defineProperty(Fn.prototype, "needsUpdate", {
  set: function(e) {
    e === !0 && this.version++;
  }
});
function In(e = 0, n = 0, t = 0, i = 1) {
  this.x = e, this.y = n, this.z = t, this.w = i;
}
Object.defineProperties(In.prototype, {
  width: {
    get: function() {
      return this.z;
    },
    set: function(e) {
      this.z = e;
    }
  },
  height: {
    get: function() {
      return this.w;
    },
    set: function(e) {
      this.w = e;
    }
  }
});
Object.assign(In.prototype, {
  isVector4: !0,
  set: function(e, n, t, i) {
    return this.x = e, this.y = n, this.z = t, this.w = i, this;
  },
  setScalar: function(e) {
    return this.x = e, this.y = e, this.z = e, this.w = e, this;
  },
  setX: function(e) {
    return this.x = e, this;
  },
  setY: function(e) {
    return this.y = e, this;
  },
  setZ: function(e) {
    return this.z = e, this;
  },
  setW: function(e) {
    return this.w = e, this;
  },
  setComponent: function(e, n) {
    switch (e) {
      case 0:
        this.x = n;
        break;
      case 1:
        this.y = n;
        break;
      case 2:
        this.z = n;
        break;
      case 3:
        this.w = n;
        break;
      default:
        throw new Error("index is out of range: " + e);
    }
    return this;
  },
  getComponent: function(e) {
    switch (e) {
      case 0:
        return this.x;
      case 1:
        return this.y;
      case 2:
        return this.z;
      case 3:
        return this.w;
      default:
        throw new Error("index is out of range: " + e);
    }
  },
  clone: function() {
    return new this.constructor(this.x, this.y, this.z, this.w);
  },
  copy: function(e) {
    return this.x = e.x, this.y = e.y, this.z = e.z, this.w = e.w !== void 0 ? e.w : 1, this;
  },
  add: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector4: .add() now only accepts one argument. Use .addVectors( a, b ) instead."), this.addVectors(e, n)) : (this.x += e.x, this.y += e.y, this.z += e.z, this.w += e.w, this);
  },
  addScalar: function(e) {
    return this.x += e, this.y += e, this.z += e, this.w += e, this;
  },
  addVectors: function(e, n) {
    return this.x = e.x + n.x, this.y = e.y + n.y, this.z = e.z + n.z, this.w = e.w + n.w, this;
  },
  addScaledVector: function(e, n) {
    return this.x += e.x * n, this.y += e.y * n, this.z += e.z * n, this.w += e.w * n, this;
  },
  sub: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector4: .sub() now only accepts one argument. Use .subVectors( a, b ) instead."), this.subVectors(e, n)) : (this.x -= e.x, this.y -= e.y, this.z -= e.z, this.w -= e.w, this);
  },
  subScalar: function(e) {
    return this.x -= e, this.y -= e, this.z -= e, this.w -= e, this;
  },
  subVectors: function(e, n) {
    return this.x = e.x - n.x, this.y = e.y - n.y, this.z = e.z - n.z, this.w = e.w - n.w, this;
  },
  multiplyScalar: function(e) {
    return this.x *= e, this.y *= e, this.z *= e, this.w *= e, this;
  },
  applyMatrix4: function(e) {
    const n = this.x, t = this.y, i = this.z, r = this.w, a = e.elements;
    return this.x = a[0] * n + a[4] * t + a[8] * i + a[12] * r, this.y = a[1] * n + a[5] * t + a[9] * i + a[13] * r, this.z = a[2] * n + a[6] * t + a[10] * i + a[14] * r, this.w = a[3] * n + a[7] * t + a[11] * i + a[15] * r, this;
  },
  divideScalar: function(e) {
    return this.multiplyScalar(1 / e);
  },
  setAxisAngleFromQuaternion: function(e) {
    this.w = 2 * Math.acos(e.w);
    const n = Math.sqrt(1 - e.w * e.w);
    return n < 1e-4 ? (this.x = 1, this.y = 0, this.z = 0) : (this.x = e.x / n, this.y = e.y / n, this.z = e.z / n), this;
  },
  setAxisAngleFromRotationMatrix: function(e) {
    let n, t, i, r;
    const u = e.elements, l = u[0], f = u[4], m = u[8], h = u[1], p = u[5], _ = u[9], v = u[2], S = u[6], D = u[10];
    if (Math.abs(f - h) < 0.01 && Math.abs(m - v) < 0.01 && Math.abs(_ - S) < 0.01) {
      if (Math.abs(f + h) < 0.1 && Math.abs(m + v) < 0.1 && Math.abs(_ + S) < 0.1 && Math.abs(l + p + D - 3) < 0.1)
        return this.set(1, 0, 0, 0), this;
      n = Math.PI;
      const T = (l + 1) / 2, F = (p + 1) / 2, E = (D + 1) / 2, A = (f + h) / 4, L = (m + v) / 4, I = (_ + S) / 4;
      return T > F && T > E ? T < 0.01 ? (t = 0, i = 0.707106781, r = 0.707106781) : (t = Math.sqrt(T), i = A / t, r = L / t) : F > E ? F < 0.01 ? (t = 0.707106781, i = 0, r = 0.707106781) : (i = Math.sqrt(F), t = A / i, r = I / i) : E < 0.01 ? (t = 0.707106781, i = 0.707106781, r = 0) : (r = Math.sqrt(E), t = L / r, i = I / r), this.set(t, i, r, n), this;
    }
    let w = Math.sqrt((S - _) * (S - _) + (m - v) * (m - v) + (h - f) * (h - f));
    return Math.abs(w) < 1e-3 && (w = 1), this.x = (S - _) / w, this.y = (m - v) / w, this.z = (h - f) / w, this.w = Math.acos((l + p + D - 1) / 2), this;
  },
  min: function(e) {
    return this.x = Math.min(this.x, e.x), this.y = Math.min(this.y, e.y), this.z = Math.min(this.z, e.z), this.w = Math.min(this.w, e.w), this;
  },
  max: function(e) {
    return this.x = Math.max(this.x, e.x), this.y = Math.max(this.y, e.y), this.z = Math.max(this.z, e.z), this.w = Math.max(this.w, e.w), this;
  },
  clamp: function(e, n) {
    return this.x = Math.max(e.x, Math.min(n.x, this.x)), this.y = Math.max(e.y, Math.min(n.y, this.y)), this.z = Math.max(e.z, Math.min(n.z, this.z)), this.w = Math.max(e.w, Math.min(n.w, this.w)), this;
  },
  clampScalar: function(e, n) {
    return this.x = Math.max(e, Math.min(n, this.x)), this.y = Math.max(e, Math.min(n, this.y)), this.z = Math.max(e, Math.min(n, this.z)), this.w = Math.max(e, Math.min(n, this.w)), this;
  },
  clampLength: function(e, n) {
    const t = this.length();
    return this.divideScalar(t || 1).multiplyScalar(Math.max(e, Math.min(n, t)));
  },
  floor: function() {
    return this.x = Math.floor(this.x), this.y = Math.floor(this.y), this.z = Math.floor(this.z), this.w = Math.floor(this.w), this;
  },
  ceil: function() {
    return this.x = Math.ceil(this.x), this.y = Math.ceil(this.y), this.z = Math.ceil(this.z), this.w = Math.ceil(this.w), this;
  },
  round: function() {
    return this.x = Math.round(this.x), this.y = Math.round(this.y), this.z = Math.round(this.z), this.w = Math.round(this.w), this;
  },
  roundToZero: function() {
    return this.x = this.x < 0 ? Math.ceil(this.x) : Math.floor(this.x), this.y = this.y < 0 ? Math.ceil(this.y) : Math.floor(this.y), this.z = this.z < 0 ? Math.ceil(this.z) : Math.floor(this.z), this.w = this.w < 0 ? Math.ceil(this.w) : Math.floor(this.w), this;
  },
  negate: function() {
    return this.x = -this.x, this.y = -this.y, this.z = -this.z, this.w = -this.w, this;
  },
  dot: function(e) {
    return this.x * e.x + this.y * e.y + this.z * e.z + this.w * e.w;
  },
  lengthSq: function() {
    return this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w;
  },
  length: function() {
    return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w);
  },
  manhattanLength: function() {
    return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z) + Math.abs(this.w);
  },
  normalize: function() {
    return this.divideScalar(this.length() || 1);
  },
  setLength: function(e) {
    return this.normalize().multiplyScalar(e);
  },
  lerp: function(e, n) {
    return this.x += (e.x - this.x) * n, this.y += (e.y - this.y) * n, this.z += (e.z - this.z) * n, this.w += (e.w - this.w) * n, this;
  },
  lerpVectors: function(e, n, t) {
    return this.x = e.x + (n.x - e.x) * t, this.y = e.y + (n.y - e.y) * t, this.z = e.z + (n.z - e.z) * t, this.w = e.w + (n.w - e.w) * t, this;
  },
  equals: function(e) {
    return e.x === this.x && e.y === this.y && e.z === this.z && e.w === this.w;
  },
  fromArray: function(e, n) {
    return n === void 0 && (n = 0), this.x = e[n], this.y = e[n + 1], this.z = e[n + 2], this.w = e[n + 3], this;
  },
  toArray: function(e, n) {
    return e === void 0 && (e = []), n === void 0 && (n = 0), e[n] = this.x, e[n + 1] = this.y, e[n + 2] = this.z, e[n + 3] = this.w, e;
  },
  fromBufferAttribute: function(e, n, t) {
    return t !== void 0 && console.warn("THREE.Vector4: offset has been removed from .fromBufferAttribute()."), this.x = e.getX(n), this.y = e.getY(n), this.z = e.getZ(n), this.w = e.getW(n), this;
  },
  random: function() {
    return this.x = Math.random(), this.y = Math.random(), this.z = Math.random(), this.w = Math.random(), this;
  }
});
function xs(e, n, t) {
  this.width = e, this.height = n, this.scissor = new In(0, 0, e, n), this.scissorTest = !1, this.viewport = new In(0, 0, e, n), t = t || {}, this.texture = new Fn(void 0, t.mapping, t.wrapS, t.wrapT, t.magFilter, t.minFilter, t.format, t.type, t.anisotropy, t.encoding), this.texture.image = {}, this.texture.image.width = e, this.texture.image.height = n, this.texture.generateMipmaps = t.generateMipmaps !== void 0 ? t.generateMipmaps : !1, this.texture.minFilter = t.minFilter !== void 0 ? t.minFilter : Li, this.depthBuffer = t.depthBuffer !== void 0 ? t.depthBuffer : !0, this.stencilBuffer = t.stencilBuffer !== void 0 ? t.stencilBuffer : !0, this.depthTexture = t.depthTexture !== void 0 ? t.depthTexture : null;
}
xs.prototype = Object.assign(Object.create(Fr.prototype), {
  constructor: xs,
  isWebGLRenderTarget: !0,
  setSize: function(e, n) {
    (this.width !== e || this.height !== n) && (this.width = e, this.height = n, this.texture.image.width = e, this.texture.image.height = n, this.dispose()), this.viewport.set(0, 0, e, n), this.scissor.set(0, 0, e, n);
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.width = e.width, this.height = e.height, this.viewport.copy(e.viewport), this.texture = e.texture.clone(), this.depthBuffer = e.depthBuffer, this.stencilBuffer = e.stencilBuffer, this.depthTexture = e.depthTexture, this;
  },
  dispose: function() {
    this.dispatchEvent({ type: "dispose" });
  }
});
function lw(e, n, t) {
  xs.call(this, e, n, t), this.samples = 4;
}
lw.prototype = Object.assign(Object.create(xs.prototype), {
  constructor: lw,
  isWebGLMultisampleRenderTarget: !0,
  copy: function(e) {
    return xs.prototype.copy.call(this, e), this.samples = e.samples, this;
  }
});
function yi(e = 0, n = 0, t = 0, i = 1) {
  this._x = e, this._y = n, this._z = t, this._w = i;
}
Object.assign(yi, {
  slerp: function(e, n, t, i) {
    return t.copy(e).slerp(n, i);
  },
  slerpFlat: function(e, n, t, i, r, a, c) {
    let u = t[i + 0], l = t[i + 1], f = t[i + 2], m = t[i + 3];
    const h = r[a + 0], p = r[a + 1], _ = r[a + 2], v = r[a + 3];
    if (m !== v || u !== h || l !== p || f !== _) {
      let S = 1 - c, D = u * h + l * p + f * _ + m * v, w = D >= 0 ? 1 : -1, T = 1 - D * D;
      if (T > Number.EPSILON) {
        const E = Math.sqrt(T), A = Math.atan2(E, D * w);
        S = Math.sin(S * A) / E, c = Math.sin(c * A) / E;
      }
      const F = c * w;
      if (u = u * S + h * F, l = l * S + p * F, f = f * S + _ * F, m = m * S + v * F, S === 1 - c) {
        const E = 1 / Math.sqrt(u * u + l * l + f * f + m * m);
        u *= E, l *= E, f *= E, m *= E;
      }
    }
    e[n] = u, e[n + 1] = l, e[n + 2] = f, e[n + 3] = m;
  },
  multiplyQuaternionsFlat: function(e, n, t, i, r, a) {
    const c = t[i], u = t[i + 1], l = t[i + 2], f = t[i + 3], m = r[a], h = r[a + 1], p = r[a + 2], _ = r[a + 3];
    return e[n] = c * _ + f * m + u * p - l * h, e[n + 1] = u * _ + f * h + l * m - c * p, e[n + 2] = l * _ + f * p + c * h - u * m, e[n + 3] = f * _ - c * m - u * h - l * p, e;
  }
});
Object.defineProperties(yi.prototype, {
  x: {
    get: function() {
      return this._x;
    },
    set: function(e) {
      this._x = e, this._onChangeCallback();
    }
  },
  y: {
    get: function() {
      return this._y;
    },
    set: function(e) {
      this._y = e, this._onChangeCallback();
    }
  },
  z: {
    get: function() {
      return this._z;
    },
    set: function(e) {
      this._z = e, this._onChangeCallback();
    }
  },
  w: {
    get: function() {
      return this._w;
    },
    set: function(e) {
      this._w = e, this._onChangeCallback();
    }
  }
});
Object.assign(yi.prototype, {
  isQuaternion: !0,
  set: function(e, n, t, i) {
    return this._x = e, this._y = n, this._z = t, this._w = i, this._onChangeCallback(), this;
  },
  clone: function() {
    return new this.constructor(this._x, this._y, this._z, this._w);
  },
  copy: function(e) {
    return this._x = e.x, this._y = e.y, this._z = e.z, this._w = e.w, this._onChangeCallback(), this;
  },
  setFromEuler: function(e, n) {
    if (!(e && e.isEuler))
      throw new Error("THREE.Quaternion: .setFromEuler() now expects an Euler rotation rather than a Vector3 and order.");
    const t = e._x, i = e._y, r = e._z, a = e.order, c = Math.cos, u = Math.sin, l = c(t / 2), f = c(i / 2), m = c(r / 2), h = u(t / 2), p = u(i / 2), _ = u(r / 2);
    switch (a) {
      case "XYZ":
        this._x = h * f * m + l * p * _, this._y = l * p * m - h * f * _, this._z = l * f * _ + h * p * m, this._w = l * f * m - h * p * _;
        break;
      case "YXZ":
        this._x = h * f * m + l * p * _, this._y = l * p * m - h * f * _, this._z = l * f * _ - h * p * m, this._w = l * f * m + h * p * _;
        break;
      case "ZXY":
        this._x = h * f * m - l * p * _, this._y = l * p * m + h * f * _, this._z = l * f * _ + h * p * m, this._w = l * f * m - h * p * _;
        break;
      case "ZYX":
        this._x = h * f * m - l * p * _, this._y = l * p * m + h * f * _, this._z = l * f * _ - h * p * m, this._w = l * f * m + h * p * _;
        break;
      case "YZX":
        this._x = h * f * m + l * p * _, this._y = l * p * m + h * f * _, this._z = l * f * _ - h * p * m, this._w = l * f * m - h * p * _;
        break;
      case "XZY":
        this._x = h * f * m - l * p * _, this._y = l * p * m - h * f * _, this._z = l * f * _ + h * p * m, this._w = l * f * m + h * p * _;
        break;
      default:
        console.warn("THREE.Quaternion: .setFromEuler() encountered an unknown order: " + a);
    }
    return n !== !1 && this._onChangeCallback(), this;
  },
  setFromAxisAngle: function(e, n) {
    const t = n / 2, i = Math.sin(t);
    return this._x = e.x * i, this._y = e.y * i, this._z = e.z * i, this._w = Math.cos(t), this._onChangeCallback(), this;
  },
  setFromRotationMatrix: function(e) {
    const n = e.elements, t = n[0], i = n[4], r = n[8], a = n[1], c = n[5], u = n[9], l = n[2], f = n[6], m = n[10], h = t + c + m;
    if (h > 0) {
      const p = 0.5 / Math.sqrt(h + 1);
      this._w = 0.25 / p, this._x = (f - u) * p, this._y = (r - l) * p, this._z = (a - i) * p;
    } else if (t > c && t > m) {
      const p = 2 * Math.sqrt(1 + t - c - m);
      this._w = (f - u) / p, this._x = 0.25 * p, this._y = (i + a) / p, this._z = (r + l) / p;
    } else if (c > m) {
      const p = 2 * Math.sqrt(1 + c - t - m);
      this._w = (r - l) / p, this._x = (i + a) / p, this._y = 0.25 * p, this._z = (u + f) / p;
    } else {
      const p = 2 * Math.sqrt(1 + m - t - c);
      this._w = (a - i) / p, this._x = (r + l) / p, this._y = (u + f) / p, this._z = 0.25 * p;
    }
    return this._onChangeCallback(), this;
  },
  setFromUnitVectors: function(e, n) {
    let i = e.dot(n) + 1;
    return i < 1e-6 ? (i = 0, Math.abs(e.x) > Math.abs(e.z) ? (this._x = -e.y, this._y = e.x, this._z = 0, this._w = i) : (this._x = 0, this._y = -e.z, this._z = e.y, this._w = i)) : (this._x = e.y * n.z - e.z * n.y, this._y = e.z * n.x - e.x * n.z, this._z = e.x * n.y - e.y * n.x, this._w = i), this.normalize();
  },
  angleTo: function(e) {
    return 2 * Math.acos(Math.abs(un.clamp(this.dot(e), -1, 1)));
  },
  rotateTowards: function(e, n) {
    const t = this.angleTo(e);
    if (t === 0)
      return this;
    const i = Math.min(1, n / t);
    return this.slerp(e, i), this;
  },
  identity: function() {
    return this.set(0, 0, 0, 1);
  },
  inverse: function() {
    return this.conjugate();
  },
  conjugate: function() {
    return this._x *= -1, this._y *= -1, this._z *= -1, this._onChangeCallback(), this;
  },
  dot: function(e) {
    return this._x * e._x + this._y * e._y + this._z * e._z + this._w * e._w;
  },
  lengthSq: function() {
    return this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w;
  },
  length: function() {
    return Math.sqrt(this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w);
  },
  normalize: function() {
    let e = this.length();
    return e === 0 ? (this._x = 0, this._y = 0, this._z = 0, this._w = 1) : (e = 1 / e, this._x = this._x * e, this._y = this._y * e, this._z = this._z * e, this._w = this._w * e), this._onChangeCallback(), this;
  },
  multiply: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Quaternion: .multiply() now only accepts one argument. Use .multiplyQuaternions( a, b ) instead."), this.multiplyQuaternions(e, n)) : this.multiplyQuaternions(this, e);
  },
  premultiply: function(e) {
    return this.multiplyQuaternions(e, this);
  },
  multiplyQuaternions: function(e, n) {
    const t = e._x, i = e._y, r = e._z, a = e._w, c = n._x, u = n._y, l = n._z, f = n._w;
    return this._x = t * f + a * c + i * l - r * u, this._y = i * f + a * u + r * c - t * l, this._z = r * f + a * l + t * u - i * c, this._w = a * f - t * c - i * u - r * l, this._onChangeCallback(), this;
  },
  slerp: function(e, n) {
    if (n === 0)
      return this;
    if (n === 1)
      return this.copy(e);
    const t = this._x, i = this._y, r = this._z, a = this._w;
    let c = a * e._w + t * e._x + i * e._y + r * e._z;
    if (c < 0 ? (this._w = -e._w, this._x = -e._x, this._y = -e._y, this._z = -e._z, c = -c) : this.copy(e), c >= 1)
      return this._w = a, this._x = t, this._y = i, this._z = r, this;
    const u = 1 - c * c;
    if (u <= Number.EPSILON) {
      const p = 1 - n;
      return this._w = p * a + n * this._w, this._x = p * t + n * this._x, this._y = p * i + n * this._y, this._z = p * r + n * this._z, this.normalize(), this._onChangeCallback(), this;
    }
    const l = Math.sqrt(u), f = Math.atan2(l, c), m = Math.sin((1 - n) * f) / l, h = Math.sin(n * f) / l;
    return this._w = a * m + this._w * h, this._x = t * m + this._x * h, this._y = i * m + this._y * h, this._z = r * m + this._z * h, this._onChangeCallback(), this;
  },
  equals: function(e) {
    return e._x === this._x && e._y === this._y && e._z === this._z && e._w === this._w;
  },
  fromArray: function(e, n) {
    return n === void 0 && (n = 0), this._x = e[n], this._y = e[n + 1], this._z = e[n + 2], this._w = e[n + 3], this._onChangeCallback(), this;
  },
  toArray: function(e, n) {
    return e === void 0 && (e = []), n === void 0 && (n = 0), e[n] = this._x, e[n + 1] = this._y, e[n + 2] = this._z, e[n + 3] = this._w, e;
  },
  fromBufferAttribute: function(e, n) {
    return this._x = e.getX(n), this._y = e.getY(n), this._z = e.getZ(n), this._w = e.getW(n), this;
  },
  _onChange: function(e) {
    return this._onChangeCallback = e, this;
  },
  _onChangeCallback: function() {
  }
});
const nv = new ve(), cw = new yi();
function ve(e = 0, n = 0, t = 0) {
  this.x = e, this.y = n, this.z = t;
}
Object.assign(ve.prototype, {
  isVector3: !0,
  set: function(e, n, t) {
    return t === void 0 && (t = this.z), this.x = e, this.y = n, this.z = t, this;
  },
  setScalar: function(e) {
    return this.x = e, this.y = e, this.z = e, this;
  },
  setX: function(e) {
    return this.x = e, this;
  },
  setY: function(e) {
    return this.y = e, this;
  },
  setZ: function(e) {
    return this.z = e, this;
  },
  setComponent: function(e, n) {
    switch (e) {
      case 0:
        this.x = n;
        break;
      case 1:
        this.y = n;
        break;
      case 2:
        this.z = n;
        break;
      default:
        throw new Error("index is out of range: " + e);
    }
    return this;
  },
  getComponent: function(e) {
    switch (e) {
      case 0:
        return this.x;
      case 1:
        return this.y;
      case 2:
        return this.z;
      default:
        throw new Error("index is out of range: " + e);
    }
  },
  clone: function() {
    return new this.constructor(this.x, this.y, this.z);
  },
  copy: function(e) {
    return this.x = e.x, this.y = e.y, this.z = e.z, this;
  },
  add: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector3: .add() now only accepts one argument. Use .addVectors( a, b ) instead."), this.addVectors(e, n)) : (this.x += e.x, this.y += e.y, this.z += e.z, this);
  },
  addScalar: function(e) {
    return this.x += e, this.y += e, this.z += e, this;
  },
  addVectors: function(e, n) {
    return this.x = e.x + n.x, this.y = e.y + n.y, this.z = e.z + n.z, this;
  },
  addScaledVector: function(e, n) {
    return this.x += e.x * n, this.y += e.y * n, this.z += e.z * n, this;
  },
  sub: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector3: .sub() now only accepts one argument. Use .subVectors( a, b ) instead."), this.subVectors(e, n)) : (this.x -= e.x, this.y -= e.y, this.z -= e.z, this);
  },
  subScalar: function(e) {
    return this.x -= e, this.y -= e, this.z -= e, this;
  },
  subVectors: function(e, n) {
    return this.x = e.x - n.x, this.y = e.y - n.y, this.z = e.z - n.z, this;
  },
  multiply: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector3: .multiply() now only accepts one argument. Use .multiplyVectors( a, b ) instead."), this.multiplyVectors(e, n)) : (this.x *= e.x, this.y *= e.y, this.z *= e.z, this);
  },
  multiplyScalar: function(e) {
    return this.x *= e, this.y *= e, this.z *= e, this;
  },
  multiplyVectors: function(e, n) {
    return this.x = e.x * n.x, this.y = e.y * n.y, this.z = e.z * n.z, this;
  },
  applyEuler: function(e) {
    return e && e.isEuler || console.error("THREE.Vector3: .applyEuler() now expects an Euler rotation rather than a Vector3 and order."), this.applyQuaternion(cw.setFromEuler(e));
  },
  applyAxisAngle: function(e, n) {
    return this.applyQuaternion(cw.setFromAxisAngle(e, n));
  },
  applyMatrix3: function(e) {
    const n = this.x, t = this.y, i = this.z, r = e.elements;
    return this.x = r[0] * n + r[3] * t + r[6] * i, this.y = r[1] * n + r[4] * t + r[7] * i, this.z = r[2] * n + r[5] * t + r[8] * i, this;
  },
  applyNormalMatrix: function(e) {
    return this.applyMatrix3(e).normalize();
  },
  applyMatrix4: function(e) {
    const n = this.x, t = this.y, i = this.z, r = e.elements, a = 1 / (r[3] * n + r[7] * t + r[11] * i + r[15]);
    return this.x = (r[0] * n + r[4] * t + r[8] * i + r[12]) * a, this.y = (r[1] * n + r[5] * t + r[9] * i + r[13]) * a, this.z = (r[2] * n + r[6] * t + r[10] * i + r[14]) * a, this;
  },
  applyQuaternion: function(e) {
    const n = this.x, t = this.y, i = this.z, r = e.x, a = e.y, c = e.z, u = e.w, l = u * n + a * i - c * t, f = u * t + c * n - r * i, m = u * i + r * t - a * n, h = -r * n - a * t - c * i;
    return this.x = l * u + h * -r + f * -c - m * -a, this.y = f * u + h * -a + m * -r - l * -c, this.z = m * u + h * -c + l * -a - f * -r, this;
  },
  project: function(e) {
    return this.applyMatrix4(e.matrixWorldInverse).applyMatrix4(e.projectionMatrix);
  },
  unproject: function(e) {
    return this.applyMatrix4(e.projectionMatrixInverse).applyMatrix4(e.matrixWorld);
  },
  transformDirection: function(e) {
    const n = this.x, t = this.y, i = this.z, r = e.elements;
    return this.x = r[0] * n + r[4] * t + r[8] * i, this.y = r[1] * n + r[5] * t + r[9] * i, this.z = r[2] * n + r[6] * t + r[10] * i, this.normalize();
  },
  divide: function(e) {
    return this.x /= e.x, this.y /= e.y, this.z /= e.z, this;
  },
  divideScalar: function(e) {
    return this.multiplyScalar(1 / e);
  },
  min: function(e) {
    return this.x = Math.min(this.x, e.x), this.y = Math.min(this.y, e.y), this.z = Math.min(this.z, e.z), this;
  },
  max: function(e) {
    return this.x = Math.max(this.x, e.x), this.y = Math.max(this.y, e.y), this.z = Math.max(this.z, e.z), this;
  },
  clamp: function(e, n) {
    return this.x = Math.max(e.x, Math.min(n.x, this.x)), this.y = Math.max(e.y, Math.min(n.y, this.y)), this.z = Math.max(e.z, Math.min(n.z, this.z)), this;
  },
  clampScalar: function(e, n) {
    return this.x = Math.max(e, Math.min(n, this.x)), this.y = Math.max(e, Math.min(n, this.y)), this.z = Math.max(e, Math.min(n, this.z)), this;
  },
  clampLength: function(e, n) {
    const t = this.length();
    return this.divideScalar(t || 1).multiplyScalar(Math.max(e, Math.min(n, t)));
  },
  floor: function() {
    return this.x = Math.floor(this.x), this.y = Math.floor(this.y), this.z = Math.floor(this.z), this;
  },
  ceil: function() {
    return this.x = Math.ceil(this.x), this.y = Math.ceil(this.y), this.z = Math.ceil(this.z), this;
  },
  round: function() {
    return this.x = Math.round(this.x), this.y = Math.round(this.y), this.z = Math.round(this.z), this;
  },
  roundToZero: function() {
    return this.x = this.x < 0 ? Math.ceil(this.x) : Math.floor(this.x), this.y = this.y < 0 ? Math.ceil(this.y) : Math.floor(this.y), this.z = this.z < 0 ? Math.ceil(this.z) : Math.floor(this.z), this;
  },
  negate: function() {
    return this.x = -this.x, this.y = -this.y, this.z = -this.z, this;
  },
  dot: function(e) {
    return this.x * e.x + this.y * e.y + this.z * e.z;
  },
  // TODO lengthSquared?
  lengthSq: function() {
    return this.x * this.x + this.y * this.y + this.z * this.z;
  },
  length: function() {
    return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);
  },
  manhattanLength: function() {
    return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z);
  },
  normalize: function() {
    return this.divideScalar(this.length() || 1);
  },
  setLength: function(e) {
    return this.normalize().multiplyScalar(e);
  },
  lerp: function(e, n) {
    return this.x += (e.x - this.x) * n, this.y += (e.y - this.y) * n, this.z += (e.z - this.z) * n, this;
  },
  lerpVectors: function(e, n, t) {
    return this.x = e.x + (n.x - e.x) * t, this.y = e.y + (n.y - e.y) * t, this.z = e.z + (n.z - e.z) * t, this;
  },
  cross: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Vector3: .cross() now only accepts one argument. Use .crossVectors( a, b ) instead."), this.crossVectors(e, n)) : this.crossVectors(this, e);
  },
  crossVectors: function(e, n) {
    const t = e.x, i = e.y, r = e.z, a = n.x, c = n.y, u = n.z;
    return this.x = i * u - r * c, this.y = r * a - t * u, this.z = t * c - i * a, this;
  },
  projectOnVector: function(e) {
    const n = e.lengthSq();
    if (n === 0)
      return this.set(0, 0, 0);
    const t = e.dot(this) / n;
    return this.copy(e).multiplyScalar(t);
  },
  projectOnPlane: function(e) {
    return nv.copy(this).projectOnVector(e), this.sub(nv);
  },
  reflect: function(e) {
    return this.sub(nv.copy(e).multiplyScalar(2 * this.dot(e)));
  },
  angleTo: function(e) {
    const n = Math.sqrt(this.lengthSq() * e.lengthSq());
    if (n === 0)
      return Math.PI / 2;
    const t = this.dot(e) / n;
    return Math.acos(un.clamp(t, -1, 1));
  },
  distanceTo: function(e) {
    return Math.sqrt(this.distanceToSquared(e));
  },
  distanceToSquared: function(e) {
    const n = this.x - e.x, t = this.y - e.y, i = this.z - e.z;
    return n * n + t * t + i * i;
  },
  manhattanDistanceTo: function(e) {
    return Math.abs(this.x - e.x) + Math.abs(this.y - e.y) + Math.abs(this.z - e.z);
  },
  setFromSpherical: function(e) {
    return this.setFromSphericalCoords(e.radius, e.phi, e.theta);
  },
  setFromSphericalCoords: function(e, n, t) {
    const i = Math.sin(n) * e;
    return this.x = i * Math.sin(t), this.y = Math.cos(n) * e, this.z = i * Math.cos(t), this;
  },
  setFromCylindrical: function(e) {
    return this.setFromCylindricalCoords(e.radius, e.theta, e.y);
  },
  setFromCylindricalCoords: function(e, n, t) {
    return this.x = e * Math.sin(n), this.y = t, this.z = e * Math.cos(n), this;
  },
  setFromMatrixPosition: function(e) {
    const n = e.elements;
    return this.x = n[12], this.y = n[13], this.z = n[14], this;
  },
  setFromMatrixScale: function(e) {
    const n = this.setFromMatrixColumn(e, 0).length(), t = this.setFromMatrixColumn(e, 1).length(), i = this.setFromMatrixColumn(e, 2).length();
    return this.x = n, this.y = t, this.z = i, this;
  },
  setFromMatrixColumn: function(e, n) {
    return this.fromArray(e.elements, n * 4);
  },
  setFromMatrix3Column: function(e, n) {
    return this.fromArray(e.elements, n * 3);
  },
  equals: function(e) {
    return e.x === this.x && e.y === this.y && e.z === this.z;
  },
  fromArray: function(e, n) {
    return n === void 0 && (n = 0), this.x = e[n], this.y = e[n + 1], this.z = e[n + 2], this;
  },
  toArray: function(e, n) {
    return e === void 0 && (e = []), n === void 0 && (n = 0), e[n] = this.x, e[n + 1] = this.y, e[n + 2] = this.z, e;
  },
  fromBufferAttribute: function(e, n, t) {
    return t !== void 0 && console.warn("THREE.Vector3: offset has been removed from .fromBufferAttribute()."), this.x = e.getX(n), this.y = e.getY(n), this.z = e.getZ(n), this;
  },
  random: function() {
    return this.x = Math.random(), this.y = Math.random(), this.z = Math.random(), this;
  }
});
const Dc = new ve(), Rs = new dn(), _1 = new ve(0, 0, 0), y1 = new ve(1, 1, 1), Qr = new ve(), r_ = new ve(), rs = new ve();
function dn() {
  this.elements = [
    1,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    0,
    1
  ], arguments.length > 0 && console.error("THREE.Matrix4: the constructor no longer reads arguments. use .set() instead.");
}
Object.assign(dn.prototype, {
  isMatrix4: !0,
  set: function(e, n, t, i, r, a, c, u, l, f, m, h, p, _, v, S) {
    const D = this.elements;
    return D[0] = e, D[4] = n, D[8] = t, D[12] = i, D[1] = r, D[5] = a, D[9] = c, D[13] = u, D[2] = l, D[6] = f, D[10] = m, D[14] = h, D[3] = p, D[7] = _, D[11] = v, D[15] = S, this;
  },
  identity: function() {
    return this.set(
      1,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  clone: function() {
    return new dn().fromArray(this.elements);
  },
  copy: function(e) {
    const n = this.elements, t = e.elements;
    return n[0] = t[0], n[1] = t[1], n[2] = t[2], n[3] = t[3], n[4] = t[4], n[5] = t[5], n[6] = t[6], n[7] = t[7], n[8] = t[8], n[9] = t[9], n[10] = t[10], n[11] = t[11], n[12] = t[12], n[13] = t[13], n[14] = t[14], n[15] = t[15], this;
  },
  copyPosition: function(e) {
    const n = this.elements, t = e.elements;
    return n[12] = t[12], n[13] = t[13], n[14] = t[14], this;
  },
  extractBasis: function(e, n, t) {
    return e.setFromMatrixColumn(this, 0), n.setFromMatrixColumn(this, 1), t.setFromMatrixColumn(this, 2), this;
  },
  makeBasis: function(e, n, t) {
    return this.set(
      e.x,
      n.x,
      t.x,
      0,
      e.y,
      n.y,
      t.y,
      0,
      e.z,
      n.z,
      t.z,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  extractRotation: function(e) {
    const n = this.elements, t = e.elements, i = 1 / Dc.setFromMatrixColumn(e, 0).length(), r = 1 / Dc.setFromMatrixColumn(e, 1).length(), a = 1 / Dc.setFromMatrixColumn(e, 2).length();
    return n[0] = t[0] * i, n[1] = t[1] * i, n[2] = t[2] * i, n[3] = 0, n[4] = t[4] * r, n[5] = t[5] * r, n[6] = t[6] * r, n[7] = 0, n[8] = t[8] * a, n[9] = t[9] * a, n[10] = t[10] * a, n[11] = 0, n[12] = 0, n[13] = 0, n[14] = 0, n[15] = 1, this;
  },
  makeRotationFromEuler: function(e) {
    e && e.isEuler || console.error("THREE.Matrix4: .makeRotationFromEuler() now expects a Euler rotation rather than a Vector3 and order.");
    const n = this.elements, t = e.x, i = e.y, r = e.z, a = Math.cos(t), c = Math.sin(t), u = Math.cos(i), l = Math.sin(i), f = Math.cos(r), m = Math.sin(r);
    if (e.order === "XYZ") {
      const h = a * f, p = a * m, _ = c * f, v = c * m;
      n[0] = u * f, n[4] = -u * m, n[8] = l, n[1] = p + _ * l, n[5] = h - v * l, n[9] = -c * u, n[2] = v - h * l, n[6] = _ + p * l, n[10] = a * u;
    } else if (e.order === "YXZ") {
      const h = u * f, p = u * m, _ = l * f, v = l * m;
      n[0] = h + v * c, n[4] = _ * c - p, n[8] = a * l, n[1] = a * m, n[5] = a * f, n[9] = -c, n[2] = p * c - _, n[6] = v + h * c, n[10] = a * u;
    } else if (e.order === "ZXY") {
      const h = u * f, p = u * m, _ = l * f, v = l * m;
      n[0] = h - v * c, n[4] = -a * m, n[8] = _ + p * c, n[1] = p + _ * c, n[5] = a * f, n[9] = v - h * c, n[2] = -a * l, n[6] = c, n[10] = a * u;
    } else if (e.order === "ZYX") {
      const h = a * f, p = a * m, _ = c * f, v = c * m;
      n[0] = u * f, n[4] = _ * l - p, n[8] = h * l + v, n[1] = u * m, n[5] = v * l + h, n[9] = p * l - _, n[2] = -l, n[6] = c * u, n[10] = a * u;
    } else if (e.order === "YZX") {
      const h = a * u, p = a * l, _ = c * u, v = c * l;
      n[0] = u * f, n[4] = v - h * m, n[8] = _ * m + p, n[1] = m, n[5] = a * f, n[9] = -c * f, n[2] = -l * f, n[6] = p * m + _, n[10] = h - v * m;
    } else if (e.order === "XZY") {
      const h = a * u, p = a * l, _ = c * u, v = c * l;
      n[0] = u * f, n[4] = -m, n[8] = l * f, n[1] = h * m + v, n[5] = a * f, n[9] = p * m - _, n[2] = _ * m - p, n[6] = c * f, n[10] = v * m + h;
    }
    return n[3] = 0, n[7] = 0, n[11] = 0, n[12] = 0, n[13] = 0, n[14] = 0, n[15] = 1, this;
  },
  makeRotationFromQuaternion: function(e) {
    return this.compose(_1, e, y1);
  },
  lookAt: function(e, n, t) {
    const i = this.elements;
    return rs.subVectors(e, n), rs.lengthSq() === 0 && (rs.z = 1), rs.normalize(), Qr.crossVectors(t, rs), Qr.lengthSq() === 0 && (Math.abs(t.z) === 1 ? rs.x += 1e-4 : rs.z += 1e-4, rs.normalize(), Qr.crossVectors(t, rs)), Qr.normalize(), r_.crossVectors(rs, Qr), i[0] = Qr.x, i[4] = r_.x, i[8] = rs.x, i[1] = Qr.y, i[5] = r_.y, i[9] = rs.y, i[2] = Qr.z, i[6] = r_.z, i[10] = rs.z, this;
  },
  multiply: function(e, n) {
    return n !== void 0 ? (console.warn("THREE.Matrix4: .multiply() now only accepts one argument. Use .multiplyMatrices( a, b ) instead."), this.multiplyMatrices(e, n)) : this.multiplyMatrices(this, e);
  },
  premultiply: function(e) {
    return this.multiplyMatrices(e, this);
  },
  multiplyMatrices: function(e, n) {
    const t = e.elements, i = n.elements, r = this.elements, a = t[0], c = t[4], u = t[8], l = t[12], f = t[1], m = t[5], h = t[9], p = t[13], _ = t[2], v = t[6], S = t[10], D = t[14], w = t[3], T = t[7], F = t[11], E = t[15], A = i[0], L = i[4], I = i[8], R = i[12], N = i[1], q = i[5], ne = i[9], Q = i[13], W = i[2], te = i[6], K = i[10], pe = i[14], be = i[3], Ee = i[7], Ge = i[11], _e = i[15];
    return r[0] = a * A + c * N + u * W + l * be, r[4] = a * L + c * q + u * te + l * Ee, r[8] = a * I + c * ne + u * K + l * Ge, r[12] = a * R + c * Q + u * pe + l * _e, r[1] = f * A + m * N + h * W + p * be, r[5] = f * L + m * q + h * te + p * Ee, r[9] = f * I + m * ne + h * K + p * Ge, r[13] = f * R + m * Q + h * pe + p * _e, r[2] = _ * A + v * N + S * W + D * be, r[6] = _ * L + v * q + S * te + D * Ee, r[10] = _ * I + v * ne + S * K + D * Ge, r[14] = _ * R + v * Q + S * pe + D * _e, r[3] = w * A + T * N + F * W + E * be, r[7] = w * L + T * q + F * te + E * Ee, r[11] = w * I + T * ne + F * K + E * Ge, r[15] = w * R + T * Q + F * pe + E * _e, this;
  },
  multiplyScalar: function(e) {
    const n = this.elements;
    return n[0] *= e, n[4] *= e, n[8] *= e, n[12] *= e, n[1] *= e, n[5] *= e, n[9] *= e, n[13] *= e, n[2] *= e, n[6] *= e, n[10] *= e, n[14] *= e, n[3] *= e, n[7] *= e, n[11] *= e, n[15] *= e, this;
  },
  determinant: function() {
    const e = this.elements, n = e[0], t = e[4], i = e[8], r = e[12], a = e[1], c = e[5], u = e[9], l = e[13], f = e[2], m = e[6], h = e[10], p = e[14], _ = e[3], v = e[7], S = e[11], D = e[15];
    return _ * (+r * u * m - i * l * m - r * c * h + t * l * h + i * c * p - t * u * p) + v * (+n * u * p - n * l * h + r * a * h - i * a * p + i * l * f - r * u * f) + S * (+n * l * m - n * c * p - r * a * m + t * a * p + r * c * f - t * l * f) + D * (-i * c * f - n * u * m + n * c * h + i * a * m - t * a * h + t * u * f);
  },
  transpose: function() {
    const e = this.elements;
    let n;
    return n = e[1], e[1] = e[4], e[4] = n, n = e[2], e[2] = e[8], e[8] = n, n = e[6], e[6] = e[9], e[9] = n, n = e[3], e[3] = e[12], e[12] = n, n = e[7], e[7] = e[13], e[13] = n, n = e[11], e[11] = e[14], e[14] = n, this;
  },
  setPosition: function(e, n, t) {
    const i = this.elements;
    return e.isVector3 ? (i[12] = e.x, i[13] = e.y, i[14] = e.z) : (i[12] = e, i[13] = n, i[14] = t), this;
  },
  getInverse: function(e, n) {
    n !== void 0 && console.warn("THREE.Matrix4: .getInverse() can no longer be configured to throw on degenerate.");
    const t = this.elements, i = e.elements, r = i[0], a = i[1], c = i[2], u = i[3], l = i[4], f = i[5], m = i[6], h = i[7], p = i[8], _ = i[9], v = i[10], S = i[11], D = i[12], w = i[13], T = i[14], F = i[15], E = _ * T * h - w * v * h + w * m * S - f * T * S - _ * m * F + f * v * F, A = D * v * h - p * T * h - D * m * S + l * T * S + p * m * F - l * v * F, L = p * w * h - D * _ * h + D * f * S - l * w * S - p * f * F + l * _ * F, I = D * _ * m - p * w * m - D * f * v + l * w * v + p * f * T - l * _ * T, R = r * E + a * A + c * L + u * I;
    if (R === 0)
      return this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
    const N = 1 / R;
    return t[0] = E * N, t[1] = (w * v * u - _ * T * u - w * c * S + a * T * S + _ * c * F - a * v * F) * N, t[2] = (f * T * u - w * m * u + w * c * h - a * T * h - f * c * F + a * m * F) * N, t[3] = (_ * m * u - f * v * u - _ * c * h + a * v * h + f * c * S - a * m * S) * N, t[4] = A * N, t[5] = (p * T * u - D * v * u + D * c * S - r * T * S - p * c * F + r * v * F) * N, t[6] = (D * m * u - l * T * u - D * c * h + r * T * h + l * c * F - r * m * F) * N, t[7] = (l * v * u - p * m * u + p * c * h - r * v * h - l * c * S + r * m * S) * N, t[8] = L * N, t[9] = (D * _ * u - p * w * u - D * a * S + r * w * S + p * a * F - r * _ * F) * N, t[10] = (l * w * u - D * f * u + D * a * h - r * w * h - l * a * F + r * f * F) * N, t[11] = (p * f * u - l * _ * u - p * a * h + r * _ * h + l * a * S - r * f * S) * N, t[12] = I * N, t[13] = (p * w * c - D * _ * c + D * a * v - r * w * v - p * a * T + r * _ * T) * N, t[14] = (D * f * c - l * w * c - D * a * m + r * w * m + l * a * T - r * f * T) * N, t[15] = (l * _ * c - p * f * c + p * a * m - r * _ * m - l * a * v + r * f * v) * N, this;
  },
  scale: function(e) {
    const n = this.elements, t = e.x, i = e.y, r = e.z;
    return n[0] *= t, n[4] *= i, n[8] *= r, n[1] *= t, n[5] *= i, n[9] *= r, n[2] *= t, n[6] *= i, n[10] *= r, n[3] *= t, n[7] *= i, n[11] *= r, this;
  },
  getMaxScaleOnAxis: function() {
    const e = this.elements, n = e[0] * e[0] + e[1] * e[1] + e[2] * e[2], t = e[4] * e[4] + e[5] * e[5] + e[6] * e[6], i = e[8] * e[8] + e[9] * e[9] + e[10] * e[10];
    return Math.sqrt(Math.max(n, t, i));
  },
  makeTranslation: function(e, n, t) {
    return this.set(
      1,
      0,
      0,
      e,
      0,
      1,
      0,
      n,
      0,
      0,
      1,
      t,
      0,
      0,
      0,
      1
    ), this;
  },
  makeRotationX: function(e) {
    const n = Math.cos(e), t = Math.sin(e);
    return this.set(
      1,
      0,
      0,
      0,
      0,
      n,
      -t,
      0,
      0,
      t,
      n,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  makeRotationY: function(e) {
    const n = Math.cos(e), t = Math.sin(e);
    return this.set(
      n,
      0,
      t,
      0,
      0,
      1,
      0,
      0,
      -t,
      0,
      n,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  makeRotationZ: function(e) {
    const n = Math.cos(e), t = Math.sin(e);
    return this.set(
      n,
      -t,
      0,
      0,
      t,
      n,
      0,
      0,
      0,
      0,
      1,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  makeRotationAxis: function(e, n) {
    const t = Math.cos(n), i = Math.sin(n), r = 1 - t, a = e.x, c = e.y, u = e.z, l = r * a, f = r * c;
    return this.set(
      l * a + t,
      l * c - i * u,
      l * u + i * c,
      0,
      l * c + i * u,
      f * c + t,
      f * u - i * a,
      0,
      l * u - i * c,
      f * u + i * a,
      r * u * u + t,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  makeScale: function(e, n, t) {
    return this.set(
      e,
      0,
      0,
      0,
      0,
      n,
      0,
      0,
      0,
      0,
      t,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  makeShear: function(e, n, t) {
    return this.set(
      1,
      n,
      t,
      0,
      e,
      1,
      t,
      0,
      e,
      n,
      1,
      0,
      0,
      0,
      0,
      1
    ), this;
  },
  compose: function(e, n, t) {
    const i = this.elements, r = n._x, a = n._y, c = n._z, u = n._w, l = r + r, f = a + a, m = c + c, h = r * l, p = r * f, _ = r * m, v = a * f, S = a * m, D = c * m, w = u * l, T = u * f, F = u * m, E = t.x, A = t.y, L = t.z;
    return i[0] = (1 - (v + D)) * E, i[1] = (p + F) * E, i[2] = (_ - T) * E, i[3] = 0, i[4] = (p - F) * A, i[5] = (1 - (h + D)) * A, i[6] = (S + w) * A, i[7] = 0, i[8] = (_ + T) * L, i[9] = (S - w) * L, i[10] = (1 - (h + v)) * L, i[11] = 0, i[12] = e.x, i[13] = e.y, i[14] = e.z, i[15] = 1, this;
  },
  decompose: function(e, n, t) {
    const i = this.elements;
    let r = Dc.set(i[0], i[1], i[2]).length(), a = Dc.set(i[4], i[5], i[6]).length(), c = Dc.set(i[8], i[9], i[10]).length();
    this.determinant() < 0 && (r = -r), e.x = i[12], e.y = i[13], e.z = i[14], Rs.copy(this);
    const l = 1 / r, f = 1 / a, m = 1 / c;
    return Rs.elements[0] *= l, Rs.elements[1] *= l, Rs.elements[2] *= l, Rs.elements[4] *= f, Rs.elements[5] *= f, Rs.elements[6] *= f, Rs.elements[8] *= m, Rs.elements[9] *= m, Rs.elements[10] *= m, n.setFromRotationMatrix(Rs), t.x = r, t.y = a, t.z = c, this;
  },
  makePerspective: function(e, n, t, i, r, a) {
    a === void 0 && console.warn("THREE.Matrix4: .makePerspective() has been redefined and has a new signature. Please check the docs.");
    const c = this.elements, u = 2 * r / (n - e), l = 2 * r / (t - i), f = (n + e) / (n - e), m = (t + i) / (t - i), h = -(a + r) / (a - r), p = -2 * a * r / (a - r);
    return c[0] = u, c[4] = 0, c[8] = f, c[12] = 0, c[1] = 0, c[5] = l, c[9] = m, c[13] = 0, c[2] = 0, c[6] = 0, c[10] = h, c[14] = p, c[3] = 0, c[7] = 0, c[11] = -1, c[15] = 0, this;
  },
  makeOrthographic: function(e, n, t, i, r, a) {
    const c = this.elements, u = 1 / (n - e), l = 1 / (t - i), f = 1 / (a - r), m = (n + e) * u, h = (t + i) * l, p = (a + r) * f;
    return c[0] = 2 * u, c[4] = 0, c[8] = 0, c[12] = -m, c[1] = 0, c[5] = 2 * l, c[9] = 0, c[13] = -h, c[2] = 0, c[6] = 0, c[10] = -2 * f, c[14] = -p, c[3] = 0, c[7] = 0, c[11] = 0, c[15] = 1, this;
  },
  equals: function(e) {
    const n = this.elements, t = e.elements;
    for (let i = 0; i < 16; i++)
      if (n[i] !== t[i])
        return !1;
    return !0;
  },
  fromArray: function(e, n) {
    n === void 0 && (n = 0);
    for (let t = 0; t < 16; t++)
      this.elements[t] = e[t + n];
    return this;
  },
  toArray: function(e, n) {
    e === void 0 && (e = []), n === void 0 && (n = 0);
    const t = this.elements;
    return e[n] = t[0], e[n + 1] = t[1], e[n + 2] = t[2], e[n + 3] = t[3], e[n + 4] = t[4], e[n + 5] = t[5], e[n + 6] = t[6], e[n + 7] = t[7], e[n + 8] = t[8], e[n + 9] = t[9], e[n + 10] = t[10], e[n + 11] = t[11], e[n + 12] = t[12], e[n + 13] = t[13], e[n + 14] = t[14], e[n + 15] = t[15], e;
  }
});
const uw = new dn(), dw = new yi();
function Pu(e = 0, n = 0, t = 0, i = Pu.DefaultOrder) {
  this._x = e, this._y = n, this._z = t, this._order = i;
}
Pu.RotationOrders = ["XYZ", "YZX", "ZXY", "XZY", "YXZ", "ZYX"];
Pu.DefaultOrder = "XYZ";
Object.defineProperties(Pu.prototype, {
  x: {
    get: function() {
      return this._x;
    },
    set: function(e) {
      this._x = e, this._onChangeCallback();
    }
  },
  y: {
    get: function() {
      return this._y;
    },
    set: function(e) {
      this._y = e, this._onChangeCallback();
    }
  },
  z: {
    get: function() {
      return this._z;
    },
    set: function(e) {
      this._z = e, this._onChangeCallback();
    }
  },
  order: {
    get: function() {
      return this._order;
    },
    set: function(e) {
      this._order = e, this._onChangeCallback();
    }
  }
});
Object.assign(Pu.prototype, {
  isEuler: !0,
  set: function(e, n, t, i) {
    return this._x = e, this._y = n, this._z = t, this._order = i || this._order, this._onChangeCallback(), this;
  },
  clone: function() {
    return new this.constructor(this._x, this._y, this._z, this._order);
  },
  copy: function(e) {
    return this._x = e._x, this._y = e._y, this._z = e._z, this._order = e._order, this._onChangeCallback(), this;
  },
  setFromRotationMatrix: function(e, n, t) {
    const i = un.clamp, r = e.elements, a = r[0], c = r[4], u = r[8], l = r[1], f = r[5], m = r[9], h = r[2], p = r[6], _ = r[10];
    switch (n = n || this._order, n) {
      case "XYZ":
        this._y = Math.asin(i(u, -1, 1)), Math.abs(u) < 0.9999999 ? (this._x = Math.atan2(-m, _), this._z = Math.atan2(-c, a)) : (this._x = Math.atan2(p, f), this._z = 0);
        break;
      case "YXZ":
        this._x = Math.asin(-i(m, -1, 1)), Math.abs(m) < 0.9999999 ? (this._y = Math.atan2(u, _), this._z = Math.atan2(l, f)) : (this._y = Math.atan2(-h, a), this._z = 0);
        break;
      case "ZXY":
        this._x = Math.asin(i(p, -1, 1)), Math.abs(p) < 0.9999999 ? (this._y = Math.atan2(-h, _), this._z = Math.atan2(-c, f)) : (this._y = 0, this._z = Math.atan2(l, a));
        break;
      case "ZYX":
        this._y = Math.asin(-i(h, -1, 1)), Math.abs(h) < 0.9999999 ? (this._x = Math.atan2(p, _), this._z = Math.atan2(l, a)) : (this._x = 0, this._z = Math.atan2(-c, f));
        break;
      case "YZX":
        this._z = Math.asin(i(l, -1, 1)), Math.abs(l) < 0.9999999 ? (this._x = Math.atan2(-m, f), this._y = Math.atan2(-h, a)) : (this._x = 0, this._y = Math.atan2(u, _));
        break;
      case "XZY":
        this._z = Math.asin(-i(c, -1, 1)), Math.abs(c) < 0.9999999 ? (this._x = Math.atan2(p, f), this._y = Math.atan2(u, a)) : (this._x = Math.atan2(-m, _), this._y = 0);
        break;
      default:
        console.warn("THREE.Euler: .setFromRotationMatrix() encountered an unknown order: " + n);
    }
    return this._order = n, t !== !1 && this._onChangeCallback(), this;
  },
  setFromQuaternion: function(e, n, t) {
    return uw.makeRotationFromQuaternion(e), this.setFromRotationMatrix(uw, n, t);
  },
  setFromVector3: function(e, n) {
    return this.set(e.x, e.y, e.z, n || this._order);
  },
  reorder: function(e) {
    return dw.setFromEuler(this), this.setFromQuaternion(dw, e);
  },
  equals: function(e) {
    return e._x === this._x && e._y === this._y && e._z === this._z && e._order === this._order;
  },
  fromArray: function(e) {
    return this._x = e[0], this._y = e[1], this._z = e[2], e[3] !== void 0 && (this._order = e[3]), this._onChangeCallback(), this;
  },
  toArray: function(e, n) {
    return e === void 0 && (e = []), n === void 0 && (n = 0), e[n] = this._x, e[n + 1] = this._y, e[n + 2] = this._z, e[n + 3] = this._order, e;
  },
  toVector3: function(e) {
    return e ? e.set(this._x, this._y, this._z) : new ve(this._x, this._y, this._z);
  },
  _onChange: function(e) {
    return this._onChangeCallback = e, this;
  },
  _onChangeCallback: function() {
  }
});
function B0() {
  this.mask = 1;
}
Object.assign(B0.prototype, {
  set: function(e) {
    this.mask = 1 << e | 0;
  },
  enable: function(e) {
    this.mask |= 1 << e | 0;
  },
  enableAll: function() {
    this.mask = -1;
  },
  toggle: function(e) {
    this.mask ^= 1 << e | 0;
  },
  disable: function(e) {
    this.mask &= ~(1 << e | 0);
  },
  disableAll: function() {
    this.mask = 0;
  },
  test: function(e) {
    return (this.mask & e.mask) !== 0;
  }
});
let v1 = 0;
const hw = new ve(), kc = new yi(), Mr = new dn(), o_ = new ve(), lm = new ve(), w1 = new ve(), x1 = new yi(), fw = new ve(1, 0, 0), pw = new ve(0, 1, 0), mw = new ve(0, 0, 1), b1 = { type: "added" }, M1 = { type: "removed" };
function Ft() {
  Object.defineProperty(this, "id", { value: v1++ }), this.uuid = un.generateUUID(), this.name = "", this.type = "Object3D", this.parent = null, this.children = [], this.up = Ft.DefaultUp.clone();
  const e = new ve(), n = new Pu(), t = new yi(), i = new ve(1, 1, 1);
  function r() {
    t.setFromEuler(n, !1);
  }
  function a() {
    n.setFromQuaternion(t, void 0, !1);
  }
  n._onChange(r), t._onChange(a), Object.defineProperties(this, {
    position: {
      configurable: !0,
      enumerable: !0,
      value: e
    },
    rotation: {
      configurable: !0,
      enumerable: !0,
      value: n
    },
    quaternion: {
      configurable: !0,
      enumerable: !0,
      value: t
    },
    scale: {
      configurable: !0,
      enumerable: !0,
      value: i
    },
    modelViewMatrix: {
      value: new dn()
    },
    normalMatrix: {
      value: new Bi()
    }
  }), this.matrix = new dn(), this.matrixWorld = new dn(), this.matrixAutoUpdate = Ft.DefaultMatrixAutoUpdate, this.matrixWorldNeedsUpdate = !1, this.layers = new B0(), this.visible = !0, this.castShadow = !1, this.receiveShadow = !1, this.frustumCulled = !0, this.renderOrder = 0, this.userData = {};
}
Ft.DefaultUp = new ve(0, 1, 0);
Ft.DefaultMatrixAutoUpdate = !0;
Ft.prototype = Object.assign(Object.create(Fr.prototype), {
  constructor: Ft,
  isObject3D: !0,
  onBeforeRender: function() {
  },
  onAfterRender: function() {
  },
  applyMatrix4: function(e) {
    this.matrixAutoUpdate && this.updateMatrix(), this.matrix.premultiply(e), this.matrix.decompose(this.position, this.quaternion, this.scale);
  },
  applyQuaternion: function(e) {
    return this.quaternion.premultiply(e), this;
  },
  setRotationFromAxisAngle: function(e, n) {
    this.quaternion.setFromAxisAngle(e, n);
  },
  setRotationFromEuler: function(e) {
    this.quaternion.setFromEuler(e, !0);
  },
  setRotationFromMatrix: function(e) {
    this.quaternion.setFromRotationMatrix(e);
  },
  setRotationFromQuaternion: function(e) {
    this.quaternion.copy(e);
  },
  rotateOnAxis: function(e, n) {
    return kc.setFromAxisAngle(e, n), this.quaternion.multiply(kc), this;
  },
  rotateOnWorldAxis: function(e, n) {
    return kc.setFromAxisAngle(e, n), this.quaternion.premultiply(kc), this;
  },
  rotateX: function(e) {
    return this.rotateOnAxis(fw, e);
  },
  rotateY: function(e) {
    return this.rotateOnAxis(pw, e);
  },
  rotateZ: function(e) {
    return this.rotateOnAxis(mw, e);
  },
  translateOnAxis: function(e, n) {
    return hw.copy(e).applyQuaternion(this.quaternion), this.position.add(hw.multiplyScalar(n)), this;
  },
  translateX: function(e) {
    return this.translateOnAxis(fw, e);
  },
  translateY: function(e) {
    return this.translateOnAxis(pw, e);
  },
  translateZ: function(e) {
    return this.translateOnAxis(mw, e);
  },
  localToWorld: function(e) {
    return e.applyMatrix4(this.matrixWorld);
  },
  worldToLocal: function(e) {
    return e.applyMatrix4(Mr.getInverse(this.matrixWorld));
  },
  lookAt: function(e, n, t) {
    e.isVector3 ? o_.copy(e) : o_.set(e, n, t);
    const i = this.parent;
    this.updateWorldMatrix(!0, !1), lm.setFromMatrixPosition(this.matrixWorld), this.isCamera || this.isLight ? Mr.lookAt(lm, o_, this.up) : Mr.lookAt(o_, lm, this.up), this.quaternion.setFromRotationMatrix(Mr), i && (Mr.extractRotation(i.matrixWorld), kc.setFromRotationMatrix(Mr), this.quaternion.premultiply(kc.inverse()));
  },
  add: function(e) {
    if (arguments.length > 1) {
      for (let n = 0; n < arguments.length; n++)
        this.add(arguments[n]);
      return this;
    }
    return e === this ? (console.error("THREE.Object3D.add: object can't be added as a child of itself.", e), this) : (e && e.isObject3D ? (e.parent !== null && e.parent.remove(e), e.parent = this, this.children.push(e), e.dispatchEvent(b1)) : console.error("THREE.Object3D.add: object not an instance of THREE.Object3D.", e), this);
  },
  remove: function(e) {
    if (arguments.length > 1) {
      for (let t = 0; t < arguments.length; t++)
        this.remove(arguments[t]);
      return this;
    }
    const n = this.children.indexOf(e);
    return n !== -1 && (e.parent = null, this.children.splice(n, 1), e.dispatchEvent(M1)), this;
  },
  attach: function(e) {
    return this.updateWorldMatrix(!0, !1), Mr.getInverse(this.matrixWorld), e.parent !== null && (e.parent.updateWorldMatrix(!0, !1), Mr.multiply(e.parent.matrixWorld)), e.applyMatrix4(Mr), e.updateWorldMatrix(!1, !1), this.add(e), this;
  },
  getObjectById: function(e) {
    return this.getObjectByProperty("id", e);
  },
  getObjectByName: function(e) {
    return this.getObjectByProperty("name", e);
  },
  getObjectByProperty: function(e, n) {
    if (this[e] === n)
      return this;
    for (let t = 0, i = this.children.length; t < i; t++) {
      const a = this.children[t].getObjectByProperty(e, n);
      if (a !== void 0)
        return a;
    }
  },
  getWorldPosition: function(e) {
    return e === void 0 && (console.warn("THREE.Object3D: .getWorldPosition() target is now required"), e = new ve()), this.updateMatrixWorld(!0), e.setFromMatrixPosition(this.matrixWorld);
  },
  getWorldQuaternion: function(e) {
    return e === void 0 && (console.warn("THREE.Object3D: .getWorldQuaternion() target is now required"), e = new yi()), this.updateMatrixWorld(!0), this.matrixWorld.decompose(lm, e, w1), e;
  },
  getWorldScale: function(e) {
    return e === void 0 && (console.warn("THREE.Object3D: .getWorldScale() target is now required"), e = new ve()), this.updateMatrixWorld(!0), this.matrixWorld.decompose(lm, x1, e), e;
  },
  getWorldDirection: function(e) {
    e === void 0 && (console.warn("THREE.Object3D: .getWorldDirection() target is now required"), e = new ve()), this.updateMatrixWorld(!0);
    const n = this.matrixWorld.elements;
    return e.set(n[8], n[9], n[10]).normalize();
  },
  raycast: function() {
  },
  traverse: function(e) {
    e(this);
    const n = this.children;
    for (let t = 0, i = n.length; t < i; t++)
      n[t].traverse(e);
  },
  traverseVisible: function(e) {
    if (this.visible === !1)
      return;
    e(this);
    const n = this.children;
    for (let t = 0, i = n.length; t < i; t++)
      n[t].traverseVisible(e);
  },
  traverseAncestors: function(e) {
    const n = this.parent;
    n !== null && (e(n), n.traverseAncestors(e));
  },
  updateMatrix: function() {
    this.matrix.compose(this.position, this.quaternion, this.scale), this.matrixWorldNeedsUpdate = !0;
  },
  updateMatrixWorld: function(e) {
    this.matrixAutoUpdate && this.updateMatrix(), (this.matrixWorldNeedsUpdate || e) && (this.parent === null ? this.matrixWorld.copy(this.matrix) : this.matrixWorld.multiplyMatrices(this.parent.matrixWorld, this.matrix), this.matrixWorldNeedsUpdate = !1, e = !0);
    const n = this.children;
    for (let t = 0, i = n.length; t < i; t++)
      n[t].updateMatrixWorld(e);
  },
  updateWorldMatrix: function(e, n) {
    const t = this.parent;
    if (e === !0 && t !== null && t.updateWorldMatrix(!0, !1), this.matrixAutoUpdate && this.updateMatrix(), this.parent === null ? this.matrixWorld.copy(this.matrix) : this.matrixWorld.multiplyMatrices(this.parent.matrixWorld, this.matrix), n === !0) {
      const i = this.children;
      for (let r = 0, a = i.length; r < a; r++)
        i[r].updateWorldMatrix(!1, !0);
    }
  },
  toJSON: function(e) {
    const n = e === void 0 || typeof e == "string", t = {};
    n && (e = {
      geometries: {},
      materials: {},
      textures: {},
      images: {},
      shapes: {}
    }, t.metadata = {
      version: 4.5,
      type: "Object",
      generator: "Object3D.toJSON"
    });
    const i = {};
    i.uuid = this.uuid, i.type = this.type, this.name !== "" && (i.name = this.name), this.castShadow === !0 && (i.castShadow = !0), this.receiveShadow === !0 && (i.receiveShadow = !0), this.visible === !1 && (i.visible = !1), this.frustumCulled === !1 && (i.frustumCulled = !1), this.renderOrder !== 0 && (i.renderOrder = this.renderOrder), JSON.stringify(this.userData) !== "{}" && (i.userData = this.userData), i.layers = this.layers.mask, i.matrix = this.matrix.toArray(), this.matrixAutoUpdate === !1 && (i.matrixAutoUpdate = !1), this.isInstancedMesh && (i.type = "InstancedMesh", i.count = this.count, i.instanceMatrix = this.instanceMatrix.toJSON());
    function r(c, u) {
      return c[u.uuid] === void 0 && (c[u.uuid] = u.toJSON(e)), u.uuid;
    }
    if (this.isMesh || this.isLine || this.isPoints) {
      i.geometry = r(e.geometries, this.geometry);
      const c = this.geometry.parameters;
      if (c !== void 0 && c.shapes !== void 0) {
        const u = c.shapes;
        if (Array.isArray(u))
          for (let l = 0, f = u.length; l < f; l++) {
            const m = u[l];
            r(e.shapes, m);
          }
        else
          r(e.shapes, u);
      }
    }
    if (this.material !== void 0)
      if (Array.isArray(this.material)) {
        const c = [];
        for (let u = 0, l = this.material.length; u < l; u++)
          c.push(r(e.materials, this.material[u]));
        i.material = c;
      } else
        i.material = r(e.materials, this.material);
    if (this.children.length > 0) {
      i.children = [];
      for (let c = 0; c < this.children.length; c++)
        i.children.push(this.children[c].toJSON(e).object);
    }
    if (n) {
      const c = a(e.geometries), u = a(e.materials), l = a(e.textures), f = a(e.images), m = a(e.shapes);
      c.length > 0 && (t.geometries = c), u.length > 0 && (t.materials = u), l.length > 0 && (t.textures = l), f.length > 0 && (t.images = f), m.length > 0 && (t.shapes = m);
    }
    return t.object = i, t;
    function a(c) {
      const u = [];
      for (const l in c) {
        const f = c[l];
        delete f.metadata, u.push(f);
      }
      return u;
    }
  },
  clone: function(e) {
    return new this.constructor().copy(this, e);
  },
  copy: function(e, n) {
    if (n === void 0 && (n = !0), this.name = e.name, this.up.copy(e.up), this.position.copy(e.position), this.rotation.order = e.rotation.order, this.quaternion.copy(e.quaternion), this.scale.copy(e.scale), this.matrix.copy(e.matrix), this.matrixWorld.copy(e.matrixWorld), this.matrixAutoUpdate = e.matrixAutoUpdate, this.matrixWorldNeedsUpdate = e.matrixWorldNeedsUpdate, this.layers.mask = e.layers.mask, this.visible = e.visible, this.castShadow = e.castShadow, this.receiveShadow = e.receiveShadow, this.frustumCulled = e.frustumCulled, this.renderOrder = e.renderOrder, this.userData = JSON.parse(JSON.stringify(e.userData)), n === !0)
      for (let t = 0; t < e.children.length; t++) {
        const i = e.children[t];
        this.add(i.clone());
      }
    return this;
  }
});
function Cm() {
  Ft.call(this), this.type = "Scene", this.background = null, this.environment = null, this.fog = null, this.overrideMaterial = null, this.autoUpdate = !0, typeof __THREE_DEVTOOLS__ < "u" && __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent("observe", { detail: this }));
}
Cm.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: Cm,
  isScene: !0,
  copy: function(e, n) {
    return Ft.prototype.copy.call(this, e, n), e.background !== null && (this.background = e.background.clone()), e.environment !== null && (this.environment = e.environment.clone()), e.fog !== null && (this.fog = e.fog.clone()), e.overrideMaterial !== null && (this.overrideMaterial = e.overrideMaterial.clone()), this.autoUpdate = e.autoUpdate, this.matrixAutoUpdate = e.matrixAutoUpdate, this;
  },
  toJSON: function(e) {
    const n = Ft.prototype.toJSON.call(this, e);
    return this.background !== null && (n.object.background = this.background.toJSON(e)), this.environment !== null && (n.object.environment = this.environment.toJSON(e)), this.fog !== null && (n.object.fog = this.fog.toJSON()), n;
  },
  dispose: function() {
    this.dispatchEvent({ type: "dispose" });
  }
});
const Tr = [
  new ve(),
  new ve(),
  new ve(),
  new ve(),
  new ve(),
  new ve(),
  new ve(),
  new ve()
], cm = new ve(), iv = new mr(), Oc = new ve(), Fc = new ve(), Rc = new ve(), Zr = new ve(), eo = new ve(), sa = new ve(), um = new ve(), a_ = new ve(), l_ = new ve(), ra = new ve();
function mr(e, n) {
  this.min = e !== void 0 ? e : new ve(1 / 0, 1 / 0, 1 / 0), this.max = n !== void 0 ? n : new ve(-1 / 0, -1 / 0, -1 / 0);
}
Object.assign(mr.prototype, {
  isBox3: !0,
  set: function(e, n) {
    return this.min.copy(e), this.max.copy(n), this;
  },
  setFromArray: function(e) {
    let n = 1 / 0, t = 1 / 0, i = 1 / 0, r = -1 / 0, a = -1 / 0, c = -1 / 0;
    for (let u = 0, l = e.length; u < l; u += 3) {
      const f = e[u], m = e[u + 1], h = e[u + 2];
      f < n && (n = f), m < t && (t = m), h < i && (i = h), f > r && (r = f), m > a && (a = m), h > c && (c = h);
    }
    return this.min.set(n, t, i), this.max.set(r, a, c), this;
  },
  setFromBufferAttribute: function(e) {
    let n = 1 / 0, t = 1 / 0, i = 1 / 0, r = -1 / 0, a = -1 / 0, c = -1 / 0;
    for (let u = 0, l = e.count; u < l; u++) {
      const f = e.getX(u), m = e.getY(u), h = e.getZ(u);
      f < n && (n = f), m < t && (t = m), h < i && (i = h), f > r && (r = f), m > a && (a = m), h > c && (c = h);
    }
    return this.min.set(n, t, i), this.max.set(r, a, c), this;
  },
  setFromPoints: function(e) {
    this.makeEmpty();
    for (let n = 0, t = e.length; n < t; n++)
      this.expandByPoint(e[n]);
    return this;
  },
  setFromCenterAndSize: function(e, n) {
    const t = cm.copy(n).multiplyScalar(0.5);
    return this.min.copy(e).sub(t), this.max.copy(e).add(t), this;
  },
  setFromObject: function(e) {
    return this.makeEmpty(), this.expandByObject(e);
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.min.copy(e.min), this.max.copy(e.max), this;
  },
  makeEmpty: function() {
    return this.min.x = this.min.y = this.min.z = 1 / 0, this.max.x = this.max.y = this.max.z = -1 / 0, this;
  },
  isEmpty: function() {
    return this.max.x < this.min.x || this.max.y < this.min.y || this.max.z < this.min.z;
  },
  getCenter: function(e) {
    return e === void 0 && (console.warn("THREE.Box3: .getCenter() target is now required"), e = new ve()), this.isEmpty() ? e.set(0, 0, 0) : e.addVectors(this.min, this.max).multiplyScalar(0.5);
  },
  getSize: function(e) {
    return e === void 0 && (console.warn("THREE.Box3: .getSize() target is now required"), e = new ve()), this.isEmpty() ? e.set(0, 0, 0) : e.subVectors(this.max, this.min);
  },
  expandByPoint: function(e) {
    return this.min.min(e), this.max.max(e), this;
  },
  expandByVector: function(e) {
    return this.min.sub(e), this.max.add(e), this;
  },
  expandByScalar: function(e) {
    return this.min.addScalar(-e), this.max.addScalar(e), this;
  },
  expandByObject: function(e) {
    e.updateWorldMatrix(!1, !1);
    const n = e.geometry;
    n !== void 0 && (n.boundingBox === null && n.computeBoundingBox(), iv.copy(n.boundingBox), iv.applyMatrix4(e.matrixWorld), this.union(iv));
    const t = e.children;
    for (let i = 0, r = t.length; i < r; i++)
      this.expandByObject(t[i]);
    return this;
  },
  containsPoint: function(e) {
    return !(e.x < this.min.x || e.x > this.max.x || e.y < this.min.y || e.y > this.max.y || e.z < this.min.z || e.z > this.max.z);
  },
  containsBox: function(e) {
    return this.min.x <= e.min.x && e.max.x <= this.max.x && this.min.y <= e.min.y && e.max.y <= this.max.y && this.min.z <= e.min.z && e.max.z <= this.max.z;
  },
  getParameter: function(e, n) {
    return n === void 0 && (console.warn("THREE.Box3: .getParameter() target is now required"), n = new ve()), n.set(
      (e.x - this.min.x) / (this.max.x - this.min.x),
      (e.y - this.min.y) / (this.max.y - this.min.y),
      (e.z - this.min.z) / (this.max.z - this.min.z)
    );
  },
  intersectsBox: function(e) {
    return !(e.max.x < this.min.x || e.min.x > this.max.x || e.max.y < this.min.y || e.min.y > this.max.y || e.max.z < this.min.z || e.min.z > this.max.z);
  },
  intersectsSphere: function(e) {
    return this.clampPoint(e.center, cm), cm.distanceToSquared(e.center) <= e.radius * e.radius;
  },
  intersectsPlane: function(e) {
    let n, t;
    return e.normal.x > 0 ? (n = e.normal.x * this.min.x, t = e.normal.x * this.max.x) : (n = e.normal.x * this.max.x, t = e.normal.x * this.min.x), e.normal.y > 0 ? (n += e.normal.y * this.min.y, t += e.normal.y * this.max.y) : (n += e.normal.y * this.max.y, t += e.normal.y * this.min.y), e.normal.z > 0 ? (n += e.normal.z * this.min.z, t += e.normal.z * this.max.z) : (n += e.normal.z * this.max.z, t += e.normal.z * this.min.z), n <= -e.constant && t >= -e.constant;
  },
  intersectsTriangle: function(e) {
    if (this.isEmpty())
      return !1;
    this.getCenter(um), a_.subVectors(this.max, um), Oc.subVectors(e.a, um), Fc.subVectors(e.b, um), Rc.subVectors(e.c, um), Zr.subVectors(Fc, Oc), eo.subVectors(Rc, Fc), sa.subVectors(Oc, Rc);
    let n = [
      0,
      -Zr.z,
      Zr.y,
      0,
      -eo.z,
      eo.y,
      0,
      -sa.z,
      sa.y,
      Zr.z,
      0,
      -Zr.x,
      eo.z,
      0,
      -eo.x,
      sa.z,
      0,
      -sa.x,
      -Zr.y,
      Zr.x,
      0,
      -eo.y,
      eo.x,
      0,
      -sa.y,
      sa.x,
      0
    ];
    return !sv(n, Oc, Fc, Rc, a_) || (n = [1, 0, 0, 0, 1, 0, 0, 0, 1], !sv(n, Oc, Fc, Rc, a_)) ? !1 : (l_.crossVectors(Zr, eo), n = [l_.x, l_.y, l_.z], sv(n, Oc, Fc, Rc, a_));
  },
  clampPoint: function(e, n) {
    return n === void 0 && (console.warn("THREE.Box3: .clampPoint() target is now required"), n = new ve()), n.copy(e).clamp(this.min, this.max);
  },
  distanceToPoint: function(e) {
    return cm.copy(e).clamp(this.min, this.max).sub(e).length();
  },
  getBoundingSphere: function(e) {
    return e === void 0 && console.error("THREE.Box3: .getBoundingSphere() target is now required"), this.getCenter(e.center), e.radius = this.getSize(cm).length() * 0.5, e;
  },
  intersect: function(e) {
    return this.min.max(e.min), this.max.min(e.max), this.isEmpty() && this.makeEmpty(), this;
  },
  union: function(e) {
    return this.min.min(e.min), this.max.max(e.max), this;
  },
  applyMatrix4: function(e) {
    return this.isEmpty() ? this : (Tr[0].set(this.min.x, this.min.y, this.min.z).applyMatrix4(e), Tr[1].set(this.min.x, this.min.y, this.max.z).applyMatrix4(e), Tr[2].set(this.min.x, this.max.y, this.min.z).applyMatrix4(e), Tr[3].set(this.min.x, this.max.y, this.max.z).applyMatrix4(e), Tr[4].set(this.max.x, this.min.y, this.min.z).applyMatrix4(e), Tr[5].set(this.max.x, this.min.y, this.max.z).applyMatrix4(e), Tr[6].set(this.max.x, this.max.y, this.min.z).applyMatrix4(e), Tr[7].set(this.max.x, this.max.y, this.max.z).applyMatrix4(e), this.setFromPoints(Tr), this);
  },
  translate: function(e) {
    return this.min.add(e), this.max.add(e), this;
  },
  equals: function(e) {
    return e.min.equals(this.min) && e.max.equals(this.max);
  }
});
function sv(e, n, t, i, r) {
  for (let a = 0, c = e.length - 3; a <= c; a += 3) {
    ra.fromArray(e, a);
    const u = r.x * Math.abs(ra.x) + r.y * Math.abs(ra.y) + r.z * Math.abs(ra.z), l = n.dot(ra), f = t.dot(ra), m = i.dot(ra);
    if (Math.max(-Math.max(l, f, m), Math.min(l, f, m)) > u)
      return !1;
  }
  return !0;
}
const T1 = new mr();
function Rr(e, n) {
  this.center = e !== void 0 ? e : new ve(), this.radius = n !== void 0 ? n : -1;
}
Object.assign(Rr.prototype, {
  set: function(e, n) {
    return this.center.copy(e), this.radius = n, this;
  },
  setFromPoints: function(e, n) {
    const t = this.center;
    n !== void 0 ? t.copy(n) : T1.setFromPoints(e).getCenter(t);
    let i = 0;
    for (let r = 0, a = e.length; r < a; r++)
      i = Math.max(i, t.distanceToSquared(e[r]));
    return this.radius = Math.sqrt(i), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.center.copy(e.center), this.radius = e.radius, this;
  },
  isEmpty: function() {
    return this.radius < 0;
  },
  makeEmpty: function() {
    return this.center.set(0, 0, 0), this.radius = -1, this;
  },
  containsPoint: function(e) {
    return e.distanceToSquared(this.center) <= this.radius * this.radius;
  },
  distanceToPoint: function(e) {
    return e.distanceTo(this.center) - this.radius;
  },
  intersectsSphere: function(e) {
    const n = this.radius + e.radius;
    return e.center.distanceToSquared(this.center) <= n * n;
  },
  intersectsBox: function(e) {
    return e.intersectsSphere(this);
  },
  intersectsPlane: function(e) {
    return Math.abs(e.distanceToPoint(this.center)) <= this.radius;
  },
  clampPoint: function(e, n) {
    const t = this.center.distanceToSquared(e);
    return n === void 0 && (console.warn("THREE.Sphere: .clampPoint() target is now required"), n = new ve()), n.copy(e), t > this.radius * this.radius && (n.sub(this.center).normalize(), n.multiplyScalar(this.radius).add(this.center)), n;
  },
  getBoundingBox: function(e) {
    return e === void 0 && (console.warn("THREE.Sphere: .getBoundingBox() target is now required"), e = new mr()), this.isEmpty() ? (e.makeEmpty(), e) : (e.set(this.center, this.center), e.expandByScalar(this.radius), e);
  },
  applyMatrix4: function(e) {
    return this.center.applyMatrix4(e), this.radius = this.radius * e.getMaxScaleOnAxis(), this;
  },
  translate: function(e) {
    return this.center.add(e), this;
  },
  equals: function(e) {
    return e.center.equals(this.center) && e.radius === this.radius;
  }
});
const Er = new ve(), rv = new ve(), c_ = new ve(), to = new ve(), ov = new ve(), u_ = new ve(), av = new ve();
function Au(e, n) {
  this.origin = e !== void 0 ? e : new ve(), this.direction = n !== void 0 ? n : new ve(0, 0, -1);
}
Object.assign(Au.prototype, {
  set: function(e, n) {
    return this.origin.copy(e), this.direction.copy(n), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.origin.copy(e.origin), this.direction.copy(e.direction), this;
  },
  at: function(e, n) {
    return n === void 0 && (console.warn("THREE.Ray: .at() target is now required"), n = new ve()), n.copy(this.direction).multiplyScalar(e).add(this.origin);
  },
  lookAt: function(e) {
    return this.direction.copy(e).sub(this.origin).normalize(), this;
  },
  recast: function(e) {
    return this.origin.copy(this.at(e, Er)), this;
  },
  closestPointToPoint: function(e, n) {
    n === void 0 && (console.warn("THREE.Ray: .closestPointToPoint() target is now required"), n = new ve()), n.subVectors(e, this.origin);
    const t = n.dot(this.direction);
    return t < 0 ? n.copy(this.origin) : n.copy(this.direction).multiplyScalar(t).add(this.origin);
  },
  distanceToPoint: function(e) {
    return Math.sqrt(this.distanceSqToPoint(e));
  },
  distanceSqToPoint: function(e) {
    const n = Er.subVectors(e, this.origin).dot(this.direction);
    return n < 0 ? this.origin.distanceToSquared(e) : (Er.copy(this.direction).multiplyScalar(n).add(this.origin), Er.distanceToSquared(e));
  },
  distanceSqToSegment: function(e, n, t, i) {
    rv.copy(e).add(n).multiplyScalar(0.5), c_.copy(n).sub(e).normalize(), to.copy(this.origin).sub(rv);
    const r = e.distanceTo(n) * 0.5, a = -this.direction.dot(c_), c = to.dot(this.direction), u = -to.dot(c_), l = to.lengthSq(), f = Math.abs(1 - a * a);
    let m, h, p, _;
    if (f > 0)
      if (m = a * u - c, h = a * c - u, _ = r * f, m >= 0)
        if (h >= -_)
          if (h <= _) {
            const v = 1 / f;
            m *= v, h *= v, p = m * (m + a * h + 2 * c) + h * (a * m + h + 2 * u) + l;
          } else
            h = r, m = Math.max(0, -(a * h + c)), p = -m * m + h * (h + 2 * u) + l;
        else
          h = -r, m = Math.max(0, -(a * h + c)), p = -m * m + h * (h + 2 * u) + l;
      else
        h <= -_ ? (m = Math.max(0, -(-a * r + c)), h = m > 0 ? -r : Math.min(Math.max(-r, -u), r), p = -m * m + h * (h + 2 * u) + l) : h <= _ ? (m = 0, h = Math.min(Math.max(-r, -u), r), p = h * (h + 2 * u) + l) : (m = Math.max(0, -(a * r + c)), h = m > 0 ? r : Math.min(Math.max(-r, -u), r), p = -m * m + h * (h + 2 * u) + l);
    else
      h = a > 0 ? -r : r, m = Math.max(0, -(a * h + c)), p = -m * m + h * (h + 2 * u) + l;
    return t && t.copy(this.direction).multiplyScalar(m).add(this.origin), i && i.copy(c_).multiplyScalar(h).add(rv), p;
  },
  intersectSphere: function(e, n) {
    Er.subVectors(e.center, this.origin);
    const t = Er.dot(this.direction), i = Er.dot(Er) - t * t, r = e.radius * e.radius;
    if (i > r)
      return null;
    const a = Math.sqrt(r - i), c = t - a, u = t + a;
    return c < 0 && u < 0 ? null : c < 0 ? this.at(u, n) : this.at(c, n);
  },
  intersectsSphere: function(e) {
    return this.distanceSqToPoint(e.center) <= e.radius * e.radius;
  },
  distanceToPlane: function(e) {
    const n = e.normal.dot(this.direction);
    if (n === 0)
      return e.distanceToPoint(this.origin) === 0 ? 0 : null;
    const t = -(this.origin.dot(e.normal) + e.constant) / n;
    return t >= 0 ? t : null;
  },
  intersectPlane: function(e, n) {
    const t = this.distanceToPlane(e);
    return t === null ? null : this.at(t, n);
  },
  intersectsPlane: function(e) {
    const n = e.distanceToPoint(this.origin);
    return n === 0 || e.normal.dot(this.direction) * n < 0;
  },
  intersectBox: function(e, n) {
    let t, i, r, a, c, u;
    const l = 1 / this.direction.x, f = 1 / this.direction.y, m = 1 / this.direction.z, h = this.origin;
    return l >= 0 ? (t = (e.min.x - h.x) * l, i = (e.max.x - h.x) * l) : (t = (e.max.x - h.x) * l, i = (e.min.x - h.x) * l), f >= 0 ? (r = (e.min.y - h.y) * f, a = (e.max.y - h.y) * f) : (r = (e.max.y - h.y) * f, a = (e.min.y - h.y) * f), t > a || r > i || ((r > t || t !== t) && (t = r), (a < i || i !== i) && (i = a), m >= 0 ? (c = (e.min.z - h.z) * m, u = (e.max.z - h.z) * m) : (c = (e.max.z - h.z) * m, u = (e.min.z - h.z) * m), t > u || c > i) || ((c > t || t !== t) && (t = c), (u < i || i !== i) && (i = u), i < 0) ? null : this.at(t >= 0 ? t : i, n);
  },
  intersectsBox: function(e) {
    return this.intersectBox(e, Er) !== null;
  },
  intersectTriangle: function(e, n, t, i, r) {
    ov.subVectors(n, e), u_.subVectors(t, e), av.crossVectors(ov, u_);
    let a = this.direction.dot(av), c;
    if (a > 0) {
      if (i)
        return null;
      c = 1;
    } else if (a < 0)
      c = -1, a = -a;
    else
      return null;
    to.subVectors(this.origin, e);
    const u = c * this.direction.dot(u_.crossVectors(to, u_));
    if (u < 0)
      return null;
    const l = c * this.direction.dot(ov.cross(to));
    if (l < 0 || u + l > a)
      return null;
    const f = -c * to.dot(av);
    return f < 0 ? null : this.at(f / a, r);
  },
  applyMatrix4: function(e) {
    return this.origin.applyMatrix4(e), this.direction.transformDirection(e), this;
  },
  equals: function(e) {
    return e.origin.equals(this.origin) && e.direction.equals(this.direction);
  }
});
const lv = new ve(), E1 = new ve(), S1 = new Bi();
function or(e, n) {
  this.normal = e !== void 0 ? e : new ve(1, 0, 0), this.constant = n !== void 0 ? n : 0;
}
Object.assign(or.prototype, {
  isPlane: !0,
  set: function(e, n) {
    return this.normal.copy(e), this.constant = n, this;
  },
  setComponents: function(e, n, t, i) {
    return this.normal.set(e, n, t), this.constant = i, this;
  },
  setFromNormalAndCoplanarPoint: function(e, n) {
    return this.normal.copy(e), this.constant = -n.dot(this.normal), this;
  },
  setFromCoplanarPoints: function(e, n, t) {
    const i = lv.subVectors(t, n).cross(E1.subVectors(e, n)).normalize();
    return this.setFromNormalAndCoplanarPoint(i, e), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.normal.copy(e.normal), this.constant = e.constant, this;
  },
  normalize: function() {
    const e = 1 / this.normal.length();
    return this.normal.multiplyScalar(e), this.constant *= e, this;
  },
  negate: function() {
    return this.constant *= -1, this.normal.negate(), this;
  },
  distanceToPoint: function(e) {
    return this.normal.dot(e) + this.constant;
  },
  distanceToSphere: function(e) {
    return this.distanceToPoint(e.center) - e.radius;
  },
  projectPoint: function(e, n) {
    return n === void 0 && (console.warn("THREE.Plane: .projectPoint() target is now required"), n = new ve()), n.copy(this.normal).multiplyScalar(-this.distanceToPoint(e)).add(e);
  },
  intersectLine: function(e, n) {
    n === void 0 && (console.warn("THREE.Plane: .intersectLine() target is now required"), n = new ve());
    const t = e.delta(lv), i = this.normal.dot(t);
    if (i === 0)
      return this.distanceToPoint(e.start) === 0 ? n.copy(e.start) : void 0;
    const r = -(e.start.dot(this.normal) + this.constant) / i;
    if (!(r < 0 || r > 1))
      return n.copy(t).multiplyScalar(r).add(e.start);
  },
  intersectsLine: function(e) {
    const n = this.distanceToPoint(e.start), t = this.distanceToPoint(e.end);
    return n < 0 && t > 0 || t < 0 && n > 0;
  },
  intersectsBox: function(e) {
    return e.intersectsPlane(this);
  },
  intersectsSphere: function(e) {
    return e.intersectsPlane(this);
  },
  coplanarPoint: function(e) {
    return e === void 0 && (console.warn("THREE.Plane: .coplanarPoint() target is now required"), e = new ve()), e.copy(this.normal).multiplyScalar(-this.constant);
  },
  applyMatrix4: function(e, n) {
    const t = n || S1.getNormalMatrix(e), i = this.coplanarPoint(lv).applyMatrix4(e), r = this.normal.applyMatrix3(t).normalize();
    return this.constant = -i.dot(r), this;
  },
  translate: function(e) {
    return this.constant -= e.dot(this.normal), this;
  },
  equals: function(e) {
    return e.normal.equals(this.normal) && e.constant === this.constant;
  }
});
const $s = new ve(), Cr = new ve(), cv = new ve(), Sr = new ve(), Bc = new ve(), zc = new ve(), gw = new ve(), uv = new ve(), dv = new ve(), hv = new ve();
function Ei(e, n, t) {
  this.a = e !== void 0 ? e : new ve(), this.b = n !== void 0 ? n : new ve(), this.c = t !== void 0 ? t : new ve();
}
Object.assign(Ei, {
  getNormal: function(e, n, t, i) {
    i === void 0 && (console.warn("THREE.Triangle: .getNormal() target is now required"), i = new ve()), i.subVectors(t, n), $s.subVectors(e, n), i.cross($s);
    const r = i.lengthSq();
    return r > 0 ? i.multiplyScalar(1 / Math.sqrt(r)) : i.set(0, 0, 0);
  },
  // static/instance method to calculate barycentric coordinates
  // based on: http://www.blackpawn.com/texts/pointinpoly/default.html
  getBarycoord: function(e, n, t, i, r) {
    $s.subVectors(i, n), Cr.subVectors(t, n), cv.subVectors(e, n);
    const a = $s.dot($s), c = $s.dot(Cr), u = $s.dot(cv), l = Cr.dot(Cr), f = Cr.dot(cv), m = a * l - c * c;
    if (r === void 0 && (console.warn("THREE.Triangle: .getBarycoord() target is now required"), r = new ve()), m === 0)
      return r.set(-2, -1, -1);
    const h = 1 / m, p = (l * u - c * f) * h, _ = (a * f - c * u) * h;
    return r.set(1 - p - _, _, p);
  },
  containsPoint: function(e, n, t, i) {
    return Ei.getBarycoord(e, n, t, i, Sr), Sr.x >= 0 && Sr.y >= 0 && Sr.x + Sr.y <= 1;
  },
  getUV: function(e, n, t, i, r, a, c, u) {
    return this.getBarycoord(e, n, t, i, Sr), u.set(0, 0), u.addScaledVector(r, Sr.x), u.addScaledVector(a, Sr.y), u.addScaledVector(c, Sr.z), u;
  },
  isFrontFacing: function(e, n, t, i) {
    return $s.subVectors(t, n), Cr.subVectors(e, n), $s.cross(Cr).dot(i) < 0;
  }
});
Object.assign(Ei.prototype, {
  set: function(e, n, t) {
    return this.a.copy(e), this.b.copy(n), this.c.copy(t), this;
  },
  setFromPointsAndIndices: function(e, n, t, i) {
    return this.a.copy(e[n]), this.b.copy(e[t]), this.c.copy(e[i]), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.a.copy(e.a), this.b.copy(e.b), this.c.copy(e.c), this;
  },
  getArea: function() {
    return $s.subVectors(this.c, this.b), Cr.subVectors(this.a, this.b), $s.cross(Cr).length() * 0.5;
  },
  getMidpoint: function(e) {
    return e === void 0 && (console.warn("THREE.Triangle: .getMidpoint() target is now required"), e = new ve()), e.addVectors(this.a, this.b).add(this.c).multiplyScalar(1 / 3);
  },
  getNormal: function(e) {
    return Ei.getNormal(this.a, this.b, this.c, e);
  },
  getPlane: function(e) {
    return e === void 0 && (console.warn("THREE.Triangle: .getPlane() target is now required"), e = new or()), e.setFromCoplanarPoints(this.a, this.b, this.c);
  },
  getBarycoord: function(e, n) {
    return Ei.getBarycoord(e, this.a, this.b, this.c, n);
  },
  getUV: function(e, n, t, i, r) {
    return Ei.getUV(e, this.a, this.b, this.c, n, t, i, r);
  },
  containsPoint: function(e) {
    return Ei.containsPoint(e, this.a, this.b, this.c);
  },
  isFrontFacing: function(e) {
    return Ei.isFrontFacing(this.a, this.b, this.c, e);
  },
  intersectsBox: function(e) {
    return e.intersectsTriangle(this);
  },
  closestPointToPoint: function(e, n) {
    n === void 0 && (console.warn("THREE.Triangle: .closestPointToPoint() target is now required"), n = new ve());
    const t = this.a, i = this.b, r = this.c;
    let a, c;
    Bc.subVectors(i, t), zc.subVectors(r, t), uv.subVectors(e, t);
    const u = Bc.dot(uv), l = zc.dot(uv);
    if (u <= 0 && l <= 0)
      return n.copy(t);
    dv.subVectors(e, i);
    const f = Bc.dot(dv), m = zc.dot(dv);
    if (f >= 0 && m <= f)
      return n.copy(i);
    const h = u * m - f * l;
    if (h <= 0 && u >= 0 && f <= 0)
      return a = u / (u - f), n.copy(t).addScaledVector(Bc, a);
    hv.subVectors(e, r);
    const p = Bc.dot(hv), _ = zc.dot(hv);
    if (_ >= 0 && p <= _)
      return n.copy(r);
    const v = p * l - u * _;
    if (v <= 0 && l >= 0 && _ <= 0)
      return c = l / (l - _), n.copy(t).addScaledVector(zc, c);
    const S = f * _ - p * m;
    if (S <= 0 && m - f >= 0 && p - _ >= 0)
      return gw.subVectors(r, i), c = (m - f) / (m - f + (p - _)), n.copy(i).addScaledVector(gw, c);
    const D = 1 / (S + v + h);
    return a = v * D, c = h * D, n.copy(t).addScaledVector(Bc, a).addScaledVector(zc, c);
  },
  equals: function(e) {
    return e.a.equals(this.a) && e.b.equals(this.b) && e.c.equals(this.c);
  }
});
const Ux = {
  aliceblue: 15792383,
  antiquewhite: 16444375,
  aqua: 65535,
  aquamarine: 8388564,
  azure: 15794175,
  beige: 16119260,
  bisque: 16770244,
  black: 0,
  blanchedalmond: 16772045,
  blue: 255,
  blueviolet: 9055202,
  brown: 10824234,
  burlywood: 14596231,
  cadetblue: 6266528,
  chartreuse: 8388352,
  chocolate: 13789470,
  coral: 16744272,
  cornflowerblue: 6591981,
  cornsilk: 16775388,
  crimson: 14423100,
  cyan: 65535,
  darkblue: 139,
  darkcyan: 35723,
  darkgoldenrod: 12092939,
  darkgray: 11119017,
  darkgreen: 25600,
  darkgrey: 11119017,
  darkkhaki: 12433259,
  darkmagenta: 9109643,
  darkolivegreen: 5597999,
  darkorange: 16747520,
  darkorchid: 10040012,
  darkred: 9109504,
  darksalmon: 15308410,
  darkseagreen: 9419919,
  darkslateblue: 4734347,
  darkslategray: 3100495,
  darkslategrey: 3100495,
  darkturquoise: 52945,
  darkviolet: 9699539,
  deeppink: 16716947,
  deepskyblue: 49151,
  dimgray: 6908265,
  dimgrey: 6908265,
  dodgerblue: 2003199,
  firebrick: 11674146,
  floralwhite: 16775920,
  forestgreen: 2263842,
  fuchsia: 16711935,
  gainsboro: 14474460,
  ghostwhite: 16316671,
  gold: 16766720,
  goldenrod: 14329120,
  gray: 8421504,
  green: 32768,
  greenyellow: 11403055,
  grey: 8421504,
  honeydew: 15794160,
  hotpink: 16738740,
  indianred: 13458524,
  indigo: 4915330,
  ivory: 16777200,
  khaki: 15787660,
  lavender: 15132410,
  lavenderblush: 16773365,
  lawngreen: 8190976,
  lemonchiffon: 16775885,
  lightblue: 11393254,
  lightcoral: 15761536,
  lightcyan: 14745599,
  lightgoldenrodyellow: 16448210,
  lightgray: 13882323,
  lightgreen: 9498256,
  lightgrey: 13882323,
  lightpink: 16758465,
  lightsalmon: 16752762,
  lightseagreen: 2142890,
  lightskyblue: 8900346,
  lightslategray: 7833753,
  lightslategrey: 7833753,
  lightsteelblue: 11584734,
  lightyellow: 16777184,
  lime: 65280,
  limegreen: 3329330,
  linen: 16445670,
  magenta: 16711935,
  maroon: 8388608,
  mediumaquamarine: 6737322,
  mediumblue: 205,
  mediumorchid: 12211667,
  mediumpurple: 9662683,
  mediumseagreen: 3978097,
  mediumslateblue: 8087790,
  mediumspringgreen: 64154,
  mediumturquoise: 4772300,
  mediumvioletred: 13047173,
  midnightblue: 1644912,
  mintcream: 16121850,
  mistyrose: 16770273,
  moccasin: 16770229,
  navajowhite: 16768685,
  navy: 128,
  oldlace: 16643558,
  olive: 8421376,
  olivedrab: 7048739,
  orange: 16753920,
  orangered: 16729344,
  orchid: 14315734,
  palegoldenrod: 15657130,
  palegreen: 10025880,
  paleturquoise: 11529966,
  palevioletred: 14381203,
  papayawhip: 16773077,
  peachpuff: 16767673,
  peru: 13468991,
  pink: 16761035,
  plum: 14524637,
  powderblue: 11591910,
  purple: 8388736,
  rebeccapurple: 6697881,
  red: 16711680,
  rosybrown: 12357519,
  royalblue: 4286945,
  saddlebrown: 9127187,
  salmon: 16416882,
  sandybrown: 16032864,
  seagreen: 3050327,
  seashell: 16774638,
  sienna: 10506797,
  silver: 12632256,
  skyblue: 8900331,
  slateblue: 6970061,
  slategray: 7372944,
  slategrey: 7372944,
  snow: 16775930,
  springgreen: 65407,
  steelblue: 4620980,
  tan: 13808780,
  teal: 32896,
  thistle: 14204888,
  tomato: 16737095,
  turquoise: 4251856,
  violet: 15631086,
  wheat: 16113331,
  white: 16777215,
  whitesmoke: 16119285,
  yellow: 16776960,
  yellowgreen: 10145074
}, Bs = { h: 0, s: 0, l: 0 }, d_ = { h: 0, s: 0, l: 0 };
function Wt(e, n, t) {
  return n === void 0 && t === void 0 ? this.set(e) : this.setRGB(e, n, t);
}
function fv(e, n, t) {
  return t < 0 && (t += 1), t > 1 && (t -= 1), t < 1 / 6 ? e + (n - e) * 6 * t : t < 1 / 2 ? n : t < 2 / 3 ? e + (n - e) * 6 * (2 / 3 - t) : e;
}
function pv(e) {
  return e < 0.04045 ? e * 0.0773993808 : Math.pow(e * 0.9478672986 + 0.0521327014, 2.4);
}
function mv(e) {
  return e < 31308e-7 ? e * 12.92 : 1.055 * Math.pow(e, 0.41666) - 0.055;
}
Object.assign(Wt.prototype, {
  isColor: !0,
  r: 1,
  g: 1,
  b: 1,
  set: function(e) {
    return e && e.isColor ? this.copy(e) : typeof e == "number" ? this.setHex(e) : typeof e == "string" && this.setStyle(e), this;
  },
  setScalar: function(e) {
    return this.r = e, this.g = e, this.b = e, this;
  },
  setHex: function(e) {
    return e = Math.floor(e), this.r = (e >> 16 & 255) / 255, this.g = (e >> 8 & 255) / 255, this.b = (e & 255) / 255, this;
  },
  setRGB: function(e, n, t) {
    return this.r = e, this.g = n, this.b = t, this;
  },
  setHSL: function(e, n, t) {
    if (e = un.euclideanModulo(e, 1), n = un.clamp(n, 0, 1), t = un.clamp(t, 0, 1), n === 0)
      this.r = this.g = this.b = t;
    else {
      const i = t <= 0.5 ? t * (1 + n) : t + n - t * n, r = 2 * t - i;
      this.r = fv(r, i, e + 1 / 3), this.g = fv(r, i, e), this.b = fv(r, i, e - 1 / 3);
    }
    return this;
  },
  setStyle: function(e) {
    function n(i) {
      i !== void 0 && parseFloat(i) < 1 && console.warn("THREE.Color: Alpha component of " + e + " will be ignored.");
    }
    let t;
    if (t = /^((?:rgb|hsl)a?)\(\s*([^\)]*)\)/.exec(e)) {
      let i;
      const r = t[1], a = t[2];
      switch (r) {
        case "rgb":
        case "rgba":
          if (i = /^(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*(,\s*([0-9]*\.?[0-9]+)\s*)?$/.exec(a))
            return this.r = Math.min(255, parseInt(i[1], 10)) / 255, this.g = Math.min(255, parseInt(i[2], 10)) / 255, this.b = Math.min(255, parseInt(i[3], 10)) / 255, n(i[5]), this;
          if (i = /^(\d+)\%\s*,\s*(\d+)\%\s*,\s*(\d+)\%\s*(,\s*([0-9]*\.?[0-9]+)\s*)?$/.exec(a))
            return this.r = Math.min(100, parseInt(i[1], 10)) / 100, this.g = Math.min(100, parseInt(i[2], 10)) / 100, this.b = Math.min(100, parseInt(i[3], 10)) / 100, n(i[5]), this;
          break;
        case "hsl":
        case "hsla":
          if (i = /^([0-9]*\.?[0-9]+)\s*,\s*(\d+)\%\s*,\s*(\d+)\%\s*(,\s*([0-9]*\.?[0-9]+)\s*)?$/.exec(a)) {
            const c = parseFloat(i[1]) / 360, u = parseInt(i[2], 10) / 100, l = parseInt(i[3], 10) / 100;
            return n(i[5]), this.setHSL(c, u, l);
          }
          break;
      }
    } else if (t = /^\#([A-Fa-f0-9]+)$/.exec(e)) {
      const i = t[1], r = i.length;
      if (r === 3)
        return this.r = parseInt(i.charAt(0) + i.charAt(0), 16) / 255, this.g = parseInt(i.charAt(1) + i.charAt(1), 16) / 255, this.b = parseInt(i.charAt(2) + i.charAt(2), 16) / 255, this;
      if (r === 6)
        return this.r = parseInt(i.charAt(0) + i.charAt(1), 16) / 255, this.g = parseInt(i.charAt(2) + i.charAt(3), 16) / 255, this.b = parseInt(i.charAt(4) + i.charAt(5), 16) / 255, this;
    }
    return e && e.length > 0 ? this.setColorName(e) : this;
  },
  setColorName: function(e) {
    const n = Ux[e];
    return n !== void 0 ? this.setHex(n) : console.warn("THREE.Color: Unknown color " + e), this;
  },
  clone: function() {
    return new this.constructor(this.r, this.g, this.b);
  },
  copy: function(e) {
    return this.r = e.r, this.g = e.g, this.b = e.b, this;
  },
  copyGammaToLinear: function(e, n) {
    return n === void 0 && (n = 2), this.r = Math.pow(e.r, n), this.g = Math.pow(e.g, n), this.b = Math.pow(e.b, n), this;
  },
  copyLinearToGamma: function(e, n) {
    n === void 0 && (n = 2);
    const t = n > 0 ? 1 / n : 1;
    return this.r = Math.pow(e.r, t), this.g = Math.pow(e.g, t), this.b = Math.pow(e.b, t), this;
  },
  convertGammaToLinear: function(e) {
    return this.copyGammaToLinear(this, e), this;
  },
  convertLinearToGamma: function(e) {
    return this.copyLinearToGamma(this, e), this;
  },
  copySRGBToLinear: function(e) {
    return this.r = pv(e.r), this.g = pv(e.g), this.b = pv(e.b), this;
  },
  copyLinearToSRGB: function(e) {
    return this.r = mv(e.r), this.g = mv(e.g), this.b = mv(e.b), this;
  },
  convertSRGBToLinear: function() {
    return this.copySRGBToLinear(this), this;
  },
  convertLinearToSRGB: function() {
    return this.copyLinearToSRGB(this), this;
  },
  getHex: function() {
    return this.r * 255 << 16 ^ this.g * 255 << 8 ^ this.b * 255 << 0;
  },
  getHexString: function() {
    return ("000000" + this.getHex().toString(16)).slice(-6);
  },
  getHSL: function(e) {
    e === void 0 && (console.warn("THREE.Color: .getHSL() target is now required"), e = { h: 0, s: 0, l: 0 });
    const n = this.r, t = this.g, i = this.b, r = Math.max(n, t, i), a = Math.min(n, t, i);
    let c, u;
    const l = (a + r) / 2;
    if (a === r)
      c = 0, u = 0;
    else {
      const f = r - a;
      switch (u = l <= 0.5 ? f / (r + a) : f / (2 - r - a), r) {
        case n:
          c = (t - i) / f + (t < i ? 6 : 0);
          break;
        case t:
          c = (i - n) / f + 2;
          break;
        case i:
          c = (n - t) / f + 4;
          break;
      }
      c /= 6;
    }
    return e.h = c, e.s = u, e.l = l, e;
  },
  getStyle: function() {
    return "rgb(" + (this.r * 255 | 0) + "," + (this.g * 255 | 0) + "," + (this.b * 255 | 0) + ")";
  },
  offsetHSL: function(e, n, t) {
    return this.getHSL(Bs), Bs.h += e, Bs.s += n, Bs.l += t, this.setHSL(Bs.h, Bs.s, Bs.l), this;
  },
  add: function(e) {
    return this.r += e.r, this.g += e.g, this.b += e.b, this;
  },
  addColors: function(e, n) {
    return this.r = e.r + n.r, this.g = e.g + n.g, this.b = e.b + n.b, this;
  },
  addScalar: function(e) {
    return this.r += e, this.g += e, this.b += e, this;
  },
  sub: function(e) {
    return this.r = Math.max(0, this.r - e.r), this.g = Math.max(0, this.g - e.g), this.b = Math.max(0, this.b - e.b), this;
  },
  multiply: function(e) {
    return this.r *= e.r, this.g *= e.g, this.b *= e.b, this;
  },
  multiplyScalar: function(e) {
    return this.r *= e, this.g *= e, this.b *= e, this;
  },
  lerp: function(e, n) {
    return this.r += (e.r - this.r) * n, this.g += (e.g - this.g) * n, this.b += (e.b - this.b) * n, this;
  },
  lerpHSL: function(e, n) {
    this.getHSL(Bs), e.getHSL(d_);
    const t = un.lerp(Bs.h, d_.h, n), i = un.lerp(Bs.s, d_.s, n), r = un.lerp(Bs.l, d_.l, n);
    return this.setHSL(t, i, r), this;
  },
  equals: function(e) {
    return e.r === this.r && e.g === this.g && e.b === this.b;
  },
  fromArray: function(e, n) {
    return n === void 0 && (n = 0), this.r = e[n], this.g = e[n + 1], this.b = e[n + 2], this;
  },
  toArray: function(e, n) {
    return e === void 0 && (e = []), n === void 0 && (n = 0), e[n] = this.r, e[n + 1] = this.g, e[n + 2] = this.b, e;
  },
  fromBufferAttribute: function(e, n) {
    return this.r = e.getX(n), this.g = e.getY(n), this.b = e.getZ(n), e.normalized === !0 && (this.r /= 255, this.g /= 255, this.b /= 255), this;
  },
  toJSON: function() {
    return this.getHex();
  }
});
Wt.NAMES = Ux;
function ty(e, n, t, i, r, a) {
  this.a = e, this.b = n, this.c = t, this.normal = i && i.isVector3 ? i : new ve(), this.vertexNormals = Array.isArray(i) ? i : [], this.color = r && r.isColor ? r : new Wt(), this.vertexColors = Array.isArray(r) ? r : [], this.materialIndex = a !== void 0 ? a : 0;
}
Object.assign(ty.prototype, {
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    this.a = e.a, this.b = e.b, this.c = e.c, this.normal.copy(e.normal), this.color.copy(e.color), this.materialIndex = e.materialIndex;
    for (let n = 0, t = e.vertexNormals.length; n < t; n++)
      this.vertexNormals[n] = e.vertexNormals[n].clone();
    for (let n = 0, t = e.vertexColors.length; n < t; n++)
      this.vertexColors[n] = e.vertexColors[n].clone();
    return this;
  }
});
let P1 = 0;
function rn() {
  Object.defineProperty(this, "id", { value: P1++ }), this.uuid = un.generateUUID(), this.name = "", this.type = "Material", this.fog = !0, this.blending = xm, this.side = cg, this.flatShading = !1, this.vertexColors = !1, this.opacity = 1, this.transparent = !1, this.blendSrc = kx, this.blendDst = Ox, this.blendEquation = Xc, this.blendSrcAlpha = null, this.blendDstAlpha = null, this.blendEquationAlpha = null, this.depthFunc = Ov, this.depthTest = !0, this.depthWrite = !0, this.stencilWriteMask = 255, this.stencilFunc = m1, this.stencilRef = 0, this.stencilFuncMask = 255, this.stencilFail = tv, this.stencilZFail = tv, this.stencilZPass = tv, this.stencilWrite = !1, this.clippingPlanes = null, this.clipIntersection = !1, this.clipShadows = !1, this.shadowSide = null, this.colorWrite = !0, this.precision = null, this.polygonOffset = !1, this.polygonOffsetFactor = 0, this.polygonOffsetUnits = 0, this.dithering = !1, this.alphaTest = 0, this.premultipliedAlpha = !1, this.visible = !0, this.toneMapped = !0, this.userData = {}, this.version = 0;
}
rn.prototype = Object.assign(Object.create(Fr.prototype), {
  constructor: rn,
  isMaterial: !0,
  onBeforeCompile: function() {
  },
  customProgramCacheKey: function() {
    return this.onBeforeCompile.toString();
  },
  setValues: function(e) {
    if (e !== void 0)
      for (const n in e) {
        const t = e[n];
        if (t === void 0) {
          console.warn("THREE.Material: '" + n + "' parameter is undefined.");
          continue;
        }
        if (n === "shading") {
          console.warn("THREE." + this.type + ": .shading has been removed. Use the boolean .flatShading instead."), this.flatShading = t === Dx;
          continue;
        }
        const i = this[n];
        if (i === void 0) {
          console.warn("THREE." + this.type + ": '" + n + "' is not a property of this material.");
          continue;
        }
        i && i.isColor ? i.set(t) : i && i.isVector3 && t && t.isVector3 ? i.copy(t) : this[n] = t;
      }
  },
  toJSON: function(e) {
    const n = e === void 0 || typeof e == "string";
    n && (e = {
      textures: {},
      images: {}
    });
    const t = {
      metadata: {
        version: 4.5,
        type: "Material",
        generator: "Material.toJSON"
      }
    };
    t.uuid = this.uuid, t.type = this.type, this.name !== "" && (t.name = this.name), this.color && this.color.isColor && (t.color = this.color.getHex()), this.roughness !== void 0 && (t.roughness = this.roughness), this.metalness !== void 0 && (t.metalness = this.metalness), this.sheen && this.sheen.isColor && (t.sheen = this.sheen.getHex()), this.emissive && this.emissive.isColor && (t.emissive = this.emissive.getHex()), this.emissiveIntensity && this.emissiveIntensity !== 1 && (t.emissiveIntensity = this.emissiveIntensity), this.specular && this.specular.isColor && (t.specular = this.specular.getHex()), this.shininess !== void 0 && (t.shininess = this.shininess), this.clearcoat !== void 0 && (t.clearcoat = this.clearcoat), this.clearcoatRoughness !== void 0 && (t.clearcoatRoughness = this.clearcoatRoughness), this.clearcoatMap && this.clearcoatMap.isTexture && (t.clearcoatMap = this.clearcoatMap.toJSON(e).uuid), this.clearcoatRoughnessMap && this.clearcoatRoughnessMap.isTexture && (t.clearcoatRoughnessMap = this.clearcoatRoughnessMap.toJSON(e).uuid), this.clearcoatNormalMap && this.clearcoatNormalMap.isTexture && (t.clearcoatNormalMap = this.clearcoatNormalMap.toJSON(e).uuid, t.clearcoatNormalScale = this.clearcoatNormalScale.toArray()), this.map && this.map.isTexture && (t.map = this.map.toJSON(e).uuid), this.matcap && this.matcap.isTexture && (t.matcap = this.matcap.toJSON(e).uuid), this.alphaMap && this.alphaMap.isTexture && (t.alphaMap = this.alphaMap.toJSON(e).uuid), this.lightMap && this.lightMap.isTexture && (t.lightMap = this.lightMap.toJSON(e).uuid), this.aoMap && this.aoMap.isTexture && (t.aoMap = this.aoMap.toJSON(e).uuid, t.aoMapIntensity = this.aoMapIntensity), this.bumpMap && this.bumpMap.isTexture && (t.bumpMap = this.bumpMap.toJSON(e).uuid, t.bumpScale = this.bumpScale), this.normalMap && this.normalMap.isTexture && (t.normalMap = this.normalMap.toJSON(e).uuid, t.normalMapType = this.normalMapType, t.normalScale = this.normalScale.toArray()), this.displacementMap && this.displacementMap.isTexture && (t.displacementMap = this.displacementMap.toJSON(e).uuid, t.displacementScale = this.displacementScale, t.displacementBias = this.displacementBias), this.roughnessMap && this.roughnessMap.isTexture && (t.roughnessMap = this.roughnessMap.toJSON(e).uuid), this.metalnessMap && this.metalnessMap.isTexture && (t.metalnessMap = this.metalnessMap.toJSON(e).uuid), this.emissiveMap && this.emissiveMap.isTexture && (t.emissiveMap = this.emissiveMap.toJSON(e).uuid), this.specularMap && this.specularMap.isTexture && (t.specularMap = this.specularMap.toJSON(e).uuid), this.envMap && this.envMap.isTexture && (t.envMap = this.envMap.toJSON(e).uuid, t.reflectivity = this.reflectivity, t.refractionRatio = this.refractionRatio, this.combine !== void 0 && (t.combine = this.combine), this.envMapIntensity !== void 0 && (t.envMapIntensity = this.envMapIntensity)), this.gradientMap && this.gradientMap.isTexture && (t.gradientMap = this.gradientMap.toJSON(e).uuid), this.size !== void 0 && (t.size = this.size), this.sizeAttenuation !== void 0 && (t.sizeAttenuation = this.sizeAttenuation), this.blending !== xm && (t.blending = this.blending), this.flatShading === !0 && (t.flatShading = this.flatShading), this.side !== cg && (t.side = this.side), this.vertexColors && (t.vertexColors = !0), this.opacity < 1 && (t.opacity = this.opacity), this.transparent === !0 && (t.transparent = this.transparent), t.depthFunc = this.depthFunc, t.depthTest = this.depthTest, t.depthWrite = this.depthWrite, t.stencilWrite = this.stencilWrite, t.stencilWriteMask = this.stencilWriteMask, t.stencilFunc = this.stencilFunc, t.stencilRef = this.stencilRef, t.stencilFuncMask = this.stencilFuncMask, t.stencilFail = this.stencilFail, t.stencilZFail = this.stencilZFail, t.stencilZPass = this.stencilZPass, this.rotation && this.rotation !== 0 && (t.rotation = this.rotation), this.polygonOffset === !0 && (t.polygonOffset = !0), this.polygonOffsetFactor !== 0 && (t.polygonOffsetFactor = this.polygonOffsetFactor), this.polygonOffsetUnits !== 0 && (t.polygonOffsetUnits = this.polygonOffsetUnits), this.linewidth && this.linewidth !== 1 && (t.linewidth = this.linewidth), this.dashSize !== void 0 && (t.dashSize = this.dashSize), this.gapSize !== void 0 && (t.gapSize = this.gapSize), this.scale !== void 0 && (t.scale = this.scale), this.dithering === !0 && (t.dithering = !0), this.alphaTest > 0 && (t.alphaTest = this.alphaTest), this.premultipliedAlpha === !0 && (t.premultipliedAlpha = this.premultipliedAlpha), this.wireframe === !0 && (t.wireframe = this.wireframe), this.wireframeLinewidth > 1 && (t.wireframeLinewidth = this.wireframeLinewidth), this.wireframeLinecap !== "round" && (t.wireframeLinecap = this.wireframeLinecap), this.wireframeLinejoin !== "round" && (t.wireframeLinejoin = this.wireframeLinejoin), this.morphTargets === !0 && (t.morphTargets = !0), this.morphNormals === !0 && (t.morphNormals = !0), this.skinning === !0 && (t.skinning = !0), this.visible === !1 && (t.visible = !1), this.toneMapped === !1 && (t.toneMapped = !1), JSON.stringify(this.userData) !== "{}" && (t.userData = this.userData);
    function i(r) {
      const a = [];
      for (const c in r) {
        const u = r[c];
        delete u.metadata, a.push(u);
      }
      return a;
    }
    if (n) {
      const r = i(e.textures), a = i(e.images);
      r.length > 0 && (t.textures = r), a.length > 0 && (t.images = a);
    }
    return t;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    this.name = e.name, this.fog = e.fog, this.blending = e.blending, this.side = e.side, this.flatShading = e.flatShading, this.vertexColors = e.vertexColors, this.opacity = e.opacity, this.transparent = e.transparent, this.blendSrc = e.blendSrc, this.blendDst = e.blendDst, this.blendEquation = e.blendEquation, this.blendSrcAlpha = e.blendSrcAlpha, this.blendDstAlpha = e.blendDstAlpha, this.blendEquationAlpha = e.blendEquationAlpha, this.depthFunc = e.depthFunc, this.depthTest = e.depthTest, this.depthWrite = e.depthWrite, this.stencilWriteMask = e.stencilWriteMask, this.stencilFunc = e.stencilFunc, this.stencilRef = e.stencilRef, this.stencilFuncMask = e.stencilFuncMask, this.stencilFail = e.stencilFail, this.stencilZFail = e.stencilZFail, this.stencilZPass = e.stencilZPass, this.stencilWrite = e.stencilWrite;
    const n = e.clippingPlanes;
    let t = null;
    if (n !== null) {
      const i = n.length;
      t = new Array(i);
      for (let r = 0; r !== i; ++r)
        t[r] = n[r].clone();
    }
    return this.clippingPlanes = t, this.clipIntersection = e.clipIntersection, this.clipShadows = e.clipShadows, this.shadowSide = e.shadowSide, this.colorWrite = e.colorWrite, this.precision = e.precision, this.polygonOffset = e.polygonOffset, this.polygonOffsetFactor = e.polygonOffsetFactor, this.polygonOffsetUnits = e.polygonOffsetUnits, this.dithering = e.dithering, this.alphaTest = e.alphaTest, this.premultipliedAlpha = e.premultipliedAlpha, this.visible = e.visible, this.toneMapped = e.toneMapped, this.userData = JSON.parse(JSON.stringify(e.userData)), this;
  },
  dispose: function() {
    this.dispatchEvent({ type: "dispose" });
  }
});
Object.defineProperty(rn.prototype, "needsUpdate", {
  set: function(e) {
    e === !0 && this.version++;
  }
});
function Ms(e) {
  rn.call(this), this.type = "MeshBasicMaterial", this.color = new Wt(16777215), this.map = null, this.lightMap = null, this.lightMapIntensity = 1, this.aoMap = null, this.aoMapIntensity = 1, this.specularMap = null, this.alphaMap = null, this.envMap = null, this.combine = Ry, this.reflectivity = 1, this.refractionRatio = 0.98, this.wireframe = !1, this.wireframeLinewidth = 1, this.wireframeLinecap = "round", this.wireframeLinejoin = "round", this.skinning = !1, this.morphTargets = !1, this.setValues(e);
}
Ms.prototype = Object.create(rn.prototype);
Ms.prototype.constructor = Ms;
Ms.prototype.isMeshBasicMaterial = !0;
Ms.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this.map = e.map, this.lightMap = e.lightMap, this.lightMapIntensity = e.lightMapIntensity, this.aoMap = e.aoMap, this.aoMapIntensity = e.aoMapIntensity, this.specularMap = e.specularMap, this.alphaMap = e.alphaMap, this.envMap = e.envMap, this.combine = e.combine, this.reflectivity = e.reflectivity, this.refractionRatio = e.refractionRatio, this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this.wireframeLinecap = e.wireframeLinecap, this.wireframeLinejoin = e.wireframeLinejoin, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this;
};
const zn = new ve(), h_ = new vt();
function Jt(e, n, t) {
  if (Array.isArray(e))
    throw new TypeError("THREE.BufferAttribute: array should be a Typed Array.");
  this.name = "", this.array = e, this.itemSize = n, this.count = e !== void 0 ? e.length / n : 0, this.normalized = t === !0, this.usage = Ny, this.updateRange = { offset: 0, count: -1 }, this.version = 0;
}
Object.defineProperty(Jt.prototype, "needsUpdate", {
  set: function(e) {
    e === !0 && this.version++;
  }
});
Object.assign(Jt.prototype, {
  isBufferAttribute: !0,
  onUploadCallback: function() {
  },
  setUsage: function(e) {
    return this.usage = e, this;
  },
  copy: function(e) {
    return this.name = e.name, this.array = new e.array.constructor(e.array), this.itemSize = e.itemSize, this.count = e.count, this.normalized = e.normalized, this.usage = e.usage, this;
  },
  copyAt: function(e, n, t) {
    e *= this.itemSize, t *= n.itemSize;
    for (let i = 0, r = this.itemSize; i < r; i++)
      this.array[e + i] = n.array[t + i];
    return this;
  },
  copyArray: function(e) {
    return this.array.set(e), this;
  },
  copyColorsArray: function(e) {
    const n = this.array;
    let t = 0;
    for (let i = 0, r = e.length; i < r; i++) {
      let a = e[i];
      a === void 0 && (console.warn("THREE.BufferAttribute.copyColorsArray(): color is undefined", i), a = new Wt()), n[t++] = a.r, n[t++] = a.g, n[t++] = a.b;
    }
    return this;
  },
  copyVector2sArray: function(e) {
    const n = this.array;
    let t = 0;
    for (let i = 0, r = e.length; i < r; i++) {
      let a = e[i];
      a === void 0 && (console.warn("THREE.BufferAttribute.copyVector2sArray(): vector is undefined", i), a = new vt()), n[t++] = a.x, n[t++] = a.y;
    }
    return this;
  },
  copyVector3sArray: function(e) {
    const n = this.array;
    let t = 0;
    for (let i = 0, r = e.length; i < r; i++) {
      let a = e[i];
      a === void 0 && (console.warn("THREE.BufferAttribute.copyVector3sArray(): vector is undefined", i), a = new ve()), n[t++] = a.x, n[t++] = a.y, n[t++] = a.z;
    }
    return this;
  },
  copyVector4sArray: function(e) {
    const n = this.array;
    let t = 0;
    for (let i = 0, r = e.length; i < r; i++) {
      let a = e[i];
      a === void 0 && (console.warn("THREE.BufferAttribute.copyVector4sArray(): vector is undefined", i), a = new In()), n[t++] = a.x, n[t++] = a.y, n[t++] = a.z, n[t++] = a.w;
    }
    return this;
  },
  applyMatrix3: function(e) {
    if (this.itemSize === 2)
      for (let n = 0, t = this.count; n < t; n++)
        h_.fromBufferAttribute(this, n), h_.applyMatrix3(e), this.setXY(n, h_.x, h_.y);
    else if (this.itemSize === 3)
      for (let n = 0, t = this.count; n < t; n++)
        zn.fromBufferAttribute(this, n), zn.applyMatrix3(e), this.setXYZ(n, zn.x, zn.y, zn.z);
    return this;
  },
  applyMatrix4: function(e) {
    for (let n = 0, t = this.count; n < t; n++)
      zn.x = this.getX(n), zn.y = this.getY(n), zn.z = this.getZ(n), zn.applyMatrix4(e), this.setXYZ(n, zn.x, zn.y, zn.z);
    return this;
  },
  applyNormalMatrix: function(e) {
    for (let n = 0, t = this.count; n < t; n++)
      zn.x = this.getX(n), zn.y = this.getY(n), zn.z = this.getZ(n), zn.applyNormalMatrix(e), this.setXYZ(n, zn.x, zn.y, zn.z);
    return this;
  },
  transformDirection: function(e) {
    for (let n = 0, t = this.count; n < t; n++)
      zn.x = this.getX(n), zn.y = this.getY(n), zn.z = this.getZ(n), zn.transformDirection(e), this.setXYZ(n, zn.x, zn.y, zn.z);
    return this;
  },
  set: function(e, n) {
    return n === void 0 && (n = 0), this.array.set(e, n), this;
  },
  getX: function(e) {
    return this.array[e * this.itemSize];
  },
  setX: function(e, n) {
    return this.array[e * this.itemSize] = n, this;
  },
  getY: function(e) {
    return this.array[e * this.itemSize + 1];
  },
  setY: function(e, n) {
    return this.array[e * this.itemSize + 1] = n, this;
  },
  getZ: function(e) {
    return this.array[e * this.itemSize + 2];
  },
  setZ: function(e, n) {
    return this.array[e * this.itemSize + 2] = n, this;
  },
  getW: function(e) {
    return this.array[e * this.itemSize + 3];
  },
  setW: function(e, n) {
    return this.array[e * this.itemSize + 3] = n, this;
  },
  setXY: function(e, n, t) {
    return e *= this.itemSize, this.array[e + 0] = n, this.array[e + 1] = t, this;
  },
  setXYZ: function(e, n, t, i) {
    return e *= this.itemSize, this.array[e + 0] = n, this.array[e + 1] = t, this.array[e + 2] = i, this;
  },
  setXYZW: function(e, n, t, i, r) {
    return e *= this.itemSize, this.array[e + 0] = n, this.array[e + 1] = t, this.array[e + 2] = i, this.array[e + 3] = r, this;
  },
  onUpload: function(e) {
    return this.onUploadCallback = e, this;
  },
  clone: function() {
    return new this.constructor(this.array, this.itemSize).copy(this);
  },
  toJSON: function() {
    return {
      itemSize: this.itemSize,
      type: this.array.constructor.name,
      array: Array.prototype.slice.call(this.array),
      normalized: this.normalized
    };
  }
});
function Bv(e, n, t) {
  Jt.call(this, new Int8Array(e), n, t);
}
Bv.prototype = Object.create(Jt.prototype);
Bv.prototype.constructor = Bv;
function zv(e, n, t) {
  Jt.call(this, new Uint8Array(e), n, t);
}
zv.prototype = Object.create(Jt.prototype);
zv.prototype.constructor = zv;
function $v(e, n, t) {
  Jt.call(this, new Uint8ClampedArray(e), n, t);
}
$v.prototype = Object.create(Jt.prototype);
$v.prototype.constructor = $v;
function Nv(e, n, t) {
  Jt.call(this, new Int16Array(e), n, t);
}
Nv.prototype = Object.create(Jt.prototype);
Nv.prototype.constructor = Nv;
function Im(e, n, t) {
  Jt.call(this, new Uint16Array(e), n, t);
}
Im.prototype = Object.create(Jt.prototype);
Im.prototype.constructor = Im;
function Uv(e, n, t) {
  Jt.call(this, new Int32Array(e), n, t);
}
Uv.prototype = Object.create(Jt.prototype);
Uv.prototype.constructor = Uv;
function Lm(e, n, t) {
  Jt.call(this, new Uint32Array(e), n, t);
}
Lm.prototype = Object.create(Jt.prototype);
Lm.prototype.constructor = Lm;
function zt(e, n, t) {
  Jt.call(this, new Float32Array(e), n, t);
}
zt.prototype = Object.create(Jt.prototype);
zt.prototype.constructor = zt;
function Gv(e, n, t) {
  Jt.call(this, new Float64Array(e), n, t);
}
Gv.prototype = Object.create(Jt.prototype);
Gv.prototype.constructor = Gv;
function Gx() {
  this.vertices = [], this.normals = [], this.colors = [], this.uvs = [], this.uvs2 = [], this.groups = [], this.morphTargets = {}, this.skinWeights = [], this.skinIndices = [], this.boundingBox = null, this.boundingSphere = null, this.verticesNeedUpdate = !1, this.normalsNeedUpdate = !1, this.colorsNeedUpdate = !1, this.uvsNeedUpdate = !1, this.groupsNeedUpdate = !1;
}
Object.assign(Gx.prototype, {
  computeGroups: function(e) {
    const n = [];
    let t, i, r;
    const a = e.faces;
    for (i = 0; i < a.length; i++) {
      const c = a[i];
      c.materialIndex !== r && (r = c.materialIndex, t !== void 0 && (t.count = i * 3 - t.start, n.push(t)), t = {
        start: i * 3,
        materialIndex: r
      });
    }
    t !== void 0 && (t.count = i * 3 - t.start, n.push(t)), this.groups = n;
  },
  fromGeometry: function(e) {
    const n = e.faces, t = e.vertices, i = e.faceVertexUvs, r = i[0] && i[0].length > 0, a = i[1] && i[1].length > 0, c = e.morphTargets, u = c.length;
    let l;
    if (u > 0) {
      l = [];
      for (let D = 0; D < u; D++)
        l[D] = {
          name: c[D].name,
          data: []
        };
      this.morphTargets.position = l;
    }
    const f = e.morphNormals, m = f.length;
    let h;
    if (m > 0) {
      h = [];
      for (let D = 0; D < m; D++)
        h[D] = {
          name: f[D].name,
          data: []
        };
      this.morphTargets.normal = h;
    }
    const p = e.skinIndices, _ = e.skinWeights, v = p.length === t.length, S = _.length === t.length;
    t.length > 0 && n.length === 0 && console.error("THREE.DirectGeometry: Faceless geometries are not supported.");
    for (let D = 0; D < n.length; D++) {
      const w = n[D];
      this.vertices.push(t[w.a], t[w.b], t[w.c]);
      const T = w.vertexNormals;
      if (T.length === 3)
        this.normals.push(T[0], T[1], T[2]);
      else {
        const E = w.normal;
        this.normals.push(E, E, E);
      }
      const F = w.vertexColors;
      if (F.length === 3)
        this.colors.push(F[0], F[1], F[2]);
      else {
        const E = w.color;
        this.colors.push(E, E, E);
      }
      if (r === !0) {
        const E = i[0][D];
        E !== void 0 ? this.uvs.push(E[0], E[1], E[2]) : (console.warn("THREE.DirectGeometry.fromGeometry(): Undefined vertexUv ", D), this.uvs.push(new vt(), new vt(), new vt()));
      }
      if (a === !0) {
        const E = i[1][D];
        E !== void 0 ? this.uvs2.push(E[0], E[1], E[2]) : (console.warn("THREE.DirectGeometry.fromGeometry(): Undefined vertexUv2 ", D), this.uvs2.push(new vt(), new vt(), new vt()));
      }
      for (let E = 0; E < u; E++) {
        const A = c[E].vertices;
        l[E].data.push(A[w.a], A[w.b], A[w.c]);
      }
      for (let E = 0; E < m; E++) {
        const A = f[E].vertexNormals[D];
        h[E].data.push(A.a, A.b, A.c);
      }
      v && this.skinIndices.push(p[w.a], p[w.b], p[w.c]), S && this.skinWeights.push(_[w.a], _[w.b], _[w.c]);
    }
    return this.computeGroups(e), this.verticesNeedUpdate = e.verticesNeedUpdate, this.normalsNeedUpdate = e.normalsNeedUpdate, this.colorsNeedUpdate = e.colorsNeedUpdate, this.uvsNeedUpdate = e.uvsNeedUpdate, this.groupsNeedUpdate = e.groupsNeedUpdate, e.boundingSphere !== null && (this.boundingSphere = e.boundingSphere.clone()), e.boundingBox !== null && (this.boundingBox = e.boundingBox.clone()), this;
  }
});
function Vx(e) {
  if (e.length === 0)
    return -1 / 0;
  let n = e[0];
  for (let t = 1, i = e.length; t < i; ++t)
    e[t] > n && (n = e[t]);
  return n;
}
let A1 = 1;
const ir = new dn(), gv = new Ft(), $c = new ve(), os = new mr(), dm = new mr(), gi = new ve();
function Gt() {
  Object.defineProperty(this, "id", { value: A1 += 2 }), this.uuid = un.generateUUID(), this.name = "", this.type = "BufferGeometry", this.index = null, this.attributes = {}, this.morphAttributes = {}, this.morphTargetsRelative = !1, this.groups = [], this.boundingBox = null, this.boundingSphere = null, this.drawRange = { start: 0, count: 1 / 0 }, this.userData = {};
}
Gt.prototype = Object.assign(Object.create(Fr.prototype), {
  constructor: Gt,
  isBufferGeometry: !0,
  getIndex: function() {
    return this.index;
  },
  setIndex: function(e) {
    Array.isArray(e) ? this.index = new (Vx(e) > 65535 ? Lm : Im)(e, 1) : this.index = e;
  },
  getAttribute: function(e) {
    return this.attributes[e];
  },
  setAttribute: function(e, n) {
    return this.attributes[e] = n, this;
  },
  deleteAttribute: function(e) {
    return delete this.attributes[e], this;
  },
  addGroup: function(e, n, t) {
    this.groups.push({
      start: e,
      count: n,
      materialIndex: t !== void 0 ? t : 0
    });
  },
  clearGroups: function() {
    this.groups = [];
  },
  setDrawRange: function(e, n) {
    this.drawRange.start = e, this.drawRange.count = n;
  },
  applyMatrix4: function(e) {
    const n = this.attributes.position;
    n !== void 0 && (n.applyMatrix4(e), n.needsUpdate = !0);
    const t = this.attributes.normal;
    if (t !== void 0) {
      const r = new Bi().getNormalMatrix(e);
      t.applyNormalMatrix(r), t.needsUpdate = !0;
    }
    const i = this.attributes.tangent;
    return i !== void 0 && (i.transformDirection(e), i.needsUpdate = !0), this.boundingBox !== null && this.computeBoundingBox(), this.boundingSphere !== null && this.computeBoundingSphere(), this;
  },
  rotateX: function(e) {
    return ir.makeRotationX(e), this.applyMatrix4(ir), this;
  },
  rotateY: function(e) {
    return ir.makeRotationY(e), this.applyMatrix4(ir), this;
  },
  rotateZ: function(e) {
    return ir.makeRotationZ(e), this.applyMatrix4(ir), this;
  },
  translate: function(e, n, t) {
    return ir.makeTranslation(e, n, t), this.applyMatrix4(ir), this;
  },
  scale: function(e, n, t) {
    return ir.makeScale(e, n, t), this.applyMatrix4(ir), this;
  },
  lookAt: function(e) {
    return gv.lookAt(e), gv.updateMatrix(), this.applyMatrix4(gv.matrix), this;
  },
  center: function() {
    return this.computeBoundingBox(), this.boundingBox.getCenter($c).negate(), this.translate($c.x, $c.y, $c.z), this;
  },
  setFromObject: function(e) {
    const n = e.geometry;
    if (e.isPoints || e.isLine) {
      const t = new zt(n.vertices.length * 3, 3), i = new zt(n.colors.length * 3, 3);
      if (this.setAttribute("position", t.copyVector3sArray(n.vertices)), this.setAttribute("color", i.copyColorsArray(n.colors)), n.lineDistances && n.lineDistances.length === n.vertices.length) {
        const r = new zt(n.lineDistances.length, 1);
        this.setAttribute("lineDistance", r.copyArray(n.lineDistances));
      }
      n.boundingSphere !== null && (this.boundingSphere = n.boundingSphere.clone()), n.boundingBox !== null && (this.boundingBox = n.boundingBox.clone());
    } else
      e.isMesh && n && n.isGeometry && this.fromGeometry(n);
    return this;
  },
  setFromPoints: function(e) {
    const n = [];
    for (let t = 0, i = e.length; t < i; t++) {
      const r = e[t];
      n.push(r.x, r.y, r.z || 0);
    }
    return this.setAttribute("position", new zt(n, 3)), this;
  },
  updateFromObject: function(e) {
    let n = e.geometry;
    if (e.isMesh) {
      let t = n.__directGeometry;
      if (n.elementsNeedUpdate === !0 && (t = void 0, n.elementsNeedUpdate = !1), t === void 0)
        return this.fromGeometry(n);
      t.verticesNeedUpdate = n.verticesNeedUpdate, t.normalsNeedUpdate = n.normalsNeedUpdate, t.colorsNeedUpdate = n.colorsNeedUpdate, t.uvsNeedUpdate = n.uvsNeedUpdate, t.groupsNeedUpdate = n.groupsNeedUpdate, n.verticesNeedUpdate = !1, n.normalsNeedUpdate = !1, n.colorsNeedUpdate = !1, n.uvsNeedUpdate = !1, n.groupsNeedUpdate = !1, n = t;
    }
    if (n.verticesNeedUpdate === !0) {
      const t = this.attributes.position;
      t !== void 0 && (t.copyVector3sArray(n.vertices), t.needsUpdate = !0), n.verticesNeedUpdate = !1;
    }
    if (n.normalsNeedUpdate === !0) {
      const t = this.attributes.normal;
      t !== void 0 && (t.copyVector3sArray(n.normals), t.needsUpdate = !0), n.normalsNeedUpdate = !1;
    }
    if (n.colorsNeedUpdate === !0) {
      const t = this.attributes.color;
      t !== void 0 && (t.copyColorsArray(n.colors), t.needsUpdate = !0), n.colorsNeedUpdate = !1;
    }
    if (n.uvsNeedUpdate) {
      const t = this.attributes.uv;
      t !== void 0 && (t.copyVector2sArray(n.uvs), t.needsUpdate = !0), n.uvsNeedUpdate = !1;
    }
    if (n.lineDistancesNeedUpdate) {
      const t = this.attributes.lineDistance;
      t !== void 0 && (t.copyArray(n.lineDistances), t.needsUpdate = !0), n.lineDistancesNeedUpdate = !1;
    }
    return n.groupsNeedUpdate && (n.computeGroups(e.geometry), this.groups = n.groups, n.groupsNeedUpdate = !1), this;
  },
  fromGeometry: function(e) {
    return e.__directGeometry = new Gx().fromGeometry(e), this.fromDirectGeometry(e.__directGeometry);
  },
  fromDirectGeometry: function(e) {
    const n = new Float32Array(e.vertices.length * 3);
    if (this.setAttribute("position", new Jt(n, 3).copyVector3sArray(e.vertices)), e.normals.length > 0) {
      const t = new Float32Array(e.normals.length * 3);
      this.setAttribute("normal", new Jt(t, 3).copyVector3sArray(e.normals));
    }
    if (e.colors.length > 0) {
      const t = new Float32Array(e.colors.length * 3);
      this.setAttribute("color", new Jt(t, 3).copyColorsArray(e.colors));
    }
    if (e.uvs.length > 0) {
      const t = new Float32Array(e.uvs.length * 2);
      this.setAttribute("uv", new Jt(t, 2).copyVector2sArray(e.uvs));
    }
    if (e.uvs2.length > 0) {
      const t = new Float32Array(e.uvs2.length * 2);
      this.setAttribute("uv2", new Jt(t, 2).copyVector2sArray(e.uvs2));
    }
    this.groups = e.groups;
    for (const t in e.morphTargets) {
      const i = [], r = e.morphTargets[t];
      for (let a = 0, c = r.length; a < c; a++) {
        const u = r[a], l = new zt(u.data.length * 3, 3);
        l.name = u.name, i.push(l.copyVector3sArray(u.data));
      }
      this.morphAttributes[t] = i;
    }
    if (e.skinIndices.length > 0) {
      const t = new zt(e.skinIndices.length * 4, 4);
      this.setAttribute("skinIndex", t.copyVector4sArray(e.skinIndices));
    }
    if (e.skinWeights.length > 0) {
      const t = new zt(e.skinWeights.length * 4, 4);
      this.setAttribute("skinWeight", t.copyVector4sArray(e.skinWeights));
    }
    return e.boundingSphere !== null && (this.boundingSphere = e.boundingSphere.clone()), e.boundingBox !== null && (this.boundingBox = e.boundingBox.clone()), this;
  },
  computeBoundingBox: function() {
    this.boundingBox === null && (this.boundingBox = new mr());
    const e = this.attributes.position, n = this.morphAttributes.position;
    if (e !== void 0) {
      if (this.boundingBox.setFromBufferAttribute(e), n)
        for (let t = 0, i = n.length; t < i; t++) {
          const r = n[t];
          os.setFromBufferAttribute(r), this.morphTargetsRelative ? (gi.addVectors(this.boundingBox.min, os.min), this.boundingBox.expandByPoint(gi), gi.addVectors(this.boundingBox.max, os.max), this.boundingBox.expandByPoint(gi)) : (this.boundingBox.expandByPoint(os.min), this.boundingBox.expandByPoint(os.max));
        }
    } else
      this.boundingBox.makeEmpty();
    (isNaN(this.boundingBox.min.x) || isNaN(this.boundingBox.min.y) || isNaN(this.boundingBox.min.z)) && console.error('THREE.BufferGeometry.computeBoundingBox: Computed min/max have NaN values. The "position" attribute is likely to have NaN values.', this);
  },
  computeBoundingSphere: function() {
    this.boundingSphere === null && (this.boundingSphere = new Rr());
    const e = this.attributes.position, n = this.morphAttributes.position;
    if (e) {
      const t = this.boundingSphere.center;
      if (os.setFromBufferAttribute(e), n)
        for (let r = 0, a = n.length; r < a; r++) {
          const c = n[r];
          dm.setFromBufferAttribute(c), this.morphTargetsRelative ? (gi.addVectors(os.min, dm.min), os.expandByPoint(gi), gi.addVectors(os.max, dm.max), os.expandByPoint(gi)) : (os.expandByPoint(dm.min), os.expandByPoint(dm.max));
        }
      os.getCenter(t);
      let i = 0;
      for (let r = 0, a = e.count; r < a; r++)
        gi.fromBufferAttribute(e, r), i = Math.max(i, t.distanceToSquared(gi));
      if (n)
        for (let r = 0, a = n.length; r < a; r++) {
          const c = n[r], u = this.morphTargetsRelative;
          for (let l = 0, f = c.count; l < f; l++)
            gi.fromBufferAttribute(c, l), u && ($c.fromBufferAttribute(e, l), gi.add($c)), i = Math.max(i, t.distanceToSquared(gi));
        }
      this.boundingSphere.radius = Math.sqrt(i), isNaN(this.boundingSphere.radius) && console.error('THREE.BufferGeometry.computeBoundingSphere(): Computed radius is NaN. The "position" attribute is likely to have NaN values.', this);
    }
  },
  computeFaceNormals: function() {
  },
  computeVertexNormals: function() {
    const e = this.index, n = this.getAttribute("position");
    if (n !== void 0) {
      let t = this.getAttribute("normal");
      if (t === void 0)
        t = new Jt(new Float32Array(n.count * 3), 3), this.setAttribute("normal", t);
      else
        for (let h = 0, p = t.count; h < p; h++)
          t.setXYZ(h, 0, 0, 0);
      const i = new ve(), r = new ve(), a = new ve(), c = new ve(), u = new ve(), l = new ve(), f = new ve(), m = new ve();
      if (e)
        for (let h = 0, p = e.count; h < p; h += 3) {
          const _ = e.getX(h + 0), v = e.getX(h + 1), S = e.getX(h + 2);
          i.fromBufferAttribute(n, _), r.fromBufferAttribute(n, v), a.fromBufferAttribute(n, S), f.subVectors(a, r), m.subVectors(i, r), f.cross(m), c.fromBufferAttribute(t, _), u.fromBufferAttribute(t, v), l.fromBufferAttribute(t, S), c.add(f), u.add(f), l.add(f), t.setXYZ(_, c.x, c.y, c.z), t.setXYZ(v, u.x, u.y, u.z), t.setXYZ(S, l.x, l.y, l.z);
        }
      else
        for (let h = 0, p = n.count; h < p; h += 3)
          i.fromBufferAttribute(n, h + 0), r.fromBufferAttribute(n, h + 1), a.fromBufferAttribute(n, h + 2), f.subVectors(a, r), m.subVectors(i, r), f.cross(m), t.setXYZ(h + 0, f.x, f.y, f.z), t.setXYZ(h + 1, f.x, f.y, f.z), t.setXYZ(h + 2, f.x, f.y, f.z);
      this.normalizeNormals(), t.needsUpdate = !0;
    }
  },
  merge: function(e, n) {
    if (!(e && e.isBufferGeometry)) {
      console.error("THREE.BufferGeometry.merge(): geometry not an instance of THREE.BufferGeometry.", e);
      return;
    }
    n === void 0 && (n = 0, console.warn(
      "THREE.BufferGeometry.merge(): Overwriting original geometry, starting at offset=0. Use BufferGeometryUtils.mergeBufferGeometries() for lossless merge."
    ));
    const t = this.attributes;
    for (const i in t) {
      if (e.attributes[i] === void 0)
        continue;
      const a = t[i].array, c = e.attributes[i], u = c.array, l = c.itemSize * n, f = Math.min(u.length, a.length - l);
      for (let m = 0, h = l; m < f; m++, h++)
        a[h] = u[m];
    }
    return this;
  },
  normalizeNormals: function() {
    const e = this.attributes.normal;
    for (let n = 0, t = e.count; n < t; n++)
      gi.fromBufferAttribute(e, n), gi.normalize(), e.setXYZ(n, gi.x, gi.y, gi.z);
  },
  toNonIndexed: function() {
    function e(c, u) {
      const l = c.array, f = c.itemSize, m = c.normalized, h = new l.constructor(u.length * f);
      let p = 0, _ = 0;
      for (let v = 0, S = u.length; v < S; v++) {
        p = u[v] * f;
        for (let D = 0; D < f; D++)
          h[_++] = l[p++];
      }
      return new Jt(h, f, m);
    }
    if (this.index === null)
      return console.warn("THREE.BufferGeometry.toNonIndexed(): Geometry is already non-indexed."), this;
    const n = new Gt(), t = this.index.array, i = this.attributes;
    for (const c in i) {
      const u = i[c], l = e(u, t);
      n.setAttribute(c, l);
    }
    const r = this.morphAttributes;
    for (const c in r) {
      const u = [], l = r[c];
      for (let f = 0, m = l.length; f < m; f++) {
        const h = l[f], p = e(h, t);
        u.push(p);
      }
      n.morphAttributes[c] = u;
    }
    n.morphTargetsRelative = this.morphTargetsRelative;
    const a = this.groups;
    for (let c = 0, u = a.length; c < u; c++) {
      const l = a[c];
      n.addGroup(l.start, l.count, l.materialIndex);
    }
    return n;
  },
  toJSON: function() {
    const e = {
      metadata: {
        version: 4.5,
        type: "BufferGeometry",
        generator: "BufferGeometry.toJSON"
      }
    };
    if (e.uuid = this.uuid, e.type = this.type, this.name !== "" && (e.name = this.name), Object.keys(this.userData).length > 0 && (e.userData = this.userData), this.parameters !== void 0) {
      const u = this.parameters;
      for (const l in u)
        u[l] !== void 0 && (e[l] = u[l]);
      return e;
    }
    e.data = { attributes: {} };
    const n = this.index;
    n !== null && (e.data.index = {
      type: n.array.constructor.name,
      array: Array.prototype.slice.call(n.array)
    });
    const t = this.attributes;
    for (const u in t) {
      const l = t[u], f = l.toJSON(e.data);
      l.name !== "" && (f.name = l.name), e.data.attributes[u] = f;
    }
    const i = {};
    let r = !1;
    for (const u in this.morphAttributes) {
      const l = this.morphAttributes[u], f = [];
      for (let m = 0, h = l.length; m < h; m++) {
        const p = l[m], _ = p.toJSON(e.data);
        p.name !== "" && (_.name = p.name), f.push(_);
      }
      f.length > 0 && (i[u] = f, r = !0);
    }
    r && (e.data.morphAttributes = i, e.data.morphTargetsRelative = this.morphTargetsRelative);
    const a = this.groups;
    a.length > 0 && (e.data.groups = JSON.parse(JSON.stringify(a)));
    const c = this.boundingSphere;
    return c !== null && (e.data.boundingSphere = {
      center: c.center.toArray(),
      radius: c.radius
    }), e;
  },
  clone: function() {
    return new Gt().copy(this);
  },
  copy: function(e) {
    this.index = null, this.attributes = {}, this.morphAttributes = {}, this.groups = [], this.boundingBox = null, this.boundingSphere = null;
    const n = {};
    this.name = e.name;
    const t = e.index;
    t !== null && this.setIndex(t.clone(n));
    const i = e.attributes;
    for (const l in i) {
      const f = i[l];
      this.setAttribute(l, f.clone(n));
    }
    const r = e.morphAttributes;
    for (const l in r) {
      const f = [], m = r[l];
      for (let h = 0, p = m.length; h < p; h++)
        f.push(m[h].clone(n));
      this.morphAttributes[l] = f;
    }
    this.morphTargetsRelative = e.morphTargetsRelative;
    const a = e.groups;
    for (let l = 0, f = a.length; l < f; l++) {
      const m = a[l];
      this.addGroup(m.start, m.count, m.materialIndex);
    }
    const c = e.boundingBox;
    c !== null && (this.boundingBox = c.clone());
    const u = e.boundingSphere;
    return u !== null && (this.boundingSphere = u.clone()), this.drawRange.start = e.drawRange.start, this.drawRange.count = e.drawRange.count, this.userData = e.userData, this;
  },
  dispose: function() {
    this.dispatchEvent({ type: "dispose" });
  }
});
const _w = new dn(), oa = new Au(), _v = new Rr(), no = new ve(), io = new ve(), so = new ve(), yv = new ve(), vv = new ve(), wv = new ve(), f_ = new ve(), p_ = new ve(), m_ = new ve(), Zc = new vt(), eu = new vt(), tu = new vt(), Mm = new ve(), g_ = new ve();
function Ln(e, n) {
  Ft.call(this), this.type = "Mesh", this.geometry = e !== void 0 ? e : new Gt(), this.material = n !== void 0 ? n : new Ms(), this.updateMorphTargets();
}
Ln.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: Ln,
  isMesh: !0,
  copy: function(e) {
    return Ft.prototype.copy.call(this, e), e.morphTargetInfluences !== void 0 && (this.morphTargetInfluences = e.morphTargetInfluences.slice()), e.morphTargetDictionary !== void 0 && (this.morphTargetDictionary = Object.assign({}, e.morphTargetDictionary)), this.material = e.material, this.geometry = e.geometry, this;
  },
  updateMorphTargets: function() {
    const e = this.geometry;
    if (e.isBufferGeometry) {
      const n = e.morphAttributes, t = Object.keys(n);
      if (t.length > 0) {
        const i = n[t[0]];
        if (i !== void 0) {
          this.morphTargetInfluences = [], this.morphTargetDictionary = {};
          for (let r = 0, a = i.length; r < a; r++) {
            const c = i[r].name || String(r);
            this.morphTargetInfluences.push(0), this.morphTargetDictionary[c] = r;
          }
        }
      }
    } else {
      const n = e.morphTargets;
      n !== void 0 && n.length > 0 && console.error("THREE.Mesh.updateMorphTargets() no longer supports THREE.Geometry. Use THREE.BufferGeometry instead.");
    }
  },
  raycast: function(e, n) {
    const t = this.geometry, i = this.material, r = this.matrixWorld;
    if (i === void 0 || (t.boundingSphere === null && t.computeBoundingSphere(), _v.copy(t.boundingSphere), _v.applyMatrix4(r), e.ray.intersectsSphere(_v) === !1) || (_w.getInverse(r), oa.copy(e.ray).applyMatrix4(_w), t.boundingBox !== null && oa.intersectsBox(t.boundingBox) === !1))
      return;
    let a;
    if (t.isBufferGeometry) {
      const c = t.index, u = t.attributes.position, l = t.morphAttributes.position, f = t.morphTargetsRelative, m = t.attributes.uv, h = t.attributes.uv2, p = t.groups, _ = t.drawRange;
      if (c !== null)
        if (Array.isArray(i))
          for (let v = 0, S = p.length; v < S; v++) {
            const D = p[v], w = i[D.materialIndex], T = Math.max(D.start, _.start), F = Math.min(D.start + D.count, _.start + _.count);
            for (let E = T, A = F; E < A; E += 3) {
              const L = c.getX(E), I = c.getX(E + 1), R = c.getX(E + 2);
              a = __(this, w, e, oa, u, l, f, m, h, L, I, R), a && (a.faceIndex = Math.floor(E / 3), a.face.materialIndex = D.materialIndex, n.push(a));
            }
          }
        else {
          const v = Math.max(0, _.start), S = Math.min(c.count, _.start + _.count);
          for (let D = v, w = S; D < w; D += 3) {
            const T = c.getX(D), F = c.getX(D + 1), E = c.getX(D + 2);
            a = __(this, i, e, oa, u, l, f, m, h, T, F, E), a && (a.faceIndex = Math.floor(D / 3), n.push(a));
          }
        }
      else if (u !== void 0)
        if (Array.isArray(i))
          for (let v = 0, S = p.length; v < S; v++) {
            const D = p[v], w = i[D.materialIndex], T = Math.max(D.start, _.start), F = Math.min(D.start + D.count, _.start + _.count);
            for (let E = T, A = F; E < A; E += 3) {
              const L = E, I = E + 1, R = E + 2;
              a = __(this, w, e, oa, u, l, f, m, h, L, I, R), a && (a.faceIndex = Math.floor(E / 3), a.face.materialIndex = D.materialIndex, n.push(a));
            }
          }
        else {
          const v = Math.max(0, _.start), S = Math.min(u.count, _.start + _.count);
          for (let D = v, w = S; D < w; D += 3) {
            const T = D, F = D + 1, E = D + 2;
            a = __(this, i, e, oa, u, l, f, m, h, T, F, E), a && (a.faceIndex = Math.floor(D / 3), n.push(a));
          }
        }
    } else if (t.isGeometry) {
      const c = Array.isArray(i), u = t.vertices, l = t.faces;
      let f;
      const m = t.faceVertexUvs[0];
      m.length > 0 && (f = m);
      for (let h = 0, p = l.length; h < p; h++) {
        const _ = l[h], v = c ? i[_.materialIndex] : i;
        if (v === void 0)
          continue;
        const S = u[_.a], D = u[_.b], w = u[_.c];
        if (a = jx(this, v, e, oa, S, D, w, Mm), a) {
          if (f && f[h]) {
            const T = f[h];
            Zc.copy(T[0]), eu.copy(T[1]), tu.copy(T[2]), a.uv = Ei.getUV(Mm, S, D, w, Zc, eu, tu, new vt());
          }
          a.face = _, a.faceIndex = h, n.push(a);
        }
      }
    }
  }
});
function jx(e, n, t, i, r, a, c, u) {
  let l;
  if (n.side === hi ? l = i.intersectTriangle(c, a, r, !0, u) : l = i.intersectTriangle(r, a, c, n.side !== Fy, u), l === null)
    return null;
  g_.copy(u), g_.applyMatrix4(e.matrixWorld);
  const f = t.ray.origin.distanceTo(g_);
  return f < t.near || f > t.far ? null : {
    distance: f,
    point: g_.clone(),
    object: e
  };
}
function __(e, n, t, i, r, a, c, u, l, f, m, h) {
  no.fromBufferAttribute(r, f), io.fromBufferAttribute(r, m), so.fromBufferAttribute(r, h);
  const p = e.morphTargetInfluences;
  if (n.morphTargets && a && p) {
    f_.set(0, 0, 0), p_.set(0, 0, 0), m_.set(0, 0, 0);
    for (let v = 0, S = a.length; v < S; v++) {
      const D = p[v], w = a[v];
      D !== 0 && (yv.fromBufferAttribute(w, f), vv.fromBufferAttribute(w, m), wv.fromBufferAttribute(w, h), c ? (f_.addScaledVector(yv, D), p_.addScaledVector(vv, D), m_.addScaledVector(wv, D)) : (f_.addScaledVector(yv.sub(no), D), p_.addScaledVector(vv.sub(io), D), m_.addScaledVector(wv.sub(so), D)));
    }
    no.add(f_), io.add(p_), so.add(m_);
  }
  e.isSkinnedMesh && (e.boneTransform(f, no), e.boneTransform(m, io), e.boneTransform(h, so));
  const _ = jx(e, n, t, i, no, io, so, Mm);
  if (_) {
    u && (Zc.fromBufferAttribute(u, f), eu.fromBufferAttribute(u, m), tu.fromBufferAttribute(u, h), _.uv = Ei.getUV(Mm, no, io, so, Zc, eu, tu, new vt())), l && (Zc.fromBufferAttribute(l, f), eu.fromBufferAttribute(l, m), tu.fromBufferAttribute(l, h), _.uv2 = Ei.getUV(Mm, no, io, so, Zc, eu, tu, new vt()));
    const v = new ty(f, m, h);
    Ei.getNormal(no, io, so, v.normal), _.face = v;
  }
  return _;
}
let C1 = 0;
const sr = new dn(), xv = new Ft(), y_ = new ve();
function an() {
  Object.defineProperty(this, "id", { value: C1 += 2 }), this.uuid = un.generateUUID(), this.name = "", this.type = "Geometry", this.vertices = [], this.colors = [], this.faces = [], this.faceVertexUvs = [[]], this.morphTargets = [], this.morphNormals = [], this.skinWeights = [], this.skinIndices = [], this.lineDistances = [], this.boundingBox = null, this.boundingSphere = null, this.elementsNeedUpdate = !1, this.verticesNeedUpdate = !1, this.uvsNeedUpdate = !1, this.normalsNeedUpdate = !1, this.colorsNeedUpdate = !1, this.lineDistancesNeedUpdate = !1, this.groupsNeedUpdate = !1;
}
an.prototype = Object.assign(Object.create(Fr.prototype), {
  constructor: an,
  isGeometry: !0,
  applyMatrix4: function(e) {
    const n = new Bi().getNormalMatrix(e);
    for (let t = 0, i = this.vertices.length; t < i; t++)
      this.vertices[t].applyMatrix4(e);
    for (let t = 0, i = this.faces.length; t < i; t++) {
      const r = this.faces[t];
      r.normal.applyMatrix3(n).normalize();
      for (let a = 0, c = r.vertexNormals.length; a < c; a++)
        r.vertexNormals[a].applyMatrix3(n).normalize();
    }
    return this.boundingBox !== null && this.computeBoundingBox(), this.boundingSphere !== null && this.computeBoundingSphere(), this.verticesNeedUpdate = !0, this.normalsNeedUpdate = !0, this;
  },
  rotateX: function(e) {
    return sr.makeRotationX(e), this.applyMatrix4(sr), this;
  },
  rotateY: function(e) {
    return sr.makeRotationY(e), this.applyMatrix4(sr), this;
  },
  rotateZ: function(e) {
    return sr.makeRotationZ(e), this.applyMatrix4(sr), this;
  },
  translate: function(e, n, t) {
    return sr.makeTranslation(e, n, t), this.applyMatrix4(sr), this;
  },
  scale: function(e, n, t) {
    return sr.makeScale(e, n, t), this.applyMatrix4(sr), this;
  },
  lookAt: function(e) {
    return xv.lookAt(e), xv.updateMatrix(), this.applyMatrix4(xv.matrix), this;
  },
  fromBufferGeometry: function(e) {
    const n = this, t = e.index !== null ? e.index : void 0, i = e.attributes;
    if (i.position === void 0)
      return console.error("THREE.Geometry.fromBufferGeometry(): Position attribute required for conversion."), this;
    const r = i.position, a = i.normal, c = i.color, u = i.uv, l = i.uv2;
    l !== void 0 && (this.faceVertexUvs[1] = []);
    for (let h = 0; h < r.count; h++)
      n.vertices.push(new ve().fromBufferAttribute(r, h)), c !== void 0 && n.colors.push(new Wt().fromBufferAttribute(c, h));
    function f(h, p, _, v) {
      const S = c === void 0 ? [] : [
        n.colors[h].clone(),
        n.colors[p].clone(),
        n.colors[_].clone()
      ], D = a === void 0 ? [] : [
        new ve().fromBufferAttribute(a, h),
        new ve().fromBufferAttribute(a, p),
        new ve().fromBufferAttribute(a, _)
      ], w = new ty(h, p, _, D, S, v);
      n.faces.push(w), u !== void 0 && n.faceVertexUvs[0].push([
        new vt().fromBufferAttribute(u, h),
        new vt().fromBufferAttribute(u, p),
        new vt().fromBufferAttribute(u, _)
      ]), l !== void 0 && n.faceVertexUvs[1].push([
        new vt().fromBufferAttribute(l, h),
        new vt().fromBufferAttribute(l, p),
        new vt().fromBufferAttribute(l, _)
      ]);
    }
    const m = e.groups;
    if (m.length > 0)
      for (let h = 0; h < m.length; h++) {
        const p = m[h], _ = p.start, v = p.count;
        for (let S = _, D = _ + v; S < D; S += 3)
          t !== void 0 ? f(t.getX(S), t.getX(S + 1), t.getX(S + 2), p.materialIndex) : f(S, S + 1, S + 2, p.materialIndex);
      }
    else if (t !== void 0)
      for (let h = 0; h < t.count; h += 3)
        f(t.getX(h), t.getX(h + 1), t.getX(h + 2));
    else
      for (let h = 0; h < r.count; h += 3)
        f(h, h + 1, h + 2);
    return this.computeFaceNormals(), e.boundingBox !== null && (this.boundingBox = e.boundingBox.clone()), e.boundingSphere !== null && (this.boundingSphere = e.boundingSphere.clone()), this;
  },
  center: function() {
    return this.computeBoundingBox(), this.boundingBox.getCenter(y_).negate(), this.translate(y_.x, y_.y, y_.z), this;
  },
  normalize: function() {
    this.computeBoundingSphere();
    const e = this.boundingSphere.center, n = this.boundingSphere.radius, t = n === 0 ? 1 : 1 / n, i = new dn();
    return i.set(
      t,
      0,
      0,
      -t * e.x,
      0,
      t,
      0,
      -t * e.y,
      0,
      0,
      t,
      -t * e.z,
      0,
      0,
      0,
      1
    ), this.applyMatrix4(i), this;
  },
  computeFaceNormals: function() {
    const e = new ve(), n = new ve();
    for (let t = 0, i = this.faces.length; t < i; t++) {
      const r = this.faces[t], a = this.vertices[r.a], c = this.vertices[r.b], u = this.vertices[r.c];
      e.subVectors(u, c), n.subVectors(a, c), e.cross(n), e.normalize(), r.normal.copy(e);
    }
  },
  computeVertexNormals: function(e) {
    e === void 0 && (e = !0);
    const n = new Array(this.vertices.length);
    for (let t = 0, i = this.vertices.length; t < i; t++)
      n[t] = new ve();
    if (e) {
      const t = new ve(), i = new ve();
      for (let r = 0, a = this.faces.length; r < a; r++) {
        const c = this.faces[r], u = this.vertices[c.a], l = this.vertices[c.b], f = this.vertices[c.c];
        t.subVectors(f, l), i.subVectors(u, l), t.cross(i), n[c.a].add(t), n[c.b].add(t), n[c.c].add(t);
      }
    } else {
      this.computeFaceNormals();
      for (let t = 0, i = this.faces.length; t < i; t++) {
        const r = this.faces[t];
        n[r.a].add(r.normal), n[r.b].add(r.normal), n[r.c].add(r.normal);
      }
    }
    for (let t = 0, i = this.vertices.length; t < i; t++)
      n[t].normalize();
    for (let t = 0, i = this.faces.length; t < i; t++) {
      const r = this.faces[t], a = r.vertexNormals;
      a.length === 3 ? (a[0].copy(n[r.a]), a[1].copy(n[r.b]), a[2].copy(n[r.c])) : (a[0] = n[r.a].clone(), a[1] = n[r.b].clone(), a[2] = n[r.c].clone());
    }
    this.faces.length > 0 && (this.normalsNeedUpdate = !0);
  },
  computeFlatVertexNormals: function() {
    this.computeFaceNormals();
    for (let e = 0, n = this.faces.length; e < n; e++) {
      const t = this.faces[e], i = t.vertexNormals;
      i.length === 3 ? (i[0].copy(t.normal), i[1].copy(t.normal), i[2].copy(t.normal)) : (i[0] = t.normal.clone(), i[1] = t.normal.clone(), i[2] = t.normal.clone());
    }
    this.faces.length > 0 && (this.normalsNeedUpdate = !0);
  },
  computeMorphNormals: function() {
    for (let n = 0, t = this.faces.length; n < t; n++) {
      const i = this.faces[n];
      i.__originalFaceNormal ? i.__originalFaceNormal.copy(i.normal) : i.__originalFaceNormal = i.normal.clone(), i.__originalVertexNormals || (i.__originalVertexNormals = []);
      for (let r = 0, a = i.vertexNormals.length; r < a; r++)
        i.__originalVertexNormals[r] ? i.__originalVertexNormals[r].copy(i.vertexNormals[r]) : i.__originalVertexNormals[r] = i.vertexNormals[r].clone();
    }
    const e = new an();
    e.faces = this.faces;
    for (let n = 0, t = this.morphTargets.length; n < t; n++) {
      if (!this.morphNormals[n]) {
        this.morphNormals[n] = {}, this.morphNormals[n].faceNormals = [], this.morphNormals[n].vertexNormals = [];
        const r = this.morphNormals[n].faceNormals, a = this.morphNormals[n].vertexNormals;
        for (let c = 0, u = this.faces.length; c < u; c++) {
          const l = new ve(), f = { a: new ve(), b: new ve(), c: new ve() };
          r.push(l), a.push(f);
        }
      }
      const i = this.morphNormals[n];
      e.vertices = this.morphTargets[n].vertices, e.computeFaceNormals(), e.computeVertexNormals();
      for (let r = 0, a = this.faces.length; r < a; r++) {
        const c = this.faces[r], u = i.faceNormals[r], l = i.vertexNormals[r];
        u.copy(c.normal), l.a.copy(c.vertexNormals[0]), l.b.copy(c.vertexNormals[1]), l.c.copy(c.vertexNormals[2]);
      }
    }
    for (let n = 0, t = this.faces.length; n < t; n++) {
      const i = this.faces[n];
      i.normal = i.__originalFaceNormal, i.vertexNormals = i.__originalVertexNormals;
    }
  },
  computeBoundingBox: function() {
    this.boundingBox === null && (this.boundingBox = new mr()), this.boundingBox.setFromPoints(this.vertices);
  },
  computeBoundingSphere: function() {
    this.boundingSphere === null && (this.boundingSphere = new Rr()), this.boundingSphere.setFromPoints(this.vertices);
  },
  merge: function(e, n, t) {
    if (!(e && e.isGeometry)) {
      console.error("THREE.Geometry.merge(): geometry not an instance of THREE.Geometry.", e);
      return;
    }
    let i, r = this.vertices.length, a = this.vertices, c = e.vertices, u = this.faces, l = e.faces, f = this.colors, m = e.colors;
    t === void 0 && (t = 0), n !== void 0 && (i = new Bi().getNormalMatrix(n));
    for (let h = 0, p = c.length; h < p; h++) {
      const v = c[h].clone();
      n !== void 0 && v.applyMatrix4(n), a.push(v);
    }
    for (let h = 0, p = m.length; h < p; h++)
      f.push(m[h].clone());
    for (let h = 0, p = l.length; h < p; h++) {
      let _ = l[h], v, S, D, w = _.vertexNormals, T = _.vertexColors;
      v = new ty(_.a + r, _.b + r, _.c + r), v.normal.copy(_.normal), i !== void 0 && v.normal.applyMatrix3(i).normalize();
      for (let F = 0, E = w.length; F < E; F++)
        S = w[F].clone(), i !== void 0 && S.applyMatrix3(i).normalize(), v.vertexNormals.push(S);
      v.color.copy(_.color);
      for (let F = 0, E = T.length; F < E; F++)
        D = T[F], v.vertexColors.push(D.clone());
      v.materialIndex = _.materialIndex + t, u.push(v);
    }
    for (let h = 0, p = e.faceVertexUvs.length; h < p; h++) {
      const _ = e.faceVertexUvs[h];
      this.faceVertexUvs[h] === void 0 && (this.faceVertexUvs[h] = []);
      for (let v = 0, S = _.length; v < S; v++) {
        const D = _[v], w = [];
        for (let T = 0, F = D.length; T < F; T++)
          w.push(D[T].clone());
        this.faceVertexUvs[h].push(w);
      }
    }
  },
  mergeMesh: function(e) {
    if (!(e && e.isMesh)) {
      console.error("THREE.Geometry.mergeMesh(): mesh not an instance of THREE.Mesh.", e);
      return;
    }
    e.matrixAutoUpdate && e.updateMatrix(), this.merge(e.geometry, e.matrix);
  },
  /*
   * Checks for duplicate vertices with hashmap.
   * Duplicated vertices are removed
   * and faces' vertices are updated.
   */
  mergeVertices: function() {
    const e = {}, n = [], t = [], r = Math.pow(10, 4);
    for (let u = 0, l = this.vertices.length; u < l; u++) {
      const f = this.vertices[u], m = Math.round(f.x * r) + "_" + Math.round(f.y * r) + "_" + Math.round(f.z * r);
      e[m] === void 0 ? (e[m] = u, n.push(this.vertices[u]), t[u] = n.length - 1) : t[u] = t[e[m]];
    }
    const a = [];
    for (let u = 0, l = this.faces.length; u < l; u++) {
      const f = this.faces[u];
      f.a = t[f.a], f.b = t[f.b], f.c = t[f.c];
      const m = [f.a, f.b, f.c];
      for (let h = 0; h < 3; h++)
        if (m[h] === m[(h + 1) % 3]) {
          a.push(u);
          break;
        }
    }
    for (let u = a.length - 1; u >= 0; u--) {
      const l = a[u];
      this.faces.splice(l, 1);
      for (let f = 0, m = this.faceVertexUvs.length; f < m; f++)
        this.faceVertexUvs[f].splice(l, 1);
    }
    const c = this.vertices.length - n.length;
    return this.vertices = n, c;
  },
  setFromPoints: function(e) {
    this.vertices = [];
    for (let n = 0, t = e.length; n < t; n++) {
      const i = e[n];
      this.vertices.push(new ve(i.x, i.y, i.z || 0));
    }
    return this;
  },
  sortFacesByMaterialIndex: function() {
    const e = this.faces, n = e.length;
    for (let u = 0; u < n; u++)
      e[u]._id = u;
    function t(u, l) {
      return u.materialIndex - l.materialIndex;
    }
    e.sort(t);
    const i = this.faceVertexUvs[0], r = this.faceVertexUvs[1];
    let a, c;
    i && i.length === n && (a = []), r && r.length === n && (c = []);
    for (let u = 0; u < n; u++) {
      const l = e[u]._id;
      a && a.push(i[l]), c && c.push(r[l]);
    }
    a && (this.faceVertexUvs[0] = a), c && (this.faceVertexUvs[1] = c);
  },
  toJSON: function() {
    const e = {
      metadata: {
        version: 4.5,
        type: "Geometry",
        generator: "Geometry.toJSON"
      }
    };
    if (e.uuid = this.uuid, e.type = this.type, this.name !== "" && (e.name = this.name), this.parameters !== void 0) {
      const _ = this.parameters;
      for (const v in _)
        _[v] !== void 0 && (e[v] = _[v]);
      return e;
    }
    const n = [];
    for (let _ = 0; _ < this.vertices.length; _++) {
      const v = this.vertices[_];
      n.push(v.x, v.y, v.z);
    }
    const t = [], i = [], r = {}, a = [], c = {}, u = [], l = {};
    for (let _ = 0; _ < this.faces.length; _++) {
      const v = this.faces[_], S = !0, D = !1, w = this.faceVertexUvs[0][_] !== void 0, T = v.normal.length() > 0, F = v.vertexNormals.length > 0, E = v.color.r !== 1 || v.color.g !== 1 || v.color.b !== 1, A = v.vertexColors.length > 0;
      let L = 0;
      if (L = f(L, 0, 0), L = f(L, 1, S), L = f(L, 2, D), L = f(L, 3, w), L = f(L, 4, T), L = f(L, 5, F), L = f(L, 6, E), L = f(L, 7, A), t.push(L), t.push(v.a, v.b, v.c), t.push(v.materialIndex), w) {
        const I = this.faceVertexUvs[0][_];
        t.push(
          p(I[0]),
          p(I[1]),
          p(I[2])
        );
      }
      if (T && t.push(m(v.normal)), F) {
        const I = v.vertexNormals;
        t.push(
          m(I[0]),
          m(I[1]),
          m(I[2])
        );
      }
      if (E && t.push(h(v.color)), A) {
        const I = v.vertexColors;
        t.push(
          h(I[0]),
          h(I[1]),
          h(I[2])
        );
      }
    }
    function f(_, v, S) {
      return S ? _ | 1 << v : _ & ~(1 << v);
    }
    function m(_) {
      const v = _.x.toString() + _.y.toString() + _.z.toString();
      return r[v] !== void 0 || (r[v] = i.length / 3, i.push(_.x, _.y, _.z)), r[v];
    }
    function h(_) {
      const v = _.r.toString() + _.g.toString() + _.b.toString();
      return c[v] !== void 0 || (c[v] = a.length, a.push(_.getHex())), c[v];
    }
    function p(_) {
      const v = _.x.toString() + _.y.toString();
      return l[v] !== void 0 || (l[v] = u.length / 2, u.push(_.x, _.y)), l[v];
    }
    return e.data = {}, e.data.vertices = n, e.data.normals = i, a.length > 0 && (e.data.colors = a), u.length > 0 && (e.data.uvs = [u]), e.data.faces = t, e;
  },
  clone: function() {
    return new an().copy(this);
  },
  copy: function(e) {
    this.vertices = [], this.colors = [], this.faces = [], this.faceVertexUvs = [[]], this.morphTargets = [], this.morphNormals = [], this.skinWeights = [], this.skinIndices = [], this.lineDistances = [], this.boundingBox = null, this.boundingSphere = null, this.name = e.name;
    const n = e.vertices;
    for (let h = 0, p = n.length; h < p; h++)
      this.vertices.push(n[h].clone());
    const t = e.colors;
    for (let h = 0, p = t.length; h < p; h++)
      this.colors.push(t[h].clone());
    const i = e.faces;
    for (let h = 0, p = i.length; h < p; h++)
      this.faces.push(i[h].clone());
    for (let h = 0, p = e.faceVertexUvs.length; h < p; h++) {
      const _ = e.faceVertexUvs[h];
      this.faceVertexUvs[h] === void 0 && (this.faceVertexUvs[h] = []);
      for (let v = 0, S = _.length; v < S; v++) {
        const D = _[v], w = [];
        for (let T = 0, F = D.length; T < F; T++) {
          const E = D[T];
          w.push(E.clone());
        }
        this.faceVertexUvs[h].push(w);
      }
    }
    const r = e.morphTargets;
    for (let h = 0, p = r.length; h < p; h++) {
      const _ = {};
      if (_.name = r[h].name, r[h].vertices !== void 0) {
        _.vertices = [];
        for (let v = 0, S = r[h].vertices.length; v < S; v++)
          _.vertices.push(r[h].vertices[v].clone());
      }
      if (r[h].normals !== void 0) {
        _.normals = [];
        for (let v = 0, S = r[h].normals.length; v < S; v++)
          _.normals.push(r[h].normals[v].clone());
      }
      this.morphTargets.push(_);
    }
    const a = e.morphNormals;
    for (let h = 0, p = a.length; h < p; h++) {
      const _ = {};
      if (a[h].vertexNormals !== void 0) {
        _.vertexNormals = [];
        for (let v = 0, S = a[h].vertexNormals.length; v < S; v++) {
          const D = a[h].vertexNormals[v], w = {};
          w.a = D.a.clone(), w.b = D.b.clone(), w.c = D.c.clone(), _.vertexNormals.push(w);
        }
      }
      if (a[h].faceNormals !== void 0) {
        _.faceNormals = [];
        for (let v = 0, S = a[h].faceNormals.length; v < S; v++)
          _.faceNormals.push(a[h].faceNormals[v].clone());
      }
      this.morphNormals.push(_);
    }
    const c = e.skinWeights;
    for (let h = 0, p = c.length; h < p; h++)
      this.skinWeights.push(c[h].clone());
    const u = e.skinIndices;
    for (let h = 0, p = u.length; h < p; h++)
      this.skinIndices.push(u[h].clone());
    const l = e.lineDistances;
    for (let h = 0, p = l.length; h < p; h++)
      this.lineDistances.push(l[h]);
    const f = e.boundingBox;
    f !== null && (this.boundingBox = f.clone());
    const m = e.boundingSphere;
    return m !== null && (this.boundingSphere = m.clone()), this.elementsNeedUpdate = e.elementsNeedUpdate, this.verticesNeedUpdate = e.verticesNeedUpdate, this.uvsNeedUpdate = e.uvsNeedUpdate, this.normalsNeedUpdate = e.normalsNeedUpdate, this.colorsNeedUpdate = e.colorsNeedUpdate, this.lineDistancesNeedUpdate = e.lineDistancesNeedUpdate, this.groupsNeedUpdate = e.groupsNeedUpdate, this;
  },
  dispose: function() {
    this.dispatchEvent({ type: "dispose" });
  }
});
class I1 extends an {
  constructor(n, t, i, r, a, c) {
    super(), this.type = "BoxGeometry", this.parameters = {
      width: n,
      height: t,
      depth: i,
      widthSegments: r,
      heightSegments: a,
      depthSegments: c
    }, this.fromBufferGeometry(new Uy(n, t, i, r, a, c)), this.mergeVertices();
  }
}
class Uy extends Gt {
  constructor(n = 1, t = 1, i = 1, r = 1, a = 1, c = 1) {
    super(), this.type = "BoxBufferGeometry", this.parameters = {
      width: n,
      height: t,
      depth: i,
      widthSegments: r,
      heightSegments: a,
      depthSegments: c
    };
    const u = this;
    r = Math.floor(r), a = Math.floor(a), c = Math.floor(c);
    const l = [], f = [], m = [], h = [];
    let p = 0, _ = 0;
    v("z", "y", "x", -1, -1, i, t, n, c, a, 0), v("z", "y", "x", 1, -1, i, t, -n, c, a, 1), v("x", "z", "y", 1, 1, n, i, t, r, c, 2), v("x", "z", "y", 1, -1, n, i, -t, r, c, 3), v("x", "y", "z", 1, -1, n, t, i, r, a, 4), v("x", "y", "z", -1, -1, n, t, -i, r, a, 5), this.setIndex(l), this.setAttribute("position", new zt(f, 3)), this.setAttribute("normal", new zt(m, 3)), this.setAttribute("uv", new zt(h, 2));
    function v(S, D, w, T, F, E, A, L, I, R, N) {
      const q = E / I, ne = A / R, Q = E / 2, W = A / 2, te = L / 2, K = I + 1, pe = R + 1;
      let be = 0, Ee = 0;
      const Ge = new ve();
      for (let _e = 0; _e < pe; _e++) {
        const De = _e * ne - W;
        for (let he = 0; he < K; he++) {
          const Z = he * q - Q;
          Ge[S] = Z * T, Ge[D] = De * F, Ge[w] = te, f.push(Ge.x, Ge.y, Ge.z), Ge[S] = 0, Ge[D] = 0, Ge[w] = L > 0 ? 1 : -1, m.push(Ge.x, Ge.y, Ge.z), h.push(he / I), h.push(1 - _e / R), be += 1;
        }
      }
      for (let _e = 0; _e < R; _e++)
        for (let De = 0; De < I; De++) {
          const he = p + De + K * _e, Z = p + De + K * (_e + 1), me = p + (De + 1) + K * (_e + 1), we = p + (De + 1) + K * _e;
          l.push(he, Z, we), l.push(Z, me, we), Ee += 6;
        }
      u.addGroup(_, Ee, N), _ += Ee, p += be;
    }
  }
}
function lu(e) {
  const n = {};
  for (const t in e) {
    n[t] = {};
    for (const i in e[t]) {
      const r = e[t][i];
      r && (r.isColor || r.isMatrix3 || r.isMatrix4 || r.isVector2 || r.isVector3 || r.isVector4 || r.isTexture) ? n[t][i] = r.clone() : Array.isArray(r) ? n[t][i] = r.slice() : n[t][i] = r;
    }
  }
  return n;
}
function Ii(e) {
  const n = {};
  for (let t = 0; t < e.length; t++) {
    const i = lu(e[t]);
    for (const r in i)
      n[r] = i[r];
  }
  return n;
}
const L1 = { clone: lu, merge: Ii };
var D1 = `void main() {
	gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
}`, k1 = `void main() {
	gl_FragColor = vec4( 1.0, 0.0, 0.0, 1.0 );
}`;
function Xi(e) {
  rn.call(this), this.type = "ShaderMaterial", this.defines = {}, this.uniforms = {}, this.vertexShader = D1, this.fragmentShader = k1, this.linewidth = 1, this.wireframe = !1, this.wireframeLinewidth = 1, this.fog = !1, this.lights = !1, this.clipping = !1, this.skinning = !1, this.morphTargets = !1, this.morphNormals = !1, this.extensions = {
    derivatives: !1,
    // set to use derivatives
    fragDepth: !1,
    // set to use fragment depth values
    drawBuffers: !1,
    // set to use draw buffers
    shaderTextureLOD: !1
    // set to use shader texture LOD
  }, this.defaultAttributeValues = {
    color: [1, 1, 1],
    uv: [0, 0],
    uv2: [0, 0]
  }, this.index0AttributeName = void 0, this.uniformsNeedUpdate = !1, e !== void 0 && (e.attributes !== void 0 && console.error("THREE.ShaderMaterial: attributes should now be defined in THREE.BufferGeometry instead."), this.setValues(e));
}
Xi.prototype = Object.create(rn.prototype);
Xi.prototype.constructor = Xi;
Xi.prototype.isShaderMaterial = !0;
Xi.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.fragmentShader = e.fragmentShader, this.vertexShader = e.vertexShader, this.uniforms = lu(e.uniforms), this.defines = Object.assign({}, e.defines), this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this.lights = e.lights, this.clipping = e.clipping, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.morphNormals = e.morphNormals, this.extensions = Object.assign({}, e.extensions), this;
};
Xi.prototype.toJSON = function(e) {
  const n = rn.prototype.toJSON.call(this, e);
  n.uniforms = {};
  for (const i in this.uniforms) {
    const a = this.uniforms[i].value;
    a && a.isTexture ? n.uniforms[i] = {
      type: "t",
      value: a.toJSON(e).uuid
    } : a && a.isColor ? n.uniforms[i] = {
      type: "c",
      value: a.getHex()
    } : a && a.isVector2 ? n.uniforms[i] = {
      type: "v2",
      value: a.toArray()
    } : a && a.isVector3 ? n.uniforms[i] = {
      type: "v3",
      value: a.toArray()
    } : a && a.isVector4 ? n.uniforms[i] = {
      type: "v4",
      value: a.toArray()
    } : a && a.isMatrix3 ? n.uniforms[i] = {
      type: "m3",
      value: a.toArray()
    } : a && a.isMatrix4 ? n.uniforms[i] = {
      type: "m4",
      value: a.toArray()
    } : n.uniforms[i] = {
      value: a
    };
  }
  Object.keys(this.defines).length > 0 && (n.defines = this.defines), n.vertexShader = this.vertexShader, n.fragmentShader = this.fragmentShader;
  const t = {};
  for (const i in this.extensions)
    this.extensions[i] === !0 && (t[i] = !0);
  return Object.keys(t).length > 0 && (n.extensions = t), n;
};
function Ir() {
  Ft.call(this), this.type = "Camera", this.matrixWorldInverse = new dn(), this.projectionMatrix = new dn(), this.projectionMatrixInverse = new dn();
}
Ir.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: Ir,
  isCamera: !0,
  copy: function(e, n) {
    return Ft.prototype.copy.call(this, e, n), this.matrixWorldInverse.copy(e.matrixWorldInverse), this.projectionMatrix.copy(e.projectionMatrix), this.projectionMatrixInverse.copy(e.projectionMatrixInverse), this;
  },
  getWorldDirection: function(e) {
    e === void 0 && (console.warn("THREE.Camera: .getWorldDirection() target is now required"), e = new ve()), this.updateMatrixWorld(!0);
    const n = this.matrixWorld.elements;
    return e.set(-n[8], -n[9], -n[10]).normalize();
  },
  updateMatrixWorld: function(e) {
    Ft.prototype.updateMatrixWorld.call(this, e), this.matrixWorldInverse.getInverse(this.matrixWorld);
  },
  updateWorldMatrix: function(e, n) {
    Ft.prototype.updateWorldMatrix.call(this, e, n), this.matrixWorldInverse.getInverse(this.matrixWorld);
  },
  clone: function() {
    return new this.constructor().copy(this);
  }
});
function oi(e, n, t, i) {
  Ir.call(this), this.type = "PerspectiveCamera", this.fov = e !== void 0 ? e : 50, this.zoom = 1, this.near = t !== void 0 ? t : 0.1, this.far = i !== void 0 ? i : 2e3, this.focus = 10, this.aspect = n !== void 0 ? n : 1, this.view = null, this.filmGauge = 35, this.filmOffset = 0, this.updateProjectionMatrix();
}
oi.prototype = Object.assign(Object.create(Ir.prototype), {
  constructor: oi,
  isPerspectiveCamera: !0,
  copy: function(e, n) {
    return Ir.prototype.copy.call(this, e, n), this.fov = e.fov, this.zoom = e.zoom, this.near = e.near, this.far = e.far, this.focus = e.focus, this.aspect = e.aspect, this.view = e.view === null ? null : Object.assign({}, e.view), this.filmGauge = e.filmGauge, this.filmOffset = e.filmOffset, this;
  },
  /**
   * Sets the FOV by focal length in respect to the current .filmGauge.
   *
   * The default film gauge is 35, so that the focal length can be specified for
   * a 35mm (full frame) camera.
   *
   * Values for focal length and film gauge must have the same unit.
   */
  setFocalLength: function(e) {
    const n = 0.5 * this.getFilmHeight() / e;
    this.fov = un.RAD2DEG * 2 * Math.atan(n), this.updateProjectionMatrix();
  },
  /**
   * Calculates the focal length from the current .fov and .filmGauge.
   */
  getFocalLength: function() {
    const e = Math.tan(un.DEG2RAD * 0.5 * this.fov);
    return 0.5 * this.getFilmHeight() / e;
  },
  getEffectiveFOV: function() {
    return un.RAD2DEG * 2 * Math.atan(
      Math.tan(un.DEG2RAD * 0.5 * this.fov) / this.zoom
    );
  },
  getFilmWidth: function() {
    return this.filmGauge * Math.min(this.aspect, 1);
  },
  getFilmHeight: function() {
    return this.filmGauge / Math.max(this.aspect, 1);
  },
  /**
   * Sets an offset in a larger frustum. This is useful for multi-window or
   * multi-monitor/multi-machine setups.
   *
   * For example, if you have 3x2 monitors and each monitor is 1920x1080 and
   * the monitors are in grid like this
   *
   *   +---+---+---+
   *   | A | B | C |
   *   +---+---+---+
   *   | D | E | F |
   *   +---+---+---+
   *
   * then for each monitor you would call it like this
   *
   *   const w = 1920;
   *   const h = 1080;
   *   const fullWidth = w * 3;
   *   const fullHeight = h * 2;
   *
   *   --A--
   *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 0, w, h );
   *   --B--
   *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 0, w, h );
   *   --C--
   *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 0, w, h );
   *   --D--
   *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 1, w, h );
   *   --E--
   *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 1, w, h );
   *   --F--
   *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 1, w, h );
   *
   *   Note there is no reason monitors have to be the same size or in a grid.
   */
  setViewOffset: function(e, n, t, i, r, a) {
    this.aspect = e / n, this.view === null && (this.view = {
      enabled: !0,
      fullWidth: 1,
      fullHeight: 1,
      offsetX: 0,
      offsetY: 0,
      width: 1,
      height: 1
    }), this.view.enabled = !0, this.view.fullWidth = e, this.view.fullHeight = n, this.view.offsetX = t, this.view.offsetY = i, this.view.width = r, this.view.height = a, this.updateProjectionMatrix();
  },
  clearViewOffset: function() {
    this.view !== null && (this.view.enabled = !1), this.updateProjectionMatrix();
  },
  updateProjectionMatrix: function() {
    let e = this.near, n = e * Math.tan(un.DEG2RAD * 0.5 * this.fov) / this.zoom, t = 2 * n, i = this.aspect * t, r = -0.5 * i, a = this.view;
    if (this.view !== null && this.view.enabled) {
      const u = a.fullWidth, l = a.fullHeight;
      r += a.offsetX * i / u, n -= a.offsetY * t / l, i *= a.width / u, t *= a.height / l;
    }
    const c = this.filmOffset;
    c !== 0 && (r += e * c / this.getFilmWidth()), this.projectionMatrix.makePerspective(r, r + i, n, n - t, e, this.far), this.projectionMatrixInverse.getInverse(this.projectionMatrix);
  },
  toJSON: function(e) {
    const n = Ft.prototype.toJSON.call(this, e);
    return n.object.fov = this.fov, n.object.zoom = this.zoom, n.object.near = this.near, n.object.far = this.far, n.object.focus = this.focus, n.object.aspect = this.aspect, this.view !== null && (n.object.view = Object.assign({}, this.view)), n.object.filmGauge = this.filmGauge, n.object.filmOffset = this.filmOffset, n;
  }
});
const Nc = 90, Uc = 1;
function Dm(e, n, t) {
  if (Ft.call(this), this.type = "CubeCamera", t.isWebGLCubeRenderTarget !== !0) {
    console.error("THREE.CubeCamera: The constructor now expects an instance of WebGLCubeRenderTarget as third parameter.");
    return;
  }
  this.renderTarget = t;
  const i = new oi(Nc, Uc, e, n);
  i.layers = this.layers, i.up.set(0, -1, 0), i.lookAt(new ve(1, 0, 0)), this.add(i);
  const r = new oi(Nc, Uc, e, n);
  r.layers = this.layers, r.up.set(0, -1, 0), r.lookAt(new ve(-1, 0, 0)), this.add(r);
  const a = new oi(Nc, Uc, e, n);
  a.layers = this.layers, a.up.set(0, 0, 1), a.lookAt(new ve(0, 1, 0)), this.add(a);
  const c = new oi(Nc, Uc, e, n);
  c.layers = this.layers, c.up.set(0, 0, -1), c.lookAt(new ve(0, -1, 0)), this.add(c);
  const u = new oi(Nc, Uc, e, n);
  u.layers = this.layers, u.up.set(0, -1, 0), u.lookAt(new ve(0, 0, 1)), this.add(u);
  const l = new oi(Nc, Uc, e, n);
  l.layers = this.layers, l.up.set(0, -1, 0), l.lookAt(new ve(0, 0, -1)), this.add(l), this.update = function(f, m) {
    this.parent === null && this.updateMatrixWorld();
    const h = f.xr.enabled, p = f.getRenderTarget();
    f.xr.enabled = !1;
    const _ = t.texture.generateMipmaps;
    t.texture.generateMipmaps = !1, f.setRenderTarget(t, 0), f.render(m, i), f.setRenderTarget(t, 1), f.render(m, r), f.setRenderTarget(t, 2), f.render(m, a), f.setRenderTarget(t, 3), f.render(m, c), f.setRenderTarget(t, 4), f.render(m, u), t.texture.generateMipmaps = _, f.setRenderTarget(t, 5), f.render(m, l), f.setRenderTarget(p), f.xr.enabled = h;
  }, this.clear = function(f, m, h, p) {
    const _ = f.getRenderTarget();
    for (let v = 0; v < 6; v++)
      f.setRenderTarget(t, v), f.clear(m, h, p);
    f.setRenderTarget(_);
  };
}
Dm.prototype = Object.create(Ft.prototype);
Dm.prototype.constructor = Dm;
function km(e, n, t) {
  Number.isInteger(n) && (console.warn("THREE.WebGLCubeRenderTarget: constructor signature is now WebGLCubeRenderTarget( size, options )"), n = t), xs.call(this, e, e, n);
}
km.prototype = Object.create(xs.prototype);
km.prototype.constructor = km;
km.prototype.isWebGLCubeRenderTarget = !0;
km.prototype.fromEquirectangularTexture = function(e, n) {
  this.texture.type = n.type, this.texture.format = ws, this.texture.encoding = n.encoding, this.texture.generateMipmaps = n.generateMipmaps, this.texture.minFilter = n.minFilter, this.texture.magFilter = n.magFilter;
  const t = new Cm(), i = {
    uniforms: {
      tEquirect: { value: null }
    },
    vertexShader: (
      /* glsl */
      `

			varying vec3 vWorldDirection;

			vec3 transformDirection( in vec3 dir, in mat4 matrix ) {

				return normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );

			}

			void main() {

				vWorldDirection = transformDirection( position, modelMatrix );

				#include <begin_vertex>
				#include <project_vertex>

			}
		`
    ),
    fragmentShader: (
      /* glsl */
      `

			uniform sampler2D tEquirect;

			varying vec3 vWorldDirection;

			#include <common>

			void main() {

				vec3 direction = normalize( vWorldDirection );

				vec2 sampleUV = equirectUv( direction );

				gl_FragColor = texture2D( tEquirect, sampleUV );

			}
		`
    )
  }, r = new Xi({
    name: "CubemapFromEquirect",
    uniforms: lu(i.uniforms),
    vertexShader: i.vertexShader,
    fragmentShader: i.fragmentShader,
    side: hi,
    blending: co
  });
  r.uniforms.tEquirect.value = n;
  const a = new Ln(new Uy(5, 5, 5), r);
  return t.add(a), new Dm(1, 10, this).update(e, t), a.geometry.dispose(), a.material.dispose(), this;
};
function cu(e, n, t, i, r, a, c, u, l, f, m, h) {
  Fn.call(this, null, a, c, u, l, f, i, r, m, h), this.image = { data: e || null, width: n || 1, height: t || 1 }, this.magFilter = l !== void 0 ? l : _i, this.minFilter = f !== void 0 ? f : _i, this.generateMipmaps = !1, this.flipY = !1, this.unpackAlignment = 1, this.needsUpdate = !0;
}
cu.prototype = Object.create(Fn.prototype);
cu.prototype.constructor = cu;
cu.prototype.isDataTexture = !0;
const Gc = new Rr(), v_ = new ve();
function hg(e, n, t, i, r, a) {
  this.planes = [
    e !== void 0 ? e : new or(),
    n !== void 0 ? n : new or(),
    t !== void 0 ? t : new or(),
    i !== void 0 ? i : new or(),
    r !== void 0 ? r : new or(),
    a !== void 0 ? a : new or()
  ];
}
Object.assign(hg.prototype, {
  set: function(e, n, t, i, r, a) {
    const c = this.planes;
    return c[0].copy(e), c[1].copy(n), c[2].copy(t), c[3].copy(i), c[4].copy(r), c[5].copy(a), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    const n = this.planes;
    for (let t = 0; t < 6; t++)
      n[t].copy(e.planes[t]);
    return this;
  },
  setFromProjectionMatrix: function(e) {
    const n = this.planes, t = e.elements, i = t[0], r = t[1], a = t[2], c = t[3], u = t[4], l = t[5], f = t[6], m = t[7], h = t[8], p = t[9], _ = t[10], v = t[11], S = t[12], D = t[13], w = t[14], T = t[15];
    return n[0].setComponents(c - i, m - u, v - h, T - S).normalize(), n[1].setComponents(c + i, m + u, v + h, T + S).normalize(), n[2].setComponents(c + r, m + l, v + p, T + D).normalize(), n[3].setComponents(c - r, m - l, v - p, T - D).normalize(), n[4].setComponents(c - a, m - f, v - _, T - w).normalize(), n[5].setComponents(c + a, m + f, v + _, T + w).normalize(), this;
  },
  intersectsObject: function(e) {
    const n = e.geometry;
    return n.boundingSphere === null && n.computeBoundingSphere(), Gc.copy(n.boundingSphere).applyMatrix4(e.matrixWorld), this.intersectsSphere(Gc);
  },
  intersectsSprite: function(e) {
    return Gc.center.set(0, 0, 0), Gc.radius = 0.7071067811865476, Gc.applyMatrix4(e.matrixWorld), this.intersectsSphere(Gc);
  },
  intersectsSphere: function(e) {
    const n = this.planes, t = e.center, i = -e.radius;
    for (let r = 0; r < 6; r++)
      if (n[r].distanceToPoint(t) < i)
        return !1;
    return !0;
  },
  intersectsBox: function(e) {
    const n = this.planes;
    for (let t = 0; t < 6; t++) {
      const i = n[t];
      if (v_.x = i.normal.x > 0 ? e.max.x : e.min.x, v_.y = i.normal.y > 0 ? e.max.y : e.min.y, v_.z = i.normal.z > 0 ? e.max.z : e.min.z, i.distanceToPoint(v_) < 0)
        return !1;
    }
    return !0;
  },
  containsPoint: function(e) {
    const n = this.planes;
    for (let t = 0; t < 6; t++)
      if (n[t].distanceToPoint(e) < 0)
        return !1;
    return !0;
  }
});
const Bt = {
  common: {
    diffuse: { value: new Wt(15658734) },
    opacity: { value: 1 },
    map: { value: null },
    uvTransform: { value: new Bi() },
    uv2Transform: { value: new Bi() },
    alphaMap: { value: null }
  },
  specularmap: {
    specularMap: { value: null }
  },
  envmap: {
    envMap: { value: null },
    flipEnvMap: { value: -1 },
    reflectivity: { value: 1 },
    refractionRatio: { value: 0.98 },
    maxMipLevel: { value: 0 }
  },
  aomap: {
    aoMap: { value: null },
    aoMapIntensity: { value: 1 }
  },
  lightmap: {
    lightMap: { value: null },
    lightMapIntensity: { value: 1 }
  },
  emissivemap: {
    emissiveMap: { value: null }
  },
  bumpmap: {
    bumpMap: { value: null },
    bumpScale: { value: 1 }
  },
  normalmap: {
    normalMap: { value: null },
    normalScale: { value: new vt(1, 1) }
  },
  displacementmap: {
    displacementMap: { value: null },
    displacementScale: { value: 1 },
    displacementBias: { value: 0 }
  },
  roughnessmap: {
    roughnessMap: { value: null }
  },
  metalnessmap: {
    metalnessMap: { value: null }
  },
  gradientmap: {
    gradientMap: { value: null }
  },
  fog: {
    fogDensity: { value: 25e-5 },
    fogNear: { value: 1 },
    fogFar: { value: 2e3 },
    fogColor: { value: new Wt(16777215) }
  },
  lights: {
    ambientLightColor: { value: [] },
    lightProbe: { value: [] },
    directionalLights: { value: [], properties: {
      direction: {},
      color: {}
    } },
    directionalLightShadows: { value: [], properties: {
      shadowBias: {},
      shadowNormalBias: {},
      shadowRadius: {},
      shadowMapSize: {}
    } },
    directionalShadowMap: { value: [] },
    directionalShadowMatrix: { value: [] },
    spotLights: { value: [], properties: {
      color: {},
      position: {},
      direction: {},
      distance: {},
      coneCos: {},
      penumbraCos: {},
      decay: {}
    } },
    spotLightShadows: { value: [], properties: {
      shadowBias: {},
      shadowNormalBias: {},
      shadowRadius: {},
      shadowMapSize: {}
    } },
    spotShadowMap: { value: [] },
    spotShadowMatrix: { value: [] },
    pointLights: { value: [], properties: {
      color: {},
      position: {},
      decay: {},
      distance: {}
    } },
    pointLightShadows: { value: [], properties: {
      shadowBias: {},
      shadowNormalBias: {},
      shadowRadius: {},
      shadowMapSize: {},
      shadowCameraNear: {},
      shadowCameraFar: {}
    } },
    pointShadowMap: { value: [] },
    pointShadowMatrix: { value: [] },
    hemisphereLights: { value: [], properties: {
      direction: {},
      skyColor: {},
      groundColor: {}
    } },
    // TODO (abelnation): RectAreaLight BRDF data needs to be moved from example to main src
    rectAreaLights: { value: [], properties: {
      color: {},
      position: {},
      width: {},
      height: {}
    } }
  },
  points: {
    diffuse: { value: new Wt(15658734) },
    opacity: { value: 1 },
    size: { value: 1 },
    scale: { value: 1 },
    map: { value: null },
    alphaMap: { value: null },
    uvTransform: { value: new Bi() }
  },
  sprite: {
    diffuse: { value: new Wt(15658734) },
    opacity: { value: 1 },
    center: { value: new vt(0.5, 0.5) },
    rotation: { value: 0 },
    map: { value: null },
    alphaMap: { value: null },
    uvTransform: { value: new Bi() }
  }
};
function Wx() {
  let e = null, n = !1, t = null, i = null;
  function r(a, c) {
    t(a, c), i = e.requestAnimationFrame(r);
  }
  return {
    start: function() {
      n !== !0 && t !== null && (i = e.requestAnimationFrame(r), n = !0);
    },
    stop: function() {
      e.cancelAnimationFrame(i), n = !1;
    },
    setAnimationLoop: function(a) {
      t = a;
    },
    setContext: function(a) {
      e = a;
    }
  };
}
function O1(e, n) {
  const t = n.isWebGL2, i = /* @__PURE__ */ new WeakMap();
  function r(f, m) {
    const h = f.array, p = f.usage, _ = e.createBuffer();
    e.bindBuffer(m, _), e.bufferData(m, h, p), f.onUploadCallback();
    let v = 5126;
    return h instanceof Float32Array ? v = 5126 : h instanceof Float64Array ? console.warn("THREE.WebGLAttributes: Unsupported data buffer format: Float64Array.") : h instanceof Uint16Array ? v = 5123 : h instanceof Int16Array ? v = 5122 : h instanceof Uint32Array ? v = 5125 : h instanceof Int32Array ? v = 5124 : h instanceof Int8Array ? v = 5120 : h instanceof Uint8Array && (v = 5121), {
      buffer: _,
      type: v,
      bytesPerElement: h.BYTES_PER_ELEMENT,
      version: f.version
    };
  }
  function a(f, m, h) {
    const p = m.array, _ = m.updateRange;
    e.bindBuffer(h, f), _.count === -1 ? e.bufferSubData(h, 0, p) : (t ? e.bufferSubData(
      h,
      _.offset * p.BYTES_PER_ELEMENT,
      p,
      _.offset,
      _.count
    ) : e.bufferSubData(
      h,
      _.offset * p.BYTES_PER_ELEMENT,
      p.subarray(_.offset, _.offset + _.count)
    ), _.count = -1);
  }
  function c(f) {
    return f.isInterleavedBufferAttribute && (f = f.data), i.get(f);
  }
  function u(f) {
    f.isInterleavedBufferAttribute && (f = f.data);
    const m = i.get(f);
    m && (e.deleteBuffer(m.buffer), i.delete(f));
  }
  function l(f, m) {
    f.isInterleavedBufferAttribute && (f = f.data);
    const h = i.get(f);
    h === void 0 ? i.set(f, r(f, m)) : h.version < f.version && (a(h.buffer, f, m), h.version = f.version);
  }
  return {
    get: c,
    remove: u,
    update: l
  };
}
function ny(e, n, t, i) {
  an.call(this), this.type = "PlaneGeometry", this.parameters = {
    width: e,
    height: n,
    widthSegments: t,
    heightSegments: i
  }, this.fromBufferGeometry(new uu(e, n, t, i)), this.mergeVertices();
}
ny.prototype = Object.create(an.prototype);
ny.prototype.constructor = ny;
function uu(e, n, t, i) {
  Gt.call(this), this.type = "PlaneBufferGeometry", this.parameters = {
    width: e,
    height: n,
    widthSegments: t,
    heightSegments: i
  }, e = e || 1, n = n || 1;
  const r = e / 2, a = n / 2, c = Math.floor(t) || 1, u = Math.floor(i) || 1, l = c + 1, f = u + 1, m = e / c, h = n / u, p = [], _ = [], v = [], S = [];
  for (let D = 0; D < f; D++) {
    const w = D * h - a;
    for (let T = 0; T < l; T++) {
      const F = T * m - r;
      _.push(F, -w, 0), v.push(0, 0, 1), S.push(T / c), S.push(1 - D / u);
    }
  }
  for (let D = 0; D < u; D++)
    for (let w = 0; w < c; w++) {
      const T = w + l * D, F = w + l * (D + 1), E = w + 1 + l * (D + 1), A = w + 1 + l * D;
      p.push(T, F, A), p.push(F, E, A);
    }
  this.setIndex(p), this.setAttribute("position", new zt(_, 3)), this.setAttribute("normal", new zt(v, 3)), this.setAttribute("uv", new zt(S, 2));
}
uu.prototype = Object.create(Gt.prototype);
uu.prototype.constructor = uu;
var F1 = `#ifdef USE_ALPHAMAP
	diffuseColor.a *= texture2D( alphaMap, vUv ).g;
#endif`, R1 = `#ifdef USE_ALPHAMAP
	uniform sampler2D alphaMap;
#endif`, B1 = `#ifdef ALPHATEST
	if ( diffuseColor.a < ALPHATEST ) discard;
#endif`, z1 = `#ifdef USE_AOMAP
	float ambientOcclusion = ( texture2D( aoMap, vUv2 ).r - 1.0 ) * aoMapIntensity + 1.0;
	reflectedLight.indirectDiffuse *= ambientOcclusion;
	#if defined( USE_ENVMAP ) && defined( STANDARD )
		float dotNV = saturate( dot( geometry.normal, geometry.viewDir ) );
		reflectedLight.indirectSpecular *= computeSpecularOcclusion( dotNV, ambientOcclusion, material.specularRoughness );
	#endif
#endif`, $1 = `#ifdef USE_AOMAP
	uniform sampler2D aoMap;
	uniform float aoMapIntensity;
#endif`, N1 = "vec3 transformed = vec3( position );", U1 = `vec3 objectNormal = vec3( normal );
#ifdef USE_TANGENT
	vec3 objectTangent = vec3( tangent.xyz );
#endif`, G1 = `vec2 integrateSpecularBRDF( const in float dotNV, const in float roughness ) {
	const vec4 c0 = vec4( - 1, - 0.0275, - 0.572, 0.022 );
	const vec4 c1 = vec4( 1, 0.0425, 1.04, - 0.04 );
	vec4 r = roughness * c0 + c1;
	float a004 = min( r.x * r.x, exp2( - 9.28 * dotNV ) ) * r.x + r.y;
	return vec2( -1.04, 1.04 ) * a004 + r.zw;
}
float punctualLightIntensityToIrradianceFactor( const in float lightDistance, const in float cutoffDistance, const in float decayExponent ) {
#if defined ( PHYSICALLY_CORRECT_LIGHTS )
	float distanceFalloff = 1.0 / max( pow( lightDistance, decayExponent ), 0.01 );
	if( cutoffDistance > 0.0 ) {
		distanceFalloff *= pow2( saturate( 1.0 - pow4( lightDistance / cutoffDistance ) ) );
	}
	return distanceFalloff;
#else
	if( cutoffDistance > 0.0 && decayExponent > 0.0 ) {
		return pow( saturate( -lightDistance / cutoffDistance + 1.0 ), decayExponent );
	}
	return 1.0;
#endif
}
vec3 BRDF_Diffuse_Lambert( const in vec3 diffuseColor ) {
	return RECIPROCAL_PI * diffuseColor;
}
vec3 F_Schlick( const in vec3 specularColor, const in float dotLH ) {
	float fresnel = exp2( ( -5.55473 * dotLH - 6.98316 ) * dotLH );
	return ( 1.0 - specularColor ) * fresnel + specularColor;
}
vec3 F_Schlick_RoughnessDependent( const in vec3 F0, const in float dotNV, const in float roughness ) {
	float fresnel = exp2( ( -5.55473 * dotNV - 6.98316 ) * dotNV );
	vec3 Fr = max( vec3( 1.0 - roughness ), F0 ) - F0;
	return Fr * fresnel + F0;
}
float G_GGX_Smith( const in float alpha, const in float dotNL, const in float dotNV ) {
	float a2 = pow2( alpha );
	float gl = dotNL + sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNL ) );
	float gv = dotNV + sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNV ) );
	return 1.0 / ( gl * gv );
}
float G_GGX_SmithCorrelated( const in float alpha, const in float dotNL, const in float dotNV ) {
	float a2 = pow2( alpha );
	float gv = dotNL * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNV ) );
	float gl = dotNV * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNL ) );
	return 0.5 / max( gv + gl, EPSILON );
}
float D_GGX( const in float alpha, const in float dotNH ) {
	float a2 = pow2( alpha );
	float denom = pow2( dotNH ) * ( a2 - 1.0 ) + 1.0;
	return RECIPROCAL_PI * a2 / pow2( denom );
}
vec3 BRDF_Specular_GGX( const in IncidentLight incidentLight, const in vec3 viewDir, const in vec3 normal, const in vec3 specularColor, const in float roughness ) {
	float alpha = pow2( roughness );
	vec3 halfDir = normalize( incidentLight.direction + viewDir );
	float dotNL = saturate( dot( normal, incidentLight.direction ) );
	float dotNV = saturate( dot( normal, viewDir ) );
	float dotNH = saturate( dot( normal, halfDir ) );
	float dotLH = saturate( dot( incidentLight.direction, halfDir ) );
	vec3 F = F_Schlick( specularColor, dotLH );
	float G = G_GGX_SmithCorrelated( alpha, dotNL, dotNV );
	float D = D_GGX( alpha, dotNH );
	return F * ( G * D );
}
vec2 LTC_Uv( const in vec3 N, const in vec3 V, const in float roughness ) {
	const float LUT_SIZE  = 64.0;
	const float LUT_SCALE = ( LUT_SIZE - 1.0 ) / LUT_SIZE;
	const float LUT_BIAS  = 0.5 / LUT_SIZE;
	float dotNV = saturate( dot( N, V ) );
	vec2 uv = vec2( roughness, sqrt( 1.0 - dotNV ) );
	uv = uv * LUT_SCALE + LUT_BIAS;
	return uv;
}
float LTC_ClippedSphereFormFactor( const in vec3 f ) {
	float l = length( f );
	return max( ( l * l + f.z ) / ( l + 1.0 ), 0.0 );
}
vec3 LTC_EdgeVectorFormFactor( const in vec3 v1, const in vec3 v2 ) {
	float x = dot( v1, v2 );
	float y = abs( x );
	float a = 0.8543985 + ( 0.4965155 + 0.0145206 * y ) * y;
	float b = 3.4175940 + ( 4.1616724 + y ) * y;
	float v = a / b;
	float theta_sintheta = ( x > 0.0 ) ? v : 0.5 * inversesqrt( max( 1.0 - x * x, 1e-7 ) ) - v;
	return cross( v1, v2 ) * theta_sintheta;
}
vec3 LTC_Evaluate( const in vec3 N, const in vec3 V, const in vec3 P, const in mat3 mInv, const in vec3 rectCoords[ 4 ] ) {
	vec3 v1 = rectCoords[ 1 ] - rectCoords[ 0 ];
	vec3 v2 = rectCoords[ 3 ] - rectCoords[ 0 ];
	vec3 lightNormal = cross( v1, v2 );
	if( dot( lightNormal, P - rectCoords[ 0 ] ) < 0.0 ) return vec3( 0.0 );
	vec3 T1, T2;
	T1 = normalize( V - N * dot( V, N ) );
	T2 = - cross( N, T1 );
	mat3 mat = mInv * transposeMat3( mat3( T1, T2, N ) );
	vec3 coords[ 4 ];
	coords[ 0 ] = mat * ( rectCoords[ 0 ] - P );
	coords[ 1 ] = mat * ( rectCoords[ 1 ] - P );
	coords[ 2 ] = mat * ( rectCoords[ 2 ] - P );
	coords[ 3 ] = mat * ( rectCoords[ 3 ] - P );
	coords[ 0 ] = normalize( coords[ 0 ] );
	coords[ 1 ] = normalize( coords[ 1 ] );
	coords[ 2 ] = normalize( coords[ 2 ] );
	coords[ 3 ] = normalize( coords[ 3 ] );
	vec3 vectorFormFactor = vec3( 0.0 );
	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 0 ], coords[ 1 ] );
	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 1 ], coords[ 2 ] );
	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 2 ], coords[ 3 ] );
	vectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 3 ], coords[ 0 ] );
	float result = LTC_ClippedSphereFormFactor( vectorFormFactor );
	return vec3( result );
}
vec3 BRDF_Specular_GGX_Environment( const in vec3 viewDir, const in vec3 normal, const in vec3 specularColor, const in float roughness ) {
	float dotNV = saturate( dot( normal, viewDir ) );
	vec2 brdf = integrateSpecularBRDF( dotNV, roughness );
	return specularColor * brdf.x + brdf.y;
}
void BRDF_Specular_Multiscattering_Environment( const in GeometricContext geometry, const in vec3 specularColor, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {
	float dotNV = saturate( dot( geometry.normal, geometry.viewDir ) );
	vec3 F = F_Schlick_RoughnessDependent( specularColor, dotNV, roughness );
	vec2 brdf = integrateSpecularBRDF( dotNV, roughness );
	vec3 FssEss = F * brdf.x + brdf.y;
	float Ess = brdf.x + brdf.y;
	float Ems = 1.0 - Ess;
	vec3 Favg = specularColor + ( 1.0 - specularColor ) * 0.047619;	vec3 Fms = FssEss * Favg / ( 1.0 - Ems * Favg );
	singleScatter += FssEss;
	multiScatter += Fms * Ems;
}
float G_BlinnPhong_Implicit( ) {
	return 0.25;
}
float D_BlinnPhong( const in float shininess, const in float dotNH ) {
	return RECIPROCAL_PI * ( shininess * 0.5 + 1.0 ) * pow( dotNH, shininess );
}
vec3 BRDF_Specular_BlinnPhong( const in IncidentLight incidentLight, const in GeometricContext geometry, const in vec3 specularColor, const in float shininess ) {
	vec3 halfDir = normalize( incidentLight.direction + geometry.viewDir );
	float dotNH = saturate( dot( geometry.normal, halfDir ) );
	float dotLH = saturate( dot( incidentLight.direction, halfDir ) );
	vec3 F = F_Schlick( specularColor, dotLH );
	float G = G_BlinnPhong_Implicit( );
	float D = D_BlinnPhong( shininess, dotNH );
	return F * ( G * D );
}
float GGXRoughnessToBlinnExponent( const in float ggxRoughness ) {
	return ( 2.0 / pow2( ggxRoughness + 0.0001 ) - 2.0 );
}
float BlinnExponentToGGXRoughness( const in float blinnExponent ) {
	return sqrt( 2.0 / ( blinnExponent + 2.0 ) );
}
#if defined( USE_SHEEN )
float D_Charlie(float roughness, float NoH) {
	float invAlpha  = 1.0 / roughness;
	float cos2h = NoH * NoH;
	float sin2h = max(1.0 - cos2h, 0.0078125);	return (2.0 + invAlpha) * pow(sin2h, invAlpha * 0.5) / (2.0 * PI);
}
float V_Neubelt(float NoV, float NoL) {
	return saturate(1.0 / (4.0 * (NoL + NoV - NoL * NoV)));
}
vec3 BRDF_Specular_Sheen( const in float roughness, const in vec3 L, const in GeometricContext geometry, vec3 specularColor ) {
	vec3 N = geometry.normal;
	vec3 V = geometry.viewDir;
	vec3 H = normalize( V + L );
	float dotNH = saturate( dot( N, H ) );
	return specularColor * D_Charlie( roughness, dotNH ) * V_Neubelt( dot(N, V), dot(N, L) );
}
#endif`, V1 = `#ifdef USE_BUMPMAP
	uniform sampler2D bumpMap;
	uniform float bumpScale;
	vec2 dHdxy_fwd() {
		vec2 dSTdx = dFdx( vUv );
		vec2 dSTdy = dFdy( vUv );
		float Hll = bumpScale * texture2D( bumpMap, vUv ).x;
		float dBx = bumpScale * texture2D( bumpMap, vUv + dSTdx ).x - Hll;
		float dBy = bumpScale * texture2D( bumpMap, vUv + dSTdy ).x - Hll;
		return vec2( dBx, dBy );
	}
	vec3 perturbNormalArb( vec3 surf_pos, vec3 surf_norm, vec2 dHdxy ) {
		vec3 vSigmaX = vec3( dFdx( surf_pos.x ), dFdx( surf_pos.y ), dFdx( surf_pos.z ) );
		vec3 vSigmaY = vec3( dFdy( surf_pos.x ), dFdy( surf_pos.y ), dFdy( surf_pos.z ) );
		vec3 vN = surf_norm;
		vec3 R1 = cross( vSigmaY, vN );
		vec3 R2 = cross( vN, vSigmaX );
		float fDet = dot( vSigmaX, R1 );
		fDet *= ( float( gl_FrontFacing ) * 2.0 - 1.0 );
		vec3 vGrad = sign( fDet ) * ( dHdxy.x * R1 + dHdxy.y * R2 );
		return normalize( abs( fDet ) * surf_norm - vGrad );
	}
#endif`, j1 = `#if NUM_CLIPPING_PLANES > 0
	vec4 plane;
	#pragma unroll_loop_start
	for ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {
		plane = clippingPlanes[ i ];
		if ( dot( vClipPosition, plane.xyz ) > plane.w ) discard;
	}
	#pragma unroll_loop_end
	#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES
		bool clipped = true;
		#pragma unroll_loop_start
		for ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {
			plane = clippingPlanes[ i ];
			clipped = ( dot( vClipPosition, plane.xyz ) > plane.w ) && clipped;
		}
		#pragma unroll_loop_end
		if ( clipped ) discard;
	#endif
#endif`, W1 = `#if NUM_CLIPPING_PLANES > 0
	varying vec3 vClipPosition;
	uniform vec4 clippingPlanes[ NUM_CLIPPING_PLANES ];
#endif`, H1 = `#if NUM_CLIPPING_PLANES > 0
	varying vec3 vClipPosition;
#endif`, q1 = `#if NUM_CLIPPING_PLANES > 0
	vClipPosition = - mvPosition.xyz;
#endif`, K1 = `#ifdef USE_COLOR
	diffuseColor.rgb *= vColor;
#endif`, X1 = `#ifdef USE_COLOR
	varying vec3 vColor;
#endif`, Y1 = `#ifdef USE_COLOR
	varying vec3 vColor;
#endif`, J1 = `#ifdef USE_COLOR
	vColor.xyz = color.xyz;
#endif`, Q1 = `#define PI 3.141592653589793
#define PI2 6.283185307179586
#define PI_HALF 1.5707963267948966
#define RECIPROCAL_PI 0.3183098861837907
#define RECIPROCAL_PI2 0.15915494309189535
#define EPSILON 1e-6
#ifndef saturate
#define saturate(a) clamp( a, 0.0, 1.0 )
#endif
#define whiteComplement(a) ( 1.0 - saturate( a ) )
float pow2( const in float x ) { return x*x; }
float pow3( const in float x ) { return x*x*x; }
float pow4( const in float x ) { float x2 = x*x; return x2*x2; }
float average( const in vec3 color ) { return dot( color, vec3( 0.3333 ) ); }
highp float rand( const in vec2 uv ) {
	const highp float a = 12.9898, b = 78.233, c = 43758.5453;
	highp float dt = dot( uv.xy, vec2( a,b ) ), sn = mod( dt, PI );
	return fract(sin(sn) * c);
}
#ifdef HIGH_PRECISION
	float precisionSafeLength( vec3 v ) { return length( v ); }
#else
	float max3( vec3 v ) { return max( max( v.x, v.y ), v.z ); }
	float precisionSafeLength( vec3 v ) {
		float maxComponent = max3( abs( v ) );
		return length( v / maxComponent ) * maxComponent;
	}
#endif
struct IncidentLight {
	vec3 color;
	vec3 direction;
	bool visible;
};
struct ReflectedLight {
	vec3 directDiffuse;
	vec3 directSpecular;
	vec3 indirectDiffuse;
	vec3 indirectSpecular;
};
struct GeometricContext {
	vec3 position;
	vec3 normal;
	vec3 viewDir;
#ifdef CLEARCOAT
	vec3 clearcoatNormal;
#endif
};
vec3 transformDirection( in vec3 dir, in mat4 matrix ) {
	return normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );
}
vec3 inverseTransformDirection( in vec3 dir, in mat4 matrix ) {
	return normalize( ( vec4( dir, 0.0 ) * matrix ).xyz );
}
vec3 projectOnPlane(in vec3 point, in vec3 pointOnPlane, in vec3 planeNormal ) {
	float distance = dot( planeNormal, point - pointOnPlane );
	return - distance * planeNormal + point;
}
float sideOfPlane( in vec3 point, in vec3 pointOnPlane, in vec3 planeNormal ) {
	return sign( dot( point - pointOnPlane, planeNormal ) );
}
vec3 linePlaneIntersect( in vec3 pointOnLine, in vec3 lineDirection, in vec3 pointOnPlane, in vec3 planeNormal ) {
	return lineDirection * ( dot( planeNormal, pointOnPlane - pointOnLine ) / dot( planeNormal, lineDirection ) ) + pointOnLine;
}
mat3 transposeMat3( const in mat3 m ) {
	mat3 tmp;
	tmp[ 0 ] = vec3( m[ 0 ].x, m[ 1 ].x, m[ 2 ].x );
	tmp[ 1 ] = vec3( m[ 0 ].y, m[ 1 ].y, m[ 2 ].y );
	tmp[ 2 ] = vec3( m[ 0 ].z, m[ 1 ].z, m[ 2 ].z );
	return tmp;
}
float linearToRelativeLuminance( const in vec3 color ) {
	vec3 weights = vec3( 0.2126, 0.7152, 0.0722 );
	return dot( weights, color.rgb );
}
bool isPerspectiveMatrix( mat4 m ) {
	return m[ 2 ][ 3 ] == - 1.0;
}
vec2 equirectUv( in vec3 dir ) {
	float u = atan( dir.z, dir.x ) * RECIPROCAL_PI2 + 0.5;
	float v = asin( clamp( dir.y, - 1.0, 1.0 ) ) * RECIPROCAL_PI + 0.5;
	return vec2( u, v );
}`, Z1 = `#ifdef ENVMAP_TYPE_CUBE_UV
#define cubeUV_maxMipLevel 8.0
#define cubeUV_minMipLevel 4.0
#define cubeUV_maxTileSize 256.0
#define cubeUV_minTileSize 16.0
float getFace(vec3 direction) {
    vec3 absDirection = abs(direction);
    float face = -1.0;
    if (absDirection.x > absDirection.z) {
      if (absDirection.x > absDirection.y)
        face = direction.x > 0.0 ? 0.0 : 3.0;
      else
        face = direction.y > 0.0 ? 1.0 : 4.0;
    } else {
      if (absDirection.z > absDirection.y)
        face = direction.z > 0.0 ? 2.0 : 5.0;
      else
        face = direction.y > 0.0 ? 1.0 : 4.0;
    }
    return face;
}
vec2 getUV(vec3 direction, float face) {
    vec2 uv;
    if (face == 0.0) {
      uv = vec2(direction.z, direction.y) / abs(direction.x);    } else if (face == 1.0) {
      uv = vec2(-direction.x, -direction.z) / abs(direction.y);    } else if (face == 2.0) {
      uv = vec2(-direction.x, direction.y) / abs(direction.z);    } else if (face == 3.0) {
      uv = vec2(-direction.z, direction.y) / abs(direction.x);    } else if (face == 4.0) {
      uv = vec2(-direction.x, direction.z) / abs(direction.y);    } else {
      uv = vec2(direction.x, direction.y) / abs(direction.z);    }
    return 0.5 * (uv + 1.0);
}
vec3 bilinearCubeUV(sampler2D envMap, vec3 direction, float mipInt) {
  float face = getFace(direction);
  float filterInt = max(cubeUV_minMipLevel - mipInt, 0.0);
  mipInt = max(mipInt, cubeUV_minMipLevel);
  float faceSize = exp2(mipInt);
  float texelSize = 1.0 / (3.0 * cubeUV_maxTileSize);
  vec2 uv = getUV(direction, face) * (faceSize - 1.0);
  vec2 f = fract(uv);
  uv += 0.5 - f;
  if (face > 2.0) {
    uv.y += faceSize;
    face -= 3.0;
  }
  uv.x += face * faceSize;
  if(mipInt < cubeUV_maxMipLevel){
    uv.y += 2.0 * cubeUV_maxTileSize;
  }
  uv.y += filterInt * 2.0 * cubeUV_minTileSize;
  uv.x += 3.0 * max(0.0, cubeUV_maxTileSize - 2.0 * faceSize);
  uv *= texelSize;
  vec3 tl = envMapTexelToLinear(texture2D(envMap, uv)).rgb;
  uv.x += texelSize;
  vec3 tr = envMapTexelToLinear(texture2D(envMap, uv)).rgb;
  uv.y += texelSize;
  vec3 br = envMapTexelToLinear(texture2D(envMap, uv)).rgb;
  uv.x -= texelSize;
  vec3 bl = envMapTexelToLinear(texture2D(envMap, uv)).rgb;
  vec3 tm = mix(tl, tr, f.x);
  vec3 bm = mix(bl, br, f.x);
  return mix(tm, bm, f.y);
}
#define r0 1.0
#define v0 0.339
#define m0 -2.0
#define r1 0.8
#define v1 0.276
#define m1 -1.0
#define r4 0.4
#define v4 0.046
#define m4 2.0
#define r5 0.305
#define v5 0.016
#define m5 3.0
#define r6 0.21
#define v6 0.0038
#define m6 4.0
float roughnessToMip(float roughness) {
  float mip = 0.0;
  if (roughness >= r1) {
    mip = (r0 - roughness) * (m1 - m0) / (r0 - r1) + m0;
  } else if (roughness >= r4) {
    mip = (r1 - roughness) * (m4 - m1) / (r1 - r4) + m1;
  } else if (roughness >= r5) {
    mip = (r4 - roughness) * (m5 - m4) / (r4 - r5) + m4;
  } else if (roughness >= r6) {
    mip = (r5 - roughness) * (m6 - m5) / (r5 - r6) + m5;
  } else {
    mip = -2.0 * log2(1.16 * roughness);  }
  return mip;
}
vec4 textureCubeUV(sampler2D envMap, vec3 sampleDir, float roughness) {
  float mip = clamp(roughnessToMip(roughness), m0, cubeUV_maxMipLevel);
  float mipF = fract(mip);
  float mipInt = floor(mip);
  vec3 color0 = bilinearCubeUV(envMap, sampleDir, mipInt);
  if (mipF == 0.0) {
    return vec4(color0, 1.0);
  } else {
    vec3 color1 = bilinearCubeUV(envMap, sampleDir, mipInt + 1.0);
    return vec4(mix(color0, color1, mipF), 1.0);
  }
}
#endif`, eT = `vec3 transformedNormal = objectNormal;
#ifdef USE_INSTANCING
	mat3 m = mat3( instanceMatrix );
	transformedNormal /= vec3( dot( m[ 0 ], m[ 0 ] ), dot( m[ 1 ], m[ 1 ] ), dot( m[ 2 ], m[ 2 ] ) );
	transformedNormal = m * transformedNormal;
#endif
transformedNormal = normalMatrix * transformedNormal;
#ifdef FLIP_SIDED
	transformedNormal = - transformedNormal;
#endif
#ifdef USE_TANGENT
	vec3 transformedTangent = ( modelViewMatrix * vec4( objectTangent, 0.0 ) ).xyz;
	#ifdef FLIP_SIDED
		transformedTangent = - transformedTangent;
	#endif
#endif`, tT = `#ifdef USE_DISPLACEMENTMAP
	uniform sampler2D displacementMap;
	uniform float displacementScale;
	uniform float displacementBias;
#endif`, nT = `#ifdef USE_DISPLACEMENTMAP
	transformed += normalize( objectNormal ) * ( texture2D( displacementMap, vUv ).x * displacementScale + displacementBias );
#endif`, iT = `#ifdef USE_EMISSIVEMAP
	vec4 emissiveColor = texture2D( emissiveMap, vUv );
	emissiveColor.rgb = emissiveMapTexelToLinear( emissiveColor ).rgb;
	totalEmissiveRadiance *= emissiveColor.rgb;
#endif`, sT = `#ifdef USE_EMISSIVEMAP
	uniform sampler2D emissiveMap;
#endif`, rT = "gl_FragColor = linearToOutputTexel( gl_FragColor );", oT = `
vec4 LinearToLinear( in vec4 value ) {
	return value;
}
vec4 GammaToLinear( in vec4 value, in float gammaFactor ) {
	return vec4( pow( value.rgb, vec3( gammaFactor ) ), value.a );
}
vec4 LinearToGamma( in vec4 value, in float gammaFactor ) {
	return vec4( pow( value.rgb, vec3( 1.0 / gammaFactor ) ), value.a );
}
vec4 sRGBToLinear( in vec4 value ) {
	return vec4( mix( pow( value.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), value.rgb * 0.0773993808, vec3( lessThanEqual( value.rgb, vec3( 0.04045 ) ) ) ), value.a );
}
vec4 LinearTosRGB( in vec4 value ) {
	return vec4( mix( pow( value.rgb, vec3( 0.41666 ) ) * 1.055 - vec3( 0.055 ), value.rgb * 12.92, vec3( lessThanEqual( value.rgb, vec3( 0.0031308 ) ) ) ), value.a );
}
vec4 RGBEToLinear( in vec4 value ) {
	return vec4( value.rgb * exp2( value.a * 255.0 - 128.0 ), 1.0 );
}
vec4 LinearToRGBE( in vec4 value ) {
	float maxComponent = max( max( value.r, value.g ), value.b );
	float fExp = clamp( ceil( log2( maxComponent ) ), -128.0, 127.0 );
	return vec4( value.rgb / exp2( fExp ), ( fExp + 128.0 ) / 255.0 );
}
vec4 RGBMToLinear( in vec4 value, in float maxRange ) {
	return vec4( value.rgb * value.a * maxRange, 1.0 );
}
vec4 LinearToRGBM( in vec4 value, in float maxRange ) {
	float maxRGB = max( value.r, max( value.g, value.b ) );
	float M = clamp( maxRGB / maxRange, 0.0, 1.0 );
	M = ceil( M * 255.0 ) / 255.0;
	return vec4( value.rgb / ( M * maxRange ), M );
}
vec4 RGBDToLinear( in vec4 value, in float maxRange ) {
	return vec4( value.rgb * ( ( maxRange / 255.0 ) / value.a ), 1.0 );
}
vec4 LinearToRGBD( in vec4 value, in float maxRange ) {
	float maxRGB = max( value.r, max( value.g, value.b ) );
	float D = max( maxRange / maxRGB, 1.0 );
	D = clamp( floor( D ) / 255.0, 0.0, 1.0 );
	return vec4( value.rgb * ( D * ( 255.0 / maxRange ) ), D );
}
const mat3 cLogLuvM = mat3( 0.2209, 0.3390, 0.4184, 0.1138, 0.6780, 0.7319, 0.0102, 0.1130, 0.2969 );
vec4 LinearToLogLuv( in vec4 value )  {
	vec3 Xp_Y_XYZp = cLogLuvM * value.rgb;
	Xp_Y_XYZp = max( Xp_Y_XYZp, vec3( 1e-6, 1e-6, 1e-6 ) );
	vec4 vResult;
	vResult.xy = Xp_Y_XYZp.xy / Xp_Y_XYZp.z;
	float Le = 2.0 * log2(Xp_Y_XYZp.y) + 127.0;
	vResult.w = fract( Le );
	vResult.z = ( Le - ( floor( vResult.w * 255.0 ) ) / 255.0 ) / 255.0;
	return vResult;
}
const mat3 cLogLuvInverseM = mat3( 6.0014, -2.7008, -1.7996, -1.3320, 3.1029, -5.7721, 0.3008, -1.0882, 5.6268 );
vec4 LogLuvToLinear( in vec4 value ) {
	float Le = value.z * 255.0 + value.w;
	vec3 Xp_Y_XYZp;
	Xp_Y_XYZp.y = exp2( ( Le - 127.0 ) / 2.0 );
	Xp_Y_XYZp.z = Xp_Y_XYZp.y / value.y;
	Xp_Y_XYZp.x = value.x * Xp_Y_XYZp.z;
	vec3 vRGB = cLogLuvInverseM * Xp_Y_XYZp.rgb;
	return vec4( max( vRGB, 0.0 ), 1.0 );
}`, aT = `#ifdef USE_ENVMAP
	#ifdef ENV_WORLDPOS
		vec3 cameraToFrag;
		
		if ( isOrthographic ) {
			cameraToFrag = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );
		}  else {
			cameraToFrag = normalize( vWorldPosition - cameraPosition );
		}
		vec3 worldNormal = inverseTransformDirection( normal, viewMatrix );
		#ifdef ENVMAP_MODE_REFLECTION
			vec3 reflectVec = reflect( cameraToFrag, worldNormal );
		#else
			vec3 reflectVec = refract( cameraToFrag, worldNormal, refractionRatio );
		#endif
	#else
		vec3 reflectVec = vReflect;
	#endif
	#ifdef ENVMAP_TYPE_CUBE
		vec4 envColor = textureCube( envMap, vec3( flipEnvMap * reflectVec.x, reflectVec.yz ) );
	#elif defined( ENVMAP_TYPE_CUBE_UV )
		vec4 envColor = textureCubeUV( envMap, reflectVec, 0.0 );
	#elif defined( ENVMAP_TYPE_EQUIREC )
		reflectVec = normalize( reflectVec );
		vec2 sampleUV = equirectUv( reflectVec );
		vec4 envColor = texture2D( envMap, sampleUV );
	#else
		vec4 envColor = vec4( 0.0 );
	#endif
	#ifndef ENVMAP_TYPE_CUBE_UV
		envColor = envMapTexelToLinear( envColor );
	#endif
	#ifdef ENVMAP_BLENDING_MULTIPLY
		outgoingLight = mix( outgoingLight, outgoingLight * envColor.xyz, specularStrength * reflectivity );
	#elif defined( ENVMAP_BLENDING_MIX )
		outgoingLight = mix( outgoingLight, envColor.xyz, specularStrength * reflectivity );
	#elif defined( ENVMAP_BLENDING_ADD )
		outgoingLight += envColor.xyz * specularStrength * reflectivity;
	#endif
#endif`, lT = `#ifdef USE_ENVMAP
	uniform float envMapIntensity;
	uniform float flipEnvMap;
	uniform int maxMipLevel;
	#ifdef ENVMAP_TYPE_CUBE
		uniform samplerCube envMap;
	#else
		uniform sampler2D envMap;
	#endif
	
#endif`, cT = `#ifdef USE_ENVMAP
	uniform float reflectivity;
	#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG )
		#define ENV_WORLDPOS
	#endif
	#ifdef ENV_WORLDPOS
		varying vec3 vWorldPosition;
		uniform float refractionRatio;
	#else
		varying vec3 vReflect;
	#endif
#endif`, uT = `#ifdef USE_ENVMAP
	#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) ||defined( PHONG )
		#define ENV_WORLDPOS
	#endif
	#ifdef ENV_WORLDPOS
		
		varying vec3 vWorldPosition;
	#else
		varying vec3 vReflect;
		uniform float refractionRatio;
	#endif
#endif`, dT = `#ifdef USE_ENVMAP
	#ifdef ENV_WORLDPOS
		vWorldPosition = worldPosition.xyz;
	#else
		vec3 cameraToVertex;
		if ( isOrthographic ) {
			cameraToVertex = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );
		} else {
			cameraToVertex = normalize( worldPosition.xyz - cameraPosition );
		}
		vec3 worldNormal = inverseTransformDirection( transformedNormal, viewMatrix );
		#ifdef ENVMAP_MODE_REFLECTION
			vReflect = reflect( cameraToVertex, worldNormal );
		#else
			vReflect = refract( cameraToVertex, worldNormal, refractionRatio );
		#endif
	#endif
#endif`, hT = `#ifdef USE_FOG
	fogDepth = - mvPosition.z;
#endif`, fT = `#ifdef USE_FOG
	varying float fogDepth;
#endif`, pT = `#ifdef USE_FOG
	#ifdef FOG_EXP2
		float fogFactor = 1.0 - exp( - fogDensity * fogDensity * fogDepth * fogDepth );
	#else
		float fogFactor = smoothstep( fogNear, fogFar, fogDepth );
	#endif
	gl_FragColor.rgb = mix( gl_FragColor.rgb, fogColor, fogFactor );
#endif`, mT = `#ifdef USE_FOG
	uniform vec3 fogColor;
	varying float fogDepth;
	#ifdef FOG_EXP2
		uniform float fogDensity;
	#else
		uniform float fogNear;
		uniform float fogFar;
	#endif
#endif`, gT = `#ifdef USE_GRADIENTMAP
	uniform sampler2D gradientMap;
#endif
vec3 getGradientIrradiance( vec3 normal, vec3 lightDirection ) {
	float dotNL = dot( normal, lightDirection );
	vec2 coord = vec2( dotNL * 0.5 + 0.5, 0.0 );
	#ifdef USE_GRADIENTMAP
		return texture2D( gradientMap, coord ).rgb;
	#else
		return ( coord.x < 0.7 ) ? vec3( 0.7 ) : vec3( 1.0 );
	#endif
}`, _T = `#ifdef USE_LIGHTMAP
	vec4 lightMapTexel= texture2D( lightMap, vUv2 );
	reflectedLight.indirectDiffuse += PI * lightMapTexelToLinear( lightMapTexel ).rgb * lightMapIntensity;
#endif`, yT = `#ifdef USE_LIGHTMAP
	uniform sampler2D lightMap;
	uniform float lightMapIntensity;
#endif`, vT = `vec3 diffuse = vec3( 1.0 );
GeometricContext geometry;
geometry.position = mvPosition.xyz;
geometry.normal = normalize( transformedNormal );
geometry.viewDir = ( isOrthographic ) ? vec3( 0, 0, 1 ) : normalize( -mvPosition.xyz );
GeometricContext backGeometry;
backGeometry.position = geometry.position;
backGeometry.normal = -geometry.normal;
backGeometry.viewDir = geometry.viewDir;
vLightFront = vec3( 0.0 );
vIndirectFront = vec3( 0.0 );
#ifdef DOUBLE_SIDED
	vLightBack = vec3( 0.0 );
	vIndirectBack = vec3( 0.0 );
#endif
IncidentLight directLight;
float dotNL;
vec3 directLightColor_Diffuse;
vIndirectFront += getAmbientLightIrradiance( ambientLightColor );
vIndirectFront += getLightProbeIrradiance( lightProbe, geometry );
#ifdef DOUBLE_SIDED
	vIndirectBack += getAmbientLightIrradiance( ambientLightColor );
	vIndirectBack += getLightProbeIrradiance( lightProbe, backGeometry );
#endif
#if NUM_POINT_LIGHTS > 0
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_POINT_LIGHTS; i ++ ) {
		getPointDirectLightIrradiance( pointLights[ i ], geometry, directLight );
		dotNL = dot( geometry.normal, directLight.direction );
		directLightColor_Diffuse = PI * directLight.color;
		vLightFront += saturate( dotNL ) * directLightColor_Diffuse;
		#ifdef DOUBLE_SIDED
			vLightBack += saturate( -dotNL ) * directLightColor_Diffuse;
		#endif
	}
	#pragma unroll_loop_end
#endif
#if NUM_SPOT_LIGHTS > 0
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_SPOT_LIGHTS; i ++ ) {
		getSpotDirectLightIrradiance( spotLights[ i ], geometry, directLight );
		dotNL = dot( geometry.normal, directLight.direction );
		directLightColor_Diffuse = PI * directLight.color;
		vLightFront += saturate( dotNL ) * directLightColor_Diffuse;
		#ifdef DOUBLE_SIDED
			vLightBack += saturate( -dotNL ) * directLightColor_Diffuse;
		#endif
	}
	#pragma unroll_loop_end
#endif
#if NUM_DIR_LIGHTS > 0
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_DIR_LIGHTS; i ++ ) {
		getDirectionalDirectLightIrradiance( directionalLights[ i ], geometry, directLight );
		dotNL = dot( geometry.normal, directLight.direction );
		directLightColor_Diffuse = PI * directLight.color;
		vLightFront += saturate( dotNL ) * directLightColor_Diffuse;
		#ifdef DOUBLE_SIDED
			vLightBack += saturate( -dotNL ) * directLightColor_Diffuse;
		#endif
	}
	#pragma unroll_loop_end
#endif
#if NUM_HEMI_LIGHTS > 0
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_HEMI_LIGHTS; i ++ ) {
		vIndirectFront += getHemisphereLightIrradiance( hemisphereLights[ i ], geometry );
		#ifdef DOUBLE_SIDED
			vIndirectBack += getHemisphereLightIrradiance( hemisphereLights[ i ], backGeometry );
		#endif
	}
	#pragma unroll_loop_end
#endif`, wT = `uniform bool receiveShadow;
uniform vec3 ambientLightColor;
uniform vec3 lightProbe[ 9 ];
vec3 shGetIrradianceAt( in vec3 normal, in vec3 shCoefficients[ 9 ] ) {
	float x = normal.x, y = normal.y, z = normal.z;
	vec3 result = shCoefficients[ 0 ] * 0.886227;
	result += shCoefficients[ 1 ] * 2.0 * 0.511664 * y;
	result += shCoefficients[ 2 ] * 2.0 * 0.511664 * z;
	result += shCoefficients[ 3 ] * 2.0 * 0.511664 * x;
	result += shCoefficients[ 4 ] * 2.0 * 0.429043 * x * y;
	result += shCoefficients[ 5 ] * 2.0 * 0.429043 * y * z;
	result += shCoefficients[ 6 ] * ( 0.743125 * z * z - 0.247708 );
	result += shCoefficients[ 7 ] * 2.0 * 0.429043 * x * z;
	result += shCoefficients[ 8 ] * 0.429043 * ( x * x - y * y );
	return result;
}
vec3 getLightProbeIrradiance( const in vec3 lightProbe[ 9 ], const in GeometricContext geometry ) {
	vec3 worldNormal = inverseTransformDirection( geometry.normal, viewMatrix );
	vec3 irradiance = shGetIrradianceAt( worldNormal, lightProbe );
	return irradiance;
}
vec3 getAmbientLightIrradiance( const in vec3 ambientLightColor ) {
	vec3 irradiance = ambientLightColor;
	#ifndef PHYSICALLY_CORRECT_LIGHTS
		irradiance *= PI;
	#endif
	return irradiance;
}
#if NUM_DIR_LIGHTS > 0
	struct DirectionalLight {
		vec3 direction;
		vec3 color;
	};
	uniform DirectionalLight directionalLights[ NUM_DIR_LIGHTS ];
	void getDirectionalDirectLightIrradiance( const in DirectionalLight directionalLight, const in GeometricContext geometry, out IncidentLight directLight ) {
		directLight.color = directionalLight.color;
		directLight.direction = directionalLight.direction;
		directLight.visible = true;
	}
#endif
#if NUM_POINT_LIGHTS > 0
	struct PointLight {
		vec3 position;
		vec3 color;
		float distance;
		float decay;
	};
	uniform PointLight pointLights[ NUM_POINT_LIGHTS ];
	void getPointDirectLightIrradiance( const in PointLight pointLight, const in GeometricContext geometry, out IncidentLight directLight ) {
		vec3 lVector = pointLight.position - geometry.position;
		directLight.direction = normalize( lVector );
		float lightDistance = length( lVector );
		directLight.color = pointLight.color;
		directLight.color *= punctualLightIntensityToIrradianceFactor( lightDistance, pointLight.distance, pointLight.decay );
		directLight.visible = ( directLight.color != vec3( 0.0 ) );
	}
#endif
#if NUM_SPOT_LIGHTS > 0
	struct SpotLight {
		vec3 position;
		vec3 direction;
		vec3 color;
		float distance;
		float decay;
		float coneCos;
		float penumbraCos;
	};
	uniform SpotLight spotLights[ NUM_SPOT_LIGHTS ];
	void getSpotDirectLightIrradiance( const in SpotLight spotLight, const in GeometricContext geometry, out IncidentLight directLight  ) {
		vec3 lVector = spotLight.position - geometry.position;
		directLight.direction = normalize( lVector );
		float lightDistance = length( lVector );
		float angleCos = dot( directLight.direction, spotLight.direction );
		if ( angleCos > spotLight.coneCos ) {
			float spotEffect = smoothstep( spotLight.coneCos, spotLight.penumbraCos, angleCos );
			directLight.color = spotLight.color;
			directLight.color *= spotEffect * punctualLightIntensityToIrradianceFactor( lightDistance, spotLight.distance, spotLight.decay );
			directLight.visible = true;
		} else {
			directLight.color = vec3( 0.0 );
			directLight.visible = false;
		}
	}
#endif
#if NUM_RECT_AREA_LIGHTS > 0
	struct RectAreaLight {
		vec3 color;
		vec3 position;
		vec3 halfWidth;
		vec3 halfHeight;
	};
	uniform sampler2D ltc_1;	uniform sampler2D ltc_2;
	uniform RectAreaLight rectAreaLights[ NUM_RECT_AREA_LIGHTS ];
#endif
#if NUM_HEMI_LIGHTS > 0
	struct HemisphereLight {
		vec3 direction;
		vec3 skyColor;
		vec3 groundColor;
	};
	uniform HemisphereLight hemisphereLights[ NUM_HEMI_LIGHTS ];
	vec3 getHemisphereLightIrradiance( const in HemisphereLight hemiLight, const in GeometricContext geometry ) {
		float dotNL = dot( geometry.normal, hemiLight.direction );
		float hemiDiffuseWeight = 0.5 * dotNL + 0.5;
		vec3 irradiance = mix( hemiLight.groundColor, hemiLight.skyColor, hemiDiffuseWeight );
		#ifndef PHYSICALLY_CORRECT_LIGHTS
			irradiance *= PI;
		#endif
		return irradiance;
	}
#endif`, xT = `#if defined( USE_ENVMAP )
	#ifdef ENVMAP_MODE_REFRACTION
		uniform float refractionRatio;
	#endif
	vec3 getLightProbeIndirectIrradiance( const in GeometricContext geometry, const in int maxMIPLevel ) {
		vec3 worldNormal = inverseTransformDirection( geometry.normal, viewMatrix );
		#ifdef ENVMAP_TYPE_CUBE
			vec3 queryVec = vec3( flipEnvMap * worldNormal.x, worldNormal.yz );
			#ifdef TEXTURE_LOD_EXT
				vec4 envMapColor = textureCubeLodEXT( envMap, queryVec, float( maxMIPLevel ) );
			#else
				vec4 envMapColor = textureCube( envMap, queryVec, float( maxMIPLevel ) );
			#endif
			envMapColor.rgb = envMapTexelToLinear( envMapColor ).rgb;
		#elif defined( ENVMAP_TYPE_CUBE_UV )
			vec4 envMapColor = textureCubeUV( envMap, worldNormal, 1.0 );
		#else
			vec4 envMapColor = vec4( 0.0 );
		#endif
		return PI * envMapColor.rgb * envMapIntensity;
	}
	float getSpecularMIPLevel( const in float roughness, const in int maxMIPLevel ) {
		float maxMIPLevelScalar = float( maxMIPLevel );
		float sigma = PI * roughness * roughness / ( 1.0 + roughness );
		float desiredMIPLevel = maxMIPLevelScalar + log2( sigma );
		return clamp( desiredMIPLevel, 0.0, maxMIPLevelScalar );
	}
	vec3 getLightProbeIndirectRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness, const in int maxMIPLevel ) {
		#ifdef ENVMAP_MODE_REFLECTION
		  vec3 reflectVec = reflect( -viewDir, normal );
		  reflectVec = normalize( mix( reflectVec, normal, roughness * roughness) );
		#else
		  vec3 reflectVec = refract( -viewDir, normal, refractionRatio );
		#endif
		reflectVec = inverseTransformDirection( reflectVec, viewMatrix );
		float specularMIPLevel = getSpecularMIPLevel( roughness, maxMIPLevel );
		#ifdef ENVMAP_TYPE_CUBE
			vec3 queryReflectVec = vec3( flipEnvMap * reflectVec.x, reflectVec.yz );
			#ifdef TEXTURE_LOD_EXT
				vec4 envMapColor = textureCubeLodEXT( envMap, queryReflectVec, specularMIPLevel );
			#else
				vec4 envMapColor = textureCube( envMap, queryReflectVec, specularMIPLevel );
			#endif
			envMapColor.rgb = envMapTexelToLinear( envMapColor ).rgb;
		#elif defined( ENVMAP_TYPE_CUBE_UV )
			vec4 envMapColor = textureCubeUV( envMap, reflectVec, roughness );
		#elif defined( ENVMAP_TYPE_EQUIREC )
			vec2 sampleUV = equirectUv( reflectVec );
			#ifdef TEXTURE_LOD_EXT
				vec4 envMapColor = texture2DLodEXT( envMap, sampleUV, specularMIPLevel );
			#else
				vec4 envMapColor = texture2D( envMap, sampleUV, specularMIPLevel );
			#endif
			envMapColor.rgb = envMapTexelToLinear( envMapColor ).rgb;
		#endif
		return envMapColor.rgb * envMapIntensity;
	}
#endif`, bT = `ToonMaterial material;
material.diffuseColor = diffuseColor.rgb;`, MT = `varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
#endif
struct ToonMaterial {
	vec3 diffuseColor;
};
void RE_Direct_Toon( const in IncidentLight directLight, const in GeometricContext geometry, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {
	vec3 irradiance = getGradientIrradiance( geometry.normal, directLight.direction ) * directLight.color;
	#ifndef PHYSICALLY_CORRECT_LIGHTS
		irradiance *= PI;
	#endif
	reflectedLight.directDiffuse += irradiance * BRDF_Diffuse_Lambert( material.diffuseColor );
}
void RE_IndirectDiffuse_Toon( const in vec3 irradiance, const in GeometricContext geometry, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {
	reflectedLight.indirectDiffuse += irradiance * BRDF_Diffuse_Lambert( material.diffuseColor );
}
#define RE_Direct				RE_Direct_Toon
#define RE_IndirectDiffuse		RE_IndirectDiffuse_Toon
#define Material_LightProbeLOD( material )	(0)`, TT = `BlinnPhongMaterial material;
material.diffuseColor = diffuseColor.rgb;
material.specularColor = specular;
material.specularShininess = shininess;
material.specularStrength = specularStrength;`, ET = `varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
#endif
struct BlinnPhongMaterial {
	vec3 diffuseColor;
	vec3 specularColor;
	float specularShininess;
	float specularStrength;
};
void RE_Direct_BlinnPhong( const in IncidentLight directLight, const in GeometricContext geometry, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {
	float dotNL = saturate( dot( geometry.normal, directLight.direction ) );
	vec3 irradiance = dotNL * directLight.color;
	#ifndef PHYSICALLY_CORRECT_LIGHTS
		irradiance *= PI;
	#endif
	reflectedLight.directDiffuse += irradiance * BRDF_Diffuse_Lambert( material.diffuseColor );
	reflectedLight.directSpecular += irradiance * BRDF_Specular_BlinnPhong( directLight, geometry, material.specularColor, material.specularShininess ) * material.specularStrength;
}
void RE_IndirectDiffuse_BlinnPhong( const in vec3 irradiance, const in GeometricContext geometry, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {
	reflectedLight.indirectDiffuse += irradiance * BRDF_Diffuse_Lambert( material.diffuseColor );
}
#define RE_Direct				RE_Direct_BlinnPhong
#define RE_IndirectDiffuse		RE_IndirectDiffuse_BlinnPhong
#define Material_LightProbeLOD( material )	(0)`, ST = `PhysicalMaterial material;
material.diffuseColor = diffuseColor.rgb * ( 1.0 - metalnessFactor );
vec3 dxy = max( abs( dFdx( geometryNormal ) ), abs( dFdy( geometryNormal ) ) );
float geometryRoughness = max( max( dxy.x, dxy.y ), dxy.z );
material.specularRoughness = max( roughnessFactor, 0.0525 );material.specularRoughness += geometryRoughness;
material.specularRoughness = min( material.specularRoughness, 1.0 );
#ifdef REFLECTIVITY
	material.specularColor = mix( vec3( MAXIMUM_SPECULAR_COEFFICIENT * pow2( reflectivity ) ), diffuseColor.rgb, metalnessFactor );
#else
	material.specularColor = mix( vec3( DEFAULT_SPECULAR_COEFFICIENT ), diffuseColor.rgb, metalnessFactor );
#endif
#ifdef CLEARCOAT
	material.clearcoat = clearcoat;
	material.clearcoatRoughness = clearcoatRoughness;
	#ifdef USE_CLEARCOATMAP
		material.clearcoat *= texture2D( clearcoatMap, vUv ).x;
	#endif
	#ifdef USE_CLEARCOAT_ROUGHNESSMAP
		material.clearcoatRoughness *= texture2D( clearcoatRoughnessMap, vUv ).y;
	#endif
	material.clearcoat = saturate( material.clearcoat );	material.clearcoatRoughness = max( material.clearcoatRoughness, 0.0525 );
	material.clearcoatRoughness += geometryRoughness;
	material.clearcoatRoughness = min( material.clearcoatRoughness, 1.0 );
#endif
#ifdef USE_SHEEN
	material.sheenColor = sheen;
#endif`, PT = `struct PhysicalMaterial {
	vec3 diffuseColor;
	float specularRoughness;
	vec3 specularColor;
#ifdef CLEARCOAT
	float clearcoat;
	float clearcoatRoughness;
#endif
#ifdef USE_SHEEN
	vec3 sheenColor;
#endif
};
#define MAXIMUM_SPECULAR_COEFFICIENT 0.16
#define DEFAULT_SPECULAR_COEFFICIENT 0.04
float clearcoatDHRApprox( const in float roughness, const in float dotNL ) {
	return DEFAULT_SPECULAR_COEFFICIENT + ( 1.0 - DEFAULT_SPECULAR_COEFFICIENT ) * ( pow( 1.0 - dotNL, 5.0 ) * pow( 1.0 - roughness, 2.0 ) );
}
#if NUM_RECT_AREA_LIGHTS > 0
	void RE_Direct_RectArea_Physical( const in RectAreaLight rectAreaLight, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {
		vec3 normal = geometry.normal;
		vec3 viewDir = geometry.viewDir;
		vec3 position = geometry.position;
		vec3 lightPos = rectAreaLight.position;
		vec3 halfWidth = rectAreaLight.halfWidth;
		vec3 halfHeight = rectAreaLight.halfHeight;
		vec3 lightColor = rectAreaLight.color;
		float roughness = material.specularRoughness;
		vec3 rectCoords[ 4 ];
		rectCoords[ 0 ] = lightPos + halfWidth - halfHeight;		rectCoords[ 1 ] = lightPos - halfWidth - halfHeight;
		rectCoords[ 2 ] = lightPos - halfWidth + halfHeight;
		rectCoords[ 3 ] = lightPos + halfWidth + halfHeight;
		vec2 uv = LTC_Uv( normal, viewDir, roughness );
		vec4 t1 = texture2D( ltc_1, uv );
		vec4 t2 = texture2D( ltc_2, uv );
		mat3 mInv = mat3(
			vec3( t1.x, 0, t1.y ),
			vec3(    0, 1,    0 ),
			vec3( t1.z, 0, t1.w )
		);
		vec3 fresnel = ( material.specularColor * t2.x + ( vec3( 1.0 ) - material.specularColor ) * t2.y );
		reflectedLight.directSpecular += lightColor * fresnel * LTC_Evaluate( normal, viewDir, position, mInv, rectCoords );
		reflectedLight.directDiffuse += lightColor * material.diffuseColor * LTC_Evaluate( normal, viewDir, position, mat3( 1.0 ), rectCoords );
	}
#endif
void RE_Direct_Physical( const in IncidentLight directLight, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {
	float dotNL = saturate( dot( geometry.normal, directLight.direction ) );
	vec3 irradiance = dotNL * directLight.color;
	#ifndef PHYSICALLY_CORRECT_LIGHTS
		irradiance *= PI;
	#endif
	#ifdef CLEARCOAT
		float ccDotNL = saturate( dot( geometry.clearcoatNormal, directLight.direction ) );
		vec3 ccIrradiance = ccDotNL * directLight.color;
		#ifndef PHYSICALLY_CORRECT_LIGHTS
			ccIrradiance *= PI;
		#endif
		float clearcoatDHR = material.clearcoat * clearcoatDHRApprox( material.clearcoatRoughness, ccDotNL );
		reflectedLight.directSpecular += ccIrradiance * material.clearcoat * BRDF_Specular_GGX( directLight, geometry.viewDir, geometry.clearcoatNormal, vec3( DEFAULT_SPECULAR_COEFFICIENT ), material.clearcoatRoughness );
	#else
		float clearcoatDHR = 0.0;
	#endif
	#ifdef USE_SHEEN
		reflectedLight.directSpecular += ( 1.0 - clearcoatDHR ) * irradiance * BRDF_Specular_Sheen(
			material.specularRoughness,
			directLight.direction,
			geometry,
			material.sheenColor
		);
	#else
		reflectedLight.directSpecular += ( 1.0 - clearcoatDHR ) * irradiance * BRDF_Specular_GGX( directLight, geometry.viewDir, geometry.normal, material.specularColor, material.specularRoughness);
	#endif
	reflectedLight.directDiffuse += ( 1.0 - clearcoatDHR ) * irradiance * BRDF_Diffuse_Lambert( material.diffuseColor );
}
void RE_IndirectDiffuse_Physical( const in vec3 irradiance, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {
	reflectedLight.indirectDiffuse += irradiance * BRDF_Diffuse_Lambert( material.diffuseColor );
}
void RE_IndirectSpecular_Physical( const in vec3 radiance, const in vec3 irradiance, const in vec3 clearcoatRadiance, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight) {
	#ifdef CLEARCOAT
		float ccDotNV = saturate( dot( geometry.clearcoatNormal, geometry.viewDir ) );
		reflectedLight.indirectSpecular += clearcoatRadiance * material.clearcoat * BRDF_Specular_GGX_Environment( geometry.viewDir, geometry.clearcoatNormal, vec3( DEFAULT_SPECULAR_COEFFICIENT ), material.clearcoatRoughness );
		float ccDotNL = ccDotNV;
		float clearcoatDHR = material.clearcoat * clearcoatDHRApprox( material.clearcoatRoughness, ccDotNL );
	#else
		float clearcoatDHR = 0.0;
	#endif
	float clearcoatInv = 1.0 - clearcoatDHR;
	vec3 singleScattering = vec3( 0.0 );
	vec3 multiScattering = vec3( 0.0 );
	vec3 cosineWeightedIrradiance = irradiance * RECIPROCAL_PI;
	BRDF_Specular_Multiscattering_Environment( geometry, material.specularColor, material.specularRoughness, singleScattering, multiScattering );
	vec3 diffuse = material.diffuseColor * ( 1.0 - ( singleScattering + multiScattering ) );
	reflectedLight.indirectSpecular += clearcoatInv * radiance * singleScattering;
	reflectedLight.indirectSpecular += multiScattering * cosineWeightedIrradiance;
	reflectedLight.indirectDiffuse += diffuse * cosineWeightedIrradiance;
}
#define RE_Direct				RE_Direct_Physical
#define RE_Direct_RectArea		RE_Direct_RectArea_Physical
#define RE_IndirectDiffuse		RE_IndirectDiffuse_Physical
#define RE_IndirectSpecular		RE_IndirectSpecular_Physical
float computeSpecularOcclusion( const in float dotNV, const in float ambientOcclusion, const in float roughness ) {
	return saturate( pow( dotNV + ambientOcclusion, exp2( - 16.0 * roughness - 1.0 ) ) - 1.0 + ambientOcclusion );
}`, AT = `
GeometricContext geometry;
geometry.position = - vViewPosition;
geometry.normal = normal;
geometry.viewDir = ( isOrthographic ) ? vec3( 0, 0, 1 ) : normalize( vViewPosition );
#ifdef CLEARCOAT
	geometry.clearcoatNormal = clearcoatNormal;
#endif
IncidentLight directLight;
#if ( NUM_POINT_LIGHTS > 0 ) && defined( RE_Direct )
	PointLight pointLight;
	#if defined( USE_SHADOWMAP ) && NUM_POINT_LIGHT_SHADOWS > 0
	PointLightShadow pointLightShadow;
	#endif
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_POINT_LIGHTS; i ++ ) {
		pointLight = pointLights[ i ];
		getPointDirectLightIrradiance( pointLight, geometry, directLight );
		#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_POINT_LIGHT_SHADOWS )
		pointLightShadow = pointLightShadows[ i ];
		directLight.color *= all( bvec2( directLight.visible, receiveShadow ) ) ? getPointShadow( pointShadowMap[ i ], pointLightShadow.shadowMapSize, pointLightShadow.shadowBias, pointLightShadow.shadowRadius, vPointShadowCoord[ i ], pointLightShadow.shadowCameraNear, pointLightShadow.shadowCameraFar ) : 1.0;
		#endif
		RE_Direct( directLight, geometry, material, reflectedLight );
	}
	#pragma unroll_loop_end
#endif
#if ( NUM_SPOT_LIGHTS > 0 ) && defined( RE_Direct )
	SpotLight spotLight;
	#if defined( USE_SHADOWMAP ) && NUM_SPOT_LIGHT_SHADOWS > 0
	SpotLightShadow spotLightShadow;
	#endif
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_SPOT_LIGHTS; i ++ ) {
		spotLight = spotLights[ i ];
		getSpotDirectLightIrradiance( spotLight, geometry, directLight );
		#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )
		spotLightShadow = spotLightShadows[ i ];
		directLight.color *= all( bvec2( directLight.visible, receiveShadow ) ) ? getShadow( spotShadowMap[ i ], spotLightShadow.shadowMapSize, spotLightShadow.shadowBias, spotLightShadow.shadowRadius, vSpotShadowCoord[ i ] ) : 1.0;
		#endif
		RE_Direct( directLight, geometry, material, reflectedLight );
	}
	#pragma unroll_loop_end
#endif
#if ( NUM_DIR_LIGHTS > 0 ) && defined( RE_Direct )
	DirectionalLight directionalLight;
	#if defined( USE_SHADOWMAP ) && NUM_DIR_LIGHT_SHADOWS > 0
	DirectionalLightShadow directionalLightShadow;
	#endif
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_DIR_LIGHTS; i ++ ) {
		directionalLight = directionalLights[ i ];
		getDirectionalDirectLightIrradiance( directionalLight, geometry, directLight );
		#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_DIR_LIGHT_SHADOWS )
		directionalLightShadow = directionalLightShadows[ i ];
		directLight.color *= all( bvec2( directLight.visible, receiveShadow ) ) ? getShadow( directionalShadowMap[ i ], directionalLightShadow.shadowMapSize, directionalLightShadow.shadowBias, directionalLightShadow.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;
		#endif
		RE_Direct( directLight, geometry, material, reflectedLight );
	}
	#pragma unroll_loop_end
#endif
#if ( NUM_RECT_AREA_LIGHTS > 0 ) && defined( RE_Direct_RectArea )
	RectAreaLight rectAreaLight;
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_RECT_AREA_LIGHTS; i ++ ) {
		rectAreaLight = rectAreaLights[ i ];
		RE_Direct_RectArea( rectAreaLight, geometry, material, reflectedLight );
	}
	#pragma unroll_loop_end
#endif
#if defined( RE_IndirectDiffuse )
	vec3 iblIrradiance = vec3( 0.0 );
	vec3 irradiance = getAmbientLightIrradiance( ambientLightColor );
	irradiance += getLightProbeIrradiance( lightProbe, geometry );
	#if ( NUM_HEMI_LIGHTS > 0 )
		#pragma unroll_loop_start
		for ( int i = 0; i < NUM_HEMI_LIGHTS; i ++ ) {
			irradiance += getHemisphereLightIrradiance( hemisphereLights[ i ], geometry );
		}
		#pragma unroll_loop_end
	#endif
#endif
#if defined( RE_IndirectSpecular )
	vec3 radiance = vec3( 0.0 );
	vec3 clearcoatRadiance = vec3( 0.0 );
#endif`, CT = `#if defined( RE_IndirectDiffuse )
	#ifdef USE_LIGHTMAP
		vec4 lightMapTexel= texture2D( lightMap, vUv2 );
		vec3 lightMapIrradiance = lightMapTexelToLinear( lightMapTexel ).rgb * lightMapIntensity;
		#ifndef PHYSICALLY_CORRECT_LIGHTS
			lightMapIrradiance *= PI;
		#endif
		irradiance += lightMapIrradiance;
	#endif
	#if defined( USE_ENVMAP ) && defined( STANDARD ) && defined( ENVMAP_TYPE_CUBE_UV )
		iblIrradiance += getLightProbeIndirectIrradiance( geometry, maxMipLevel );
	#endif
#endif
#if defined( USE_ENVMAP ) && defined( RE_IndirectSpecular )
	radiance += getLightProbeIndirectRadiance( geometry.viewDir, geometry.normal, material.specularRoughness, maxMipLevel );
	#ifdef CLEARCOAT
		clearcoatRadiance += getLightProbeIndirectRadiance( geometry.viewDir, geometry.clearcoatNormal, material.clearcoatRoughness, maxMipLevel );
	#endif
#endif`, IT = `#if defined( RE_IndirectDiffuse )
	RE_IndirectDiffuse( irradiance, geometry, material, reflectedLight );
#endif
#if defined( RE_IndirectSpecular )
	RE_IndirectSpecular( radiance, iblIrradiance, clearcoatRadiance, geometry, material, reflectedLight );
#endif`, LT = `#if defined( USE_LOGDEPTHBUF ) && defined( USE_LOGDEPTHBUF_EXT )
	gl_FragDepthEXT = vIsPerspective == 0.0 ? gl_FragCoord.z : log2( vFragDepth ) * logDepthBufFC * 0.5;
#endif`, DT = `#if defined( USE_LOGDEPTHBUF ) && defined( USE_LOGDEPTHBUF_EXT )
	uniform float logDepthBufFC;
	varying float vFragDepth;
	varying float vIsPerspective;
#endif`, kT = `#ifdef USE_LOGDEPTHBUF
	#ifdef USE_LOGDEPTHBUF_EXT
		varying float vFragDepth;
		varying float vIsPerspective;
	#else
		uniform float logDepthBufFC;
	#endif
#endif`, OT = `#ifdef USE_LOGDEPTHBUF
	#ifdef USE_LOGDEPTHBUF_EXT
		vFragDepth = 1.0 + gl_Position.w;
		vIsPerspective = float( isPerspectiveMatrix( projectionMatrix ) );
	#else
		if ( isPerspectiveMatrix( projectionMatrix ) ) {
			gl_Position.z = log2( max( EPSILON, gl_Position.w + 1.0 ) ) * logDepthBufFC - 1.0;
			gl_Position.z *= gl_Position.w;
		}
	#endif
#endif`, FT = `#ifdef USE_MAP
	vec4 texelColor = texture2D( map, vUv );
	texelColor = mapTexelToLinear( texelColor );
	diffuseColor *= texelColor;
#endif`, RT = `#ifdef USE_MAP
	uniform sampler2D map;
#endif`, BT = `#if defined( USE_MAP ) || defined( USE_ALPHAMAP )
	vec2 uv = ( uvTransform * vec3( gl_PointCoord.x, 1.0 - gl_PointCoord.y, 1 ) ).xy;
#endif
#ifdef USE_MAP
	vec4 mapTexel = texture2D( map, uv );
	diffuseColor *= mapTexelToLinear( mapTexel );
#endif
#ifdef USE_ALPHAMAP
	diffuseColor.a *= texture2D( alphaMap, uv ).g;
#endif`, zT = `#if defined( USE_MAP ) || defined( USE_ALPHAMAP )
	uniform mat3 uvTransform;
#endif
#ifdef USE_MAP
	uniform sampler2D map;
#endif
#ifdef USE_ALPHAMAP
	uniform sampler2D alphaMap;
#endif`, $T = `float metalnessFactor = metalness;
#ifdef USE_METALNESSMAP
	vec4 texelMetalness = texture2D( metalnessMap, vUv );
	metalnessFactor *= texelMetalness.b;
#endif`, NT = `#ifdef USE_METALNESSMAP
	uniform sampler2D metalnessMap;
#endif`, UT = `#ifdef USE_MORPHNORMALS
	objectNormal *= morphTargetBaseInfluence;
	objectNormal += morphNormal0 * morphTargetInfluences[ 0 ];
	objectNormal += morphNormal1 * morphTargetInfluences[ 1 ];
	objectNormal += morphNormal2 * morphTargetInfluences[ 2 ];
	objectNormal += morphNormal3 * morphTargetInfluences[ 3 ];
#endif`, GT = `#ifdef USE_MORPHTARGETS
	uniform float morphTargetBaseInfluence;
	#ifndef USE_MORPHNORMALS
		uniform float morphTargetInfluences[ 8 ];
	#else
		uniform float morphTargetInfluences[ 4 ];
	#endif
#endif`, VT = `#ifdef USE_MORPHTARGETS
	transformed *= morphTargetBaseInfluence;
	transformed += morphTarget0 * morphTargetInfluences[ 0 ];
	transformed += morphTarget1 * morphTargetInfluences[ 1 ];
	transformed += morphTarget2 * morphTargetInfluences[ 2 ];
	transformed += morphTarget3 * morphTargetInfluences[ 3 ];
	#ifndef USE_MORPHNORMALS
		transformed += morphTarget4 * morphTargetInfluences[ 4 ];
		transformed += morphTarget5 * morphTargetInfluences[ 5 ];
		transformed += morphTarget6 * morphTargetInfluences[ 6 ];
		transformed += morphTarget7 * morphTargetInfluences[ 7 ];
	#endif
#endif`, jT = `#ifdef FLAT_SHADED
	vec3 fdx = vec3( dFdx( vViewPosition.x ), dFdx( vViewPosition.y ), dFdx( vViewPosition.z ) );
	vec3 fdy = vec3( dFdy( vViewPosition.x ), dFdy( vViewPosition.y ), dFdy( vViewPosition.z ) );
	vec3 normal = normalize( cross( fdx, fdy ) );
#else
	vec3 normal = normalize( vNormal );
	#ifdef DOUBLE_SIDED
		normal = normal * ( float( gl_FrontFacing ) * 2.0 - 1.0 );
	#endif
	#ifdef USE_TANGENT
		vec3 tangent = normalize( vTangent );
		vec3 bitangent = normalize( vBitangent );
		#ifdef DOUBLE_SIDED
			tangent = tangent * ( float( gl_FrontFacing ) * 2.0 - 1.0 );
			bitangent = bitangent * ( float( gl_FrontFacing ) * 2.0 - 1.0 );
		#endif
		#if defined( TANGENTSPACE_NORMALMAP ) || defined( USE_CLEARCOAT_NORMALMAP )
			mat3 vTBN = mat3( tangent, bitangent, normal );
		#endif
	#endif
#endif
vec3 geometryNormal = normal;`, WT = `#ifdef OBJECTSPACE_NORMALMAP
	normal = texture2D( normalMap, vUv ).xyz * 2.0 - 1.0;
	#ifdef FLIP_SIDED
		normal = - normal;
	#endif
	#ifdef DOUBLE_SIDED
		normal = normal * ( float( gl_FrontFacing ) * 2.0 - 1.0 );
	#endif
	normal = normalize( normalMatrix * normal );
#elif defined( TANGENTSPACE_NORMALMAP )
	vec3 mapN = texture2D( normalMap, vUv ).xyz * 2.0 - 1.0;
	mapN.xy *= normalScale;
	#ifdef USE_TANGENT
		normal = normalize( vTBN * mapN );
	#else
		normal = perturbNormal2Arb( -vViewPosition, normal, mapN );
	#endif
#elif defined( USE_BUMPMAP )
	normal = perturbNormalArb( -vViewPosition, normal, dHdxy_fwd() );
#endif`, HT = `#ifdef USE_NORMALMAP
	uniform sampler2D normalMap;
	uniform vec2 normalScale;
#endif
#ifdef OBJECTSPACE_NORMALMAP
	uniform mat3 normalMatrix;
#endif
#if ! defined ( USE_TANGENT ) && ( defined ( TANGENTSPACE_NORMALMAP ) || defined ( USE_CLEARCOAT_NORMALMAP ) )
	vec3 perturbNormal2Arb( vec3 eye_pos, vec3 surf_norm, vec3 mapN ) {
		vec3 q0 = vec3( dFdx( eye_pos.x ), dFdx( eye_pos.y ), dFdx( eye_pos.z ) );
		vec3 q1 = vec3( dFdy( eye_pos.x ), dFdy( eye_pos.y ), dFdy( eye_pos.z ) );
		vec2 st0 = dFdx( vUv.st );
		vec2 st1 = dFdy( vUv.st );
		float scale = sign( st1.t * st0.s - st0.t * st1.s );
		vec3 S = normalize( ( q0 * st1.t - q1 * st0.t ) * scale );
		vec3 T = normalize( ( - q0 * st1.s + q1 * st0.s ) * scale );
		vec3 N = normalize( surf_norm );
		mat3 tsn = mat3( S, T, N );
		mapN.xy *= ( float( gl_FrontFacing ) * 2.0 - 1.0 );
		return normalize( tsn * mapN );
	}
#endif`, qT = `#ifdef CLEARCOAT
	vec3 clearcoatNormal = geometryNormal;
#endif`, KT = `#ifdef USE_CLEARCOAT_NORMALMAP
	vec3 clearcoatMapN = texture2D( clearcoatNormalMap, vUv ).xyz * 2.0 - 1.0;
	clearcoatMapN.xy *= clearcoatNormalScale;
	#ifdef USE_TANGENT
		clearcoatNormal = normalize( vTBN * clearcoatMapN );
	#else
		clearcoatNormal = perturbNormal2Arb( - vViewPosition, clearcoatNormal, clearcoatMapN );
	#endif
#endif`, XT = `#ifdef USE_CLEARCOATMAP
	uniform sampler2D clearcoatMap;
#endif
#ifdef USE_CLEARCOAT_ROUGHNESSMAP
	uniform sampler2D clearcoatRoughnessMap;
#endif
#ifdef USE_CLEARCOAT_NORMALMAP
	uniform sampler2D clearcoatNormalMap;
	uniform vec2 clearcoatNormalScale;
#endif`, YT = `vec3 packNormalToRGB( const in vec3 normal ) {
	return normalize( normal ) * 0.5 + 0.5;
}
vec3 unpackRGBToNormal( const in vec3 rgb ) {
	return 2.0 * rgb.xyz - 1.0;
}
const float PackUpscale = 256. / 255.;const float UnpackDownscale = 255. / 256.;
const vec3 PackFactors = vec3( 256. * 256. * 256., 256. * 256.,  256. );
const vec4 UnpackFactors = UnpackDownscale / vec4( PackFactors, 1. );
const float ShiftRight8 = 1. / 256.;
vec4 packDepthToRGBA( const in float v ) {
	vec4 r = vec4( fract( v * PackFactors ), v );
	r.yzw -= r.xyz * ShiftRight8;	return r * PackUpscale;
}
float unpackRGBAToDepth( const in vec4 v ) {
	return dot( v, UnpackFactors );
}
vec4 pack2HalfToRGBA( vec2 v ) {
	vec4 r = vec4( v.x, fract( v.x * 255.0 ), v.y, fract( v.y * 255.0 ));
	return vec4( r.x - r.y / 255.0, r.y, r.z - r.w / 255.0, r.w);
}
vec2 unpackRGBATo2Half( vec4 v ) {
	return vec2( v.x + ( v.y / 255.0 ), v.z + ( v.w / 255.0 ) );
}
float viewZToOrthographicDepth( const in float viewZ, const in float near, const in float far ) {
	return ( viewZ + near ) / ( near - far );
}
float orthographicDepthToViewZ( const in float linearClipZ, const in float near, const in float far ) {
	return linearClipZ * ( near - far ) - near;
}
float viewZToPerspectiveDepth( const in float viewZ, const in float near, const in float far ) {
	return (( near + viewZ ) * far ) / (( far - near ) * viewZ );
}
float perspectiveDepthToViewZ( const in float invClipZ, const in float near, const in float far ) {
	return ( near * far ) / ( ( far - near ) * invClipZ - far );
}`, JT = `#ifdef PREMULTIPLIED_ALPHA
	gl_FragColor.rgb *= gl_FragColor.a;
#endif`, QT = `vec4 mvPosition = vec4( transformed, 1.0 );
#ifdef USE_INSTANCING
	mvPosition = instanceMatrix * mvPosition;
#endif
mvPosition = modelViewMatrix * mvPosition;
gl_Position = projectionMatrix * mvPosition;`, ZT = `#ifdef DITHERING
	gl_FragColor.rgb = dithering( gl_FragColor.rgb );
#endif`, eE = `#ifdef DITHERING
	vec3 dithering( vec3 color ) {
		float grid_position = rand( gl_FragCoord.xy );
		vec3 dither_shift_RGB = vec3( 0.25 / 255.0, -0.25 / 255.0, 0.25 / 255.0 );
		dither_shift_RGB = mix( 2.0 * dither_shift_RGB, -2.0 * dither_shift_RGB, grid_position );
		return color + dither_shift_RGB;
	}
#endif`, tE = `float roughnessFactor = roughness;
#ifdef USE_ROUGHNESSMAP
	vec4 texelRoughness = texture2D( roughnessMap, vUv );
	roughnessFactor *= texelRoughness.g;
#endif`, nE = `#ifdef USE_ROUGHNESSMAP
	uniform sampler2D roughnessMap;
#endif`, iE = `#ifdef USE_SHADOWMAP
	#if NUM_DIR_LIGHT_SHADOWS > 0
		uniform sampler2D directionalShadowMap[ NUM_DIR_LIGHT_SHADOWS ];
		varying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];
		struct DirectionalLightShadow {
			float shadowBias;
			float shadowNormalBias;
			float shadowRadius;
			vec2 shadowMapSize;
		};
		uniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];
	#endif
	#if NUM_SPOT_LIGHT_SHADOWS > 0
		uniform sampler2D spotShadowMap[ NUM_SPOT_LIGHT_SHADOWS ];
		varying vec4 vSpotShadowCoord[ NUM_SPOT_LIGHT_SHADOWS ];
		struct SpotLightShadow {
			float shadowBias;
			float shadowNormalBias;
			float shadowRadius;
			vec2 shadowMapSize;
		};
		uniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];
	#endif
	#if NUM_POINT_LIGHT_SHADOWS > 0
		uniform sampler2D pointShadowMap[ NUM_POINT_LIGHT_SHADOWS ];
		varying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];
		struct PointLightShadow {
			float shadowBias;
			float shadowNormalBias;
			float shadowRadius;
			vec2 shadowMapSize;
			float shadowCameraNear;
			float shadowCameraFar;
		};
		uniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];
	#endif
	float texture2DCompare( sampler2D depths, vec2 uv, float compare ) {
		return step( compare, unpackRGBAToDepth( texture2D( depths, uv ) ) );
	}
	vec2 texture2DDistribution( sampler2D shadow, vec2 uv ) {
		return unpackRGBATo2Half( texture2D( shadow, uv ) );
	}
	float VSMShadow (sampler2D shadow, vec2 uv, float compare ){
		float occlusion = 1.0;
		vec2 distribution = texture2DDistribution( shadow, uv );
		float hard_shadow = step( compare , distribution.x );
		if (hard_shadow != 1.0 ) {
			float distance = compare - distribution.x ;
			float variance = max( 0.00000, distribution.y * distribution.y );
			float softness_probability = variance / (variance + distance * distance );			softness_probability = clamp( ( softness_probability - 0.3 ) / ( 0.95 - 0.3 ), 0.0, 1.0 );			occlusion = clamp( max( hard_shadow, softness_probability ), 0.0, 1.0 );
		}
		return occlusion;
	}
	float getShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowBias, float shadowRadius, vec4 shadowCoord ) {
		float shadow = 1.0;
		shadowCoord.xyz /= shadowCoord.w;
		shadowCoord.z += shadowBias;
		bvec4 inFrustumVec = bvec4 ( shadowCoord.x >= 0.0, shadowCoord.x <= 1.0, shadowCoord.y >= 0.0, shadowCoord.y <= 1.0 );
		bool inFrustum = all( inFrustumVec );
		bvec2 frustumTestVec = bvec2( inFrustum, shadowCoord.z <= 1.0 );
		bool frustumTest = all( frustumTestVec );
		if ( frustumTest ) {
		#if defined( SHADOWMAP_TYPE_PCF )
			vec2 texelSize = vec2( 1.0 ) / shadowMapSize;
			float dx0 = - texelSize.x * shadowRadius;
			float dy0 = - texelSize.y * shadowRadius;
			float dx1 = + texelSize.x * shadowRadius;
			float dy1 = + texelSize.y * shadowRadius;
			float dx2 = dx0 / 2.0;
			float dy2 = dy0 / 2.0;
			float dx3 = dx1 / 2.0;
			float dy3 = dy1 / 2.0;
			shadow = (
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy2 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy2 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy2 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, 0.0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, 0.0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, 0.0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, 0.0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy3 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy3 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy3 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy1 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy1 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy1 ), shadowCoord.z )
			) * ( 1.0 / 17.0 );
		#elif defined( SHADOWMAP_TYPE_PCF_SOFT )
			vec2 texelSize = vec2( 1.0 ) / shadowMapSize;
			float dx = texelSize.x;
			float dy = texelSize.y;
			vec2 uv = shadowCoord.xy;
			vec2 f = fract( uv * shadowMapSize + 0.5 );
			uv -= f * texelSize;
			shadow = (
				texture2DCompare( shadowMap, uv, shadowCoord.z ) +
				texture2DCompare( shadowMap, uv + vec2( dx, 0.0 ), shadowCoord.z ) +
				texture2DCompare( shadowMap, uv + vec2( 0.0, dy ), shadowCoord.z ) +
				texture2DCompare( shadowMap, uv + texelSize, shadowCoord.z ) +
				mix( texture2DCompare( shadowMap, uv + vec2( -dx, 0.0 ), shadowCoord.z ), 
					 texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 0.0 ), shadowCoord.z ),
					 f.x ) +
				mix( texture2DCompare( shadowMap, uv + vec2( -dx, dy ), shadowCoord.z ), 
					 texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, dy ), shadowCoord.z ),
					 f.x ) +
				mix( texture2DCompare( shadowMap, uv + vec2( 0.0, -dy ), shadowCoord.z ), 
					 texture2DCompare( shadowMap, uv + vec2( 0.0, 2.0 * dy ), shadowCoord.z ),
					 f.y ) +
				mix( texture2DCompare( shadowMap, uv + vec2( dx, -dy ), shadowCoord.z ), 
					 texture2DCompare( shadowMap, uv + vec2( dx, 2.0 * dy ), shadowCoord.z ),
					 f.y ) +
				mix( mix( texture2DCompare( shadowMap, uv + vec2( -dx, -dy ), shadowCoord.z ), 
						  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, -dy ), shadowCoord.z ),
						  f.x ),
					 mix( texture2DCompare( shadowMap, uv + vec2( -dx, 2.0 * dy ), shadowCoord.z ), 
						  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 2.0 * dy ), shadowCoord.z ),
						  f.x ),
					 f.y )
			) * ( 1.0 / 9.0 );
		#elif defined( SHADOWMAP_TYPE_VSM )
			shadow = VSMShadow( shadowMap, shadowCoord.xy, shadowCoord.z );
		#else
			shadow = texture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z );
		#endif
		}
		return shadow;
	}
	vec2 cubeToUV( vec3 v, float texelSizeY ) {
		vec3 absV = abs( v );
		float scaleToCube = 1.0 / max( absV.x, max( absV.y, absV.z ) );
		absV *= scaleToCube;
		v *= scaleToCube * ( 1.0 - 2.0 * texelSizeY );
		vec2 planar = v.xy;
		float almostATexel = 1.5 * texelSizeY;
		float almostOne = 1.0 - almostATexel;
		if ( absV.z >= almostOne ) {
			if ( v.z > 0.0 )
				planar.x = 4.0 - v.x;
		} else if ( absV.x >= almostOne ) {
			float signX = sign( v.x );
			planar.x = v.z * signX + 2.0 * signX;
		} else if ( absV.y >= almostOne ) {
			float signY = sign( v.y );
			planar.x = v.x + 2.0 * signY + 2.0;
			planar.y = v.z * signY - 2.0;
		}
		return vec2( 0.125, 0.25 ) * planar + vec2( 0.375, 0.75 );
	}
	float getPointShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowBias, float shadowRadius, vec4 shadowCoord, float shadowCameraNear, float shadowCameraFar ) {
		vec2 texelSize = vec2( 1.0 ) / ( shadowMapSize * vec2( 4.0, 2.0 ) );
		vec3 lightToPosition = shadowCoord.xyz;
		float dp = ( length( lightToPosition ) - shadowCameraNear ) / ( shadowCameraFar - shadowCameraNear );		dp += shadowBias;
		vec3 bd3D = normalize( lightToPosition );
		#if defined( SHADOWMAP_TYPE_PCF ) || defined( SHADOWMAP_TYPE_PCF_SOFT ) || defined( SHADOWMAP_TYPE_VSM )
			vec2 offset = vec2( - 1, 1 ) * shadowRadius * texelSize.y;
			return (
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyy, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyy, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyx, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyx, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxy, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxy, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxx, texelSize.y ), dp ) +
				texture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxx, texelSize.y ), dp )
			) * ( 1.0 / 9.0 );
		#else
			return texture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp );
		#endif
	}
#endif`, sE = `#ifdef USE_SHADOWMAP
	#if NUM_DIR_LIGHT_SHADOWS > 0
		uniform mat4 directionalShadowMatrix[ NUM_DIR_LIGHT_SHADOWS ];
		varying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];
		struct DirectionalLightShadow {
			float shadowBias;
			float shadowNormalBias;
			float shadowRadius;
			vec2 shadowMapSize;
		};
		uniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];
	#endif
	#if NUM_SPOT_LIGHT_SHADOWS > 0
		uniform mat4 spotShadowMatrix[ NUM_SPOT_LIGHT_SHADOWS ];
		varying vec4 vSpotShadowCoord[ NUM_SPOT_LIGHT_SHADOWS ];
		struct SpotLightShadow {
			float shadowBias;
			float shadowNormalBias;
			float shadowRadius;
			vec2 shadowMapSize;
		};
		uniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];
	#endif
	#if NUM_POINT_LIGHT_SHADOWS > 0
		uniform mat4 pointShadowMatrix[ NUM_POINT_LIGHT_SHADOWS ];
		varying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];
		struct PointLightShadow {
			float shadowBias;
			float shadowNormalBias;
			float shadowRadius;
			vec2 shadowMapSize;
			float shadowCameraNear;
			float shadowCameraFar;
		};
		uniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];
	#endif
#endif`, rE = `#ifdef USE_SHADOWMAP
	#if NUM_DIR_LIGHT_SHADOWS > 0 || NUM_SPOT_LIGHT_SHADOWS > 0 || NUM_POINT_LIGHT_SHADOWS > 0
		vec3 shadowWorldNormal = inverseTransformDirection( transformedNormal, viewMatrix );
		vec4 shadowWorldPosition;
	#endif
	#if NUM_DIR_LIGHT_SHADOWS > 0
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {
		shadowWorldPosition = worldPosition + vec4( shadowWorldNormal * directionalLightShadows[ i ].shadowNormalBias, 0 );
		vDirectionalShadowCoord[ i ] = directionalShadowMatrix[ i ] * shadowWorldPosition;
	}
	#pragma unroll_loop_end
	#endif
	#if NUM_SPOT_LIGHT_SHADOWS > 0
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_SPOT_LIGHT_SHADOWS; i ++ ) {
		shadowWorldPosition = worldPosition + vec4( shadowWorldNormal * spotLightShadows[ i ].shadowNormalBias, 0 );
		vSpotShadowCoord[ i ] = spotShadowMatrix[ i ] * shadowWorldPosition;
	}
	#pragma unroll_loop_end
	#endif
	#if NUM_POINT_LIGHT_SHADOWS > 0
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {
		shadowWorldPosition = worldPosition + vec4( shadowWorldNormal * pointLightShadows[ i ].shadowNormalBias, 0 );
		vPointShadowCoord[ i ] = pointShadowMatrix[ i ] * shadowWorldPosition;
	}
	#pragma unroll_loop_end
	#endif
#endif`, oE = `float getShadowMask() {
	float shadow = 1.0;
	#ifdef USE_SHADOWMAP
	#if NUM_DIR_LIGHT_SHADOWS > 0
	DirectionalLightShadow directionalLight;
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {
		directionalLight = directionalLightShadows[ i ];
		shadow *= receiveShadow ? getShadow( directionalShadowMap[ i ], directionalLight.shadowMapSize, directionalLight.shadowBias, directionalLight.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;
	}
	#pragma unroll_loop_end
	#endif
	#if NUM_SPOT_LIGHT_SHADOWS > 0
	SpotLightShadow spotLight;
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_SPOT_LIGHT_SHADOWS; i ++ ) {
		spotLight = spotLightShadows[ i ];
		shadow *= receiveShadow ? getShadow( spotShadowMap[ i ], spotLight.shadowMapSize, spotLight.shadowBias, spotLight.shadowRadius, vSpotShadowCoord[ i ] ) : 1.0;
	}
	#pragma unroll_loop_end
	#endif
	#if NUM_POINT_LIGHT_SHADOWS > 0
	PointLightShadow pointLight;
	#pragma unroll_loop_start
	for ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {
		pointLight = pointLightShadows[ i ];
		shadow *= receiveShadow ? getPointShadow( pointShadowMap[ i ], pointLight.shadowMapSize, pointLight.shadowBias, pointLight.shadowRadius, vPointShadowCoord[ i ], pointLight.shadowCameraNear, pointLight.shadowCameraFar ) : 1.0;
	}
	#pragma unroll_loop_end
	#endif
	#endif
	return shadow;
}`, aE = `#ifdef USE_SKINNING
	mat4 boneMatX = getBoneMatrix( skinIndex.x );
	mat4 boneMatY = getBoneMatrix( skinIndex.y );
	mat4 boneMatZ = getBoneMatrix( skinIndex.z );
	mat4 boneMatW = getBoneMatrix( skinIndex.w );
#endif`, lE = `#ifdef USE_SKINNING
	uniform mat4 bindMatrix;
	uniform mat4 bindMatrixInverse;
	#ifdef BONE_TEXTURE
		uniform highp sampler2D boneTexture;
		uniform int boneTextureSize;
		mat4 getBoneMatrix( const in float i ) {
			float j = i * 4.0;
			float x = mod( j, float( boneTextureSize ) );
			float y = floor( j / float( boneTextureSize ) );
			float dx = 1.0 / float( boneTextureSize );
			float dy = 1.0 / float( boneTextureSize );
			y = dy * ( y + 0.5 );
			vec4 v1 = texture2D( boneTexture, vec2( dx * ( x + 0.5 ), y ) );
			vec4 v2 = texture2D( boneTexture, vec2( dx * ( x + 1.5 ), y ) );
			vec4 v3 = texture2D( boneTexture, vec2( dx * ( x + 2.5 ), y ) );
			vec4 v4 = texture2D( boneTexture, vec2( dx * ( x + 3.5 ), y ) );
			mat4 bone = mat4( v1, v2, v3, v4 );
			return bone;
		}
	#else
		uniform mat4 boneMatrices[ MAX_BONES ];
		mat4 getBoneMatrix( const in float i ) {
			mat4 bone = boneMatrices[ int(i) ];
			return bone;
		}
	#endif
#endif`, cE = `#ifdef USE_SKINNING
	vec4 skinVertex = bindMatrix * vec4( transformed, 1.0 );
	vec4 skinned = vec4( 0.0 );
	skinned += boneMatX * skinVertex * skinWeight.x;
	skinned += boneMatY * skinVertex * skinWeight.y;
	skinned += boneMatZ * skinVertex * skinWeight.z;
	skinned += boneMatW * skinVertex * skinWeight.w;
	transformed = ( bindMatrixInverse * skinned ).xyz;
#endif`, uE = `#ifdef USE_SKINNING
	mat4 skinMatrix = mat4( 0.0 );
	skinMatrix += skinWeight.x * boneMatX;
	skinMatrix += skinWeight.y * boneMatY;
	skinMatrix += skinWeight.z * boneMatZ;
	skinMatrix += skinWeight.w * boneMatW;
	skinMatrix  = bindMatrixInverse * skinMatrix * bindMatrix;
	objectNormal = vec4( skinMatrix * vec4( objectNormal, 0.0 ) ).xyz;
	#ifdef USE_TANGENT
		objectTangent = vec4( skinMatrix * vec4( objectTangent, 0.0 ) ).xyz;
	#endif
#endif`, dE = `float specularStrength;
#ifdef USE_SPECULARMAP
	vec4 texelSpecular = texture2D( specularMap, vUv );
	specularStrength = texelSpecular.r;
#else
	specularStrength = 1.0;
#endif`, hE = `#ifdef USE_SPECULARMAP
	uniform sampler2D specularMap;
#endif`, fE = `#if defined( TONE_MAPPING )
	gl_FragColor.rgb = toneMapping( gl_FragColor.rgb );
#endif`, pE = `#ifndef saturate
#define saturate(a) clamp( a, 0.0, 1.0 )
#endif
uniform float toneMappingExposure;
vec3 LinearToneMapping( vec3 color ) {
	return toneMappingExposure * color;
}
vec3 ReinhardToneMapping( vec3 color ) {
	color *= toneMappingExposure;
	return saturate( color / ( vec3( 1.0 ) + color ) );
}
vec3 OptimizedCineonToneMapping( vec3 color ) {
	color *= toneMappingExposure;
	color = max( vec3( 0.0 ), color - 0.004 );
	return pow( ( color * ( 6.2 * color + 0.5 ) ) / ( color * ( 6.2 * color + 1.7 ) + 0.06 ), vec3( 2.2 ) );
}
vec3 RRTAndODTFit( vec3 v ) {
	vec3 a = v * ( v + 0.0245786 ) - 0.000090537;
	vec3 b = v * ( 0.983729 * v + 0.4329510 ) + 0.238081;
	return a / b;
}
vec3 ACESFilmicToneMapping( vec3 color ) {
	const mat3 ACESInputMat = mat3(
		vec3( 0.59719, 0.07600, 0.02840 ),		vec3( 0.35458, 0.90834, 0.13383 ),
		vec3( 0.04823, 0.01566, 0.83777 )
	);
	const mat3 ACESOutputMat = mat3(
		vec3(  1.60475, -0.10208, -0.00327 ),		vec3( -0.53108,  1.10813, -0.07276 ),
		vec3( -0.07367, -0.00605,  1.07602 )
	);
	color *= toneMappingExposure / 0.6;
	color = ACESInputMat * color;
	color = RRTAndODTFit( color );
	color = ACESOutputMat * color;
	return saturate( color );
}
vec3 CustomToneMapping( vec3 color ) { return color; }`, mE = `#ifdef USE_TRANSMISSIONMAP
	totalTransmission *= texture2D( transmissionMap, vUv ).r;
#endif`, gE = `#ifdef USE_TRANSMISSIONMAP
	uniform sampler2D transmissionMap;
#endif`, _E = `#if ( defined( USE_UV ) && ! defined( UVS_VERTEX_ONLY ) )
	varying vec2 vUv;
#endif`, yE = `#ifdef USE_UV
	#ifdef UVS_VERTEX_ONLY
		vec2 vUv;
	#else
		varying vec2 vUv;
	#endif
	uniform mat3 uvTransform;
#endif`, vE = `#ifdef USE_UV
	vUv = ( uvTransform * vec3( uv, 1 ) ).xy;
#endif`, wE = `#if defined( USE_LIGHTMAP ) || defined( USE_AOMAP )
	varying vec2 vUv2;
#endif`, xE = `#if defined( USE_LIGHTMAP ) || defined( USE_AOMAP )
	attribute vec2 uv2;
	varying vec2 vUv2;
	uniform mat3 uv2Transform;
#endif`, bE = `#if defined( USE_LIGHTMAP ) || defined( USE_AOMAP )
	vUv2 = ( uv2Transform * vec3( uv2, 1 ) ).xy;
#endif`, ME = `#if defined( USE_ENVMAP ) || defined( DISTANCE ) || defined ( USE_SHADOWMAP )
	vec4 worldPosition = vec4( transformed, 1.0 );
	#ifdef USE_INSTANCING
		worldPosition = instanceMatrix * worldPosition;
	#endif
	worldPosition = modelMatrix * worldPosition;
#endif`, TE = `uniform sampler2D t2D;
varying vec2 vUv;
void main() {
	vec4 texColor = texture2D( t2D, vUv );
	gl_FragColor = mapTexelToLinear( texColor );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
}`, EE = `varying vec2 vUv;
uniform mat3 uvTransform;
void main() {
	vUv = ( uvTransform * vec3( uv, 1 ) ).xy;
	gl_Position = vec4( position.xy, 1.0, 1.0 );
}`, SE = `#include <envmap_common_pars_fragment>
uniform float opacity;
varying vec3 vWorldDirection;
#include <cube_uv_reflection_fragment>
void main() {
	vec3 vReflect = vWorldDirection;
	#include <envmap_fragment>
	gl_FragColor = envColor;
	gl_FragColor.a *= opacity;
	#include <tonemapping_fragment>
	#include <encodings_fragment>
}`, PE = `varying vec3 vWorldDirection;
#include <common>
void main() {
	vWorldDirection = transformDirection( position, modelMatrix );
	#include <begin_vertex>
	#include <project_vertex>
	gl_Position.z = gl_Position.w;
}`, AE = `#if DEPTH_PACKING == 3200
	uniform float opacity;
#endif
#include <common>
#include <packing>
#include <uv_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
varying vec2 vHighPrecisionZW;
void main() {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( 1.0 );
	#if DEPTH_PACKING == 3200
		diffuseColor.a = opacity;
	#endif
	#include <map_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	#include <logdepthbuf_fragment>
	float fragCoordZ = 0.5 * vHighPrecisionZW[0] / vHighPrecisionZW[1] + 0.5;
	#if DEPTH_PACKING == 3200
		gl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity );
	#elif DEPTH_PACKING == 3201
		gl_FragColor = packDepthToRGBA( fragCoordZ );
	#endif
}`, CE = `#include <common>
#include <uv_pars_vertex>
#include <displacementmap_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
varying vec2 vHighPrecisionZW;
void main() {
	#include <uv_vertex>
	#include <skinbase_vertex>
	#ifdef USE_DISPLACEMENTMAP
		#include <beginnormal_vertex>
		#include <morphnormal_vertex>
		#include <skinnormal_vertex>
	#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <displacementmap_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	vHighPrecisionZW = gl_Position.zw;
}`, IE = `#define DISTANCE
uniform vec3 referencePosition;
uniform float nearDistance;
uniform float farDistance;
varying vec3 vWorldPosition;
#include <common>
#include <packing>
#include <uv_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <clipping_planes_pars_fragment>
void main () {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( 1.0 );
	#include <map_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	float dist = length( vWorldPosition - referencePosition );
	dist = ( dist - nearDistance ) / ( farDistance - nearDistance );
	dist = saturate( dist );
	gl_FragColor = packDepthToRGBA( dist );
}`, LE = `#define DISTANCE
varying vec3 vWorldPosition;
#include <common>
#include <uv_pars_vertex>
#include <displacementmap_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <skinbase_vertex>
	#ifdef USE_DISPLACEMENTMAP
		#include <beginnormal_vertex>
		#include <morphnormal_vertex>
		#include <skinnormal_vertex>
	#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <displacementmap_vertex>
	#include <project_vertex>
	#include <worldpos_vertex>
	#include <clipping_planes_vertex>
	vWorldPosition = worldPosition.xyz;
}`, DE = `uniform sampler2D tEquirect;
varying vec3 vWorldDirection;
#include <common>
void main() {
	vec3 direction = normalize( vWorldDirection );
	vec2 sampleUV = equirectUv( direction );
	vec4 texColor = texture2D( tEquirect, sampleUV );
	gl_FragColor = mapTexelToLinear( texColor );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
}`, kE = `varying vec3 vWorldDirection;
#include <common>
void main() {
	vWorldDirection = transformDirection( position, modelMatrix );
	#include <begin_vertex>
	#include <project_vertex>
}`, OE = `uniform vec3 diffuse;
uniform float opacity;
uniform float dashSize;
uniform float totalSize;
varying float vLineDistance;
#include <common>
#include <color_pars_fragment>
#include <fog_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	if ( mod( vLineDistance, totalSize ) > dashSize ) {
		discard;
	}
	vec3 outgoingLight = vec3( 0.0 );
	vec4 diffuseColor = vec4( diffuse, opacity );
	#include <logdepthbuf_fragment>
	#include <color_fragment>
	outgoingLight = diffuseColor.rgb;
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
}`, FE = `uniform float scale;
attribute float lineDistance;
varying float vLineDistance;
#include <common>
#include <color_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	vLineDistance = scale * lineDistance;
	#include <color_vertex>
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	#include <fog_vertex>
}`, RE = `uniform vec3 diffuse;
uniform float opacity;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
#endif
#include <common>
#include <dithering_pars_fragment>
#include <color_pars_fragment>
#include <uv_pars_fragment>
#include <uv2_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <aomap_pars_fragment>
#include <lightmap_pars_fragment>
#include <envmap_common_pars_fragment>
#include <envmap_pars_fragment>
#include <cube_uv_reflection_fragment>
#include <fog_pars_fragment>
#include <specularmap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( diffuse, opacity );
	#include <logdepthbuf_fragment>
	#include <map_fragment>
	#include <color_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	#include <specularmap_fragment>
	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );
	#ifdef USE_LIGHTMAP
	
		vec4 lightMapTexel= texture2D( lightMap, vUv2 );
		reflectedLight.indirectDiffuse += lightMapTexelToLinear( lightMapTexel ).rgb * lightMapIntensity;
	#else
		reflectedLight.indirectDiffuse += vec3( 1.0 );
	#endif
	#include <aomap_fragment>
	reflectedLight.indirectDiffuse *= diffuseColor.rgb;
	vec3 outgoingLight = reflectedLight.indirectDiffuse;
	#include <envmap_fragment>
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
	#include <dithering_fragment>
}`, BE = `#include <common>
#include <uv_pars_vertex>
#include <uv2_pars_vertex>
#include <envmap_pars_vertex>
#include <color_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <uv2_vertex>
	#include <color_vertex>
	#include <skinbase_vertex>
	#ifdef USE_ENVMAP
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
	#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <worldpos_vertex>
	#include <clipping_planes_vertex>
	#include <envmap_vertex>
	#include <fog_vertex>
}`, zE = `uniform vec3 diffuse;
uniform vec3 emissive;
uniform float opacity;
varying vec3 vLightFront;
varying vec3 vIndirectFront;
#ifdef DOUBLE_SIDED
	varying vec3 vLightBack;
	varying vec3 vIndirectBack;
#endif
#include <common>
#include <packing>
#include <dithering_pars_fragment>
#include <color_pars_fragment>
#include <uv_pars_fragment>
#include <uv2_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <aomap_pars_fragment>
#include <lightmap_pars_fragment>
#include <emissivemap_pars_fragment>
#include <envmap_common_pars_fragment>
#include <envmap_pars_fragment>
#include <cube_uv_reflection_fragment>
#include <bsdfs>
#include <lights_pars_begin>
#include <fog_pars_fragment>
#include <shadowmap_pars_fragment>
#include <shadowmask_pars_fragment>
#include <specularmap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( diffuse, opacity );
	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );
	vec3 totalEmissiveRadiance = emissive;
	#include <logdepthbuf_fragment>
	#include <map_fragment>
	#include <color_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	#include <specularmap_fragment>
	#include <emissivemap_fragment>
	#ifdef DOUBLE_SIDED
		reflectedLight.indirectDiffuse += ( gl_FrontFacing ) ? vIndirectFront : vIndirectBack;
	#else
		reflectedLight.indirectDiffuse += vIndirectFront;
	#endif
	#include <lightmap_fragment>
	reflectedLight.indirectDiffuse *= BRDF_Diffuse_Lambert( diffuseColor.rgb );
	#ifdef DOUBLE_SIDED
		reflectedLight.directDiffuse = ( gl_FrontFacing ) ? vLightFront : vLightBack;
	#else
		reflectedLight.directDiffuse = vLightFront;
	#endif
	reflectedLight.directDiffuse *= BRDF_Diffuse_Lambert( diffuseColor.rgb ) * getShadowMask();
	#include <aomap_fragment>
	vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;
	#include <envmap_fragment>
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
	#include <dithering_fragment>
}`, $E = `#define LAMBERT
varying vec3 vLightFront;
varying vec3 vIndirectFront;
#ifdef DOUBLE_SIDED
	varying vec3 vLightBack;
	varying vec3 vIndirectBack;
#endif
#include <common>
#include <uv_pars_vertex>
#include <uv2_pars_vertex>
#include <envmap_pars_vertex>
#include <bsdfs>
#include <lights_pars_begin>
#include <color_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <shadowmap_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <uv2_vertex>
	#include <color_vertex>
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinbase_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	#include <worldpos_vertex>
	#include <envmap_vertex>
	#include <lights_lambert_vertex>
	#include <shadowmap_vertex>
	#include <fog_vertex>
}`, NE = `#define MATCAP
uniform vec3 diffuse;
uniform float opacity;
uniform sampler2D matcap;
varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
#endif
#include <common>
#include <dithering_pars_fragment>
#include <color_pars_fragment>
#include <uv_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <fog_pars_fragment>
#include <bumpmap_pars_fragment>
#include <normalmap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( diffuse, opacity );
	#include <logdepthbuf_fragment>
	#include <map_fragment>
	#include <color_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	#include <normal_fragment_begin>
	#include <normal_fragment_maps>
	vec3 viewDir = normalize( vViewPosition );
	vec3 x = normalize( vec3( viewDir.z, 0.0, - viewDir.x ) );
	vec3 y = cross( viewDir, x );
	vec2 uv = vec2( dot( x, normal ), dot( y, normal ) ) * 0.495 + 0.5;
	#ifdef USE_MATCAP
		vec4 matcapColor = texture2D( matcap, uv );
		matcapColor = matcapTexelToLinear( matcapColor );
	#else
		vec4 matcapColor = vec4( 1.0 );
	#endif
	vec3 outgoingLight = diffuseColor.rgb * matcapColor.rgb;
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
	#include <dithering_fragment>
}`, UE = `#define MATCAP
varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
#endif
#include <common>
#include <uv_pars_vertex>
#include <color_pars_vertex>
#include <displacementmap_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <color_vertex>
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinbase_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
	#ifndef FLAT_SHADED
		vNormal = normalize( transformedNormal );
	#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <displacementmap_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	#include <fog_vertex>
	vViewPosition = - mvPosition.xyz;
}`, GE = `#define TOON
uniform vec3 diffuse;
uniform vec3 emissive;
uniform float opacity;
#include <common>
#include <packing>
#include <dithering_pars_fragment>
#include <color_pars_fragment>
#include <uv_pars_fragment>
#include <uv2_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <aomap_pars_fragment>
#include <lightmap_pars_fragment>
#include <emissivemap_pars_fragment>
#include <gradientmap_pars_fragment>
#include <fog_pars_fragment>
#include <bsdfs>
#include <lights_pars_begin>
#include <lights_toon_pars_fragment>
#include <shadowmap_pars_fragment>
#include <bumpmap_pars_fragment>
#include <normalmap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( diffuse, opacity );
	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );
	vec3 totalEmissiveRadiance = emissive;
	#include <logdepthbuf_fragment>
	#include <map_fragment>
	#include <color_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	#include <normal_fragment_begin>
	#include <normal_fragment_maps>
	#include <emissivemap_fragment>
	#include <lights_toon_fragment>
	#include <lights_fragment_begin>
	#include <lights_fragment_maps>
	#include <lights_fragment_end>
	#include <aomap_fragment>
	vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
	#include <dithering_fragment>
}`, VE = `#define TOON
varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
#endif
#include <common>
#include <uv_pars_vertex>
#include <uv2_pars_vertex>
#include <displacementmap_pars_vertex>
#include <color_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <shadowmap_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <uv2_vertex>
	#include <color_vertex>
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinbase_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
#ifndef FLAT_SHADED
	vNormal = normalize( transformedNormal );
#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <displacementmap_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	vViewPosition = - mvPosition.xyz;
	#include <worldpos_vertex>
	#include <shadowmap_vertex>
	#include <fog_vertex>
}`, jE = `#define PHONG
uniform vec3 diffuse;
uniform vec3 emissive;
uniform vec3 specular;
uniform float shininess;
uniform float opacity;
#include <common>
#include <packing>
#include <dithering_pars_fragment>
#include <color_pars_fragment>
#include <uv_pars_fragment>
#include <uv2_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <aomap_pars_fragment>
#include <lightmap_pars_fragment>
#include <emissivemap_pars_fragment>
#include <envmap_common_pars_fragment>
#include <envmap_pars_fragment>
#include <cube_uv_reflection_fragment>
#include <fog_pars_fragment>
#include <bsdfs>
#include <lights_pars_begin>
#include <lights_phong_pars_fragment>
#include <shadowmap_pars_fragment>
#include <bumpmap_pars_fragment>
#include <normalmap_pars_fragment>
#include <specularmap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( diffuse, opacity );
	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );
	vec3 totalEmissiveRadiance = emissive;
	#include <logdepthbuf_fragment>
	#include <map_fragment>
	#include <color_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	#include <specularmap_fragment>
	#include <normal_fragment_begin>
	#include <normal_fragment_maps>
	#include <emissivemap_fragment>
	#include <lights_phong_fragment>
	#include <lights_fragment_begin>
	#include <lights_fragment_maps>
	#include <lights_fragment_end>
	#include <aomap_fragment>
	vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + reflectedLight.directSpecular + reflectedLight.indirectSpecular + totalEmissiveRadiance;
	#include <envmap_fragment>
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
	#include <dithering_fragment>
}`, WE = `#define PHONG
varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
#endif
#include <common>
#include <uv_pars_vertex>
#include <uv2_pars_vertex>
#include <displacementmap_pars_vertex>
#include <envmap_pars_vertex>
#include <color_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <shadowmap_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <uv2_vertex>
	#include <color_vertex>
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinbase_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
#ifndef FLAT_SHADED
	vNormal = normalize( transformedNormal );
#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <displacementmap_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	vViewPosition = - mvPosition.xyz;
	#include <worldpos_vertex>
	#include <envmap_vertex>
	#include <shadowmap_vertex>
	#include <fog_vertex>
}`, HE = `#define STANDARD
#ifdef PHYSICAL
	#define REFLECTIVITY
	#define CLEARCOAT
	#define TRANSMISSION
#endif
uniform vec3 diffuse;
uniform vec3 emissive;
uniform float roughness;
uniform float metalness;
uniform float opacity;
#ifdef TRANSMISSION
	uniform float transmission;
#endif
#ifdef REFLECTIVITY
	uniform float reflectivity;
#endif
#ifdef CLEARCOAT
	uniform float clearcoat;
	uniform float clearcoatRoughness;
#endif
#ifdef USE_SHEEN
	uniform vec3 sheen;
#endif
varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
	#ifdef USE_TANGENT
		varying vec3 vTangent;
		varying vec3 vBitangent;
	#endif
#endif
#include <common>
#include <packing>
#include <dithering_pars_fragment>
#include <color_pars_fragment>
#include <uv_pars_fragment>
#include <uv2_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <aomap_pars_fragment>
#include <lightmap_pars_fragment>
#include <emissivemap_pars_fragment>
#include <transmissionmap_pars_fragment>
#include <bsdfs>
#include <cube_uv_reflection_fragment>
#include <envmap_common_pars_fragment>
#include <envmap_physical_pars_fragment>
#include <fog_pars_fragment>
#include <lights_pars_begin>
#include <lights_physical_pars_fragment>
#include <shadowmap_pars_fragment>
#include <bumpmap_pars_fragment>
#include <normalmap_pars_fragment>
#include <clearcoat_pars_fragment>
#include <roughnessmap_pars_fragment>
#include <metalnessmap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec4 diffuseColor = vec4( diffuse, opacity );
	ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );
	vec3 totalEmissiveRadiance = emissive;
	#ifdef TRANSMISSION
		float totalTransmission = transmission;
	#endif
	#include <logdepthbuf_fragment>
	#include <map_fragment>
	#include <color_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	#include <roughnessmap_fragment>
	#include <metalnessmap_fragment>
	#include <normal_fragment_begin>
	#include <normal_fragment_maps>
	#include <clearcoat_normal_fragment_begin>
	#include <clearcoat_normal_fragment_maps>
	#include <emissivemap_fragment>
	#include <transmissionmap_fragment>
	#include <lights_physical_fragment>
	#include <lights_fragment_begin>
	#include <lights_fragment_maps>
	#include <lights_fragment_end>
	#include <aomap_fragment>
	vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + reflectedLight.directSpecular + reflectedLight.indirectSpecular + totalEmissiveRadiance;
	#ifdef TRANSMISSION
		diffuseColor.a *= saturate( 1. - totalTransmission + linearToRelativeLuminance( reflectedLight.directSpecular + reflectedLight.indirectSpecular ) );
	#endif
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
	#include <dithering_fragment>
}`, qE = `#define STANDARD
varying vec3 vViewPosition;
#ifndef FLAT_SHADED
	varying vec3 vNormal;
	#ifdef USE_TANGENT
		varying vec3 vTangent;
		varying vec3 vBitangent;
	#endif
#endif
#include <common>
#include <uv_pars_vertex>
#include <uv2_pars_vertex>
#include <displacementmap_pars_vertex>
#include <color_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <shadowmap_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <uv2_vertex>
	#include <color_vertex>
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinbase_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
#ifndef FLAT_SHADED
	vNormal = normalize( transformedNormal );
	#ifdef USE_TANGENT
		vTangent = normalize( transformedTangent );
		vBitangent = normalize( cross( vNormal, vTangent ) * tangent.w );
	#endif
#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <displacementmap_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	vViewPosition = - mvPosition.xyz;
	#include <worldpos_vertex>
	#include <shadowmap_vertex>
	#include <fog_vertex>
}`, KE = `#define NORMAL
uniform float opacity;
#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( TANGENTSPACE_NORMALMAP )
	varying vec3 vViewPosition;
#endif
#ifndef FLAT_SHADED
	varying vec3 vNormal;
	#ifdef USE_TANGENT
		varying vec3 vTangent;
		varying vec3 vBitangent;
	#endif
#endif
#include <packing>
#include <uv_pars_fragment>
#include <bumpmap_pars_fragment>
#include <normalmap_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	#include <logdepthbuf_fragment>
	#include <normal_fragment_begin>
	#include <normal_fragment_maps>
	gl_FragColor = vec4( packNormalToRGB( normal ), opacity );
}`, XE = `#define NORMAL
#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( TANGENTSPACE_NORMALMAP )
	varying vec3 vViewPosition;
#endif
#ifndef FLAT_SHADED
	varying vec3 vNormal;
	#ifdef USE_TANGENT
		varying vec3 vTangent;
		varying vec3 vBitangent;
	#endif
#endif
#include <common>
#include <uv_pars_vertex>
#include <displacementmap_pars_vertex>
#include <morphtarget_pars_vertex>
#include <skinning_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinbase_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
#ifndef FLAT_SHADED
	vNormal = normalize( transformedNormal );
	#ifdef USE_TANGENT
		vTangent = normalize( transformedTangent );
		vBitangent = normalize( cross( vNormal, vTangent ) * tangent.w );
	#endif
#endif
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <skinning_vertex>
	#include <displacementmap_vertex>
	#include <project_vertex>
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( TANGENTSPACE_NORMALMAP )
	vViewPosition = - mvPosition.xyz;
#endif
}`, YE = `uniform vec3 diffuse;
uniform float opacity;
#include <common>
#include <color_pars_fragment>
#include <map_particle_pars_fragment>
#include <fog_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec3 outgoingLight = vec3( 0.0 );
	vec4 diffuseColor = vec4( diffuse, opacity );
	#include <logdepthbuf_fragment>
	#include <map_particle_fragment>
	#include <color_fragment>
	#include <alphatest_fragment>
	outgoingLight = diffuseColor.rgb;
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
	#include <premultiplied_alpha_fragment>
}`, JE = `uniform float size;
uniform float scale;
#include <common>
#include <color_pars_vertex>
#include <fog_pars_vertex>
#include <morphtarget_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <color_vertex>
	#include <begin_vertex>
	#include <morphtarget_vertex>
	#include <project_vertex>
	gl_PointSize = size;
	#ifdef USE_SIZEATTENUATION
		bool isPerspective = isPerspectiveMatrix( projectionMatrix );
		if ( isPerspective ) gl_PointSize *= ( scale / - mvPosition.z );
	#endif
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	#include <worldpos_vertex>
	#include <fog_vertex>
}`, QE = `uniform vec3 color;
uniform float opacity;
#include <common>
#include <packing>
#include <fog_pars_fragment>
#include <bsdfs>
#include <lights_pars_begin>
#include <shadowmap_pars_fragment>
#include <shadowmask_pars_fragment>
void main() {
	gl_FragColor = vec4( color, opacity * ( 1.0 - getShadowMask() ) );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
}`, ZE = `#include <common>
#include <fog_pars_vertex>
#include <shadowmap_pars_vertex>
void main() {
	#include <begin_vertex>
	#include <project_vertex>
	#include <worldpos_vertex>
	#include <beginnormal_vertex>
	#include <morphnormal_vertex>
	#include <skinbase_vertex>
	#include <skinnormal_vertex>
	#include <defaultnormal_vertex>
	#include <shadowmap_vertex>
	#include <fog_vertex>
}`, e2 = `uniform vec3 diffuse;
uniform float opacity;
#include <common>
#include <uv_pars_fragment>
#include <map_pars_fragment>
#include <alphamap_pars_fragment>
#include <fog_pars_fragment>
#include <logdepthbuf_pars_fragment>
#include <clipping_planes_pars_fragment>
void main() {
	#include <clipping_planes_fragment>
	vec3 outgoingLight = vec3( 0.0 );
	vec4 diffuseColor = vec4( diffuse, opacity );
	#include <logdepthbuf_fragment>
	#include <map_fragment>
	#include <alphamap_fragment>
	#include <alphatest_fragment>
	outgoingLight = diffuseColor.rgb;
	gl_FragColor = vec4( outgoingLight, diffuseColor.a );
	#include <tonemapping_fragment>
	#include <encodings_fragment>
	#include <fog_fragment>
}`, t2 = `uniform float rotation;
uniform vec2 center;
#include <common>
#include <uv_pars_vertex>
#include <fog_pars_vertex>
#include <logdepthbuf_pars_vertex>
#include <clipping_planes_pars_vertex>
void main() {
	#include <uv_vertex>
	vec4 mvPosition = modelViewMatrix * vec4( 0.0, 0.0, 0.0, 1.0 );
	vec2 scale;
	scale.x = length( vec3( modelMatrix[ 0 ].x, modelMatrix[ 0 ].y, modelMatrix[ 0 ].z ) );
	scale.y = length( vec3( modelMatrix[ 1 ].x, modelMatrix[ 1 ].y, modelMatrix[ 1 ].z ) );
	#ifndef USE_SIZEATTENUATION
		bool isPerspective = isPerspectiveMatrix( projectionMatrix );
		if ( isPerspective ) scale *= - mvPosition.z;
	#endif
	vec2 alignedPosition = ( position.xy - ( center - vec2( 0.5 ) ) ) * scale;
	vec2 rotatedPosition;
	rotatedPosition.x = cos( rotation ) * alignedPosition.x - sin( rotation ) * alignedPosition.y;
	rotatedPosition.y = sin( rotation ) * alignedPosition.x + cos( rotation ) * alignedPosition.y;
	mvPosition.xy += rotatedPosition;
	gl_Position = projectionMatrix * mvPosition;
	#include <logdepthbuf_vertex>
	#include <clipping_planes_vertex>
	#include <fog_vertex>
}`;
const gn = {
  alphamap_fragment: F1,
  alphamap_pars_fragment: R1,
  alphatest_fragment: B1,
  aomap_fragment: z1,
  aomap_pars_fragment: $1,
  begin_vertex: N1,
  beginnormal_vertex: U1,
  bsdfs: G1,
  bumpmap_pars_fragment: V1,
  clipping_planes_fragment: j1,
  clipping_planes_pars_fragment: W1,
  clipping_planes_pars_vertex: H1,
  clipping_planes_vertex: q1,
  color_fragment: K1,
  color_pars_fragment: X1,
  color_pars_vertex: Y1,
  color_vertex: J1,
  common: Q1,
  cube_uv_reflection_fragment: Z1,
  defaultnormal_vertex: eT,
  displacementmap_pars_vertex: tT,
  displacementmap_vertex: nT,
  emissivemap_fragment: iT,
  emissivemap_pars_fragment: sT,
  encodings_fragment: rT,
  encodings_pars_fragment: oT,
  envmap_fragment: aT,
  envmap_common_pars_fragment: lT,
  envmap_pars_fragment: cT,
  envmap_pars_vertex: uT,
  envmap_physical_pars_fragment: xT,
  envmap_vertex: dT,
  fog_vertex: hT,
  fog_pars_vertex: fT,
  fog_fragment: pT,
  fog_pars_fragment: mT,
  gradientmap_pars_fragment: gT,
  lightmap_fragment: _T,
  lightmap_pars_fragment: yT,
  lights_lambert_vertex: vT,
  lights_pars_begin: wT,
  lights_toon_fragment: bT,
  lights_toon_pars_fragment: MT,
  lights_phong_fragment: TT,
  lights_phong_pars_fragment: ET,
  lights_physical_fragment: ST,
  lights_physical_pars_fragment: PT,
  lights_fragment_begin: AT,
  lights_fragment_maps: CT,
  lights_fragment_end: IT,
  logdepthbuf_fragment: LT,
  logdepthbuf_pars_fragment: DT,
  logdepthbuf_pars_vertex: kT,
  logdepthbuf_vertex: OT,
  map_fragment: FT,
  map_pars_fragment: RT,
  map_particle_fragment: BT,
  map_particle_pars_fragment: zT,
  metalnessmap_fragment: $T,
  metalnessmap_pars_fragment: NT,
  morphnormal_vertex: UT,
  morphtarget_pars_vertex: GT,
  morphtarget_vertex: VT,
  normal_fragment_begin: jT,
  normal_fragment_maps: WT,
  normalmap_pars_fragment: HT,
  clearcoat_normal_fragment_begin: qT,
  clearcoat_normal_fragment_maps: KT,
  clearcoat_pars_fragment: XT,
  packing: YT,
  premultiplied_alpha_fragment: JT,
  project_vertex: QT,
  dithering_fragment: ZT,
  dithering_pars_fragment: eE,
  roughnessmap_fragment: tE,
  roughnessmap_pars_fragment: nE,
  shadowmap_pars_fragment: iE,
  shadowmap_pars_vertex: sE,
  shadowmap_vertex: rE,
  shadowmask_pars_fragment: oE,
  skinbase_vertex: aE,
  skinning_pars_vertex: lE,
  skinning_vertex: cE,
  skinnormal_vertex: uE,
  specularmap_fragment: dE,
  specularmap_pars_fragment: hE,
  tonemapping_fragment: fE,
  tonemapping_pars_fragment: pE,
  transmissionmap_fragment: mE,
  transmissionmap_pars_fragment: gE,
  uv_pars_fragment: _E,
  uv_pars_vertex: yE,
  uv_vertex: vE,
  uv2_pars_fragment: wE,
  uv2_pars_vertex: xE,
  uv2_vertex: bE,
  worldpos_vertex: ME,
  background_frag: TE,
  background_vert: EE,
  cube_frag: SE,
  cube_vert: PE,
  depth_frag: AE,
  depth_vert: CE,
  distanceRGBA_frag: IE,
  distanceRGBA_vert: LE,
  equirect_frag: DE,
  equirect_vert: kE,
  linedashed_frag: OE,
  linedashed_vert: FE,
  meshbasic_frag: RE,
  meshbasic_vert: BE,
  meshlambert_frag: zE,
  meshlambert_vert: $E,
  meshmatcap_frag: NE,
  meshmatcap_vert: UE,
  meshtoon_frag: GE,
  meshtoon_vert: VE,
  meshphong_frag: jE,
  meshphong_vert: WE,
  meshphysical_frag: HE,
  meshphysical_vert: qE,
  normal_frag: KE,
  normal_vert: XE,
  points_frag: YE,
  points_vert: JE,
  shadow_frag: QE,
  shadow_vert: ZE,
  sprite_frag: e2,
  sprite_vert: t2
}, ar = {
  basic: {
    uniforms: Ii([
      Bt.common,
      Bt.specularmap,
      Bt.envmap,
      Bt.aomap,
      Bt.lightmap,
      Bt.fog
    ]),
    vertexShader: gn.meshbasic_vert,
    fragmentShader: gn.meshbasic_frag
  },
  lambert: {
    uniforms: Ii([
      Bt.common,
      Bt.specularmap,
      Bt.envmap,
      Bt.aomap,
      Bt.lightmap,
      Bt.emissivemap,
      Bt.fog,
      Bt.lights,
      {
        emissive: { value: new Wt(0) }
      }
    ]),
    vertexShader: gn.meshlambert_vert,
    fragmentShader: gn.meshlambert_frag
  },
  phong: {
    uniforms: Ii([
      Bt.common,
      Bt.specularmap,
      Bt.envmap,
      Bt.aomap,
      Bt.lightmap,
      Bt.emissivemap,
      Bt.bumpmap,
      Bt.normalmap,
      Bt.displacementmap,
      Bt.fog,
      Bt.lights,
      {
        emissive: { value: new Wt(0) },
        specular: { value: new Wt(1118481) },
        shininess: { value: 30 }
      }
    ]),
    vertexShader: gn.meshphong_vert,
    fragmentShader: gn.meshphong_frag
  },
  standard: {
    uniforms: Ii([
      Bt.common,
      Bt.envmap,
      Bt.aomap,
      Bt.lightmap,
      Bt.emissivemap,
      Bt.bumpmap,
      Bt.normalmap,
      Bt.displacementmap,
      Bt.roughnessmap,
      Bt.metalnessmap,
      Bt.fog,
      Bt.lights,
      {
        emissive: { value: new Wt(0) },
        roughness: { value: 1 },
        metalness: { value: 0 },
        envMapIntensity: { value: 1 }
        // temporary
      }
    ]),
    vertexShader: gn.meshphysical_vert,
    fragmentShader: gn.meshphysical_frag
  },
  toon: {
    uniforms: Ii([
      Bt.common,
      Bt.aomap,
      Bt.lightmap,
      Bt.emissivemap,
      Bt.bumpmap,
      Bt.normalmap,
      Bt.displacementmap,
      Bt.gradientmap,
      Bt.fog,
      Bt.lights,
      {
        emissive: { value: new Wt(0) }
      }
    ]),
    vertexShader: gn.meshtoon_vert,
    fragmentShader: gn.meshtoon_frag
  },
  matcap: {
    uniforms: Ii([
      Bt.common,
      Bt.bumpmap,
      Bt.normalmap,
      Bt.displacementmap,
      Bt.fog,
      {
        matcap: { value: null }
      }
    ]),
    vertexShader: gn.meshmatcap_vert,
    fragmentShader: gn.meshmatcap_frag
  },
  points: {
    uniforms: Ii([
      Bt.points,
      Bt.fog
    ]),
    vertexShader: gn.points_vert,
    fragmentShader: gn.points_frag
  },
  dashed: {
    uniforms: Ii([
      Bt.common,
      Bt.fog,
      {
        scale: { value: 1 },
        dashSize: { value: 1 },
        totalSize: { value: 2 }
      }
    ]),
    vertexShader: gn.linedashed_vert,
    fragmentShader: gn.linedashed_frag
  },
  depth: {
    uniforms: Ii([
      Bt.common,
      Bt.displacementmap
    ]),
    vertexShader: gn.depth_vert,
    fragmentShader: gn.depth_frag
  },
  normal: {
    uniforms: Ii([
      Bt.common,
      Bt.bumpmap,
      Bt.normalmap,
      Bt.displacementmap,
      {
        opacity: { value: 1 }
      }
    ]),
    vertexShader: gn.normal_vert,
    fragmentShader: gn.normal_frag
  },
  sprite: {
    uniforms: Ii([
      Bt.sprite,
      Bt.fog
    ]),
    vertexShader: gn.sprite_vert,
    fragmentShader: gn.sprite_frag
  },
  background: {
    uniforms: {
      uvTransform: { value: new Bi() },
      t2D: { value: null }
    },
    vertexShader: gn.background_vert,
    fragmentShader: gn.background_frag
  },
  /* -------------------------------------------------------------------------
  //	Cube map shader
   ------------------------------------------------------------------------- */
  cube: {
    uniforms: Ii([
      Bt.envmap,
      {
        opacity: { value: 1 }
      }
    ]),
    vertexShader: gn.cube_vert,
    fragmentShader: gn.cube_frag
  },
  equirect: {
    uniforms: {
      tEquirect: { value: null }
    },
    vertexShader: gn.equirect_vert,
    fragmentShader: gn.equirect_frag
  },
  distanceRGBA: {
    uniforms: Ii([
      Bt.common,
      Bt.displacementmap,
      {
        referencePosition: { value: new ve() },
        nearDistance: { value: 1 },
        farDistance: { value: 1e3 }
      }
    ]),
    vertexShader: gn.distanceRGBA_vert,
    fragmentShader: gn.distanceRGBA_frag
  },
  shadow: {
    uniforms: Ii([
      Bt.lights,
      Bt.fog,
      {
        color: { value: new Wt(0) },
        opacity: { value: 1 }
      }
    ]),
    vertexShader: gn.shadow_vert,
    fragmentShader: gn.shadow_frag
  }
};
ar.physical = {
  uniforms: Ii([
    ar.standard.uniforms,
    {
      clearcoat: { value: 0 },
      clearcoatMap: { value: null },
      clearcoatRoughness: { value: 0 },
      clearcoatRoughnessMap: { value: null },
      clearcoatNormalScale: { value: new vt(1, 1) },
      clearcoatNormalMap: { value: null },
      sheen: { value: new Wt(0) },
      transmission: { value: 0 },
      transmissionMap: { value: null }
    }
  ]),
  vertexShader: gn.meshphysical_vert,
  fragmentShader: gn.meshphysical_frag
};
function n2(e, n, t, i) {
  const r = new Wt(0);
  let a = 0, c, u, l = null, f = 0, m = null;
  function h(_, v, S, D) {
    let w = v.isScene === !0 ? v.background : null;
    const T = e.xr, F = T.getSession && T.getSession();
    if (F && F.environmentBlendMode === "additive" && (w = null), w === null ? p(r, a) : w && w.isColor && (p(w, 1), D = !0), (e.autoClear || D) && e.clear(e.autoClearColor, e.autoClearDepth, e.autoClearStencil), w && (w.isCubeTexture || w.isWebGLCubeRenderTarget || w.mapping === ug)) {
      u === void 0 && (u = new Ln(
        new Uy(1, 1, 1),
        new Xi({
          name: "BackgroundCubeMaterial",
          uniforms: lu(ar.cube.uniforms),
          vertexShader: ar.cube.vertexShader,
          fragmentShader: ar.cube.fragmentShader,
          side: hi,
          depthTest: !1,
          depthWrite: !1,
          fog: !1
        })
      ), u.geometry.deleteAttribute("normal"), u.geometry.deleteAttribute("uv"), u.onBeforeRender = function(A, L, I) {
        this.matrixWorld.copyPosition(I.matrixWorld);
      }, Object.defineProperty(u.material, "envMap", {
        get: function() {
          return this.uniforms.envMap.value;
        }
      }), t.update(u));
      const E = w.isWebGLCubeRenderTarget ? w.texture : w;
      u.material.uniforms.envMap.value = E, u.material.uniforms.flipEnvMap.value = E.isCubeTexture ? -1 : 1, (l !== w || f !== E.version || m !== e.toneMapping) && (u.material.needsUpdate = !0, l = w, f = E.version, m = e.toneMapping), _.unshift(u, u.geometry, u.material, 0, 0, null);
    } else
      w && w.isTexture && (c === void 0 && (c = new Ln(
        new uu(2, 2),
        new Xi({
          name: "BackgroundMaterial",
          uniforms: lu(ar.background.uniforms),
          vertexShader: ar.background.vertexShader,
          fragmentShader: ar.background.fragmentShader,
          side: cg,
          depthTest: !1,
          depthWrite: !1,
          fog: !1
        })
      ), c.geometry.deleteAttribute("normal"), Object.defineProperty(c.material, "map", {
        get: function() {
          return this.uniforms.t2D.value;
        }
      }), t.update(c)), c.material.uniforms.t2D.value = w, w.matrixAutoUpdate === !0 && w.updateMatrix(), c.material.uniforms.uvTransform.value.copy(w.matrix), (l !== w || f !== w.version || m !== e.toneMapping) && (c.material.needsUpdate = !0, l = w, f = w.version, m = e.toneMapping), _.unshift(c, c.geometry, c.material, 0, 0, null));
  }
  function p(_, v) {
    n.buffers.color.setClear(_.r, _.g, _.b, v, i);
  }
  return {
    getClearColor: function() {
      return r;
    },
    setClearColor: function(_, v) {
      r.set(_), a = v !== void 0 ? v : 1, p(r, a);
    },
    getClearAlpha: function() {
      return a;
    },
    setClearAlpha: function(_) {
      a = _, p(r, a);
    },
    render: h
  };
}
function i2(e, n, t, i) {
  const r = e.getParameter(34921), a = i.isWebGL2 ? null : n.get("OES_vertex_array_object"), c = i.isWebGL2 || a !== null, u = {}, l = S(null);
  let f = l;
  function m(W, te, K, pe, be) {
    let Ee = !1;
    if (c) {
      const Ge = v(pe, K, te);
      f !== Ge && (f = Ge, p(f.object)), Ee = D(pe), Ee && w(pe);
    } else {
      const Ge = te.wireframe === !0;
      (f.geometry !== pe.id || f.program !== K.id || f.wireframe !== Ge) && (f.geometry = pe.id, f.program = K.id, f.wireframe = Ge, Ee = !0);
    }
    W.isInstancedMesh === !0 && (Ee = !0), be !== null && t.update(be, 34963), Ee && (I(W, te, K, pe), be !== null && e.bindBuffer(34963, t.get(be).buffer));
  }
  function h() {
    return i.isWebGL2 ? e.createVertexArray() : a.createVertexArrayOES();
  }
  function p(W) {
    return i.isWebGL2 ? e.bindVertexArray(W) : a.bindVertexArrayOES(W);
  }
  function _(W) {
    return i.isWebGL2 ? e.deleteVertexArray(W) : a.deleteVertexArrayOES(W);
  }
  function v(W, te, K) {
    const pe = K.wireframe === !0;
    let be = u[W.id];
    be === void 0 && (be = {}, u[W.id] = be);
    let Ee = be[te.id];
    Ee === void 0 && (Ee = {}, be[te.id] = Ee);
    let Ge = Ee[pe];
    return Ge === void 0 && (Ge = S(h()), Ee[pe] = Ge), Ge;
  }
  function S(W) {
    const te = [], K = [], pe = [];
    for (let be = 0; be < r; be++)
      te[be] = 0, K[be] = 0, pe[be] = 0;
    return {
      // for backward compatibility on non-VAO support browser
      geometry: null,
      program: null,
      wireframe: !1,
      newAttributes: te,
      enabledAttributes: K,
      attributeDivisors: pe,
      object: W,
      attributes: {}
    };
  }
  function D(W) {
    const te = f.attributes, K = W.attributes;
    if (Object.keys(te).length !== Object.keys(K).length)
      return !0;
    for (const pe in K) {
      const be = te[pe], Ee = K[pe];
      if (be.attribute !== Ee || be.data !== Ee.data)
        return !0;
    }
    return !1;
  }
  function w(W) {
    const te = {}, K = W.attributes;
    for (const pe in K) {
      const be = K[pe], Ee = {};
      Ee.attribute = be, be.data && (Ee.data = be.data), te[pe] = Ee;
    }
    f.attributes = te;
  }
  function T() {
    const W = f.newAttributes;
    for (let te = 0, K = W.length; te < K; te++)
      W[te] = 0;
  }
  function F(W) {
    E(W, 0);
  }
  function E(W, te) {
    const K = f.newAttributes, pe = f.enabledAttributes, be = f.attributeDivisors;
    K[W] = 1, pe[W] === 0 && (e.enableVertexAttribArray(W), pe[W] = 1), be[W] !== te && ((i.isWebGL2 ? e : n.get("ANGLE_instanced_arrays"))[i.isWebGL2 ? "vertexAttribDivisor" : "vertexAttribDivisorANGLE"](W, te), be[W] = te);
  }
  function A() {
    const W = f.newAttributes, te = f.enabledAttributes;
    for (let K = 0, pe = te.length; K < pe; K++)
      te[K] !== W[K] && (e.disableVertexAttribArray(K), te[K] = 0);
  }
  function L(W, te, K, pe, be, Ee) {
    i.isWebGL2 === !0 && (K === 5124 || K === 5125) ? e.vertexAttribIPointer(W, te, K, be, Ee) : e.vertexAttribPointer(W, te, K, pe, be, Ee);
  }
  function I(W, te, K, pe) {
    if (i.isWebGL2 === !1 && (W.isInstancedMesh || pe.isInstancedBufferGeometry) && n.get("ANGLE_instanced_arrays") === null)
      return;
    T();
    const be = pe.attributes, Ee = K.getAttributes(), Ge = te.defaultAttributeValues;
    for (const _e in Ee) {
      const De = Ee[_e];
      if (De >= 0) {
        const he = be[_e];
        if (he !== void 0) {
          const Z = he.normalized, me = he.itemSize, we = t.get(he);
          if (we === void 0)
            continue;
          const xe = we.buffer, et = we.type, Ve = we.bytesPerElement;
          if (he.isInterleavedBufferAttribute) {
            const nt = he.data, Be = nt.stride, ae = he.offset;
            nt && nt.isInstancedInterleavedBuffer ? (E(De, nt.meshPerAttribute), pe._maxInstanceCount === void 0 && (pe._maxInstanceCount = nt.meshPerAttribute * nt.count)) : F(De), e.bindBuffer(34962, xe), L(De, me, et, Z, Be * Ve, ae * Ve);
          } else
            he.isInstancedBufferAttribute ? (E(De, he.meshPerAttribute), pe._maxInstanceCount === void 0 && (pe._maxInstanceCount = he.meshPerAttribute * he.count)) : F(De), e.bindBuffer(34962, xe), L(De, me, et, Z, 0, 0);
        } else if (_e === "instanceMatrix") {
          const Z = t.get(W.instanceMatrix);
          if (Z === void 0)
            continue;
          const me = Z.buffer, we = Z.type;
          E(De + 0, 1), E(De + 1, 1), E(De + 2, 1), E(De + 3, 1), e.bindBuffer(34962, me), e.vertexAttribPointer(De + 0, 4, we, !1, 64, 0), e.vertexAttribPointer(De + 1, 4, we, !1, 64, 16), e.vertexAttribPointer(De + 2, 4, we, !1, 64, 32), e.vertexAttribPointer(De + 3, 4, we, !1, 64, 48);
        } else if (Ge !== void 0) {
          const Z = Ge[_e];
          if (Z !== void 0)
            switch (Z.length) {
              case 2:
                e.vertexAttrib2fv(De, Z);
                break;
              case 3:
                e.vertexAttrib3fv(De, Z);
                break;
              case 4:
                e.vertexAttrib4fv(De, Z);
                break;
              default:
                e.vertexAttrib1fv(De, Z);
            }
        }
      }
    }
    A();
  }
  function R() {
    ne();
    for (const W in u) {
      const te = u[W];
      for (const K in te) {
        const pe = te[K];
        for (const be in pe)
          _(pe[be].object), delete pe[be];
        delete te[K];
      }
      delete u[W];
    }
  }
  function N(W) {
    if (u[W.id] === void 0)
      return;
    const te = u[W.id];
    for (const K in te) {
      const pe = te[K];
      for (const be in pe)
        _(pe[be].object), delete pe[be];
      delete te[K];
    }
    delete u[W.id];
  }
  function q(W) {
    for (const te in u) {
      const K = u[te];
      if (K[W.id] === void 0)
        continue;
      const pe = K[W.id];
      for (const be in pe)
        _(pe[be].object), delete pe[be];
      delete K[W.id];
    }
  }
  function ne() {
    Q(), f !== l && (f = l, p(f.object));
  }
  function Q() {
    l.geometry = null, l.program = null, l.wireframe = !1;
  }
  return {
    setup: m,
    reset: ne,
    resetDefaultState: Q,
    dispose: R,
    releaseStatesOfGeometry: N,
    releaseStatesOfProgram: q,
    initAttributes: T,
    enableAttribute: F,
    disableUnusedAttributes: A
  };
}
function s2(e, n, t, i) {
  const r = i.isWebGL2;
  let a;
  function c(f) {
    a = f;
  }
  function u(f, m) {
    e.drawArrays(a, f, m), t.update(m, a, 1);
  }
  function l(f, m, h) {
    if (h === 0)
      return;
    let p, _;
    if (r)
      p = e, _ = "drawArraysInstanced";
    else if (p = n.get("ANGLE_instanced_arrays"), _ = "drawArraysInstancedANGLE", p === null) {
      console.error("THREE.WebGLBufferRenderer: using THREE.InstancedBufferGeometry but hardware does not support extension ANGLE_instanced_arrays.");
      return;
    }
    p[_](a, f, m, h), t.update(m, a, h);
  }
  this.setMode = c, this.render = u, this.renderInstances = l;
}
function r2(e, n, t) {
  let i;
  function r() {
    if (i !== void 0)
      return i;
    const L = n.get("EXT_texture_filter_anisotropic");
    return L !== null ? i = e.getParameter(L.MAX_TEXTURE_MAX_ANISOTROPY_EXT) : i = 0, i;
  }
  function a(L) {
    if (L === "highp") {
      if (e.getShaderPrecisionFormat(35633, 36338).precision > 0 && e.getShaderPrecisionFormat(35632, 36338).precision > 0)
        return "highp";
      L = "mediump";
    }
    return L === "mediump" && e.getShaderPrecisionFormat(35633, 36337).precision > 0 && e.getShaderPrecisionFormat(35632, 36337).precision > 0 ? "mediump" : "lowp";
  }
  const c = typeof WebGL2RenderingContext < "u" && e instanceof WebGL2RenderingContext || typeof WebGL2ComputeRenderingContext < "u" && e instanceof WebGL2ComputeRenderingContext;
  let u = t.precision !== void 0 ? t.precision : "highp";
  const l = a(u);
  l !== u && (console.warn("THREE.WebGLRenderer:", u, "not supported, using", l, "instead."), u = l);
  const f = t.logarithmicDepthBuffer === !0, m = e.getParameter(34930), h = e.getParameter(35660), p = e.getParameter(3379), _ = e.getParameter(34076), v = e.getParameter(34921), S = e.getParameter(36347), D = e.getParameter(36348), w = e.getParameter(36349), T = h > 0, F = c || !!n.get("OES_texture_float"), E = T && F, A = c ? e.getParameter(36183) : 0;
  return {
    isWebGL2: c,
    getMaxAnisotropy: r,
    getMaxPrecision: a,
    precision: u,
    logarithmicDepthBuffer: f,
    maxTextures: m,
    maxVertexTextures: h,
    maxTextureSize: p,
    maxCubemapSize: _,
    maxAttributes: v,
    maxVertexUniforms: S,
    maxVaryings: D,
    maxFragmentUniforms: w,
    vertexTextures: T,
    floatFragmentTextures: F,
    floatVertexTextures: E,
    maxSamples: A
  };
}
function o2() {
  const e = this;
  let n = null, t = 0, i = !1, r = !1;
  const a = new or(), c = new Bi(), u = { value: null, needsUpdate: !1 };
  this.uniform = u, this.numPlanes = 0, this.numIntersection = 0, this.init = function(m, h, p) {
    const _ = m.length !== 0 || h || // enable state of previous frame - the clipping code has to
    // run another frame in order to reset the state:
    t !== 0 || i;
    return i = h, n = f(m, p, 0), t = m.length, _;
  }, this.beginShadows = function() {
    r = !0, f(null);
  }, this.endShadows = function() {
    r = !1, l();
  }, this.setState = function(m, h, p, _, v, S) {
    if (!i || m === null || m.length === 0 || r && !p)
      r ? f(null) : l();
    else {
      const D = r ? 0 : t, w = D * 4;
      let T = v.clippingState || null;
      u.value = T, T = f(m, _, w, S);
      for (let F = 0; F !== w; ++F)
        T[F] = n[F];
      v.clippingState = T, this.numIntersection = h ? this.numPlanes : 0, this.numPlanes += D;
    }
  };
  function l() {
    u.value !== n && (u.value = n, u.needsUpdate = t > 0), e.numPlanes = t, e.numIntersection = 0;
  }
  function f(m, h, p, _) {
    let v = m !== null ? m.length : 0, S = null;
    if (v !== 0) {
      if (S = u.value, _ !== !0 || S === null) {
        const D = p + v * 4, w = h.matrixWorldInverse;
        c.getNormalMatrix(w), (S === null || S.length < D) && (S = new Float32Array(D));
        for (let T = 0, F = p; T !== v; ++T, F += 4)
          a.copy(m[T]).applyMatrix4(w, c), a.normal.toArray(S, F), S[F + 3] = a.constant;
      }
      u.value = S, u.needsUpdate = !0;
    }
    return e.numPlanes = v, e.numIntersection = 0, S;
  }
}
function a2(e) {
  const n = {};
  return {
    has: function(t) {
      if (n[t] !== void 0)
        return n[t];
      let i;
      switch (t) {
        case "WEBGL_depth_texture":
          i = e.getExtension("WEBGL_depth_texture") || e.getExtension("MOZ_WEBGL_depth_texture") || e.getExtension("WEBKIT_WEBGL_depth_texture");
          break;
        case "EXT_texture_filter_anisotropic":
          i = e.getExtension("EXT_texture_filter_anisotropic") || e.getExtension("MOZ_EXT_texture_filter_anisotropic") || e.getExtension("WEBKIT_EXT_texture_filter_anisotropic");
          break;
        case "WEBGL_compressed_texture_s3tc":
          i = e.getExtension("WEBGL_compressed_texture_s3tc") || e.getExtension("MOZ_WEBGL_compressed_texture_s3tc") || e.getExtension("WEBKIT_WEBGL_compressed_texture_s3tc");
          break;
        case "WEBGL_compressed_texture_pvrtc":
          i = e.getExtension("WEBGL_compressed_texture_pvrtc") || e.getExtension("WEBKIT_WEBGL_compressed_texture_pvrtc");
          break;
        default:
          i = e.getExtension(t);
      }
      return n[t] = i, !!i;
    },
    get: function(t) {
      return this.has(t) || console.warn("THREE.WebGLRenderer: " + t + " extension not supported."), n[t];
    }
  };
}
function l2(e, n, t, i) {
  const r = /* @__PURE__ */ new WeakMap(), a = /* @__PURE__ */ new WeakMap();
  function c(h) {
    const p = h.target, _ = r.get(p);
    _.index !== null && n.remove(_.index);
    for (const S in _.attributes)
      n.remove(_.attributes[S]);
    p.removeEventListener("dispose", c), r.delete(p);
    const v = a.get(_);
    v && (n.remove(v), a.delete(_)), i.releaseStatesOfGeometry(p), p.isInstancedBufferGeometry === !0 && delete p._maxInstanceCount, t.memory.geometries--;
  }
  function u(h, p) {
    let _ = r.get(p);
    return _ || (p.addEventListener("dispose", c), p.isBufferGeometry ? _ = p : p.isGeometry && (p._bufferGeometry === void 0 && (p._bufferGeometry = new Gt().setFromObject(h)), _ = p._bufferGeometry), r.set(p, _), t.memory.geometries++, _);
  }
  function l(h) {
    const p = h.attributes;
    for (const v in p)
      n.update(p[v], 34962);
    const _ = h.morphAttributes;
    for (const v in _) {
      const S = _[v];
      for (let D = 0, w = S.length; D < w; D++)
        n.update(S[D], 34962);
    }
  }
  function f(h) {
    const p = [], _ = h.index, v = h.attributes.position;
    let S = 0;
    if (_ !== null) {
      const T = _.array;
      S = _.version;
      for (let F = 0, E = T.length; F < E; F += 3) {
        const A = T[F + 0], L = T[F + 1], I = T[F + 2];
        p.push(A, L, L, I, I, A);
      }
    } else {
      const T = v.array;
      S = v.version;
      for (let F = 0, E = T.length / 3 - 1; F < E; F += 3) {
        const A = F + 0, L = F + 1, I = F + 2;
        p.push(A, L, L, I, I, A);
      }
    }
    const D = new (Vx(p) > 65535 ? Lm : Im)(p, 1);
    D.version = S;
    const w = a.get(h);
    w && n.remove(w), a.set(h, D);
  }
  function m(h) {
    const p = a.get(h);
    if (p) {
      const _ = h.index;
      _ !== null && p.version < _.version && f(h);
    } else
      f(h);
    return a.get(h);
  }
  return {
    get: u,
    update: l,
    getWireframeAttribute: m
  };
}
function c2(e, n, t, i) {
  const r = i.isWebGL2;
  let a;
  function c(p) {
    a = p;
  }
  let u, l;
  function f(p) {
    u = p.type, l = p.bytesPerElement;
  }
  function m(p, _) {
    e.drawElements(a, _, u, p * l), t.update(_, a, 1);
  }
  function h(p, _, v) {
    if (v === 0)
      return;
    let S, D;
    if (r)
      S = e, D = "drawElementsInstanced";
    else if (S = n.get("ANGLE_instanced_arrays"), D = "drawElementsInstancedANGLE", S === null) {
      console.error("THREE.WebGLIndexedBufferRenderer: using THREE.InstancedBufferGeometry but hardware does not support extension ANGLE_instanced_arrays.");
      return;
    }
    S[D](a, _, u, p * l, v), t.update(_, a, v);
  }
  this.setMode = c, this.setIndex = f, this.render = m, this.renderInstances = h;
}
function u2(e) {
  const n = {
    geometries: 0,
    textures: 0
  }, t = {
    frame: 0,
    calls: 0,
    triangles: 0,
    points: 0,
    lines: 0
  };
  function i(a, c, u) {
    switch (t.calls++, c) {
      case 4:
        t.triangles += u * (a / 3);
        break;
      case 1:
        t.lines += u * (a / 2);
        break;
      case 3:
        t.lines += u * (a - 1);
        break;
      case 2:
        t.lines += u * a;
        break;
      case 0:
        t.points += u * a;
        break;
      default:
        console.error("THREE.WebGLInfo: Unknown draw mode:", c);
        break;
    }
  }
  function r() {
    t.frame++, t.calls = 0, t.triangles = 0, t.points = 0, t.lines = 0;
  }
  return {
    memory: n,
    render: t,
    programs: null,
    autoReset: !0,
    reset: r,
    update: i
  };
}
function d2(e, n) {
  return e[0] - n[0];
}
function h2(e, n) {
  return Math.abs(n[1]) - Math.abs(e[1]);
}
function f2(e) {
  const n = {}, t = new Float32Array(8), i = [];
  for (let a = 0; a < 8; a++)
    i[a] = [a, 0];
  function r(a, c, u, l) {
    const f = a.morphTargetInfluences, m = f === void 0 ? 0 : f.length;
    let h = n[c.id];
    if (h === void 0) {
      h = [];
      for (let D = 0; D < m; D++)
        h[D] = [D, 0];
      n[c.id] = h;
    }
    for (let D = 0; D < m; D++) {
      const w = h[D];
      w[0] = D, w[1] = f[D];
    }
    h.sort(h2);
    for (let D = 0; D < 8; D++)
      D < m && h[D][1] ? (i[D][0] = h[D][0], i[D][1] = h[D][1]) : (i[D][0] = Number.MAX_SAFE_INTEGER, i[D][1] = 0);
    i.sort(d2);
    const p = u.morphTargets && c.morphAttributes.position, _ = u.morphNormals && c.morphAttributes.normal;
    let v = 0;
    for (let D = 0; D < 8; D++) {
      const w = i[D], T = w[0], F = w[1];
      T !== Number.MAX_SAFE_INTEGER && F ? (p && c.getAttribute("morphTarget" + D) !== p[T] && c.setAttribute("morphTarget" + D, p[T]), _ && c.getAttribute("morphNormal" + D) !== _[T] && c.setAttribute("morphNormal" + D, _[T]), t[D] = F, v += F) : (p && c.getAttribute("morphTarget" + D) !== void 0 && c.deleteAttribute("morphTarget" + D), _ && c.getAttribute("morphNormal" + D) !== void 0 && c.deleteAttribute("morphNormal" + D), t[D] = 0);
    }
    const S = c.morphTargetsRelative ? 1 : 1 - v;
    l.getUniforms().setValue(e, "morphTargetBaseInfluence", S), l.getUniforms().setValue(e, "morphTargetInfluences", t);
  }
  return {
    update: r
  };
}
function p2(e, n, t, i) {
  let r = /* @__PURE__ */ new WeakMap();
  function a(u) {
    const l = i.render.frame, f = u.geometry, m = n.get(u, f);
    return r.get(m) !== l && (f.isGeometry && m.updateFromObject(u), n.update(m), r.set(m, l)), u.isInstancedMesh && t.update(u.instanceMatrix, 34962), m;
  }
  function c() {
    r = /* @__PURE__ */ new WeakMap();
  }
  return {
    update: a,
    dispose: c
  };
}
function po(e, n, t, i, r, a, c, u, l, f) {
  e = e !== void 0 ? e : [], n = n !== void 0 ? n : L0, c = c !== void 0 ? c : pa, Fn.call(this, e, n, t, i, r, a, c, u, l, f), this.flipY = !1;
}
po.prototype = Object.create(Fn.prototype);
po.prototype.constructor = po;
po.prototype.isCubeTexture = !0;
Object.defineProperty(po.prototype, "images", {
  get: function() {
    return this.image;
  },
  set: function(e) {
    this.image = e;
  }
});
function Om(e, n, t, i) {
  Fn.call(this, null), this.image = { data: e || null, width: n || 1, height: t || 1, depth: i || 1 }, this.magFilter = _i, this.minFilter = _i, this.wrapR = qi, this.generateMipmaps = !1, this.flipY = !1, this.needsUpdate = !0;
}
Om.prototype = Object.create(Fn.prototype);
Om.prototype.constructor = Om;
Om.prototype.isDataTexture2DArray = !0;
function Fm(e, n, t, i) {
  Fn.call(this, null), this.image = { data: e || null, width: n || 1, height: t || 1, depth: i || 1 }, this.magFilter = _i, this.minFilter = _i, this.wrapR = qi, this.generateMipmaps = !1, this.flipY = !1, this.needsUpdate = !0;
}
Fm.prototype = Object.create(Fn.prototype);
Fm.prototype.constructor = Fm;
Fm.prototype.isDataTexture3D = !0;
const Hx = new Fn(), m2 = new Om(), g2 = new Fm(), qx = new po(), yw = [], vw = [], ww = new Float32Array(16), xw = new Float32Array(9), bw = new Float32Array(4);
function Cu(e, n, t) {
  const i = e[0];
  if (i <= 0 || i > 0)
    return e;
  let r = n * t, a = yw[r];
  if (a === void 0 && (a = new Float32Array(r), yw[r] = a), n !== 0) {
    i.toArray(a, 0);
    for (let c = 1, u = 0; c !== n; ++c)
      u += t, e[c].toArray(a, u);
  }
  return a;
}
function Ts(e, n) {
  if (e.length !== n.length)
    return !1;
  for (let t = 0, i = e.length; t < i; t++)
    if (e[t] !== n[t])
      return !1;
  return !0;
}
function as(e, n) {
  for (let t = 0, i = n.length; t < i; t++)
    e[t] = n[t];
}
function Kx(e, n) {
  let t = vw[n];
  t === void 0 && (t = new Int32Array(n), vw[n] = t);
  for (let i = 0; i !== n; ++i)
    t[i] = e.allocateTextureUnit();
  return t;
}
function _2(e, n) {
  const t = this.cache;
  t[0] !== n && (e.uniform1f(this.addr, n), t[0] = n);
}
function y2(e, n) {
  const t = this.cache;
  if (n.x !== void 0)
    (t[0] !== n.x || t[1] !== n.y) && (e.uniform2f(this.addr, n.x, n.y), t[0] = n.x, t[1] = n.y);
  else {
    if (Ts(t, n))
      return;
    e.uniform2fv(this.addr, n), as(t, n);
  }
}
function v2(e, n) {
  const t = this.cache;
  if (n.x !== void 0)
    (t[0] !== n.x || t[1] !== n.y || t[2] !== n.z) && (e.uniform3f(this.addr, n.x, n.y, n.z), t[0] = n.x, t[1] = n.y, t[2] = n.z);
  else if (n.r !== void 0)
    (t[0] !== n.r || t[1] !== n.g || t[2] !== n.b) && (e.uniform3f(this.addr, n.r, n.g, n.b), t[0] = n.r, t[1] = n.g, t[2] = n.b);
  else {
    if (Ts(t, n))
      return;
    e.uniform3fv(this.addr, n), as(t, n);
  }
}
function w2(e, n) {
  const t = this.cache;
  if (n.x !== void 0)
    (t[0] !== n.x || t[1] !== n.y || t[2] !== n.z || t[3] !== n.w) && (e.uniform4f(this.addr, n.x, n.y, n.z, n.w), t[0] = n.x, t[1] = n.y, t[2] = n.z, t[3] = n.w);
  else {
    if (Ts(t, n))
      return;
    e.uniform4fv(this.addr, n), as(t, n);
  }
}
function x2(e, n) {
  const t = this.cache, i = n.elements;
  if (i === void 0) {
    if (Ts(t, n))
      return;
    e.uniformMatrix2fv(this.addr, !1, n), as(t, n);
  } else {
    if (Ts(t, i))
      return;
    bw.set(i), e.uniformMatrix2fv(this.addr, !1, bw), as(t, i);
  }
}
function b2(e, n) {
  const t = this.cache, i = n.elements;
  if (i === void 0) {
    if (Ts(t, n))
      return;
    e.uniformMatrix3fv(this.addr, !1, n), as(t, n);
  } else {
    if (Ts(t, i))
      return;
    xw.set(i), e.uniformMatrix3fv(this.addr, !1, xw), as(t, i);
  }
}
function M2(e, n) {
  const t = this.cache, i = n.elements;
  if (i === void 0) {
    if (Ts(t, n))
      return;
    e.uniformMatrix4fv(this.addr, !1, n), as(t, n);
  } else {
    if (Ts(t, i))
      return;
    ww.set(i), e.uniformMatrix4fv(this.addr, !1, ww), as(t, i);
  }
}
function T2(e, n, t) {
  const i = this.cache, r = t.allocateTextureUnit();
  i[0] !== r && (e.uniform1i(this.addr, r), i[0] = r), t.safeSetTexture2D(n || Hx, r);
}
function E2(e, n, t) {
  const i = this.cache, r = t.allocateTextureUnit();
  i[0] !== r && (e.uniform1i(this.addr, r), i[0] = r), t.setTexture2DArray(n || m2, r);
}
function S2(e, n, t) {
  const i = this.cache, r = t.allocateTextureUnit();
  i[0] !== r && (e.uniform1i(this.addr, r), i[0] = r), t.setTexture3D(n || g2, r);
}
function P2(e, n, t) {
  const i = this.cache, r = t.allocateTextureUnit();
  i[0] !== r && (e.uniform1i(this.addr, r), i[0] = r), t.safeSetTextureCube(n || qx, r);
}
function A2(e, n) {
  const t = this.cache;
  t[0] !== n && (e.uniform1i(this.addr, n), t[0] = n);
}
function C2(e, n) {
  const t = this.cache;
  Ts(t, n) || (e.uniform2iv(this.addr, n), as(t, n));
}
function I2(e, n) {
  const t = this.cache;
  Ts(t, n) || (e.uniform3iv(this.addr, n), as(t, n));
}
function L2(e, n) {
  const t = this.cache;
  Ts(t, n) || (e.uniform4iv(this.addr, n), as(t, n));
}
function D2(e, n) {
  const t = this.cache;
  t[0] !== n && (e.uniform1ui(this.addr, n), t[0] = n);
}
function k2(e) {
  switch (e) {
    case 5126:
      return _2;
    case 35664:
      return y2;
    case 35665:
      return v2;
    case 35666:
      return w2;
    case 35674:
      return x2;
    case 35675:
      return b2;
    case 35676:
      return M2;
    case 5124:
    case 35670:
      return A2;
    case 35667:
    case 35671:
      return C2;
    case 35668:
    case 35672:
      return I2;
    case 35669:
    case 35673:
      return L2;
    case 5125:
      return D2;
    case 35678:
    case 36198:
    case 36298:
    case 36306:
    case 35682:
      return T2;
    case 35679:
    case 36299:
    case 36307:
      return S2;
    case 35680:
    case 36300:
    case 36308:
    case 36293:
      return P2;
    case 36289:
    case 36303:
    case 36311:
    case 36292:
      return E2;
  }
}
function O2(e, n) {
  e.uniform1fv(this.addr, n);
}
function F2(e, n) {
  e.uniform1iv(this.addr, n);
}
function R2(e, n) {
  e.uniform2iv(this.addr, n);
}
function B2(e, n) {
  e.uniform3iv(this.addr, n);
}
function z2(e, n) {
  e.uniform4iv(this.addr, n);
}
function $2(e, n) {
  const t = Cu(n, this.size, 2);
  e.uniform2fv(this.addr, t);
}
function N2(e, n) {
  const t = Cu(n, this.size, 3);
  e.uniform3fv(this.addr, t);
}
function U2(e, n) {
  const t = Cu(n, this.size, 4);
  e.uniform4fv(this.addr, t);
}
function G2(e, n) {
  const t = Cu(n, this.size, 4);
  e.uniformMatrix2fv(this.addr, !1, t);
}
function V2(e, n) {
  const t = Cu(n, this.size, 9);
  e.uniformMatrix3fv(this.addr, !1, t);
}
function j2(e, n) {
  const t = Cu(n, this.size, 16);
  e.uniformMatrix4fv(this.addr, !1, t);
}
function W2(e, n, t) {
  const i = n.length, r = Kx(t, i);
  e.uniform1iv(this.addr, r);
  for (let a = 0; a !== i; ++a)
    t.safeSetTexture2D(n[a] || Hx, r[a]);
}
function H2(e, n, t) {
  const i = n.length, r = Kx(t, i);
  e.uniform1iv(this.addr, r);
  for (let a = 0; a !== i; ++a)
    t.safeSetTextureCube(n[a] || qx, r[a]);
}
function q2(e) {
  switch (e) {
    case 5126:
      return O2;
    case 35664:
      return $2;
    case 35665:
      return N2;
    case 35666:
      return U2;
    case 35674:
      return G2;
    case 35675:
      return V2;
    case 35676:
      return j2;
    case 5124:
    case 35670:
      return F2;
    case 35667:
    case 35671:
      return R2;
    case 35668:
    case 35672:
      return B2;
    case 35669:
    case 35673:
      return z2;
    case 35678:
    case 36198:
    case 36298:
    case 36306:
    case 35682:
      return W2;
    case 35680:
    case 36300:
    case 36308:
    case 36293:
      return H2;
  }
}
function K2(e, n, t) {
  this.id = e, this.addr = t, this.cache = [], this.setValue = k2(n.type);
}
function Xx(e, n, t) {
  this.id = e, this.addr = t, this.cache = [], this.size = n.size, this.setValue = q2(n.type);
}
Xx.prototype.updateCache = function(e) {
  let n = this.cache;
  e instanceof Float32Array && n.length !== e.length && (this.cache = new Float32Array(e.length)), as(n, e);
};
function Yx(e) {
  this.id = e, this.seq = [], this.map = {};
}
Yx.prototype.setValue = function(e, n, t) {
  const i = this.seq;
  for (let r = 0, a = i.length; r !== a; ++r) {
    const c = i[r];
    c.setValue(e, n[c.id], t);
  }
};
const bv = /([\w\d_]+)(\])?(\[|\.)?/g;
function Mw(e, n) {
  e.seq.push(n), e.map[n.id] = n;
}
function X2(e, n, t) {
  const i = e.name, r = i.length;
  for (bv.lastIndex = 0; ; ) {
    const a = bv.exec(i), c = bv.lastIndex;
    let u = a[1], l = a[2] === "]", f = a[3];
    if (l && (u = u | 0), f === void 0 || f === "[" && c + 2 === r) {
      Mw(t, f === void 0 ? new K2(u, e, n) : new Xx(u, e, n));
      break;
    } else {
      let h = t.map[u];
      h === void 0 && (h = new Yx(u), Mw(t, h)), t = h;
    }
  }
}
function uo(e, n) {
  this.seq = [], this.map = {};
  const t = e.getProgramParameter(n, 35718);
  for (let i = 0; i < t; ++i) {
    const r = e.getActiveUniform(n, i), a = e.getUniformLocation(n, r.name);
    X2(r, a, this);
  }
}
uo.prototype.setValue = function(e, n, t, i) {
  const r = this.map[n];
  r !== void 0 && r.setValue(e, t, i);
};
uo.prototype.setOptional = function(e, n, t) {
  const i = n[t];
  i !== void 0 && this.setValue(e, t, i);
};
uo.upload = function(e, n, t, i) {
  for (let r = 0, a = n.length; r !== a; ++r) {
    const c = n[r], u = t[c.id];
    u.needsUpdate !== !1 && c.setValue(e, u.value, i);
  }
};
uo.seqWithValue = function(e, n) {
  const t = [];
  for (let i = 0, r = e.length; i !== r; ++i) {
    const a = e[i];
    a.id in n && t.push(a);
  }
  return t;
};
function Tw(e, n, t) {
  const i = e.createShader(n);
  return e.shaderSource(i, t), e.compileShader(i), i;
}
let Y2 = 0;
function J2(e) {
  const n = e.split(`
`);
  for (let t = 0; t < n.length; t++)
    n[t] = t + 1 + ": " + n[t];
  return n.join(`
`);
}
function Jx(e) {
  switch (e) {
    case Ki:
      return ["Linear", "( value )"];
    case $y:
      return ["sRGB", "( value )"];
    case R0:
      return ["RGBE", "( value )"];
    case zx:
      return ["RGBM", "( value, 7.0 )"];
    case $x:
      return ["RGBM", "( value, 16.0 )"];
    case Nx:
      return ["RGBD", "( value, 256.0 )"];
    case F0:
      return ["Gamma", "( value, float( GAMMA_FACTOR ) )"];
    case d1:
      return ["LogLuv", "( value )"];
    default:
      return console.warn("THREE.WebGLProgram: Unsupported encoding:", e), ["Linear", "( value )"];
  }
}
function Ew(e, n, t) {
  const i = e.getShaderParameter(n, 35713), r = e.getShaderInfoLog(n).trim();
  if (i && r === "")
    return "";
  const a = e.getShaderSource(n);
  return "THREE.WebGLShader: gl.getShaderInfoLog() " + t + `
` + r + J2(a);
}
function hm(e, n) {
  const t = Jx(n);
  return "vec4 " + e + "( vec4 value ) { return " + t[0] + "ToLinear" + t[1] + "; }";
}
function Q2(e, n) {
  const t = Jx(n);
  return "vec4 " + e + "( vec4 value ) { return LinearTo" + t[0] + t[1] + "; }";
}
function Z2(e, n) {
  let t;
  switch (n) {
    case uM:
      t = "Linear";
      break;
    case dM:
      t = "Reinhard";
      break;
    case hM:
      t = "OptimizedCineon";
      break;
    case fM:
      t = "ACESFilmic";
      break;
    case pM:
      t = "Custom";
      break;
    default:
      console.warn("THREE.WebGLProgram: Unsupported toneMapping:", n), t = "Linear";
  }
  return "vec3 " + e + "( vec3 color ) { return " + t + "ToneMapping( color ); }";
}
function eS(e) {
  return [
    e.extensionDerivatives || e.envMapCubeUV || e.bumpMap || e.tangentSpaceNormalMap || e.clearcoatNormalMap || e.flatShading || e.shaderID === "physical" ? "#extension GL_OES_standard_derivatives : enable" : "",
    (e.extensionFragDepth || e.logarithmicDepthBuffer) && e.rendererExtensionFragDepth ? "#extension GL_EXT_frag_depth : enable" : "",
    e.extensionDrawBuffers && e.rendererExtensionDrawBuffers ? "#extension GL_EXT_draw_buffers : require" : "",
    (e.extensionShaderTextureLOD || e.envMap) && e.rendererExtensionShaderTextureLod ? "#extension GL_EXT_shader_texture_lod : enable" : ""
  ].filter(vm).join(`
`);
}
function tS(e) {
  const n = [];
  for (const t in e) {
    const i = e[t];
    i !== !1 && n.push("#define " + t + " " + i);
  }
  return n.join(`
`);
}
function nS(e, n) {
  const t = {}, i = e.getProgramParameter(n, 35721);
  for (let r = 0; r < i; r++) {
    const c = e.getActiveAttrib(n, r).name;
    t[c] = e.getAttribLocation(n, c);
  }
  return t;
}
function vm(e) {
  return e !== "";
}
function Sw(e, n) {
  return e.replace(/NUM_DIR_LIGHTS/g, n.numDirLights).replace(/NUM_SPOT_LIGHTS/g, n.numSpotLights).replace(/NUM_RECT_AREA_LIGHTS/g, n.numRectAreaLights).replace(/NUM_POINT_LIGHTS/g, n.numPointLights).replace(/NUM_HEMI_LIGHTS/g, n.numHemiLights).replace(/NUM_DIR_LIGHT_SHADOWS/g, n.numDirLightShadows).replace(/NUM_SPOT_LIGHT_SHADOWS/g, n.numSpotLightShadows).replace(/NUM_POINT_LIGHT_SHADOWS/g, n.numPointLightShadows);
}
function Pw(e, n) {
  return e.replace(/NUM_CLIPPING_PLANES/g, n.numClippingPlanes).replace(/UNION_CLIPPING_PLANES/g, n.numClippingPlanes - n.numClipIntersection);
}
const iS = /^[ \t]*#include +<([\w\d./]+)>/gm;
function Vv(e) {
  return e.replace(iS, sS);
}
function sS(e, n) {
  const t = gn[n];
  if (t === void 0)
    throw new Error("Can not resolve #include <" + n + ">");
  return Vv(t);
}
const rS = /#pragma unroll_loop[\s]+?for \( int i \= (\d+)\; i < (\d+)\; i \+\+ \) \{([\s\S]+?)(?=\})\}/g, oS = /#pragma unroll_loop_start[\s]+?for \( int i \= (\d+)\; i < (\d+)\; i \+\+ \) \{([\s\S]+?)(?=\})\}[\s]+?#pragma unroll_loop_end/g;
function Aw(e) {
  return e.replace(oS, Qx).replace(rS, aS);
}
function aS(e, n, t, i) {
  return console.warn("WebGLProgram: #pragma unroll_loop shader syntax is deprecated. Please use #pragma unroll_loop_start syntax instead."), Qx(e, n, t, i);
}
function Qx(e, n, t, i) {
  let r = "";
  for (let a = parseInt(n); a < parseInt(t); a++)
    r += i.replace(/\[ i \]/g, "[ " + a + " ]").replace(/UNROLLED_LOOP_INDEX/g, a);
  return r;
}
function Cw(e) {
  let n = "precision " + e.precision + ` float;
precision ` + e.precision + " int;";
  return e.precision === "highp" ? n += `
#define HIGH_PRECISION` : e.precision === "mediump" ? n += `
#define MEDIUM_PRECISION` : e.precision === "lowp" && (n += `
#define LOW_PRECISION`), n;
}
function lS(e) {
  let n = "SHADOWMAP_TYPE_BASIC";
  return e.shadowMapType === Lx ? n = "SHADOWMAP_TYPE_PCF" : e.shadowMapType === Gb ? n = "SHADOWMAP_TYPE_PCF_SOFT" : e.shadowMapType === ym && (n = "SHADOWMAP_TYPE_VSM"), n;
}
function cS(e) {
  let n = "ENVMAP_TYPE_CUBE";
  if (e.envMap)
    switch (e.envMapMode) {
      case L0:
      case D0:
        n = "ENVMAP_TYPE_CUBE";
        break;
      case ug:
      case By:
        n = "ENVMAP_TYPE_CUBE_UV";
        break;
      case Fx:
      case k0:
        n = "ENVMAP_TYPE_EQUIREC";
        break;
    }
  return n;
}
function uS(e) {
  let n = "ENVMAP_MODE_REFLECTION";
  if (e.envMap)
    switch (e.envMapMode) {
      case D0:
      case k0:
      case By:
        n = "ENVMAP_MODE_REFRACTION";
        break;
    }
  return n;
}
function dS(e) {
  let n = "ENVMAP_BLENDING_NONE";
  if (e.envMap)
    switch (e.combine) {
      case Ry:
        n = "ENVMAP_BLENDING_MULTIPLY";
        break;
      case lM:
        n = "ENVMAP_BLENDING_MIX";
        break;
      case cM:
        n = "ENVMAP_BLENDING_ADD";
        break;
    }
  return n;
}
function hS(e, n, t, i) {
  const r = e.getContext(), a = t.defines;
  let c = t.vertexShader, u = t.fragmentShader;
  const l = lS(t), f = cS(t), m = uS(t), h = dS(t), p = e.gammaFactor > 0 ? e.gammaFactor : 1, _ = t.isWebGL2 ? "" : eS(t), v = tS(a), S = r.createProgram();
  let D, w;
  t.isRawShaderMaterial ? (D = [
    v
  ].filter(vm).join(`
`), D.length > 0 && (D += `
`), w = [
    _,
    v
  ].filter(vm).join(`
`), w.length > 0 && (w += `
`)) : (D = [
    Cw(t),
    "#define SHADER_NAME " + t.shaderName,
    v,
    t.instancing ? "#define USE_INSTANCING" : "",
    t.supportsVertexTextures ? "#define VERTEX_TEXTURES" : "",
    "#define GAMMA_FACTOR " + p,
    "#define MAX_BONES " + t.maxBones,
    t.useFog && t.fog ? "#define USE_FOG" : "",
    t.useFog && t.fogExp2 ? "#define FOG_EXP2" : "",
    t.map ? "#define USE_MAP" : "",
    t.envMap ? "#define USE_ENVMAP" : "",
    t.envMap ? "#define " + m : "",
    t.lightMap ? "#define USE_LIGHTMAP" : "",
    t.aoMap ? "#define USE_AOMAP" : "",
    t.emissiveMap ? "#define USE_EMISSIVEMAP" : "",
    t.bumpMap ? "#define USE_BUMPMAP" : "",
    t.normalMap ? "#define USE_NORMALMAP" : "",
    t.normalMap && t.objectSpaceNormalMap ? "#define OBJECTSPACE_NORMALMAP" : "",
    t.normalMap && t.tangentSpaceNormalMap ? "#define TANGENTSPACE_NORMALMAP" : "",
    t.clearcoatMap ? "#define USE_CLEARCOATMAP" : "",
    t.clearcoatRoughnessMap ? "#define USE_CLEARCOAT_ROUGHNESSMAP" : "",
    t.clearcoatNormalMap ? "#define USE_CLEARCOAT_NORMALMAP" : "",
    t.displacementMap && t.supportsVertexTextures ? "#define USE_DISPLACEMENTMAP" : "",
    t.specularMap ? "#define USE_SPECULARMAP" : "",
    t.roughnessMap ? "#define USE_ROUGHNESSMAP" : "",
    t.metalnessMap ? "#define USE_METALNESSMAP" : "",
    t.alphaMap ? "#define USE_ALPHAMAP" : "",
    t.transmissionMap ? "#define USE_TRANSMISSIONMAP" : "",
    t.vertexTangents ? "#define USE_TANGENT" : "",
    t.vertexColors ? "#define USE_COLOR" : "",
    t.vertexUvs ? "#define USE_UV" : "",
    t.uvsVertexOnly ? "#define UVS_VERTEX_ONLY" : "",
    t.flatShading ? "#define FLAT_SHADED" : "",
    t.skinning ? "#define USE_SKINNING" : "",
    t.useVertexTexture ? "#define BONE_TEXTURE" : "",
    t.morphTargets ? "#define USE_MORPHTARGETS" : "",
    t.morphNormals && t.flatShading === !1 ? "#define USE_MORPHNORMALS" : "",
    t.doubleSided ? "#define DOUBLE_SIDED" : "",
    t.flipSided ? "#define FLIP_SIDED" : "",
    t.shadowMapEnabled ? "#define USE_SHADOWMAP" : "",
    t.shadowMapEnabled ? "#define " + l : "",
    t.sizeAttenuation ? "#define USE_SIZEATTENUATION" : "",
    t.logarithmicDepthBuffer ? "#define USE_LOGDEPTHBUF" : "",
    t.logarithmicDepthBuffer && t.rendererExtensionFragDepth ? "#define USE_LOGDEPTHBUF_EXT" : "",
    "uniform mat4 modelMatrix;",
    "uniform mat4 modelViewMatrix;",
    "uniform mat4 projectionMatrix;",
    "uniform mat4 viewMatrix;",
    "uniform mat3 normalMatrix;",
    "uniform vec3 cameraPosition;",
    "uniform bool isOrthographic;",
    "#ifdef USE_INSTANCING",
    " attribute mat4 instanceMatrix;",
    "#endif",
    "attribute vec3 position;",
    "attribute vec3 normal;",
    "attribute vec2 uv;",
    "#ifdef USE_TANGENT",
    "	attribute vec4 tangent;",
    "#endif",
    "#ifdef USE_COLOR",
    "	attribute vec3 color;",
    "#endif",
    "#ifdef USE_MORPHTARGETS",
    "	attribute vec3 morphTarget0;",
    "	attribute vec3 morphTarget1;",
    "	attribute vec3 morphTarget2;",
    "	attribute vec3 morphTarget3;",
    "	#ifdef USE_MORPHNORMALS",
    "		attribute vec3 morphNormal0;",
    "		attribute vec3 morphNormal1;",
    "		attribute vec3 morphNormal2;",
    "		attribute vec3 morphNormal3;",
    "	#else",
    "		attribute vec3 morphTarget4;",
    "		attribute vec3 morphTarget5;",
    "		attribute vec3 morphTarget6;",
    "		attribute vec3 morphTarget7;",
    "	#endif",
    "#endif",
    "#ifdef USE_SKINNING",
    "	attribute vec4 skinIndex;",
    "	attribute vec4 skinWeight;",
    "#endif",
    `
`
  ].filter(vm).join(`
`), w = [
    _,
    Cw(t),
    "#define SHADER_NAME " + t.shaderName,
    v,
    t.alphaTest ? "#define ALPHATEST " + t.alphaTest + (t.alphaTest % 1 ? "" : ".0") : "",
    // add '.0' if integer
    "#define GAMMA_FACTOR " + p,
    t.useFog && t.fog ? "#define USE_FOG" : "",
    t.useFog && t.fogExp2 ? "#define FOG_EXP2" : "",
    t.map ? "#define USE_MAP" : "",
    t.matcap ? "#define USE_MATCAP" : "",
    t.envMap ? "#define USE_ENVMAP" : "",
    t.envMap ? "#define " + f : "",
    t.envMap ? "#define " + m : "",
    t.envMap ? "#define " + h : "",
    t.lightMap ? "#define USE_LIGHTMAP" : "",
    t.aoMap ? "#define USE_AOMAP" : "",
    t.emissiveMap ? "#define USE_EMISSIVEMAP" : "",
    t.bumpMap ? "#define USE_BUMPMAP" : "",
    t.normalMap ? "#define USE_NORMALMAP" : "",
    t.normalMap && t.objectSpaceNormalMap ? "#define OBJECTSPACE_NORMALMAP" : "",
    t.normalMap && t.tangentSpaceNormalMap ? "#define TANGENTSPACE_NORMALMAP" : "",
    t.clearcoatMap ? "#define USE_CLEARCOATMAP" : "",
    t.clearcoatRoughnessMap ? "#define USE_CLEARCOAT_ROUGHNESSMAP" : "",
    t.clearcoatNormalMap ? "#define USE_CLEARCOAT_NORMALMAP" : "",
    t.specularMap ? "#define USE_SPECULARMAP" : "",
    t.roughnessMap ? "#define USE_ROUGHNESSMAP" : "",
    t.metalnessMap ? "#define USE_METALNESSMAP" : "",
    t.alphaMap ? "#define USE_ALPHAMAP" : "",
    t.sheen ? "#define USE_SHEEN" : "",
    t.transmissionMap ? "#define USE_TRANSMISSIONMAP" : "",
    t.vertexTangents ? "#define USE_TANGENT" : "",
    t.vertexColors ? "#define USE_COLOR" : "",
    t.vertexUvs ? "#define USE_UV" : "",
    t.uvsVertexOnly ? "#define UVS_VERTEX_ONLY" : "",
    t.gradientMap ? "#define USE_GRADIENTMAP" : "",
    t.flatShading ? "#define FLAT_SHADED" : "",
    t.doubleSided ? "#define DOUBLE_SIDED" : "",
    t.flipSided ? "#define FLIP_SIDED" : "",
    t.shadowMapEnabled ? "#define USE_SHADOWMAP" : "",
    t.shadowMapEnabled ? "#define " + l : "",
    t.premultipliedAlpha ? "#define PREMULTIPLIED_ALPHA" : "",
    t.physicallyCorrectLights ? "#define PHYSICALLY_CORRECT_LIGHTS" : "",
    t.logarithmicDepthBuffer ? "#define USE_LOGDEPTHBUF" : "",
    t.logarithmicDepthBuffer && t.rendererExtensionFragDepth ? "#define USE_LOGDEPTHBUF_EXT" : "",
    (t.extensionShaderTextureLOD || t.envMap) && t.rendererExtensionShaderTextureLod ? "#define TEXTURE_LOD_EXT" : "",
    "uniform mat4 viewMatrix;",
    "uniform vec3 cameraPosition;",
    "uniform bool isOrthographic;",
    t.toneMapping !== su ? "#define TONE_MAPPING" : "",
    t.toneMapping !== su ? gn.tonemapping_pars_fragment : "",
    // this code is required here because it is used by the toneMapping() function defined below
    t.toneMapping !== su ? Z2("toneMapping", t.toneMapping) : "",
    t.dithering ? "#define DITHERING" : "",
    gn.encodings_pars_fragment,
    // this code is required here because it is used by the various encoding/decoding function defined below
    t.map ? hm("mapTexelToLinear", t.mapEncoding) : "",
    t.matcap ? hm("matcapTexelToLinear", t.matcapEncoding) : "",
    t.envMap ? hm("envMapTexelToLinear", t.envMapEncoding) : "",
    t.emissiveMap ? hm("emissiveMapTexelToLinear", t.emissiveMapEncoding) : "",
    t.lightMap ? hm("lightMapTexelToLinear", t.lightMapEncoding) : "",
    Q2("linearToOutputTexel", t.outputEncoding),
    t.depthPacking ? "#define DEPTH_PACKING " + t.depthPacking : "",
    `
`
  ].filter(vm).join(`
`)), c = Vv(c), c = Sw(c, t), c = Pw(c, t), u = Vv(u), u = Sw(u, t), u = Pw(u, t), c = Aw(c), u = Aw(u), t.isWebGL2 && !t.isRawShaderMaterial && (D = [
    `#version 300 es
`,
    "#define attribute in",
    "#define varying out",
    "#define texture2D texture"
  ].join(`
`) + `
` + D, w = [
    `#version 300 es
`,
    "#define varying in",
    "out highp vec4 pc_fragColor;",
    "#define gl_FragColor pc_fragColor",
    "#define gl_FragDepthEXT gl_FragDepth",
    "#define texture2D texture",
    "#define textureCube texture",
    "#define texture2DProj textureProj",
    "#define texture2DLodEXT textureLod",
    "#define texture2DProjLodEXT textureProjLod",
    "#define textureCubeLodEXT textureLod",
    "#define texture2DGradEXT textureGrad",
    "#define texture2DProjGradEXT textureProjGrad",
    "#define textureCubeGradEXT textureGrad"
  ].join(`
`) + `
` + w);
  const T = D + c, F = w + u, E = Tw(r, 35633, T), A = Tw(r, 35632, F);
  if (r.attachShader(S, E), r.attachShader(S, A), t.index0AttributeName !== void 0 ? r.bindAttribLocation(S, 0, t.index0AttributeName) : t.morphTargets === !0 && r.bindAttribLocation(S, 0, "position"), r.linkProgram(S), e.debug.checkShaderErrors) {
    const R = r.getProgramInfoLog(S).trim(), N = r.getShaderInfoLog(E).trim(), q = r.getShaderInfoLog(A).trim();
    let ne = !0, Q = !0;
    if (r.getProgramParameter(S, 35714) === !1) {
      ne = !1;
      const W = Ew(r, E, "vertex"), te = Ew(r, A, "fragment");
      console.error("THREE.WebGLProgram: shader error: ", r.getError(), "35715", r.getProgramParameter(S, 35715), "gl.getProgramInfoLog", R, W, te);
    } else
      R !== "" ? console.warn("THREE.WebGLProgram: gl.getProgramInfoLog()", R) : (N === "" || q === "") && (Q = !1);
    Q && (this.diagnostics = {
      runnable: ne,
      programLog: R,
      vertexShader: {
        log: N,
        prefix: D
      },
      fragmentShader: {
        log: q,
        prefix: w
      }
    });
  }
  r.deleteShader(E), r.deleteShader(A);
  let L;
  this.getUniforms = function() {
    return L === void 0 && (L = new uo(r, S)), L;
  };
  let I;
  return this.getAttributes = function() {
    return I === void 0 && (I = nS(r, S)), I;
  }, this.destroy = function() {
    i.releaseStatesOfProgram(this), r.deleteProgram(S), this.program = void 0;
  }, this.name = t.shaderName, this.id = Y2++, this.cacheKey = n, this.usedTimes = 1, this.program = S, this.vertexShader = E, this.fragmentShader = A, this;
}
function fS(e, n, t, i) {
  const r = [], a = t.isWebGL2, c = t.logarithmicDepthBuffer, u = t.floatVertexTextures, l = t.maxVertexUniforms, f = t.vertexTextures;
  let m = t.precision;
  const h = {
    MeshDepthMaterial: "depth",
    MeshDistanceMaterial: "distanceRGBA",
    MeshNormalMaterial: "normal",
    MeshBasicMaterial: "basic",
    MeshLambertMaterial: "lambert",
    MeshPhongMaterial: "phong",
    MeshToonMaterial: "toon",
    MeshStandardMaterial: "physical",
    MeshPhysicalMaterial: "physical",
    MeshMatcapMaterial: "matcap",
    LineBasicMaterial: "basic",
    LineDashedMaterial: "dashed",
    PointsMaterial: "points",
    ShadowMaterial: "shadow",
    SpriteMaterial: "sprite"
  }, p = [
    "precision",
    "isWebGL2",
    "supportsVertexTextures",
    "outputEncoding",
    "instancing",
    "map",
    "mapEncoding",
    "matcap",
    "matcapEncoding",
    "envMap",
    "envMapMode",
    "envMapEncoding",
    "envMapCubeUV",
    "lightMap",
    "lightMapEncoding",
    "aoMap",
    "emissiveMap",
    "emissiveMapEncoding",
    "bumpMap",
    "normalMap",
    "objectSpaceNormalMap",
    "tangentSpaceNormalMap",
    "clearcoatMap",
    "clearcoatRoughnessMap",
    "clearcoatNormalMap",
    "displacementMap",
    "specularMap",
    "roughnessMap",
    "metalnessMap",
    "gradientMap",
    "alphaMap",
    "combine",
    "vertexColors",
    "vertexTangents",
    "vertexUvs",
    "uvsVertexOnly",
    "fog",
    "useFog",
    "fogExp2",
    "flatShading",
    "sizeAttenuation",
    "logarithmicDepthBuffer",
    "skinning",
    "maxBones",
    "useVertexTexture",
    "morphTargets",
    "morphNormals",
    "maxMorphTargets",
    "maxMorphNormals",
    "premultipliedAlpha",
    "numDirLights",
    "numPointLights",
    "numSpotLights",
    "numHemiLights",
    "numRectAreaLights",
    "numDirLightShadows",
    "numPointLightShadows",
    "numSpotLightShadows",
    "shadowMapEnabled",
    "shadowMapType",
    "toneMapping",
    "physicallyCorrectLights",
    "alphaTest",
    "doubleSided",
    "flipSided",
    "numClippingPlanes",
    "numClipIntersection",
    "depthPacking",
    "dithering",
    "sheen",
    "transmissionMap"
  ];
  function _(E) {
    const L = E.skeleton.bones;
    if (u)
      return 1024;
    {
      const R = Math.floor((l - 20) / 4), N = Math.min(R, L.length);
      return N < L.length ? (console.warn("THREE.WebGLRenderer: Skeleton has " + L.length + " bones. This GPU supports " + N + "."), 0) : N;
    }
  }
  function v(E) {
    let A;
    return E ? E.isTexture ? A = E.encoding : E.isWebGLRenderTarget && (console.warn("THREE.WebGLPrograms.getTextureEncodingFromMap: don't use render targets as textures. Use their .texture property instead."), A = E.texture.encoding) : A = Ki, A;
  }
  function S(E, A, L, I, R, N, q) {
    const ne = I.fog, Q = E.isMeshStandardMaterial ? I.environment : null, W = E.envMap || Q, te = h[E.type], K = q.isSkinnedMesh ? _(q) : 0;
    E.precision !== null && (m = t.getMaxPrecision(E.precision), m !== E.precision && console.warn("THREE.WebGLProgram.getParameters:", E.precision, "not supported, using", m, "instead."));
    let pe, be;
    if (te) {
      const _e = ar[te];
      pe = _e.vertexShader, be = _e.fragmentShader;
    } else
      pe = E.vertexShader, be = E.fragmentShader;
    const Ee = e.getRenderTarget();
    return {
      isWebGL2: a,
      shaderID: te,
      shaderName: E.type,
      vertexShader: pe,
      fragmentShader: be,
      defines: E.defines,
      isRawShaderMaterial: E.isRawShaderMaterial,
      isShaderMaterial: E.isShaderMaterial,
      precision: m,
      instancing: q.isInstancedMesh === !0,
      supportsVertexTextures: f,
      outputEncoding: Ee !== null ? v(Ee.texture) : e.outputEncoding,
      map: !!E.map,
      mapEncoding: v(E.map),
      matcap: !!E.matcap,
      matcapEncoding: v(E.matcap),
      envMap: !!W,
      envMapMode: W && W.mapping,
      envMapEncoding: v(W),
      envMapCubeUV: !!W && (W.mapping === ug || W.mapping === By),
      lightMap: !!E.lightMap,
      lightMapEncoding: v(E.lightMap),
      aoMap: !!E.aoMap,
      emissiveMap: !!E.emissiveMap,
      emissiveMapEncoding: v(E.emissiveMap),
      bumpMap: !!E.bumpMap,
      normalMap: !!E.normalMap,
      objectSpaceNormalMap: E.normalMapType === p1,
      tangentSpaceNormalMap: E.normalMapType === Su,
      clearcoatMap: !!E.clearcoatMap,
      clearcoatRoughnessMap: !!E.clearcoatRoughnessMap,
      clearcoatNormalMap: !!E.clearcoatNormalMap,
      displacementMap: !!E.displacementMap,
      roughnessMap: !!E.roughnessMap,
      metalnessMap: !!E.metalnessMap,
      specularMap: !!E.specularMap,
      alphaMap: !!E.alphaMap,
      gradientMap: !!E.gradientMap,
      sheen: !!E.sheen,
      transmissionMap: !!E.transmissionMap,
      combine: E.combine,
      vertexTangents: E.normalMap && E.vertexTangents,
      vertexColors: E.vertexColors,
      vertexUvs: !!E.map || !!E.bumpMap || !!E.normalMap || !!E.specularMap || !!E.alphaMap || !!E.emissiveMap || !!E.roughnessMap || !!E.metalnessMap || !!E.clearcoatMap || !!E.clearcoatRoughnessMap || !!E.clearcoatNormalMap || !!E.displacementMap || !!E.transmissionMap,
      uvsVertexOnly: !(E.map || E.bumpMap || E.normalMap || E.specularMap || E.alphaMap || E.emissiveMap || E.roughnessMap || E.metalnessMap || E.clearcoatNormalMap || E.transmissionMap) && !!E.displacementMap,
      fog: !!ne,
      useFog: E.fog,
      fogExp2: ne && ne.isFogExp2,
      flatShading: E.flatShading,
      sizeAttenuation: E.sizeAttenuation,
      logarithmicDepthBuffer: c,
      skinning: E.skinning && K > 0,
      maxBones: K,
      useVertexTexture: u,
      morphTargets: E.morphTargets,
      morphNormals: E.morphNormals,
      maxMorphTargets: e.maxMorphTargets,
      maxMorphNormals: e.maxMorphNormals,
      numDirLights: A.directional.length,
      numPointLights: A.point.length,
      numSpotLights: A.spot.length,
      numRectAreaLights: A.rectArea.length,
      numHemiLights: A.hemi.length,
      numDirLightShadows: A.directionalShadowMap.length,
      numPointLightShadows: A.pointShadowMap.length,
      numSpotLightShadows: A.spotShadowMap.length,
      numClippingPlanes: R,
      numClipIntersection: N,
      dithering: E.dithering,
      shadowMapEnabled: e.shadowMap.enabled && L.length > 0,
      shadowMapType: e.shadowMap.type,
      toneMapping: E.toneMapped ? e.toneMapping : su,
      physicallyCorrectLights: e.physicallyCorrectLights,
      premultipliedAlpha: E.premultipliedAlpha,
      alphaTest: E.alphaTest,
      doubleSided: E.side === Fy,
      flipSided: E.side === hi,
      depthPacking: E.depthPacking !== void 0 ? E.depthPacking : !1,
      index0AttributeName: E.index0AttributeName,
      extensionDerivatives: E.extensions && E.extensions.derivatives,
      extensionFragDepth: E.extensions && E.extensions.fragDepth,
      extensionDrawBuffers: E.extensions && E.extensions.drawBuffers,
      extensionShaderTextureLOD: E.extensions && E.extensions.shaderTextureLOD,
      rendererExtensionFragDepth: a || n.get("EXT_frag_depth") !== null,
      rendererExtensionDrawBuffers: a || n.get("WEBGL_draw_buffers") !== null,
      rendererExtensionShaderTextureLod: a || n.get("EXT_shader_texture_lod") !== null,
      customProgramCacheKey: E.customProgramCacheKey()
    };
  }
  function D(E) {
    const A = [];
    if (E.shaderID ? A.push(E.shaderID) : (A.push(E.fragmentShader), A.push(E.vertexShader)), E.defines !== void 0)
      for (const L in E.defines)
        A.push(L), A.push(E.defines[L]);
    if (E.isRawShaderMaterial === void 0) {
      for (let L = 0; L < p.length; L++)
        A.push(E[p[L]]);
      A.push(e.outputEncoding), A.push(e.gammaFactor);
    }
    return A.push(E.customProgramCacheKey), A.join();
  }
  function w(E) {
    const A = h[E.type];
    let L;
    if (A) {
      const I = ar[A];
      L = L1.clone(I.uniforms);
    } else
      L = E.uniforms;
    return L;
  }
  function T(E, A) {
    let L;
    for (let I = 0, R = r.length; I < R; I++) {
      const N = r[I];
      if (N.cacheKey === A) {
        L = N, ++L.usedTimes;
        break;
      }
    }
    return L === void 0 && (L = new hS(e, A, E, i), r.push(L)), L;
  }
  function F(E) {
    if (--E.usedTimes === 0) {
      const A = r.indexOf(E);
      r[A] = r[r.length - 1], r.pop(), E.destroy();
    }
  }
  return {
    getParameters: S,
    getProgramCacheKey: D,
    getUniforms: w,
    acquireProgram: T,
    releaseProgram: F,
    // Exposed for resource monitoring & error feedback via renderer.info:
    programs: r
  };
}
function pS() {
  let e = /* @__PURE__ */ new WeakMap();
  function n(a) {
    let c = e.get(a);
    return c === void 0 && (c = {}, e.set(a, c)), c;
  }
  function t(a) {
    e.delete(a);
  }
  function i(a, c, u) {
    e.get(a)[c] = u;
  }
  function r() {
    e = /* @__PURE__ */ new WeakMap();
  }
  return {
    get: n,
    remove: t,
    update: i,
    dispose: r
  };
}
function mS(e, n) {
  return e.groupOrder !== n.groupOrder ? e.groupOrder - n.groupOrder : e.renderOrder !== n.renderOrder ? e.renderOrder - n.renderOrder : e.program !== n.program ? e.program.id - n.program.id : e.material.id !== n.material.id ? e.material.id - n.material.id : e.z !== n.z ? e.z - n.z : e.id - n.id;
}
function gS(e, n) {
  return e.groupOrder !== n.groupOrder ? e.groupOrder - n.groupOrder : e.renderOrder !== n.renderOrder ? e.renderOrder - n.renderOrder : e.z !== n.z ? n.z - e.z : e.id - n.id;
}
function Iw(e) {
  const n = [];
  let t = 0;
  const i = [], r = [], a = { id: -1 };
  function c() {
    t = 0, i.length = 0, r.length = 0;
  }
  function u(p, _, v, S, D, w) {
    let T = n[t];
    const F = e.get(v);
    return T === void 0 ? (T = {
      id: p.id,
      object: p,
      geometry: _,
      material: v,
      program: F.program || a,
      groupOrder: S,
      renderOrder: p.renderOrder,
      z: D,
      group: w
    }, n[t] = T) : (T.id = p.id, T.object = p, T.geometry = _, T.material = v, T.program = F.program || a, T.groupOrder = S, T.renderOrder = p.renderOrder, T.z = D, T.group = w), t++, T;
  }
  function l(p, _, v, S, D, w) {
    const T = u(p, _, v, S, D, w);
    (v.transparent === !0 ? r : i).push(T);
  }
  function f(p, _, v, S, D, w) {
    const T = u(p, _, v, S, D, w);
    (v.transparent === !0 ? r : i).unshift(T);
  }
  function m(p, _) {
    i.length > 1 && i.sort(p || mS), r.length > 1 && r.sort(_ || gS);
  }
  function h() {
    for (let p = t, _ = n.length; p < _; p++) {
      const v = n[p];
      if (v.id === null)
        break;
      v.id = null, v.object = null, v.geometry = null, v.material = null, v.program = null, v.group = null;
    }
  }
  return {
    opaque: i,
    transparent: r,
    init: c,
    push: l,
    unshift: f,
    finish: h,
    sort: m
  };
}
function _S(e) {
  let n = /* @__PURE__ */ new WeakMap();
  function t(a) {
    const c = a.target;
    c.removeEventListener("dispose", t), n.delete(c);
  }
  function i(a, c) {
    const u = n.get(a);
    let l;
    return u === void 0 ? (l = new Iw(e), n.set(a, /* @__PURE__ */ new WeakMap()), n.get(a).set(c, l), a.addEventListener("dispose", t)) : (l = u.get(c), l === void 0 && (l = new Iw(e), u.set(c, l))), l;
  }
  function r() {
    n = /* @__PURE__ */ new WeakMap();
  }
  return {
    get: i,
    dispose: r
  };
}
function yS() {
  const e = {};
  return {
    get: function(n) {
      if (e[n.id] !== void 0)
        return e[n.id];
      let t;
      switch (n.type) {
        case "DirectionalLight":
          t = {
            direction: new ve(),
            color: new Wt()
          };
          break;
        case "SpotLight":
          t = {
            position: new ve(),
            direction: new ve(),
            color: new Wt(),
            distance: 0,
            coneCos: 0,
            penumbraCos: 0,
            decay: 0
          };
          break;
        case "PointLight":
          t = {
            position: new ve(),
            color: new Wt(),
            distance: 0,
            decay: 0
          };
          break;
        case "HemisphereLight":
          t = {
            direction: new ve(),
            skyColor: new Wt(),
            groundColor: new Wt()
          };
          break;
        case "RectAreaLight":
          t = {
            color: new Wt(),
            position: new ve(),
            halfWidth: new ve(),
            halfHeight: new ve()
          };
          break;
      }
      return e[n.id] = t, t;
    }
  };
}
function vS() {
  const e = {};
  return {
    get: function(n) {
      if (e[n.id] !== void 0)
        return e[n.id];
      let t;
      switch (n.type) {
        case "DirectionalLight":
          t = {
            shadowBias: 0,
            shadowNormalBias: 0,
            shadowRadius: 1,
            shadowMapSize: new vt()
          };
          break;
        case "SpotLight":
          t = {
            shadowBias: 0,
            shadowNormalBias: 0,
            shadowRadius: 1,
            shadowMapSize: new vt()
          };
          break;
        case "PointLight":
          t = {
            shadowBias: 0,
            shadowNormalBias: 0,
            shadowRadius: 1,
            shadowMapSize: new vt(),
            shadowCameraNear: 1,
            shadowCameraFar: 1e3
          };
          break;
      }
      return e[n.id] = t, t;
    }
  };
}
let wS = 0;
function xS(e, n) {
  return (n.castShadow ? 1 : 0) - (e.castShadow ? 1 : 0);
}
function bS() {
  const e = new yS(), n = vS(), t = {
    version: 0,
    hash: {
      directionalLength: -1,
      pointLength: -1,
      spotLength: -1,
      rectAreaLength: -1,
      hemiLength: -1,
      numDirectionalShadows: -1,
      numPointShadows: -1,
      numSpotShadows: -1
    },
    ambient: [0, 0, 0],
    probe: [],
    directional: [],
    directionalShadow: [],
    directionalShadowMap: [],
    directionalShadowMatrix: [],
    spot: [],
    spotShadow: [],
    spotShadowMap: [],
    spotShadowMatrix: [],
    rectArea: [],
    point: [],
    pointShadow: [],
    pointShadowMap: [],
    pointShadowMatrix: [],
    hemi: []
  };
  for (let u = 0; u < 9; u++)
    t.probe.push(new ve());
  const i = new ve(), r = new dn(), a = new dn();
  function c(u, l, f) {
    let m = 0, h = 0, p = 0;
    for (let I = 0; I < 9; I++)
      t.probe[I].set(0, 0, 0);
    let _ = 0, v = 0, S = 0, D = 0, w = 0, T = 0, F = 0, E = 0;
    const A = f.matrixWorldInverse;
    u.sort(xS);
    for (let I = 0, R = u.length; I < R; I++) {
      const N = u[I], q = N.color, ne = N.intensity, Q = N.distance, W = N.shadow && N.shadow.map ? N.shadow.map.texture : null;
      if (N.isAmbientLight)
        m += q.r * ne, h += q.g * ne, p += q.b * ne;
      else if (N.isLightProbe)
        for (let te = 0; te < 9; te++)
          t.probe[te].addScaledVector(N.sh.coefficients[te], ne);
      else if (N.isDirectionalLight) {
        const te = e.get(N);
        if (te.color.copy(N.color).multiplyScalar(N.intensity), te.direction.setFromMatrixPosition(N.matrixWorld), i.setFromMatrixPosition(N.target.matrixWorld), te.direction.sub(i), te.direction.transformDirection(A), N.castShadow) {
          const K = N.shadow, pe = n.get(N);
          pe.shadowBias = K.bias, pe.shadowNormalBias = K.normalBias, pe.shadowRadius = K.radius, pe.shadowMapSize = K.mapSize, t.directionalShadow[_] = pe, t.directionalShadowMap[_] = W, t.directionalShadowMatrix[_] = N.shadow.matrix, T++;
        }
        t.directional[_] = te, _++;
      } else if (N.isSpotLight) {
        const te = e.get(N);
        if (te.position.setFromMatrixPosition(N.matrixWorld), te.position.applyMatrix4(A), te.color.copy(q).multiplyScalar(ne), te.distance = Q, te.direction.setFromMatrixPosition(N.matrixWorld), i.setFromMatrixPosition(N.target.matrixWorld), te.direction.sub(i), te.direction.transformDirection(A), te.coneCos = Math.cos(N.angle), te.penumbraCos = Math.cos(N.angle * (1 - N.penumbra)), te.decay = N.decay, N.castShadow) {
          const K = N.shadow, pe = n.get(N);
          pe.shadowBias = K.bias, pe.shadowNormalBias = K.normalBias, pe.shadowRadius = K.radius, pe.shadowMapSize = K.mapSize, t.spotShadow[S] = pe, t.spotShadowMap[S] = W, t.spotShadowMatrix[S] = N.shadow.matrix, E++;
        }
        t.spot[S] = te, S++;
      } else if (N.isRectAreaLight) {
        const te = e.get(N);
        te.color.copy(q).multiplyScalar(ne), te.position.setFromMatrixPosition(N.matrixWorld), te.position.applyMatrix4(A), a.identity(), r.copy(N.matrixWorld), r.premultiply(A), a.extractRotation(r), te.halfWidth.set(N.width * 0.5, 0, 0), te.halfHeight.set(0, N.height * 0.5, 0), te.halfWidth.applyMatrix4(a), te.halfHeight.applyMatrix4(a), t.rectArea[D] = te, D++;
      } else if (N.isPointLight) {
        const te = e.get(N);
        if (te.position.setFromMatrixPosition(N.matrixWorld), te.position.applyMatrix4(A), te.color.copy(N.color).multiplyScalar(N.intensity), te.distance = N.distance, te.decay = N.decay, N.castShadow) {
          const K = N.shadow, pe = n.get(N);
          pe.shadowBias = K.bias, pe.shadowNormalBias = K.normalBias, pe.shadowRadius = K.radius, pe.shadowMapSize = K.mapSize, pe.shadowCameraNear = K.camera.near, pe.shadowCameraFar = K.camera.far, t.pointShadow[v] = pe, t.pointShadowMap[v] = W, t.pointShadowMatrix[v] = N.shadow.matrix, F++;
        }
        t.point[v] = te, v++;
      } else if (N.isHemisphereLight) {
        const te = e.get(N);
        te.direction.setFromMatrixPosition(N.matrixWorld), te.direction.transformDirection(A), te.direction.normalize(), te.skyColor.copy(N.color).multiplyScalar(ne), te.groundColor.copy(N.groundColor).multiplyScalar(ne), t.hemi[w] = te, w++;
      }
    }
    t.ambient[0] = m, t.ambient[1] = h, t.ambient[2] = p;
    const L = t.hash;
    (L.directionalLength !== _ || L.pointLength !== v || L.spotLength !== S || L.rectAreaLength !== D || L.hemiLength !== w || L.numDirectionalShadows !== T || L.numPointShadows !== F || L.numSpotShadows !== E) && (t.directional.length = _, t.spot.length = S, t.rectArea.length = D, t.point.length = v, t.hemi.length = w, t.directionalShadow.length = T, t.directionalShadowMap.length = T, t.pointShadow.length = F, t.pointShadowMap.length = F, t.spotShadow.length = E, t.spotShadowMap.length = E, t.directionalShadowMatrix.length = T, t.pointShadowMatrix.length = F, t.spotShadowMatrix.length = E, L.directionalLength = _, L.pointLength = v, L.spotLength = S, L.rectAreaLength = D, L.hemiLength = w, L.numDirectionalShadows = T, L.numPointShadows = F, L.numSpotShadows = E, t.version = wS++);
  }
  return {
    setup: c,
    state: t
  };
}
function Lw() {
  const e = new bS(), n = [], t = [];
  function i() {
    n.length = 0, t.length = 0;
  }
  function r(l) {
    n.push(l);
  }
  function a(l) {
    t.push(l);
  }
  function c(l) {
    e.setup(n, t, l);
  }
  return {
    init: i,
    state: {
      lightsArray: n,
      shadowsArray: t,
      lights: e
    },
    setupLights: c,
    pushLight: r,
    pushShadow: a
  };
}
function MS() {
  let e = /* @__PURE__ */ new WeakMap();
  function n(r) {
    const a = r.target;
    a.removeEventListener("dispose", n), e.delete(a);
  }
  function t(r, a) {
    let c;
    return e.has(r) === !1 ? (c = new Lw(), e.set(r, /* @__PURE__ */ new WeakMap()), e.get(r).set(a, c), r.addEventListener("dispose", n)) : e.get(r).has(a) === !1 ? (c = new Lw(), e.get(r).set(a, c)) : c = e.get(r).get(a), c;
  }
  function i() {
    e = /* @__PURE__ */ new WeakMap();
  }
  return {
    get: t,
    dispose: i
  };
}
function _a(e) {
  rn.call(this), this.type = "MeshDepthMaterial", this.depthPacking = h1, this.skinning = !1, this.morphTargets = !1, this.map = null, this.alphaMap = null, this.displacementMap = null, this.displacementScale = 1, this.displacementBias = 0, this.wireframe = !1, this.wireframeLinewidth = 1, this.fog = !1, this.setValues(e);
}
_a.prototype = Object.create(rn.prototype);
_a.prototype.constructor = _a;
_a.prototype.isMeshDepthMaterial = !0;
_a.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.depthPacking = e.depthPacking, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.map = e.map, this.alphaMap = e.alphaMap, this.displacementMap = e.displacementMap, this.displacementScale = e.displacementScale, this.displacementBias = e.displacementBias, this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this;
};
function ya(e) {
  rn.call(this), this.type = "MeshDistanceMaterial", this.referencePosition = new ve(), this.nearDistance = 1, this.farDistance = 1e3, this.skinning = !1, this.morphTargets = !1, this.map = null, this.alphaMap = null, this.displacementMap = null, this.displacementScale = 1, this.displacementBias = 0, this.fog = !1, this.setValues(e);
}
ya.prototype = Object.create(rn.prototype);
ya.prototype.constructor = ya;
ya.prototype.isMeshDistanceMaterial = !0;
ya.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.referencePosition.copy(e.referencePosition), this.nearDistance = e.nearDistance, this.farDistance = e.farDistance, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.map = e.map, this.alphaMap = e.alphaMap, this.displacementMap = e.displacementMap, this.displacementScale = e.displacementScale, this.displacementBias = e.displacementBias, this;
};
var TS = `uniform sampler2D shadow_pass;
uniform vec2 resolution;
uniform float radius;
#include <packing>
void main() {
  float mean = 0.0;
  float squared_mean = 0.0;
	float depth = unpackRGBAToDepth( texture2D( shadow_pass, ( gl_FragCoord.xy  ) / resolution ) );
  for ( float i = -1.0; i < 1.0 ; i += SAMPLE_RATE) {
    #ifdef HORIZONAL_PASS
      vec2 distribution = unpackRGBATo2Half( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( i, 0.0 ) * radius ) / resolution ) );
      mean += distribution.x;
      squared_mean += distribution.y * distribution.y + distribution.x * distribution.x;
    #else
      float depth = unpackRGBAToDepth( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( 0.0,  i )  * radius ) / resolution ) );
      mean += depth;
      squared_mean += depth * depth;
    #endif
  }
  mean = mean * HALF_SAMPLE_RATE;
  squared_mean = squared_mean * HALF_SAMPLE_RATE;
  float std_dev = sqrt( squared_mean - mean * mean );
  gl_FragColor = pack2HalfToRGBA( vec2( mean, std_dev ) );
}`, ES = `void main() {
	gl_Position = vec4( position, 1.0 );
}`;
function Zx(e, n, t) {
  let i = new hg();
  const r = new vt(), a = new vt(), c = new In(), u = [], l = [], f = {}, m = { 0: hi, 1: cg, 2: Fy }, h = new Xi({
    defines: {
      SAMPLE_RATE: 2 / 8,
      HALF_SAMPLE_RATE: 1 / 8
    },
    uniforms: {
      shadow_pass: { value: null },
      resolution: { value: new vt() },
      radius: { value: 4 }
    },
    vertexShader: ES,
    fragmentShader: TS
  }), p = h.clone();
  p.defines.HORIZONAL_PASS = 1;
  const _ = new Gt();
  _.setAttribute(
    "position",
    new Jt(
      new Float32Array([-1, -1, 0.5, 3, -1, 0.5, -1, 3, 0.5]),
      3
    )
  );
  const v = new Ln(_, h), S = this;
  this.enabled = !1, this.autoUpdate = !0, this.needsUpdate = !1, this.type = Lx, this.render = function(A, L, I) {
    if (S.enabled === !1 || S.autoUpdate === !1 && S.needsUpdate === !1 || A.length === 0)
      return;
    const R = e.getRenderTarget(), N = e.getActiveCubeFace(), q = e.getActiveMipmapLevel(), ne = e.state;
    ne.setBlending(co), ne.buffers.color.setClear(1, 1, 1, 1), ne.buffers.depth.setTest(!0), ne.setScissorTest(!1);
    for (let Q = 0, W = A.length; Q < W; Q++) {
      const te = A[Q], K = te.shadow;
      if (K.autoUpdate === !1 && K.needsUpdate === !1)
        continue;
      if (K === void 0) {
        console.warn("THREE.WebGLShadowMap:", te, "has no shadow.");
        continue;
      }
      r.copy(K.mapSize);
      const pe = K.getFrameExtents();
      if (r.multiply(pe), a.copy(K.mapSize), (r.x > t || r.y > t) && (r.x > t && (a.x = Math.floor(t / pe.x), r.x = a.x * pe.x, K.mapSize.x = a.x), r.y > t && (a.y = Math.floor(t / pe.y), r.y = a.y * pe.y, K.mapSize.y = a.y)), K.map === null && !K.isPointLightShadow && this.type === ym) {
        const Ee = { minFilter: Li, magFilter: Li, format: ws, stencilBuffer: !1 };
        K.map = new xs(r.x, r.y, Ee), K.map.texture.name = te.name + ".shadowMap", K.mapPass = new xs(r.x, r.y, Ee), K.camera.updateProjectionMatrix();
      }
      if (K.map === null) {
        const Ee = { minFilter: _i, magFilter: _i, format: ws, stencilBuffer: !1 };
        K.map = new xs(r.x, r.y, Ee), K.map.texture.name = te.name + ".shadowMap", K.camera.updateProjectionMatrix();
      }
      e.setRenderTarget(K.map), e.clear();
      const be = K.getViewportCount();
      for (let Ee = 0; Ee < be; Ee++) {
        const Ge = K.getViewport(Ee);
        c.set(
          a.x * Ge.x,
          a.y * Ge.y,
          a.x * Ge.z,
          a.y * Ge.w
        ), ne.viewport(c), K.updateMatrices(te, Ee), i = K.getFrustum(), E(L, I, K.camera, te, this.type);
      }
      !K.isPointLightShadow && this.type === ym && D(K, I), K.needsUpdate = !1;
    }
    S.needsUpdate = !1, e.setRenderTarget(R, N, q);
  };
  function D(A, L) {
    const I = n.update(v);
    h.uniforms.shadow_pass.value = A.map.texture, h.uniforms.resolution.value = A.mapSize, h.uniforms.radius.value = A.radius, e.setRenderTarget(A.mapPass), e.clear(), e.renderBufferDirect(L, null, I, h, v, null), p.uniforms.shadow_pass.value = A.mapPass.texture, p.uniforms.resolution.value = A.mapSize, p.uniforms.radius.value = A.radius, e.setRenderTarget(A.map), e.clear(), e.renderBufferDirect(L, null, I, p, v, null);
  }
  function w(A, L, I) {
    const R = A << 0 | L << 1 | I << 2;
    let N = u[R];
    return N === void 0 && (N = new _a({
      depthPacking: f1,
      morphTargets: A,
      skinning: L
    }), u[R] = N), N;
  }
  function T(A, L, I) {
    const R = A << 0 | L << 1 | I << 2;
    let N = l[R];
    return N === void 0 && (N = new ya({
      morphTargets: A,
      skinning: L
    }), l[R] = N), N;
  }
  function F(A, L, I, R, N, q, ne) {
    let Q = null, W = w, te = A.customDepthMaterial;
    if (R.isPointLight === !0 && (W = T, te = A.customDistanceMaterial), te === void 0) {
      let K = !1;
      I.morphTargets === !0 && (K = L.morphAttributes && L.morphAttributes.position && L.morphAttributes.position.length > 0);
      let pe = !1;
      A.isSkinnedMesh === !0 && (I.skinning === !0 ? pe = !0 : console.warn("THREE.WebGLShadowMap: THREE.SkinnedMesh with material.skinning set to false:", A));
      const be = A.isInstancedMesh === !0;
      Q = W(K, pe, be);
    } else
      Q = te;
    if (e.localClippingEnabled && I.clipShadows === !0 && I.clippingPlanes.length !== 0) {
      const K = Q.uuid, pe = I.uuid;
      let be = f[K];
      be === void 0 && (be = {}, f[K] = be);
      let Ee = be[pe];
      Ee === void 0 && (Ee = Q.clone(), be[pe] = Ee), Q = Ee;
    }
    return Q.visible = I.visible, Q.wireframe = I.wireframe, ne === ym ? Q.side = I.shadowSide !== null ? I.shadowSide : I.side : Q.side = I.shadowSide !== null ? I.shadowSide : m[I.side], Q.clipShadows = I.clipShadows, Q.clippingPlanes = I.clippingPlanes, Q.clipIntersection = I.clipIntersection, Q.wireframeLinewidth = I.wireframeLinewidth, Q.linewidth = I.linewidth, R.isPointLight === !0 && Q.isMeshDistanceMaterial === !0 && (Q.referencePosition.setFromMatrixPosition(R.matrixWorld), Q.nearDistance = N, Q.farDistance = q), Q;
  }
  function E(A, L, I, R, N) {
    if (A.visible === !1)
      return;
    if (A.layers.test(L.layers) && (A.isMesh || A.isLine || A.isPoints) && (A.castShadow || A.receiveShadow && N === ym) && (!A.frustumCulled || i.intersectsObject(A))) {
      A.modelViewMatrix.multiplyMatrices(I.matrixWorldInverse, A.matrixWorld);
      const Q = n.update(A), W = A.material;
      if (Array.isArray(W)) {
        const te = Q.groups;
        for (let K = 0, pe = te.length; K < pe; K++) {
          const be = te[K], Ee = W[be.materialIndex];
          if (Ee && Ee.visible) {
            const Ge = F(A, Q, Ee, R, I.near, I.far, N);
            e.renderBufferDirect(I, null, Q, Ge, A, be);
          }
        }
      } else if (W.visible) {
        const te = F(A, Q, W, R, I.near, I.far, N);
        e.renderBufferDirect(I, null, Q, te, A, null);
      }
    }
    const ne = A.children;
    for (let Q = 0, W = ne.length; Q < W; Q++)
      E(ne[Q], L, I, R, N);
  }
}
function SS(e, n, t) {
  const i = t.isWebGL2;
  function r() {
    let fe = !1;
    const Qe = new In();
    let Ne = null;
    const ut = new In(0, 0, 0, 0);
    return {
      setMask: function(de) {
        Ne !== de && !fe && (e.colorMask(de, de, de, de), Ne = de);
      },
      setLocked: function(de) {
        fe = de;
      },
      setClear: function(de, qe, tt, He, je) {
        je === !0 && (de *= He, qe *= He, tt *= He), Qe.set(de, qe, tt, He), ut.equals(Qe) === !1 && (e.clearColor(de, qe, tt, He), ut.copy(Qe));
      },
      reset: function() {
        fe = !1, Ne = null, ut.set(-1, 0, 0, 0);
      }
    };
  }
  function a() {
    let fe = !1, Qe = null, Ne = null, ut = null;
    return {
      setTest: function(de) {
        de ? _e(2929) : De(2929);
      },
      setMask: function(de) {
        Qe !== de && !fe && (e.depthMask(de), Qe = de);
      },
      setFunc: function(de) {
        if (Ne !== de) {
          if (de)
            switch (de) {
              case tM:
                e.depthFunc(512);
                break;
              case nM:
                e.depthFunc(519);
                break;
              case iM:
                e.depthFunc(513);
                break;
              case Ov:
                e.depthFunc(515);
                break;
              case sM:
                e.depthFunc(514);
                break;
              case rM:
                e.depthFunc(518);
                break;
              case oM:
                e.depthFunc(516);
                break;
              case aM:
                e.depthFunc(517);
                break;
              default:
                e.depthFunc(515);
            }
          else
            e.depthFunc(515);
          Ne = de;
        }
      },
      setLocked: function(de) {
        fe = de;
      },
      setClear: function(de) {
        ut !== de && (e.clearDepth(de), ut = de);
      },
      reset: function() {
        fe = !1, Qe = null, Ne = null, ut = null;
      }
    };
  }
  function c() {
    let fe = !1, Qe = null, Ne = null, ut = null, de = null, qe = null, tt = null, He = null, je = null;
    return {
      setTest: function(lt) {
        fe || (lt ? _e(2960) : De(2960));
      },
      setMask: function(lt) {
        Qe !== lt && !fe && (e.stencilMask(lt), Qe = lt);
      },
      setFunc: function(lt, Mt, Rt) {
        (Ne !== lt || ut !== Mt || de !== Rt) && (e.stencilFunc(lt, Mt, Rt), Ne = lt, ut = Mt, de = Rt);
      },
      setOp: function(lt, Mt, Rt) {
        (qe !== lt || tt !== Mt || He !== Rt) && (e.stencilOp(lt, Mt, Rt), qe = lt, tt = Mt, He = Rt);
      },
      setLocked: function(lt) {
        fe = lt;
      },
      setClear: function(lt) {
        je !== lt && (e.clearStencil(lt), je = lt);
      },
      reset: function() {
        fe = !1, Qe = null, Ne = null, ut = null, de = null, qe = null, tt = null, He = null, je = null;
      }
    };
  }
  const u = new r(), l = new a(), f = new c();
  let m = {}, h = null, p = null, _ = null, v = null, S = null, D = null, w = null, T = null, F = null, E = !1, A = null, L = null, I = null, R = null, N = null;
  const q = e.getParameter(35661);
  let ne = !1, Q = 0;
  const W = e.getParameter(7938);
  W.indexOf("WebGL") !== -1 ? (Q = parseFloat(/^WebGL\ ([0-9])/.exec(W)[1]), ne = Q >= 1) : W.indexOf("OpenGL ES") !== -1 && (Q = parseFloat(/^OpenGL\ ES\ ([0-9])/.exec(W)[1]), ne = Q >= 2);
  let te = null, K = {};
  const pe = new In(), be = new In();
  function Ee(fe, Qe, Ne) {
    const ut = new Uint8Array(4), de = e.createTexture();
    e.bindTexture(fe, de), e.texParameteri(fe, 10241, 9728), e.texParameteri(fe, 10240, 9728);
    for (let qe = 0; qe < Ne; qe++)
      e.texImage2D(Qe + qe, 0, 6408, 1, 1, 0, 6408, 5121, ut);
    return de;
  }
  const Ge = {};
  Ge[3553] = Ee(3553, 3553, 1), Ge[34067] = Ee(34067, 34069, 6), u.setClear(0, 0, 0, 1), l.setClear(1), f.setClear(0), _e(2929), l.setFunc(Ov), et(!1), Ve(H0), _e(2884), we(co);
  function _e(fe) {
    m[fe] !== !0 && (e.enable(fe), m[fe] = !0);
  }
  function De(fe) {
    m[fe] !== !1 && (e.disable(fe), m[fe] = !1);
  }
  function he(fe) {
    return h !== fe ? (e.useProgram(fe), h = fe, !0) : !1;
  }
  const Z = {
    [Xc]: 32774,
    [jb]: 32778,
    [Wb]: 32779
  };
  if (i)
    Z[Y0] = 32775, Z[J0] = 32776;
  else {
    const fe = n.get("EXT_blend_minmax");
    fe !== null && (Z[Y0] = fe.MIN_EXT, Z[J0] = fe.MAX_EXT);
  }
  const me = {
    [Hb]: 0,
    [qb]: 1,
    [Kb]: 768,
    [kx]: 770,
    [eM]: 776,
    [Qb]: 774,
    [Yb]: 772,
    [Xb]: 769,
    [Ox]: 771,
    [Zb]: 775,
    [Jb]: 773
  };
  function we(fe, Qe, Ne, ut, de, qe, tt, He) {
    if (fe === co) {
      p && (De(3042), p = !1);
      return;
    }
    if (p || (_e(3042), p = !0), fe !== Vb) {
      if (fe !== _ || He !== E) {
        if ((v !== Xc || w !== Xc) && (e.blendEquation(32774), v = Xc, w = Xc), He)
          switch (fe) {
            case xm:
              e.blendFuncSeparate(1, 771, 1, 771);
              break;
            case q0:
              e.blendFunc(1, 1);
              break;
            case K0:
              e.blendFuncSeparate(0, 0, 769, 771);
              break;
            case X0:
              e.blendFuncSeparate(0, 768, 0, 770);
              break;
            default:
              console.error("THREE.WebGLState: Invalid blending: ", fe);
              break;
          }
        else
          switch (fe) {
            case xm:
              e.blendFuncSeparate(770, 771, 1, 771);
              break;
            case q0:
              e.blendFunc(770, 1);
              break;
            case K0:
              e.blendFunc(0, 769);
              break;
            case X0:
              e.blendFunc(0, 768);
              break;
            default:
              console.error("THREE.WebGLState: Invalid blending: ", fe);
              break;
          }
        S = null, D = null, T = null, F = null, _ = fe, E = He;
      }
      return;
    }
    de = de || Qe, qe = qe || Ne, tt = tt || ut, (Qe !== v || de !== w) && (e.blendEquationSeparate(Z[Qe], Z[de]), v = Qe, w = de), (Ne !== S || ut !== D || qe !== T || tt !== F) && (e.blendFuncSeparate(me[Ne], me[ut], me[qe], me[tt]), S = Ne, D = ut, T = qe, F = tt), _ = fe, E = null;
  }
  function xe(fe, Qe) {
    fe.side === Fy ? De(2884) : _e(2884);
    let Ne = fe.side === hi;
    Qe && (Ne = !Ne), et(Ne), fe.blending === xm && fe.transparent === !1 ? we(co) : we(fe.blending, fe.blendEquation, fe.blendSrc, fe.blendDst, fe.blendEquationAlpha, fe.blendSrcAlpha, fe.blendDstAlpha, fe.premultipliedAlpha), l.setFunc(fe.depthFunc), l.setTest(fe.depthTest), l.setMask(fe.depthWrite), u.setMask(fe.colorWrite);
    const ut = fe.stencilWrite;
    f.setTest(ut), ut && (f.setMask(fe.stencilWriteMask), f.setFunc(fe.stencilFunc, fe.stencilRef, fe.stencilFuncMask), f.setOp(fe.stencilFail, fe.stencilZFail, fe.stencilZPass)), Be(fe.polygonOffset, fe.polygonOffsetFactor, fe.polygonOffsetUnits);
  }
  function et(fe) {
    A !== fe && (fe ? e.frontFace(2304) : e.frontFace(2305), A = fe);
  }
  function Ve(fe) {
    fe !== Nb ? (_e(2884), fe !== L && (fe === H0 ? e.cullFace(1029) : fe === Ub ? e.cullFace(1028) : e.cullFace(1032))) : De(2884), L = fe;
  }
  function nt(fe) {
    fe !== I && (ne && e.lineWidth(fe), I = fe);
  }
  function Be(fe, Qe, Ne) {
    fe ? (_e(32823), (R !== Qe || N !== Ne) && (e.polygonOffset(Qe, Ne), R = Qe, N = Ne)) : De(32823);
  }
  function ae(fe) {
    fe ? _e(3089) : De(3089);
  }
  function U(fe) {
    fe === void 0 && (fe = 33984 + q - 1), te !== fe && (e.activeTexture(fe), te = fe);
  }
  function Se(fe, Qe) {
    te === null && U();
    let Ne = K[te];
    Ne === void 0 && (Ne = { type: void 0, texture: void 0 }, K[te] = Ne), (Ne.type !== fe || Ne.texture !== Qe) && (e.bindTexture(fe, Qe || Ge[fe]), Ne.type = fe, Ne.texture = Qe);
  }
  function ze() {
    const fe = K[te];
    fe !== void 0 && fe.type !== void 0 && (e.bindTexture(fe.type, null), fe.type = void 0, fe.texture = void 0);
  }
  function Oe() {
    try {
      e.compressedTexImage2D.apply(e, arguments);
    } catch (fe) {
      console.error("THREE.WebGLState:", fe);
    }
  }
  function Ye() {
    try {
      e.texImage2D.apply(e, arguments);
    } catch (fe) {
      console.error("THREE.WebGLState:", fe);
    }
  }
  function H() {
    try {
      e.texImage3D.apply(e, arguments);
    } catch (fe) {
      console.error("THREE.WebGLState:", fe);
    }
  }
  function Y(fe) {
    pe.equals(fe) === !1 && (e.scissor(fe.x, fe.y, fe.z, fe.w), pe.copy(fe));
  }
  function $e(fe) {
    be.equals(fe) === !1 && (e.viewport(fe.x, fe.y, fe.z, fe.w), be.copy(fe));
  }
  function Ie() {
    m = {}, te = null, K = {}, h = null, _ = null, A = null, L = null, u.reset(), l.reset(), f.reset();
  }
  return {
    buffers: {
      color: u,
      depth: l,
      stencil: f
    },
    enable: _e,
    disable: De,
    useProgram: he,
    setBlending: we,
    setMaterial: xe,
    setFlipSided: et,
    setCullFace: Ve,
    setLineWidth: nt,
    setPolygonOffset: Be,
    setScissorTest: ae,
    activeTexture: U,
    bindTexture: Se,
    unbindTexture: ze,
    compressedTexImage2D: Oe,
    texImage2D: Ye,
    texImage3D: H,
    scissor: Y,
    viewport: $e,
    reset: Ie
  };
}
function PS(e, n, t, i, r, a, c) {
  const u = r.isWebGL2, l = r.maxTextures, f = r.maxCubemapSize, m = r.maxTextureSize, h = r.maxSamples, p = /* @__PURE__ */ new WeakMap();
  let _, v = !1;
  try {
    v = typeof OffscreenCanvas < "u" && new OffscreenCanvas(1, 1).getContext("2d") !== null;
  } catch {
  }
  function S(H, Y) {
    return v ? new OffscreenCanvas(H, Y) : document.createElementNS("http://www.w3.org/1999/xhtml", "canvas");
  }
  function D(H, Y, $e, Ie) {
    let fe = 1;
    if ((H.width > Ie || H.height > Ie) && (fe = Ie / Math.max(H.width, H.height)), fe < 1 || Y === !0)
      if (typeof HTMLImageElement < "u" && H instanceof HTMLImageElement || typeof HTMLCanvasElement < "u" && H instanceof HTMLCanvasElement || typeof ImageBitmap < "u" && H instanceof ImageBitmap) {
        const Qe = Y ? un.floorPowerOfTwo : Math.floor, Ne = Qe(fe * H.width), ut = Qe(fe * H.height);
        _ === void 0 && (_ = S(Ne, ut));
        const de = $e ? S(Ne, ut) : _;
        return de.width = Ne, de.height = ut, de.getContext("2d").drawImage(H, 0, 0, Ne, ut), console.warn("THREE.WebGLRenderer: Texture has been resized from (" + H.width + "x" + H.height + ") to (" + Ne + "x" + ut + ")."), de;
      } else
        return "data" in H && console.warn("THREE.WebGLRenderer: Image in DataTexture is too big (" + H.width + "x" + H.height + ")."), H;
    return H;
  }
  function w(H) {
    return un.isPowerOfTwo(H.width) && un.isPowerOfTwo(H.height);
  }
  function T(H) {
    return u ? !1 : H.wrapS !== qi || H.wrapT !== qi || H.minFilter !== _i && H.minFilter !== Li;
  }
  function F(H, Y) {
    return H.generateMipmaps && Y && H.minFilter !== _i && H.minFilter !== Li;
  }
  function E(H, Y, $e, Ie) {
    e.generateMipmap(H);
    const fe = i.get(Y);
    fe.__maxMipLevel = Math.log(Math.max($e, Ie)) * Math.LOG2E;
  }
  function A(H, Y, $e) {
    if (u === !1)
      return Y;
    if (H !== null) {
      if (e[H] !== void 0)
        return e[H];
      console.warn("THREE.WebGLRenderer: Attempt to use non-existing WebGL internal format '" + H + "'");
    }
    let Ie = Y;
    return Y === 6403 && ($e === 5126 && (Ie = 33326), $e === 5131 && (Ie = 33325), $e === 5121 && (Ie = 33321)), Y === 6407 && ($e === 5126 && (Ie = 34837), $e === 5131 && (Ie = 34843), $e === 5121 && (Ie = 32849)), Y === 6408 && ($e === 5126 && (Ie = 34836), $e === 5131 && (Ie = 34842), $e === 5121 && (Ie = 32856)), (Ie === 33325 || Ie === 33326 || Ie === 34842 || Ie === 34836) && n.get("EXT_color_buffer_float"), Ie;
  }
  function L(H) {
    return H === _i || H === Fv || H === Rv ? 9728 : 9729;
  }
  function I(H) {
    const Y = H.target;
    Y.removeEventListener("dispose", I), N(Y), Y.isVideoTexture && p.delete(Y), c.memory.textures--;
  }
  function R(H) {
    const Y = H.target;
    Y.removeEventListener("dispose", R), q(Y), c.memory.textures--;
  }
  function N(H) {
    const Y = i.get(H);
    Y.__webglInit !== void 0 && (e.deleteTexture(Y.__webglTexture), i.remove(H));
  }
  function q(H) {
    const Y = i.get(H), $e = i.get(H.texture);
    if (H) {
      if ($e.__webglTexture !== void 0 && e.deleteTexture($e.__webglTexture), H.depthTexture && H.depthTexture.dispose(), H.isWebGLCubeRenderTarget)
        for (let Ie = 0; Ie < 6; Ie++)
          e.deleteFramebuffer(Y.__webglFramebuffer[Ie]), Y.__webglDepthbuffer && e.deleteRenderbuffer(Y.__webglDepthbuffer[Ie]);
      else
        e.deleteFramebuffer(Y.__webglFramebuffer), Y.__webglDepthbuffer && e.deleteRenderbuffer(Y.__webglDepthbuffer), Y.__webglMultisampledFramebuffer && e.deleteFramebuffer(Y.__webglMultisampledFramebuffer), Y.__webglColorRenderbuffer && e.deleteRenderbuffer(Y.__webglColorRenderbuffer), Y.__webglDepthRenderbuffer && e.deleteRenderbuffer(Y.__webglDepthRenderbuffer);
      i.remove(H.texture), i.remove(H);
    }
  }
  let ne = 0;
  function Q() {
    ne = 0;
  }
  function W() {
    const H = ne;
    return H >= l && console.warn("THREE.WebGLTextures: Trying to use " + H + " texture units while this GPU supports only " + l), ne += 1, H;
  }
  function te(H, Y) {
    const $e = i.get(H);
    if (H.isVideoTexture && U(H), H.version > 0 && $e.__version !== H.version) {
      const Ie = H.image;
      if (Ie === void 0)
        console.warn("THREE.WebGLRenderer: Texture marked for update but image is undefined");
      else if (Ie.complete === !1)
        console.warn("THREE.WebGLRenderer: Texture marked for update but image is incomplete");
      else {
        Z($e, H, Y);
        return;
      }
    }
    t.activeTexture(33984 + Y), t.bindTexture(3553, $e.__webglTexture);
  }
  function K(H, Y) {
    const $e = i.get(H);
    if (H.version > 0 && $e.__version !== H.version) {
      Z($e, H, Y);
      return;
    }
    t.activeTexture(33984 + Y), t.bindTexture(35866, $e.__webglTexture);
  }
  function pe(H, Y) {
    const $e = i.get(H);
    if (H.version > 0 && $e.__version !== H.version) {
      Z($e, H, Y);
      return;
    }
    t.activeTexture(33984 + Y), t.bindTexture(32879, $e.__webglTexture);
  }
  function be(H, Y) {
    if (H.image.length !== 6)
      return;
    const $e = i.get(H);
    if (H.version > 0 && $e.__version !== H.version) {
      he($e, H), t.activeTexture(33984 + Y), t.bindTexture(34067, $e.__webglTexture), e.pixelStorei(37440, H.flipY);
      const Ie = H && (H.isCompressedTexture || H.image[0].isCompressedTexture), fe = H.image[0] && H.image[0].isDataTexture, Qe = [];
      for (let je = 0; je < 6; je++)
        !Ie && !fe ? Qe[je] = D(H.image[je], !1, !0, f) : Qe[je] = fe ? H.image[je].image : H.image[je];
      const Ne = Qe[0], ut = w(Ne) || u, de = a.convert(H.format), qe = a.convert(H.type), tt = A(H.internalFormat, de, qe);
      De(34067, H, ut);
      let He;
      if (Ie) {
        for (let je = 0; je < 6; je++) {
          He = Qe[je].mipmaps;
          for (let lt = 0; lt < He.length; lt++) {
            const Mt = He[lt];
            H.format !== ws && H.format !== pa ? de !== null ? t.compressedTexImage2D(34069 + je, lt, tt, Mt.width, Mt.height, 0, Mt.data) : console.warn("THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .setTextureCube()") : t.texImage2D(34069 + je, lt, tt, Mt.width, Mt.height, 0, de, qe, Mt.data);
          }
        }
        $e.__maxMipLevel = He.length - 1;
      } else {
        He = H.mipmaps;
        for (let je = 0; je < 6; je++)
          if (fe) {
            t.texImage2D(34069 + je, 0, tt, Qe[je].width, Qe[je].height, 0, de, qe, Qe[je].data);
            for (let lt = 0; lt < He.length; lt++) {
              const Rt = He[lt].image[je].image;
              t.texImage2D(34069 + je, lt + 1, tt, Rt.width, Rt.height, 0, de, qe, Rt.data);
            }
          } else {
            t.texImage2D(34069 + je, 0, tt, de, qe, Qe[je]);
            for (let lt = 0; lt < He.length; lt++) {
              const Mt = He[lt];
              t.texImage2D(34069 + je, lt + 1, tt, de, qe, Mt.image[je]);
            }
          }
        $e.__maxMipLevel = He.length;
      }
      F(H, ut) && E(34067, H, Ne.width, Ne.height), $e.__version = H.version, H.onUpdate && H.onUpdate(H);
    } else
      t.activeTexture(33984 + Y), t.bindTexture(34067, $e.__webglTexture);
  }
  function Ee(H, Y) {
    t.activeTexture(33984 + Y), t.bindTexture(34067, i.get(H).__webglTexture);
  }
  const Ge = {
    [X_]: 10497,
    [qi]: 33071,
    [Y_]: 33648
  }, _e = {
    [_i]: 9728,
    [Fv]: 9984,
    [Rv]: 9986,
    [Li]: 9729,
    [Rx]: 9985,
    [zy]: 9987
  };
  function De(H, Y, $e) {
    $e ? (e.texParameteri(H, 10242, Ge[Y.wrapS]), e.texParameteri(H, 10243, Ge[Y.wrapT]), (H === 32879 || H === 35866) && e.texParameteri(H, 32882, Ge[Y.wrapR]), e.texParameteri(H, 10240, _e[Y.magFilter]), e.texParameteri(H, 10241, _e[Y.minFilter])) : (e.texParameteri(H, 10242, 33071), e.texParameteri(H, 10243, 33071), (H === 32879 || H === 35866) && e.texParameteri(H, 32882, 33071), (Y.wrapS !== qi || Y.wrapT !== qi) && console.warn("THREE.WebGLRenderer: Texture is not power of two. Texture.wrapS and Texture.wrapT should be set to THREE.ClampToEdgeWrapping."), e.texParameteri(H, 10240, L(Y.magFilter)), e.texParameteri(H, 10241, L(Y.minFilter)), Y.minFilter !== _i && Y.minFilter !== Li && console.warn("THREE.WebGLRenderer: Texture is not power of two. Texture.minFilter should be set to THREE.NearestFilter or THREE.LinearFilter."));
    const Ie = n.get("EXT_texture_filter_anisotropic");
    if (Ie) {
      if (Y.type === oo && n.get("OES_texture_float_linear") === null || Y.type === Q_ && (u || n.get("OES_texture_half_float_linear")) === null)
        return;
      (Y.anisotropy > 1 || i.get(Y).__currentAnisotropy) && (e.texParameterf(H, Ie.TEXTURE_MAX_ANISOTROPY_EXT, Math.min(Y.anisotropy, r.getMaxAnisotropy())), i.get(Y).__currentAnisotropy = Y.anisotropy);
    }
  }
  function he(H, Y) {
    H.__webglInit === void 0 && (H.__webglInit = !0, Y.addEventListener("dispose", I), H.__webglTexture = e.createTexture(), c.memory.textures++);
  }
  function Z(H, Y, $e) {
    let Ie = 3553;
    Y.isDataTexture2DArray && (Ie = 35866), Y.isDataTexture3D && (Ie = 32879), he(H, Y), t.activeTexture(33984 + $e), t.bindTexture(Ie, H.__webglTexture), e.pixelStorei(37440, Y.flipY), e.pixelStorei(37441, Y.premultiplyAlpha), e.pixelStorei(3317, Y.unpackAlignment);
    const fe = T(Y) && w(Y.image) === !1, Qe = D(Y.image, fe, !1, m), Ne = w(Qe) || u, ut = a.convert(Y.format);
    let de = a.convert(Y.type), qe = A(Y.internalFormat, ut, de);
    De(Ie, Y, Ne);
    let tt;
    const He = Y.mipmaps;
    if (Y.isDepthTexture)
      qe = 6402, u ? Y.type === oo ? qe = 36012 : Y.type === j_ ? qe = 33190 : Y.type === bm ? qe = 35056 : qe = 33189 : Y.type === oo && console.error("WebGLRenderer: Floating point depth texture requires WebGL2."), Y.format === ru && qe === 6402 && Y.type !== J_ && Y.type !== j_ && (console.warn("THREE.WebGLRenderer: Use UnsignedShortType or UnsignedIntType for DepthFormat DepthTexture."), Y.type = J_, de = a.convert(Y.type)), Y.format === Pm && qe === 6402 && (qe = 34041, Y.type !== bm && (console.warn("THREE.WebGLRenderer: Use UnsignedInt248Type for DepthStencilFormat DepthTexture."), Y.type = bm, de = a.convert(Y.type))), t.texImage2D(3553, 0, qe, Qe.width, Qe.height, 0, ut, de, null);
    else if (Y.isDataTexture)
      if (He.length > 0 && Ne) {
        for (let je = 0, lt = He.length; je < lt; je++)
          tt = He[je], t.texImage2D(3553, je, qe, tt.width, tt.height, 0, ut, de, tt.data);
        Y.generateMipmaps = !1, H.__maxMipLevel = He.length - 1;
      } else
        t.texImage2D(3553, 0, qe, Qe.width, Qe.height, 0, ut, de, Qe.data), H.__maxMipLevel = 0;
    else if (Y.isCompressedTexture) {
      for (let je = 0, lt = He.length; je < lt; je++)
        tt = He[je], Y.format !== ws && Y.format !== pa ? ut !== null ? t.compressedTexImage2D(3553, je, qe, tt.width, tt.height, 0, tt.data) : console.warn("THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()") : t.texImage2D(3553, je, qe, tt.width, tt.height, 0, ut, de, tt.data);
      H.__maxMipLevel = He.length - 1;
    } else if (Y.isDataTexture2DArray)
      t.texImage3D(35866, 0, qe, Qe.width, Qe.height, Qe.depth, 0, ut, de, Qe.data), H.__maxMipLevel = 0;
    else if (Y.isDataTexture3D)
      t.texImage3D(32879, 0, qe, Qe.width, Qe.height, Qe.depth, 0, ut, de, Qe.data), H.__maxMipLevel = 0;
    else if (He.length > 0 && Ne) {
      for (let je = 0, lt = He.length; je < lt; je++)
        tt = He[je], t.texImage2D(3553, je, qe, ut, de, tt);
      Y.generateMipmaps = !1, H.__maxMipLevel = He.length - 1;
    } else
      t.texImage2D(3553, 0, qe, ut, de, Qe), H.__maxMipLevel = 0;
    F(Y, Ne) && E(Ie, Y, Qe.width, Qe.height), H.__version = Y.version, Y.onUpdate && Y.onUpdate(Y);
  }
  function me(H, Y, $e, Ie) {
    const fe = a.convert(Y.texture.format), Qe = a.convert(Y.texture.type), Ne = A(Y.texture.internalFormat, fe, Qe);
    t.texImage2D(Ie, 0, Ne, Y.width, Y.height, 0, fe, Qe, null), e.bindFramebuffer(36160, H), e.framebufferTexture2D(36160, $e, Ie, i.get(Y.texture).__webglTexture, 0), e.bindFramebuffer(36160, null);
  }
  function we(H, Y, $e) {
    if (e.bindRenderbuffer(36161, H), Y.depthBuffer && !Y.stencilBuffer) {
      let Ie = 33189;
      if ($e) {
        const fe = Y.depthTexture;
        fe && fe.isDepthTexture && (fe.type === oo ? Ie = 36012 : fe.type === j_ && (Ie = 33190));
        const Qe = ae(Y);
        e.renderbufferStorageMultisample(36161, Qe, Ie, Y.width, Y.height);
      } else
        e.renderbufferStorage(36161, Ie, Y.width, Y.height);
      e.framebufferRenderbuffer(36160, 36096, 36161, H);
    } else if (Y.depthBuffer && Y.stencilBuffer) {
      if ($e) {
        const Ie = ae(Y);
        e.renderbufferStorageMultisample(36161, Ie, 35056, Y.width, Y.height);
      } else
        e.renderbufferStorage(36161, 34041, Y.width, Y.height);
      e.framebufferRenderbuffer(36160, 33306, 36161, H);
    } else {
      const Ie = a.convert(Y.texture.format), fe = a.convert(Y.texture.type), Qe = A(Y.texture.internalFormat, Ie, fe);
      if ($e) {
        const Ne = ae(Y);
        e.renderbufferStorageMultisample(36161, Ne, Qe, Y.width, Y.height);
      } else
        e.renderbufferStorage(36161, Qe, Y.width, Y.height);
    }
    e.bindRenderbuffer(36161, null);
  }
  function xe(H, Y) {
    if (Y && Y.isWebGLCubeRenderTarget)
      throw new Error("Depth Texture with cube render targets is not supported");
    if (e.bindFramebuffer(36160, H), !(Y.depthTexture && Y.depthTexture.isDepthTexture))
      throw new Error("renderTarget.depthTexture must be an instance of THREE.DepthTexture");
    (!i.get(Y.depthTexture).__webglTexture || Y.depthTexture.image.width !== Y.width || Y.depthTexture.image.height !== Y.height) && (Y.depthTexture.image.width = Y.width, Y.depthTexture.image.height = Y.height, Y.depthTexture.needsUpdate = !0), te(Y.depthTexture, 0);
    const Ie = i.get(Y.depthTexture).__webglTexture;
    if (Y.depthTexture.format === ru)
      e.framebufferTexture2D(36160, 36096, 3553, Ie, 0);
    else if (Y.depthTexture.format === Pm)
      e.framebufferTexture2D(36160, 33306, 3553, Ie, 0);
    else
      throw new Error("Unknown depthTexture format");
  }
  function et(H) {
    const Y = i.get(H), $e = H.isWebGLCubeRenderTarget === !0;
    if (H.depthTexture) {
      if ($e)
        throw new Error("target.depthTexture not supported in Cube render targets");
      xe(Y.__webglFramebuffer, H);
    } else if ($e) {
      Y.__webglDepthbuffer = [];
      for (let Ie = 0; Ie < 6; Ie++)
        e.bindFramebuffer(36160, Y.__webglFramebuffer[Ie]), Y.__webglDepthbuffer[Ie] = e.createRenderbuffer(), we(Y.__webglDepthbuffer[Ie], H, !1);
    } else
      e.bindFramebuffer(36160, Y.__webglFramebuffer), Y.__webglDepthbuffer = e.createRenderbuffer(), we(Y.__webglDepthbuffer, H, !1);
    e.bindFramebuffer(36160, null);
  }
  function Ve(H) {
    const Y = i.get(H), $e = i.get(H.texture);
    H.addEventListener("dispose", R), $e.__webglTexture = e.createTexture(), c.memory.textures++;
    const Ie = H.isWebGLCubeRenderTarget === !0, fe = H.isWebGLMultisampleRenderTarget === !0, Qe = w(H) || u;
    if (u && H.texture.format === pa && (H.texture.type === oo || H.texture.type === Q_) && (H.texture.format = ws, console.warn("THREE.WebGLRenderer: Rendering to textures with RGB format is not supported. Using RGBA format instead.")), Ie) {
      Y.__webglFramebuffer = [];
      for (let Ne = 0; Ne < 6; Ne++)
        Y.__webglFramebuffer[Ne] = e.createFramebuffer();
    } else if (Y.__webglFramebuffer = e.createFramebuffer(), fe)
      if (u) {
        Y.__webglMultisampledFramebuffer = e.createFramebuffer(), Y.__webglColorRenderbuffer = e.createRenderbuffer(), e.bindRenderbuffer(36161, Y.__webglColorRenderbuffer);
        const Ne = a.convert(H.texture.format), ut = a.convert(H.texture.type), de = A(H.texture.internalFormat, Ne, ut), qe = ae(H);
        e.renderbufferStorageMultisample(36161, qe, de, H.width, H.height), e.bindFramebuffer(36160, Y.__webglMultisampledFramebuffer), e.framebufferRenderbuffer(36160, 36064, 36161, Y.__webglColorRenderbuffer), e.bindRenderbuffer(36161, null), H.depthBuffer && (Y.__webglDepthRenderbuffer = e.createRenderbuffer(), we(Y.__webglDepthRenderbuffer, H, !0)), e.bindFramebuffer(36160, null);
      } else
        console.warn("THREE.WebGLRenderer: WebGLMultisampleRenderTarget can only be used with WebGL2.");
    if (Ie) {
      t.bindTexture(34067, $e.__webglTexture), De(34067, H.texture, Qe);
      for (let Ne = 0; Ne < 6; Ne++)
        me(Y.__webglFramebuffer[Ne], H, 36064, 34069 + Ne);
      F(H.texture, Qe) && E(34067, H.texture, H.width, H.height), t.bindTexture(34067, null);
    } else
      t.bindTexture(3553, $e.__webglTexture), De(3553, H.texture, Qe), me(Y.__webglFramebuffer, H, 36064, 3553), F(H.texture, Qe) && E(3553, H.texture, H.width, H.height), t.bindTexture(3553, null);
    H.depthBuffer && et(H);
  }
  function nt(H) {
    const Y = H.texture, $e = w(H) || u;
    if (F(Y, $e)) {
      const Ie = H.isWebGLCubeRenderTarget ? 34067 : 3553, fe = i.get(Y).__webglTexture;
      t.bindTexture(Ie, fe), E(Ie, Y, H.width, H.height), t.bindTexture(Ie, null);
    }
  }
  function Be(H) {
    if (H.isWebGLMultisampleRenderTarget)
      if (u) {
        const Y = i.get(H);
        e.bindFramebuffer(36008, Y.__webglMultisampledFramebuffer), e.bindFramebuffer(36009, Y.__webglFramebuffer);
        const $e = H.width, Ie = H.height;
        let fe = 16384;
        H.depthBuffer && (fe |= 256), H.stencilBuffer && (fe |= 1024), e.blitFramebuffer(0, 0, $e, Ie, 0, 0, $e, Ie, fe, 9728), e.bindFramebuffer(36160, Y.__webglMultisampledFramebuffer);
      } else
        console.warn("THREE.WebGLRenderer: WebGLMultisampleRenderTarget can only be used with WebGL2.");
  }
  function ae(H) {
    return u && H.isWebGLMultisampleRenderTarget ? Math.min(h, H.samples) : 0;
  }
  function U(H) {
    const Y = c.render.frame;
    p.get(H) !== Y && (p.set(H, Y), H.update());
  }
  let Se = !1, ze = !1;
  function Oe(H, Y) {
    H && H.isWebGLRenderTarget && (Se === !1 && (console.warn("THREE.WebGLTextures.safeSetTexture2D: don't use render targets as textures. Use their .texture property instead."), Se = !0), H = H.texture), te(H, Y);
  }
  function Ye(H, Y) {
    H && H.isWebGLCubeRenderTarget && (ze === !1 && (console.warn("THREE.WebGLTextures.safeSetTextureCube: don't use cube render targets as textures. Use their .texture property instead."), ze = !0), H = H.texture), H && H.isCubeTexture || Array.isArray(H.image) && H.image.length === 6 ? be(H, Y) : Ee(H, Y);
  }
  this.allocateTextureUnit = W, this.resetTextureUnits = Q, this.setTexture2D = te, this.setTexture2DArray = K, this.setTexture3D = pe, this.setTextureCube = be, this.setTextureCubeDynamic = Ee, this.setupRenderTarget = Ve, this.updateRenderTargetMipmap = nt, this.updateMultisampleRenderTarget = Be, this.safeSetTexture2D = Oe, this.safeSetTextureCube = Ye;
}
function AS(e, n, t) {
  const i = t.isWebGL2;
  function r(a) {
    let c;
    if (a === dg)
      return 5121;
    if (a === yM)
      return 32819;
    if (a === vM)
      return 32820;
    if (a === wM)
      return 33635;
    if (a === mM)
      return 5120;
    if (a === gM)
      return 5122;
    if (a === J_)
      return 5123;
    if (a === _M)
      return 5124;
    if (a === j_)
      return 5125;
    if (a === oo)
      return 5126;
    if (a === Q_)
      return i ? 5131 : (c = n.get("OES_texture_half_float"), c !== null ? c.HALF_FLOAT_OES : null);
    if (a === xM)
      return 6406;
    if (a === pa)
      return 6407;
    if (a === ws)
      return 6408;
    if (a === bM)
      return 6409;
    if (a === MM)
      return 6410;
    if (a === ru)
      return 6402;
    if (a === Pm)
      return 34041;
    if (a === EM)
      return 6403;
    if (a === SM)
      return 36244;
    if (a === PM)
      return 33319;
    if (a === AM)
      return 33320;
    if (a === CM)
      return 36248;
    if (a === IM)
      return 36249;
    if (a === Q0 || a === Z0 || a === ew || a === tw)
      if (c = n.get("WEBGL_compressed_texture_s3tc"), c !== null) {
        if (a === Q0)
          return c.COMPRESSED_RGB_S3TC_DXT1_EXT;
        if (a === Z0)
          return c.COMPRESSED_RGBA_S3TC_DXT1_EXT;
        if (a === ew)
          return c.COMPRESSED_RGBA_S3TC_DXT3_EXT;
        if (a === tw)
          return c.COMPRESSED_RGBA_S3TC_DXT5_EXT;
      } else
        return null;
    if (a === nw || a === iw || a === sw || a === rw)
      if (c = n.get("WEBGL_compressed_texture_pvrtc"), c !== null) {
        if (a === nw)
          return c.COMPRESSED_RGB_PVRTC_4BPPV1_IMG;
        if (a === iw)
          return c.COMPRESSED_RGB_PVRTC_2BPPV1_IMG;
        if (a === sw)
          return c.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;
        if (a === rw)
          return c.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;
      } else
        return null;
    if (a === LM)
      return c = n.get("WEBGL_compressed_texture_etc1"), c !== null ? c.COMPRESSED_RGB_ETC1_WEBGL : null;
    if ((a === ow || a === aw) && (c = n.get("WEBGL_compressed_texture_etc"), c !== null)) {
      if (a === ow)
        return c.COMPRESSED_RGB8_ETC2;
      if (a === aw)
        return c.COMPRESSED_RGBA8_ETC2_EAC;
    }
    if (a === DM || a === kM || a === OM || a === FM || a === RM || a === BM || a === zM || a === $M || a === NM || a === UM || a === GM || a === VM || a === jM || a === WM || a === qM || a === KM || a === XM || a === YM || a === JM || a === QM || a === ZM || a === e1 || a === t1 || a === n1 || a === i1 || a === s1 || a === r1 || a === o1)
      return c = n.get("WEBGL_compressed_texture_astc"), c !== null ? a : null;
    if (a === HM)
      return c = n.get("EXT_texture_compression_bptc"), c !== null ? a : null;
    if (a === bm)
      return i ? 34042 : (c = n.get("WEBGL_depth_texture"), c !== null ? c.UNSIGNED_INT_24_8_WEBGL : null);
  }
  return { convert: r };
}
function jv(e) {
  oi.call(this), this.cameras = e || [];
}
jv.prototype = Object.assign(Object.create(oi.prototype), {
  constructor: jv,
  isArrayCamera: !0
});
function ao() {
  Ft.call(this), this.type = "Group";
}
ao.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: ao,
  isGroup: !0
});
function Tm() {
  this._targetRay = null, this._grip = null, this._hand = null;
}
Object.assign(Tm.prototype, {
  constructor: Tm,
  getHandSpace: function() {
    if (this._hand === null && (this._hand = new ao(), this._hand.matrixAutoUpdate = !1, this._hand.visible = !1, this._hand.joints = [], this._hand.inputState = { pinching: !1 }, window.XRHand))
      for (let e = 0; e <= window.XRHand.LITTLE_PHALANX_TIP; e++) {
        let n = new ao();
        n.matrixAutoUpdate = !1, n.visible = !1, this._hand.joints.push(n), this._hand.add(n);
      }
    return this._hand;
  },
  getTargetRaySpace: function() {
    return this._targetRay === null && (this._targetRay = new ao(), this._targetRay.matrixAutoUpdate = !1, this._targetRay.visible = !1), this._targetRay;
  },
  getGripSpace: function() {
    return this._grip === null && (this._grip = new ao(), this._grip.matrixAutoUpdate = !1, this._grip.visible = !1), this._grip;
  },
  dispatchEvent: function(e) {
    return this._targetRay !== null && this._targetRay.dispatchEvent(e), this._grip !== null && this._grip.dispatchEvent(e), this._hand !== null && this._hand.dispatchEvent(e), this;
  },
  disconnect: function(e) {
    return this.dispatchEvent({ type: "disconnected", data: e }), this._targetRay !== null && (this._targetRay.visible = !1), this._grip !== null && (this._grip.visible = !1), this._hand !== null && (this._hand.visible = !1), this;
  },
  update: function(e, n, t) {
    let i = null, r = null, a = null;
    const c = this._targetRay, u = this._grip, l = this._hand;
    if (e)
      if (e.hand) {
        a = !0;
        for (let f = 0; f <= window.XRHand.LITTLE_PHALANX_TIP; f++)
          if (e.hand[f]) {
            let m = n.getJointPose(e.hand[f], t);
            const h = l.joints[f];
            m !== null && (h.matrix.fromArray(m.transform.matrix), h.matrix.decompose(h.position, h.rotation, h.scale), h.jointRadius = m.radius), h.visible = m !== null;
            const p = l.joints[window.XRHand.INDEX_PHALANX_TIP], _ = l.joints[window.XRHand.THUMB_PHALANX_TIP], v = p.position.distanceTo(_.position), S = 0.02, D = 5e-3;
            l.inputState.pinching && v > S + D ? (l.inputState.pinching = !1, this.dispatchEvent({
              type: "pinchend",
              handedness: e.handedness,
              target: this
            })) : !l.inputState.pinching && v <= S - D && (l.inputState.pinching = !0, this.dispatchEvent({
              type: "pinchstart",
              handedness: e.handedness,
              target: this
            }));
          }
      } else
        c !== null && (i = n.getPose(e.targetRaySpace, t), i !== null && (c.matrix.fromArray(i.transform.matrix), c.matrix.decompose(c.position, c.rotation, c.scale))), u !== null && e.gripSpace && (r = n.getPose(e.gripSpace, t), r !== null && (u.matrix.fromArray(r.transform.matrix), u.matrix.decompose(u.position, u.rotation, u.scale)));
    return c !== null && (c.visible = i !== null), u !== null && (u.visible = r !== null), l !== null && (l.visible = a !== null), this;
  }
});
function eb(e, n) {
  const t = this;
  let i = null, r = 1, a = null, c = "local-floor", u = null;
  const l = [], f = /* @__PURE__ */ new Map(), m = new oi();
  m.layers.enable(1), m.viewport = new In();
  const h = new oi();
  h.layers.enable(2), h.viewport = new In();
  const p = [m, h], _ = new jv();
  _.layers.enable(1), _.layers.enable(2);
  let v = null, S = null;
  this.enabled = !1, this.isPresenting = !1, this.getController = function(ne) {
    let Q = l[ne];
    return Q === void 0 && (Q = new Tm(), l[ne] = Q), Q.getTargetRaySpace();
  }, this.getControllerGrip = function(ne) {
    let Q = l[ne];
    return Q === void 0 && (Q = new Tm(), l[ne] = Q), Q.getGripSpace();
  }, this.getHand = function(ne) {
    let Q = l[ne];
    return Q === void 0 && (Q = new Tm(), l[ne] = Q), Q.getHandSpace();
  };
  function D(ne) {
    const Q = f.get(ne.inputSource);
    Q && Q.dispatchEvent({ type: ne.type });
  }
  function w() {
    f.forEach(function(ne, Q) {
      ne.disconnect(Q);
    }), f.clear(), e.setFramebuffer(null), e.setRenderTarget(e.getRenderTarget()), q.stop(), t.isPresenting = !1, t.dispatchEvent({ type: "sessionend" });
  }
  function T(ne) {
    a = ne, q.setContext(i), q.start(), t.isPresenting = !0, t.dispatchEvent({ type: "sessionstart" });
  }
  this.setFramebufferScaleFactor = function(ne) {
    r = ne, t.isPresenting === !0 && console.warn("THREE.WebXRManager: Cannot change framebuffer scale while presenting.");
  }, this.setReferenceSpaceType = function(ne) {
    c = ne, t.isPresenting === !0 && console.warn("THREE.WebXRManager: Cannot change reference space type while presenting.");
  }, this.getReferenceSpace = function() {
    return a;
  }, this.getSession = function() {
    return i;
  }, this.setSession = function(ne) {
    if (i = ne, i !== null) {
      i.addEventListener("select", D), i.addEventListener("selectstart", D), i.addEventListener("selectend", D), i.addEventListener("squeeze", D), i.addEventListener("squeezestart", D), i.addEventListener("squeezeend", D), i.addEventListener("end", w);
      const Q = n.getContextAttributes();
      Q.xrCompatible !== !0 && n.makeXRCompatible();
      const W = {
        antialias: Q.antialias,
        alpha: Q.alpha,
        depth: Q.depth,
        stencil: Q.stencil,
        framebufferScaleFactor: r
      }, te = new XRWebGLLayer(i, n, W);
      i.updateRenderState({ baseLayer: te }), i.requestReferenceSpace(c).then(T), i.addEventListener("inputsourceschange", F);
    }
  };
  function F(ne) {
    const Q = i.inputSources;
    for (let W = 0; W < l.length; W++)
      f.set(Q[W], l[W]);
    for (let W = 0; W < ne.removed.length; W++) {
      const te = ne.removed[W], K = f.get(te);
      K && (K.dispatchEvent({ type: "disconnected", data: te }), f.delete(te));
    }
    for (let W = 0; W < ne.added.length; W++) {
      const te = ne.added[W], K = f.get(te);
      K && K.dispatchEvent({ type: "connected", data: te });
    }
  }
  const E = new ve(), A = new ve();
  function L(ne, Q, W) {
    E.setFromMatrixPosition(Q.matrixWorld), A.setFromMatrixPosition(W.matrixWorld);
    const te = E.distanceTo(A), K = Q.projectionMatrix.elements, pe = W.projectionMatrix.elements, be = K[14] / (K[10] - 1), Ee = K[14] / (K[10] + 1), Ge = (K[9] + 1) / K[5], _e = (K[9] - 1) / K[5], De = (K[8] - 1) / K[0], he = (pe[8] + 1) / pe[0], Z = be * De, me = be * he, we = te / (-De + he), xe = we * -De;
    Q.matrixWorld.decompose(ne.position, ne.quaternion, ne.scale), ne.translateX(xe), ne.translateZ(we), ne.matrixWorld.compose(ne.position, ne.quaternion, ne.scale), ne.matrixWorldInverse.getInverse(ne.matrixWorld);
    const et = be + we, Ve = Ee + we, nt = Z - xe, Be = me + (te - xe), ae = Ge * Ee / Ve * et, U = _e * Ee / Ve * et;
    ne.projectionMatrix.makePerspective(nt, Be, ae, U, et, Ve);
  }
  function I(ne, Q) {
    Q === null ? ne.matrixWorld.copy(ne.matrix) : ne.matrixWorld.multiplyMatrices(Q.matrixWorld, ne.matrix), ne.matrixWorldInverse.getInverse(ne.matrixWorld);
  }
  this.getCamera = function(ne) {
    _.near = h.near = m.near = ne.near, _.far = h.far = m.far = ne.far, (v !== _.near || S !== _.far) && (i.updateRenderState({
      depthNear: _.near,
      depthFar: _.far
    }), v = _.near, S = _.far);
    const Q = ne.parent, W = _.cameras;
    I(_, Q);
    for (let K = 0; K < W.length; K++)
      I(W[K], Q);
    ne.matrixWorld.copy(_.matrixWorld);
    const te = ne.children;
    for (let K = 0, pe = te.length; K < pe; K++)
      te[K].updateMatrixWorld(!0);
    return W.length === 2 ? L(_, m, h) : _.projectionMatrix.copy(m.projectionMatrix), _;
  };
  let R = null;
  function N(ne, Q) {
    if (u = Q.getViewerPose(a), u !== null) {
      const te = u.views, K = i.renderState.baseLayer;
      e.setFramebuffer(K.framebuffer);
      let pe = !1;
      te.length !== _.cameras.length && (_.cameras.length = 0, pe = !0);
      for (let be = 0; be < te.length; be++) {
        const Ee = te[be], Ge = K.getViewport(Ee), _e = p[be];
        _e.matrix.fromArray(Ee.transform.matrix), _e.projectionMatrix.fromArray(Ee.projectionMatrix), _e.viewport.set(Ge.x, Ge.y, Ge.width, Ge.height), be === 0 && _.matrix.copy(_e.matrix), pe === !0 && _.cameras.push(_e);
      }
    }
    const W = i.inputSources;
    for (let te = 0; te < l.length; te++) {
      const K = l[te], pe = W[te];
      K.update(pe, Q, a);
    }
    R && R(ne, Q);
  }
  const q = new Wx();
  q.setAnimationLoop(N), this.setAnimationLoop = function(ne) {
    R = ne;
  }, this.dispose = function() {
  };
}
Object.assign(eb.prototype, Fr.prototype);
function CS(e) {
  function n(w, T) {
    w.fogColor.value.copy(T.color), T.isFog ? (w.fogNear.value = T.near, w.fogFar.value = T.far) : T.isFogExp2 && (w.fogDensity.value = T.density);
  }
  function t(w, T, F, E, A) {
    T.isMeshBasicMaterial ? i(w, T) : T.isMeshLambertMaterial ? (i(w, T), l(w, T)) : T.isMeshToonMaterial ? (i(w, T), m(w, T)) : T.isMeshPhongMaterial ? (i(w, T), f(w, T)) : T.isMeshStandardMaterial ? (i(w, T, F), T.isMeshPhysicalMaterial ? p(w, T, F) : h(w, T, F)) : T.isMeshMatcapMaterial ? (i(w, T), _(w, T)) : T.isMeshDepthMaterial ? (i(w, T), v(w, T)) : T.isMeshDistanceMaterial ? (i(w, T), S(w, T)) : T.isMeshNormalMaterial ? (i(w, T), D(w, T)) : T.isLineBasicMaterial ? (r(w, T), T.isLineDashedMaterial && a(w, T)) : T.isPointsMaterial ? c(w, T, E, A) : T.isSpriteMaterial ? u(w, T) : T.isShadowMaterial ? (w.color.value.copy(T.color), w.opacity.value = T.opacity) : T.isShaderMaterial && (T.uniformsNeedUpdate = !1);
  }
  function i(w, T, F) {
    w.opacity.value = T.opacity, T.color && w.diffuse.value.copy(T.color), T.emissive && w.emissive.value.copy(T.emissive).multiplyScalar(T.emissiveIntensity), T.map && (w.map.value = T.map), T.alphaMap && (w.alphaMap.value = T.alphaMap), T.specularMap && (w.specularMap.value = T.specularMap);
    const E = T.envMap || F;
    if (E) {
      w.envMap.value = E, w.flipEnvMap.value = E.isCubeTexture ? -1 : 1, w.reflectivity.value = T.reflectivity, w.refractionRatio.value = T.refractionRatio;
      var A = e.get(E).__maxMipLevel;
      A !== void 0 && (w.maxMipLevel.value = A);
    }
    T.lightMap && (w.lightMap.value = T.lightMap, w.lightMapIntensity.value = T.lightMapIntensity), T.aoMap && (w.aoMap.value = T.aoMap, w.aoMapIntensity.value = T.aoMapIntensity);
    let L;
    T.map ? L = T.map : T.specularMap ? L = T.specularMap : T.displacementMap ? L = T.displacementMap : T.normalMap ? L = T.normalMap : T.bumpMap ? L = T.bumpMap : T.roughnessMap ? L = T.roughnessMap : T.metalnessMap ? L = T.metalnessMap : T.alphaMap ? L = T.alphaMap : T.emissiveMap && (L = T.emissiveMap), L !== void 0 && (L.isWebGLRenderTarget && (L = L.texture), L.matrixAutoUpdate === !0 && L.updateMatrix(), w.uvTransform.value.copy(L.matrix));
    let I;
    T.aoMap ? I = T.aoMap : T.lightMap && (I = T.lightMap), I !== void 0 && (I.isWebGLRenderTarget && (I = I.texture), I.matrixAutoUpdate === !0 && I.updateMatrix(), w.uv2Transform.value.copy(I.matrix));
  }
  function r(w, T) {
    w.diffuse.value.copy(T.color), w.opacity.value = T.opacity;
  }
  function a(w, T) {
    w.dashSize.value = T.dashSize, w.totalSize.value = T.dashSize + T.gapSize, w.scale.value = T.scale;
  }
  function c(w, T, F, E) {
    w.diffuse.value.copy(T.color), w.opacity.value = T.opacity, w.size.value = T.size * F, w.scale.value = E * 0.5, T.map && (w.map.value = T.map), T.alphaMap && (w.alphaMap.value = T.alphaMap);
    let A;
    T.map ? A = T.map : T.alphaMap && (A = T.alphaMap), A !== void 0 && (A.matrixAutoUpdate === !0 && A.updateMatrix(), w.uvTransform.value.copy(A.matrix));
  }
  function u(w, T) {
    w.diffuse.value.copy(T.color), w.opacity.value = T.opacity, w.rotation.value = T.rotation, T.map && (w.map.value = T.map), T.alphaMap && (w.alphaMap.value = T.alphaMap);
    let F;
    T.map ? F = T.map : T.alphaMap && (F = T.alphaMap), F !== void 0 && (F.matrixAutoUpdate === !0 && F.updateMatrix(), w.uvTransform.value.copy(F.matrix));
  }
  function l(w, T) {
    T.emissiveMap && (w.emissiveMap.value = T.emissiveMap);
  }
  function f(w, T) {
    w.specular.value.copy(T.specular), w.shininess.value = Math.max(T.shininess, 1e-4), T.emissiveMap && (w.emissiveMap.value = T.emissiveMap), T.bumpMap && (w.bumpMap.value = T.bumpMap, w.bumpScale.value = T.bumpScale, T.side === hi && (w.bumpScale.value *= -1)), T.normalMap && (w.normalMap.value = T.normalMap, w.normalScale.value.copy(T.normalScale), T.side === hi && w.normalScale.value.negate()), T.displacementMap && (w.displacementMap.value = T.displacementMap, w.displacementScale.value = T.displacementScale, w.displacementBias.value = T.displacementBias);
  }
  function m(w, T) {
    T.gradientMap && (w.gradientMap.value = T.gradientMap), T.emissiveMap && (w.emissiveMap.value = T.emissiveMap), T.bumpMap && (w.bumpMap.value = T.bumpMap, w.bumpScale.value = T.bumpScale, T.side === hi && (w.bumpScale.value *= -1)), T.normalMap && (w.normalMap.value = T.normalMap, w.normalScale.value.copy(T.normalScale), T.side === hi && w.normalScale.value.negate()), T.displacementMap && (w.displacementMap.value = T.displacementMap, w.displacementScale.value = T.displacementScale, w.displacementBias.value = T.displacementBias);
  }
  function h(w, T, F) {
    w.roughness.value = T.roughness, w.metalness.value = T.metalness, T.roughnessMap && (w.roughnessMap.value = T.roughnessMap), T.metalnessMap && (w.metalnessMap.value = T.metalnessMap), T.emissiveMap && (w.emissiveMap.value = T.emissiveMap), T.bumpMap && (w.bumpMap.value = T.bumpMap, w.bumpScale.value = T.bumpScale, T.side === hi && (w.bumpScale.value *= -1)), T.normalMap && (w.normalMap.value = T.normalMap, w.normalScale.value.copy(T.normalScale), T.side === hi && w.normalScale.value.negate()), T.displacementMap && (w.displacementMap.value = T.displacementMap, w.displacementScale.value = T.displacementScale, w.displacementBias.value = T.displacementBias), (T.envMap || F) && (w.envMapIntensity.value = T.envMapIntensity);
  }
  function p(w, T, F) {
    h(w, T, F), w.reflectivity.value = T.reflectivity, w.clearcoat.value = T.clearcoat, w.clearcoatRoughness.value = T.clearcoatRoughness, T.sheen && w.sheen.value.copy(T.sheen), T.clearcoatMap && (w.clearcoatMap.value = T.clearcoatMap), T.clearcoatRoughnessMap && (w.clearcoatRoughnessMap.value = T.clearcoatRoughnessMap), T.clearcoatNormalMap && (w.clearcoatNormalScale.value.copy(T.clearcoatNormalScale), w.clearcoatNormalMap.value = T.clearcoatNormalMap, T.side === hi && w.clearcoatNormalScale.value.negate()), w.transmission.value = T.transmission, T.transmissionMap && (w.transmissionMap.value = T.transmissionMap);
  }
  function _(w, T) {
    T.matcap && (w.matcap.value = T.matcap), T.bumpMap && (w.bumpMap.value = T.bumpMap, w.bumpScale.value = T.bumpScale, T.side === hi && (w.bumpScale.value *= -1)), T.normalMap && (w.normalMap.value = T.normalMap, w.normalScale.value.copy(T.normalScale), T.side === hi && w.normalScale.value.negate()), T.displacementMap && (w.displacementMap.value = T.displacementMap, w.displacementScale.value = T.displacementScale, w.displacementBias.value = T.displacementBias);
  }
  function v(w, T) {
    T.displacementMap && (w.displacementMap.value = T.displacementMap, w.displacementScale.value = T.displacementScale, w.displacementBias.value = T.displacementBias);
  }
  function S(w, T) {
    T.displacementMap && (w.displacementMap.value = T.displacementMap, w.displacementScale.value = T.displacementScale, w.displacementBias.value = T.displacementBias), w.referencePosition.value.copy(T.referencePosition), w.nearDistance.value = T.nearDistance, w.farDistance.value = T.farDistance;
  }
  function D(w, T) {
    T.bumpMap && (w.bumpMap.value = T.bumpMap, w.bumpScale.value = T.bumpScale, T.side === hi && (w.bumpScale.value *= -1)), T.normalMap && (w.normalMap.value = T.normalMap, w.normalScale.value.copy(T.normalScale), T.side === hi && w.normalScale.value.negate()), T.displacementMap && (w.displacementMap.value = T.displacementMap, w.displacementScale.value = T.displacementScale, w.displacementBias.value = T.displacementBias);
  }
  return {
    refreshFogUniforms: n,
    refreshMaterialUniforms: t
  };
}
function fg(e) {
  e = e || {};
  const n = e.canvas !== void 0 ? e.canvas : document.createElementNS("http://www.w3.org/1999/xhtml", "canvas"), t = e.context !== void 0 ? e.context : null, i = e.alpha !== void 0 ? e.alpha : !1, r = e.depth !== void 0 ? e.depth : !0, a = e.stencil !== void 0 ? e.stencil : !0, c = e.antialias !== void 0 ? e.antialias : !1, u = e.premultipliedAlpha !== void 0 ? e.premultipliedAlpha : !0, l = e.preserveDrawingBuffer !== void 0 ? e.preserveDrawingBuffer : !1, f = e.powerPreference !== void 0 ? e.powerPreference : "default", m = e.failIfMajorPerformanceCaveat !== void 0 ? e.failIfMajorPerformanceCaveat : !1;
  let h = null, p = null;
  this.domElement = n, this.debug = {
    /**
     * Enables error checking and reporting when shader programs are being compiled
     * @type {boolean}
     */
    checkShaderErrors: !0
  }, this.autoClear = !0, this.autoClearColor = !0, this.autoClearDepth = !0, this.autoClearStencil = !0, this.sortObjects = !0, this.clippingPlanes = [], this.localClippingEnabled = !1, this.gammaFactor = 2, this.outputEncoding = Ki, this.physicallyCorrectLights = !1, this.toneMapping = su, this.toneMappingExposure = 1, this.maxMorphTargets = 8, this.maxMorphNormals = 4;
  const _ = this;
  let v = !1, S = null, D = 0, w = 0, T = null, F = null, E = -1, A = null, L = null;
  const I = new In(), R = new In();
  let N = null, q = n.width, ne = n.height, Q = 1, W = null, te = null;
  const K = new In(0, 0, q, ne), pe = new In(0, 0, q, ne);
  let be = !1;
  const Ee = new hg(), Ge = new o2();
  let _e = !1, De = !1;
  const he = new dn(), Z = new ve(), me = { background: null, fog: null, environment: null, overrideMaterial: null, isScene: !0 };
  function we() {
    return T === null ? Q : 1;
  }
  let xe = t;
  function et(Me, at) {
    for (let rt = 0; rt < Me.length; rt++) {
      const mt = Me[rt], _t = n.getContext(mt, at);
      if (_t !== null)
        return _t;
    }
    return null;
  }
  try {
    const Me = {
      alpha: i,
      depth: r,
      stencil: a,
      antialias: c,
      premultipliedAlpha: u,
      preserveDrawingBuffer: l,
      powerPreference: f,
      failIfMajorPerformanceCaveat: m
    };
    if (n.addEventListener("webglcontextlost", lt, !1), n.addEventListener("webglcontextrestored", Mt, !1), xe === null) {
      const at = ["webgl2", "webgl", "experimental-webgl"];
      if (_.isWebGL1Renderer === !0 && at.shift(), xe = et(at, Me), xe === null)
        throw et(at) ? new Error("Error creating WebGL context with your selected attributes.") : new Error("Error creating WebGL context.");
    }
    xe.getShaderPrecisionFormat === void 0 && (xe.getShaderPrecisionFormat = function() {
      return { rangeMin: 1, rangeMax: 1, precision: 1 };
    });
  } catch (Me) {
    throw console.error("THREE.WebGLRenderer: " + Me.message), Me;
  }
  let Ve, nt, Be, ae, U, Se, ze, Oe, Ye, H, Y, $e, Ie, fe, Qe, Ne, ut, de, qe;
  function tt() {
    Ve = new a2(xe), nt = new r2(xe, Ve, e), nt.isWebGL2 === !1 && (Ve.get("WEBGL_depth_texture"), Ve.get("OES_texture_float"), Ve.get("OES_texture_half_float"), Ve.get("OES_texture_half_float_linear"), Ve.get("OES_standard_derivatives"), Ve.get("OES_element_index_uint"), Ve.get("OES_vertex_array_object"), Ve.get("ANGLE_instanced_arrays")), Ve.get("OES_texture_float_linear"), de = new AS(xe, Ve, nt), Be = new SS(xe, Ve, nt), Be.scissor(R.copy(pe).multiplyScalar(Q).floor()), Be.viewport(I.copy(K).multiplyScalar(Q).floor()), ae = new u2(), U = new pS(), Se = new PS(xe, Ve, Be, U, nt, de, ae), ze = new O1(xe, nt), qe = new i2(xe, Ve, ze, nt), Oe = new l2(xe, ze, ae, qe), Ye = new p2(xe, Oe, ze, ae), Qe = new f2(xe), H = new fS(_, Ve, nt, qe), Y = new CS(U), $e = new _S(U), Ie = new MS(), fe = new n2(_, Be, Ye, u), Ne = new s2(xe, Ve, ae, nt), ut = new c2(xe, Ve, ae, nt), ae.programs = H.programs, _.capabilities = nt, _.extensions = Ve, _.properties = U, _.renderLists = $e, _.state = Be, _.info = ae;
  }
  tt();
  const He = new eb(_, xe);
  this.xr = He;
  const je = new Zx(_, Ye, nt.maxTextureSize);
  this.shadowMap = je, this.getContext = function() {
    return xe;
  }, this.getContextAttributes = function() {
    return xe.getContextAttributes();
  }, this.forceContextLoss = function() {
    const Me = Ve.get("WEBGL_lose_context");
    Me && Me.loseContext();
  }, this.forceContextRestore = function() {
    const Me = Ve.get("WEBGL_lose_context");
    Me && Me.restoreContext();
  }, this.getPixelRatio = function() {
    return Q;
  }, this.setPixelRatio = function(Me) {
    Me !== void 0 && (Q = Me, this.setSize(q, ne, !1));
  }, this.getSize = function(Me) {
    return Me === void 0 && (console.warn("WebGLRenderer: .getsize() now requires a Vector2 as an argument"), Me = new vt()), Me.set(q, ne);
  }, this.setSize = function(Me, at, rt) {
    if (He.isPresenting) {
      console.warn("THREE.WebGLRenderer: Can't change size while VR device is presenting.");
      return;
    }
    q = Me, ne = at, n.width = Math.floor(Me * Q), n.height = Math.floor(at * Q), rt !== !1 && (n.style.width = Me + "px", n.style.height = at + "px"), this.setViewport(0, 0, Me, at);
  }, this.getDrawingBufferSize = function(Me) {
    return Me === void 0 && (console.warn("WebGLRenderer: .getdrawingBufferSize() now requires a Vector2 as an argument"), Me = new vt()), Me.set(q * Q, ne * Q).floor();
  }, this.setDrawingBufferSize = function(Me, at, rt) {
    q = Me, ne = at, Q = rt, n.width = Math.floor(Me * rt), n.height = Math.floor(at * rt), this.setViewport(0, 0, Me, at);
  }, this.getCurrentViewport = function(Me) {
    return Me === void 0 && (console.warn("WebGLRenderer: .getCurrentViewport() now requires a Vector4 as an argument"), Me = new In()), Me.copy(I);
  }, this.getViewport = function(Me) {
    return Me.copy(K);
  }, this.setViewport = function(Me, at, rt, mt) {
    Me.isVector4 ? K.set(Me.x, Me.y, Me.z, Me.w) : K.set(Me, at, rt, mt), Be.viewport(I.copy(K).multiplyScalar(Q).floor());
  }, this.getScissor = function(Me) {
    return Me.copy(pe);
  }, this.setScissor = function(Me, at, rt, mt) {
    Me.isVector4 ? pe.set(Me.x, Me.y, Me.z, Me.w) : pe.set(Me, at, rt, mt), Be.scissor(R.copy(pe).multiplyScalar(Q).floor());
  }, this.getScissorTest = function() {
    return be;
  }, this.setScissorTest = function(Me) {
    Be.setScissorTest(be = Me);
  }, this.setOpaqueSort = function(Me) {
    W = Me;
  }, this.setTransparentSort = function(Me) {
    te = Me;
  }, this.getClearColor = function() {
    return fe.getClearColor();
  }, this.setClearColor = function() {
    fe.setClearColor.apply(fe, arguments);
  }, this.getClearAlpha = function() {
    return fe.getClearAlpha();
  }, this.setClearAlpha = function() {
    fe.setClearAlpha.apply(fe, arguments);
  }, this.clear = function(Me, at, rt) {
    let mt = 0;
    (Me === void 0 || Me) && (mt |= 16384), (at === void 0 || at) && (mt |= 256), (rt === void 0 || rt) && (mt |= 1024), xe.clear(mt);
  }, this.clearColor = function() {
    this.clear(!0, !1, !1);
  }, this.clearDepth = function() {
    this.clear(!1, !0, !1);
  }, this.clearStencil = function() {
    this.clear(!1, !1, !0);
  }, this.dispose = function() {
    n.removeEventListener("webglcontextlost", lt, !1), n.removeEventListener("webglcontextrestored", Mt, !1), $e.dispose(), Ie.dispose(), U.dispose(), Ye.dispose(), qe.dispose(), He.dispose(), li.stop();
  };
  function lt(Me) {
    Me.preventDefault(), console.log("THREE.WebGLRenderer: Context Lost."), v = !0;
  }
  function Mt() {
    console.log("THREE.WebGLRenderer: Context Restored."), v = !1, tt();
  }
  function Rt(Me) {
    const at = Me.target;
    at.removeEventListener("dispose", Rt), Kt(at);
  }
  function Kt(Me) {
    vn(Me), U.remove(Me);
  }
  function vn(Me) {
    const at = U.get(Me).program;
    at !== void 0 && H.releaseProgram(at);
  }
  function wn(Me, at) {
    Me.render(function(rt) {
      _.renderBufferImmediate(rt, at);
    });
  }
  this.renderBufferImmediate = function(Me, at) {
    qe.initAttributes();
    const rt = U.get(Me);
    Me.hasPositions && !rt.position && (rt.position = xe.createBuffer()), Me.hasNormals && !rt.normal && (rt.normal = xe.createBuffer()), Me.hasUvs && !rt.uv && (rt.uv = xe.createBuffer()), Me.hasColors && !rt.color && (rt.color = xe.createBuffer());
    const mt = at.getAttributes();
    Me.hasPositions && (xe.bindBuffer(34962, rt.position), xe.bufferData(34962, Me.positionArray, 35048), qe.enableAttribute(mt.position), xe.vertexAttribPointer(mt.position, 3, 5126, !1, 0, 0)), Me.hasNormals && (xe.bindBuffer(34962, rt.normal), xe.bufferData(34962, Me.normalArray, 35048), qe.enableAttribute(mt.normal), xe.vertexAttribPointer(mt.normal, 3, 5126, !1, 0, 0)), Me.hasUvs && (xe.bindBuffer(34962, rt.uv), xe.bufferData(34962, Me.uvArray, 35048), qe.enableAttribute(mt.uv), xe.vertexAttribPointer(mt.uv, 2, 5126, !1, 0, 0)), Me.hasColors && (xe.bindBuffer(34962, rt.color), xe.bufferData(34962, Me.colorArray, 35048), qe.enableAttribute(mt.color), xe.vertexAttribPointer(mt.color, 3, 5126, !1, 0, 0)), qe.disableUnusedAttributes(), xe.drawArrays(4, 0, Me.count), Me.count = 0;
  }, this.renderBufferDirect = function(Me, at, rt, mt, _t, on) {
    at === null && (at = me);
    const B = _t.isMesh && _t.matrixWorld.determinant() < 0, le = Si(Me, at, mt, _t);
    Be.setMaterial(mt, B);
    let J = rt.index;
    const se = rt.attributes.position;
    if (J === null) {
      if (se === void 0 || se.count === 0)
        return;
    } else if (J.count === 0)
      return;
    let ge = 1;
    mt.wireframe === !0 && (J = Oe.getWireframeAttribute(rt), ge = 2), (mt.morphTargets || mt.morphNormals) && Qe.update(_t, rt, mt, le), qe.setup(_t, mt, le, rt, J);
    let Fe, Ke = Ne;
    J !== null && (Fe = ze.get(J), Ke = ut, Ke.setIndex(Fe));
    const pt = J !== null ? J.count : se.count, Pt = rt.drawRange.start * ge, Tt = rt.drawRange.count * ge, en = on !== null ? on.start * ge : 0, Dt = on !== null ? on.count * ge : 1 / 0, tn = Math.max(Pt, en), Vt = Math.min(pt, Pt + Tt, en + Dt) - 1, nn = Math.max(0, Vt - tn + 1);
    if (nn !== 0) {
      if (_t.isMesh)
        mt.wireframe === !0 ? (Be.setLineWidth(mt.wireframeLinewidth * we()), Ke.setMode(1)) : Ke.setMode(4);
      else if (_t.isLine) {
        let Mn = mt.linewidth;
        Mn === void 0 && (Mn = 1), Be.setLineWidth(Mn * we()), _t.isLineSegments ? Ke.setMode(1) : _t.isLineLoop ? Ke.setMode(2) : Ke.setMode(3);
      } else
        _t.isPoints ? Ke.setMode(0) : _t.isSprite && Ke.setMode(4);
      if (_t.isInstancedMesh)
        Ke.renderInstances(tn, nn, _t.count);
      else if (rt.isInstancedBufferGeometry) {
        const Mn = Math.min(rt.instanceCount, rt._maxInstanceCount);
        Ke.renderInstances(tn, nn, Mn);
      } else
        Ke.render(tn, nn);
    }
  }, this.compile = function(Me, at) {
    p = Ie.get(Me, at), p.init(), Me.traverse(function(mt) {
      mt.isLight && (p.pushLight(mt), mt.castShadow && p.pushShadow(mt));
    }), p.setupLights(at);
    const rt = /* @__PURE__ */ new WeakMap();
    Me.traverse(function(mt) {
      let _t = mt.material;
      if (_t)
        if (Array.isArray(_t))
          for (let on = 0; on < _t.length; on++) {
            let B = _t[on];
            rt.has(B) === !1 && (bn(B, Me, mt), rt.set(B));
          }
        else
          rt.has(_t) === !1 && (bn(_t, Me, mt), rt.set(_t));
    });
  };
  let ln = null;
  function Gn(Me) {
    He.isPresenting || ln && ln(Me);
  }
  const li = new Wx();
  li.setAnimationLoop(Gn), typeof window < "u" && li.setContext(window), this.setAnimationLoop = function(Me) {
    ln = Me, He.setAnimationLoop(Me), Me === null ? li.stop() : li.start();
  }, this.render = function(Me, at) {
    let rt, mt;
    if (arguments[2] !== void 0 && (console.warn("THREE.WebGLRenderer.render(): the renderTarget argument has been removed. Use .setRenderTarget() instead."), rt = arguments[2]), arguments[3] !== void 0 && (console.warn("THREE.WebGLRenderer.render(): the forceClear argument has been removed. Use .clear() instead."), mt = arguments[3]), at !== void 0 && at.isCamera !== !0) {
      console.error("THREE.WebGLRenderer.render: camera is not an instance of THREE.Camera.");
      return;
    }
    if (v === !0)
      return;
    qe.resetDefaultState(), E = -1, A = null, Me.autoUpdate === !0 && Me.updateMatrixWorld(), at.parent === null && at.updateMatrixWorld(), He.enabled === !0 && He.isPresenting === !0 && (at = He.getCamera(at)), Me.isScene === !0 && Me.onBeforeRender(_, Me, at, rt || T), p = Ie.get(Me, at), p.init(), he.multiplyMatrices(at.projectionMatrix, at.matrixWorldInverse), Ee.setFromProjectionMatrix(he), De = this.localClippingEnabled, _e = Ge.init(this.clippingPlanes, De, at), h = $e.get(Me, at), h.init(), Yi(Me, at, 0, _.sortObjects), h.finish(), _.sortObjects === !0 && h.sort(W, te), _e === !0 && Ge.beginShadows();
    const _t = p.state.shadowsArray;
    je.render(_t, Me, at), p.setupLights(at), _e === !0 && Ge.endShadows(), this.info.autoReset === !0 && this.info.reset(), rt !== void 0 && this.setRenderTarget(rt), fe.render(h, Me, at, mt);
    const on = h.opaque, B = h.transparent;
    on.length > 0 && $i(on, Me, at), B.length > 0 && $i(B, Me, at), Me.isScene === !0 && Me.onAfterRender(_, Me, at), T !== null && (Se.updateRenderTargetMipmap(T), Se.updateMultisampleRenderTarget(T)), Be.buffers.depth.setTest(!0), Be.buffers.depth.setMask(!0), Be.buffers.color.setMask(!0), Be.setPolygonOffset(!1), h = null, p = null;
  };
  function Yi(Me, at, rt, mt) {
    if (Me.visible === !1)
      return;
    if (Me.layers.test(at.layers)) {
      if (Me.isGroup)
        rt = Me.renderOrder;
      else if (Me.isLOD)
        Me.autoUpdate === !0 && Me.update(at);
      else if (Me.isLight)
        p.pushLight(Me), Me.castShadow && p.pushShadow(Me);
      else if (Me.isSprite) {
        if (!Me.frustumCulled || Ee.intersectsSprite(Me)) {
          mt && Z.setFromMatrixPosition(Me.matrixWorld).applyMatrix4(he);
          const B = Ye.update(Me), le = Me.material;
          le.visible && h.push(Me, B, le, rt, Z.z, null);
        }
      } else if (Me.isImmediateRenderObject)
        mt && Z.setFromMatrixPosition(Me.matrixWorld).applyMatrix4(he), h.push(Me, null, Me.material, rt, Z.z, null);
      else if ((Me.isMesh || Me.isLine || Me.isPoints) && (Me.isSkinnedMesh && Me.skeleton.frame !== ae.render.frame && (Me.skeleton.update(), Me.skeleton.frame = ae.render.frame), !Me.frustumCulled || Ee.intersectsObject(Me))) {
        mt && Z.setFromMatrixPosition(Me.matrixWorld).applyMatrix4(he);
        const B = Ye.update(Me), le = Me.material;
        if (Array.isArray(le)) {
          const J = B.groups;
          for (let se = 0, ge = J.length; se < ge; se++) {
            const Fe = J[se], Ke = le[Fe.materialIndex];
            Ke && Ke.visible && h.push(Me, B, Ke, rt, Z.z, Fe);
          }
        } else
          le.visible && h.push(Me, B, le, rt, Z.z, null);
      }
    }
    const on = Me.children;
    for (let B = 0, le = on.length; B < le; B++)
      Yi(on[B], at, rt, mt);
  }
  function $i(Me, at, rt) {
    const mt = at.isScene === !0 ? at.overrideMaterial : null;
    for (let _t = 0, on = Me.length; _t < on; _t++) {
      const B = Me[_t], le = B.object, J = B.geometry, se = mt === null ? B.material : mt, ge = B.group;
      if (rt.isArrayCamera) {
        L = rt;
        const Fe = rt.cameras;
        for (let Ke = 0, pt = Fe.length; Ke < pt; Ke++) {
          const Pt = Fe[Ke];
          le.layers.test(Pt.layers) && (Be.viewport(I.copy(Pt.viewport)), p.setupLights(Pt), An(le, at, Pt, J, se, ge));
        }
      } else
        L = null, An(le, at, rt, J, se, ge);
    }
  }
  function An(Me, at, rt, mt, _t, on) {
    if (Me.onBeforeRender(_, at, rt, mt, _t, on), p = Ie.get(at, L || rt), Me.modelViewMatrix.multiplyMatrices(rt.matrixWorldInverse, Me.matrixWorld), Me.normalMatrix.getNormalMatrix(Me.modelViewMatrix), Me.isImmediateRenderObject) {
      const B = Si(rt, at, _t, Me);
      Be.setMaterial(_t), qe.reset(), wn(Me, B);
    } else
      _.renderBufferDirect(rt, at, mt, _t, Me, on);
    Me.onAfterRender(_, at, rt, mt, _t, on), p = Ie.get(at, L || rt);
  }
  function bn(Me, at, rt) {
    at.isScene !== !0 && (at = me);
    const mt = U.get(Me), _t = p.state.lights, on = p.state.shadowsArray, B = _t.state.version, le = H.getParameters(Me, _t.state, on, at, Ge.numPlanes, Ge.numIntersection, rt), J = H.getProgramCacheKey(le);
    let se = mt.program, ge = !0;
    if (se === void 0)
      Me.addEventListener("dispose", Rt);
    else if (se.cacheKey !== J)
      vn(Me);
    else if (mt.lightsStateVersion !== B)
      mt.lightsStateVersion = B, ge = !1;
    else {
      if (le.shaderID !== void 0)
        return;
      ge = !1;
    }
    ge && (le.uniforms = H.getUniforms(Me, le), Me.onBeforeCompile(le, _), se = H.acquireProgram(le, J), mt.program = se, mt.uniforms = le.uniforms, mt.outputEncoding = le.outputEncoding);
    const Fe = se.getAttributes();
    if (Me.morphTargets) {
      Me.numSupportedMorphTargets = 0;
      for (let Tt = 0; Tt < _.maxMorphTargets; Tt++)
        Fe["morphTarget" + Tt] >= 0 && Me.numSupportedMorphTargets++;
    }
    if (Me.morphNormals) {
      Me.numSupportedMorphNormals = 0;
      for (let Tt = 0; Tt < _.maxMorphNormals; Tt++)
        Fe["morphNormal" + Tt] >= 0 && Me.numSupportedMorphNormals++;
    }
    const Ke = mt.uniforms;
    (!Me.isShaderMaterial && !Me.isRawShaderMaterial || Me.clipping === !0) && (mt.numClippingPlanes = Ge.numPlanes, mt.numIntersection = Ge.numIntersection, Ke.clippingPlanes = Ge.uniform), mt.environment = Me.isMeshStandardMaterial ? at.environment : null, mt.fog = at.fog, mt.needsLights = qt(Me), mt.lightsStateVersion = B, mt.needsLights && (Ke.ambientLightColor.value = _t.state.ambient, Ke.lightProbe.value = _t.state.probe, Ke.directionalLights.value = _t.state.directional, Ke.directionalLightShadows.value = _t.state.directionalShadow, Ke.spotLights.value = _t.state.spot, Ke.spotLightShadows.value = _t.state.spotShadow, Ke.rectAreaLights.value = _t.state.rectArea, Ke.pointLights.value = _t.state.point, Ke.pointLightShadows.value = _t.state.pointShadow, Ke.hemisphereLights.value = _t.state.hemi, Ke.directionalShadowMap.value = _t.state.directionalShadowMap, Ke.directionalShadowMatrix.value = _t.state.directionalShadowMatrix, Ke.spotShadowMap.value = _t.state.spotShadowMap, Ke.spotShadowMatrix.value = _t.state.spotShadowMatrix, Ke.pointShadowMap.value = _t.state.pointShadowMap, Ke.pointShadowMatrix.value = _t.state.pointShadowMatrix);
    const pt = mt.program.getUniforms(), Pt = uo.seqWithValue(pt.seq, Ke);
    mt.uniformsList = Pt;
  }
  function Si(Me, at, rt, mt) {
    at.isScene !== !0 && (at = me), Se.resetTextureUnits();
    const _t = at.fog, on = rt.isMeshStandardMaterial ? at.environment : null, B = T === null ? _.outputEncoding : T.texture.encoding, le = U.get(rt), J = p.state.lights;
    if (_e === !0 && (De === !0 || Me !== A)) {
      const Tt = Me === A && rt.id === E;
      Ge.setState(
        rt.clippingPlanes,
        rt.clipIntersection,
        rt.clipShadows,
        Me,
        le,
        Tt
      );
    }
    rt.version === le.__version ? (le.program === void 0 || rt.fog && le.fog !== _t || le.environment !== on || le.needsLights && le.lightsStateVersion !== J.state.version || le.numClippingPlanes !== void 0 && (le.numClippingPlanes !== Ge.numPlanes || le.numIntersection !== Ge.numIntersection) || le.outputEncoding !== B) && bn(rt, at, mt) : (bn(rt, at, mt), le.__version = rt.version);
    let se = !1, ge = !1, Fe = !1;
    const Ke = le.program, pt = Ke.getUniforms(), Pt = le.uniforms;
    if (Be.useProgram(Ke.program) && (se = !0, ge = !0, Fe = !0), rt.id !== E && (E = rt.id, ge = !0), se || A !== Me) {
      if (pt.setValue(xe, "projectionMatrix", Me.projectionMatrix), nt.logarithmicDepthBuffer && pt.setValue(
        xe,
        "logDepthBufFC",
        2 / (Math.log(Me.far + 1) / Math.LN2)
      ), A !== Me && (A = Me, ge = !0, Fe = !0), rt.isShaderMaterial || rt.isMeshPhongMaterial || rt.isMeshToonMaterial || rt.isMeshStandardMaterial || rt.envMap) {
        const Tt = pt.map.cameraPosition;
        Tt !== void 0 && Tt.setValue(
          xe,
          Z.setFromMatrixPosition(Me.matrixWorld)
        );
      }
      (rt.isMeshPhongMaterial || rt.isMeshToonMaterial || rt.isMeshLambertMaterial || rt.isMeshBasicMaterial || rt.isMeshStandardMaterial || rt.isShaderMaterial) && pt.setValue(xe, "isOrthographic", Me.isOrthographicCamera === !0), (rt.isMeshPhongMaterial || rt.isMeshToonMaterial || rt.isMeshLambertMaterial || rt.isMeshBasicMaterial || rt.isMeshStandardMaterial || rt.isShaderMaterial || rt.isShadowMaterial || rt.skinning) && pt.setValue(xe, "viewMatrix", Me.matrixWorldInverse);
    }
    if (rt.skinning) {
      pt.setOptional(xe, mt, "bindMatrix"), pt.setOptional(xe, mt, "bindMatrixInverse");
      const Tt = mt.skeleton;
      if (Tt) {
        const en = Tt.bones;
        if (nt.floatVertexTextures) {
          if (Tt.boneTexture === void 0) {
            let Dt = Math.sqrt(en.length * 4);
            Dt = un.ceilPowerOfTwo(Dt), Dt = Math.max(Dt, 4);
            const tn = new Float32Array(Dt * Dt * 4);
            tn.set(Tt.boneMatrices);
            const Vt = new cu(tn, Dt, Dt, ws, oo);
            Tt.boneMatrices = tn, Tt.boneTexture = Vt, Tt.boneTextureSize = Dt;
          }
          pt.setValue(xe, "boneTexture", Tt.boneTexture, Se), pt.setValue(xe, "boneTextureSize", Tt.boneTextureSize);
        } else
          pt.setOptional(xe, Tt, "boneMatrices");
      }
    }
    return (ge || le.receiveShadow !== mt.receiveShadow) && (le.receiveShadow = mt.receiveShadow, pt.setValue(xe, "receiveShadow", mt.receiveShadow)), ge && (pt.setValue(xe, "toneMappingExposure", _.toneMappingExposure), le.needsLights && ds(Pt, Fe), _t && rt.fog && Y.refreshFogUniforms(Pt, _t), Y.refreshMaterialUniforms(Pt, rt, on, Q, ne), Pt.ltc_1 !== void 0 && (Pt.ltc_1.value = Bt.LTC_1), Pt.ltc_2 !== void 0 && (Pt.ltc_2.value = Bt.LTC_2), uo.upload(xe, le.uniformsList, Pt, Se)), rt.isShaderMaterial && rt.uniformsNeedUpdate === !0 && (uo.upload(xe, le.uniformsList, Pt, Se), rt.uniformsNeedUpdate = !1), rt.isSpriteMaterial && pt.setValue(xe, "center", mt.center), pt.setValue(xe, "modelViewMatrix", mt.modelViewMatrix), pt.setValue(xe, "normalMatrix", mt.normalMatrix), pt.setValue(xe, "modelMatrix", mt.matrixWorld), Ke;
  }
  function ds(Me, at) {
    Me.ambientLightColor.needsUpdate = at, Me.lightProbe.needsUpdate = at, Me.directionalLights.needsUpdate = at, Me.directionalLightShadows.needsUpdate = at, Me.pointLights.needsUpdate = at, Me.pointLightShadows.needsUpdate = at, Me.spotLights.needsUpdate = at, Me.spotLightShadows.needsUpdate = at, Me.rectAreaLights.needsUpdate = at, Me.hemisphereLights.needsUpdate = at;
  }
  function qt(Me) {
    return Me.isMeshLambertMaterial || Me.isMeshToonMaterial || Me.isMeshPhongMaterial || Me.isMeshStandardMaterial || Me.isShadowMaterial || Me.isShaderMaterial && Me.lights === !0;
  }
  this.setFramebuffer = function(Me) {
    S !== Me && T === null && xe.bindFramebuffer(36160, Me), S = Me;
  }, this.getActiveCubeFace = function() {
    return D;
  }, this.getActiveMipmapLevel = function() {
    return w;
  }, this.getRenderTarget = function() {
    return T;
  }, this.setRenderTarget = function(Me, at, rt) {
    T = Me, D = at, w = rt, Me && U.get(Me).__webglFramebuffer === void 0 && Se.setupRenderTarget(Me);
    let mt = S, _t = !1;
    if (Me) {
      const on = U.get(Me).__webglFramebuffer;
      Me.isWebGLCubeRenderTarget ? (mt = on[at || 0], _t = !0) : Me.isWebGLMultisampleRenderTarget ? mt = U.get(Me).__webglMultisampledFramebuffer : mt = on, I.copy(Me.viewport), R.copy(Me.scissor), N = Me.scissorTest;
    } else
      I.copy(K).multiplyScalar(Q).floor(), R.copy(pe).multiplyScalar(Q).floor(), N = be;
    if (F !== mt && (xe.bindFramebuffer(36160, mt), F = mt), Be.viewport(I), Be.scissor(R), Be.setScissorTest(N), _t) {
      const on = U.get(Me.texture);
      xe.framebufferTexture2D(36160, 36064, 34069 + (at || 0), on.__webglTexture, rt || 0);
    }
  }, this.readRenderTargetPixels = function(Me, at, rt, mt, _t, on, B) {
    if (!(Me && Me.isWebGLRenderTarget)) {
      console.error("THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.");
      return;
    }
    let le = U.get(Me).__webglFramebuffer;
    if (Me.isWebGLCubeRenderTarget && B !== void 0 && (le = le[B]), le) {
      let J = !1;
      le !== F && (xe.bindFramebuffer(36160, le), J = !0);
      try {
        const se = Me.texture, ge = se.format, Fe = se.type;
        if (ge !== ws && de.convert(ge) !== xe.getParameter(35739)) {
          console.error("THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in RGBA or implementation defined format.");
          return;
        }
        if (Fe !== dg && de.convert(Fe) !== xe.getParameter(35738) && // IE11, Edge and Chrome Mac < 52 (#9513)
        !(Fe === oo && (nt.isWebGL2 || Ve.get("OES_texture_float") || Ve.get("WEBGL_color_buffer_float"))) && // Chrome Mac >= 52 and Firefox
        !(Fe === Q_ && (nt.isWebGL2 ? Ve.get("EXT_color_buffer_float") : Ve.get("EXT_color_buffer_half_float")))) {
          console.error("THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in UnsignedByteType or implementation defined type.");
          return;
        }
        xe.checkFramebufferStatus(36160) === 36053 ? at >= 0 && at <= Me.width - mt && rt >= 0 && rt <= Me.height - _t && xe.readPixels(at, rt, mt, _t, de.convert(ge), de.convert(Fe), on) : console.error("THREE.WebGLRenderer.readRenderTargetPixels: readPixels from renderTarget failed. Framebuffer not complete.");
      } finally {
        J && xe.bindFramebuffer(36160, F);
      }
    }
  }, this.copyFramebufferToTexture = function(Me, at, rt) {
    rt === void 0 && (rt = 0);
    const mt = Math.pow(2, -rt), _t = Math.floor(at.image.width * mt), on = Math.floor(at.image.height * mt), B = de.convert(at.format);
    Se.setTexture2D(at, 0), xe.copyTexImage2D(3553, rt, B, Me.x, Me.y, _t, on, 0), Be.unbindTexture();
  }, this.copyTextureToTexture = function(Me, at, rt, mt) {
    mt === void 0 && (mt = 0);
    const _t = at.image.width, on = at.image.height, B = de.convert(rt.format), le = de.convert(rt.type);
    Se.setTexture2D(rt, 0), xe.pixelStorei(37440, rt.flipY), xe.pixelStorei(37441, rt.premultiplyAlpha), xe.pixelStorei(3317, rt.unpackAlignment), at.isDataTexture ? xe.texSubImage2D(3553, mt, Me.x, Me.y, _t, on, B, le, at.image.data) : at.isCompressedTexture ? xe.compressedTexSubImage2D(3553, mt, Me.x, Me.y, at.mipmaps[0].width, at.mipmaps[0].height, B, at.mipmaps[0].data) : xe.texSubImage2D(3553, mt, Me.x, Me.y, B, le, at.image), mt === 0 && rt.generateMipmaps && xe.generateMipmap(3553), Be.unbindTexture();
  }, this.initTexture = function(Me) {
    Se.setTexture2D(Me, 0), Be.unbindTexture();
  }, typeof __THREE_DEVTOOLS__ < "u" && __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent("observe", { detail: this }));
}
function Dw(e) {
  fg.call(this, e);
}
Dw.prototype = Object.assign(Object.create(fg.prototype), {
  constructor: Dw,
  isWebGL1Renderer: !0
});
function Wv(e, n) {
  this.name = "", this.color = new Wt(e), this.density = n !== void 0 ? n : 25e-5;
}
Object.assign(Wv.prototype, {
  isFogExp2: !0,
  clone: function() {
    return new Wv(this.color, this.density);
  },
  toJSON: function() {
    return {
      type: "FogExp2",
      color: this.color.getHex(),
      density: this.density
    };
  }
});
function Hv(e, n, t) {
  this.name = "", this.color = new Wt(e), this.near = n !== void 0 ? n : 1, this.far = t !== void 0 ? t : 1e3;
}
Object.assign(Hv.prototype, {
  isFog: !0,
  clone: function() {
    return new Hv(this.color, this.near, this.far);
  },
  toJSON: function() {
    return {
      type: "Fog",
      color: this.color.getHex(),
      near: this.near,
      far: this.far
    };
  }
});
function vs(e, n) {
  this.array = e, this.stride = n, this.count = e !== void 0 ? e.length / n : 0, this.usage = Ny, this.updateRange = { offset: 0, count: -1 }, this.version = 0, this.uuid = un.generateUUID();
}
Object.defineProperty(vs.prototype, "needsUpdate", {
  set: function(e) {
    e === !0 && this.version++;
  }
});
Object.assign(vs.prototype, {
  isInterleavedBuffer: !0,
  onUploadCallback: function() {
  },
  setUsage: function(e) {
    return this.usage = e, this;
  },
  copy: function(e) {
    return this.array = new e.array.constructor(e.array), this.count = e.count, this.stride = e.stride, this.usage = e.usage, this;
  },
  copyAt: function(e, n, t) {
    e *= this.stride, t *= n.stride;
    for (let i = 0, r = this.stride; i < r; i++)
      this.array[e + i] = n.array[t + i];
    return this;
  },
  set: function(e, n) {
    return n === void 0 && (n = 0), this.array.set(e, n), this;
  },
  clone: function(e) {
    e.arrayBuffers === void 0 && (e.arrayBuffers = {}), this.array.buffer._uuid === void 0 && (this.array.buffer._uuid = un.generateUUID()), e.arrayBuffers[this.array.buffer._uuid] === void 0 && (e.arrayBuffers[this.array.buffer._uuid] = this.array.slice(0).buffer);
    const n = new this.array.constructor(e.arrayBuffers[this.array.buffer._uuid]), t = new vs(n, this.stride);
    return t.setUsage(this.usage), t;
  },
  onUpload: function(e) {
    return this.onUploadCallback = e, this;
  },
  toJSON: function(e) {
    return e.arrayBuffers === void 0 && (e.arrayBuffers = {}), this.array.buffer._uuid === void 0 && (this.array.buffer._uuid = un.generateUUID()), e.arrayBuffers[this.array.buffer._uuid] === void 0 && (e.arrayBuffers[this.array.buffer._uuid] = Array.prototype.slice.call(new Uint32Array(this.array.buffer))), {
      uuid: this.uuid,
      buffer: this.array.buffer._uuid,
      type: this.array.constructor.name,
      stride: this.stride
    };
  }
});
const aa = new ve();
function va(e, n, t, i) {
  this.name = "", this.data = e, this.itemSize = n, this.offset = t, this.normalized = i === !0;
}
Object.defineProperties(va.prototype, {
  count: {
    get: function() {
      return this.data.count;
    }
  },
  array: {
    get: function() {
      return this.data.array;
    }
  },
  needsUpdate: {
    set: function(e) {
      this.data.needsUpdate = e;
    }
  }
});
Object.assign(va.prototype, {
  isInterleavedBufferAttribute: !0,
  applyMatrix4: function(e) {
    for (let n = 0, t = this.data.count; n < t; n++)
      aa.x = this.getX(n), aa.y = this.getY(n), aa.z = this.getZ(n), aa.applyMatrix4(e), this.setXYZ(n, aa.x, aa.y, aa.z);
    return this;
  },
  setX: function(e, n) {
    return this.data.array[e * this.data.stride + this.offset] = n, this;
  },
  setY: function(e, n) {
    return this.data.array[e * this.data.stride + this.offset + 1] = n, this;
  },
  setZ: function(e, n) {
    return this.data.array[e * this.data.stride + this.offset + 2] = n, this;
  },
  setW: function(e, n) {
    return this.data.array[e * this.data.stride + this.offset + 3] = n, this;
  },
  getX: function(e) {
    return this.data.array[e * this.data.stride + this.offset];
  },
  getY: function(e) {
    return this.data.array[e * this.data.stride + this.offset + 1];
  },
  getZ: function(e) {
    return this.data.array[e * this.data.stride + this.offset + 2];
  },
  getW: function(e) {
    return this.data.array[e * this.data.stride + this.offset + 3];
  },
  setXY: function(e, n, t) {
    return e = e * this.data.stride + this.offset, this.data.array[e + 0] = n, this.data.array[e + 1] = t, this;
  },
  setXYZ: function(e, n, t, i) {
    return e = e * this.data.stride + this.offset, this.data.array[e + 0] = n, this.data.array[e + 1] = t, this.data.array[e + 2] = i, this;
  },
  setXYZW: function(e, n, t, i, r) {
    return e = e * this.data.stride + this.offset, this.data.array[e + 0] = n, this.data.array[e + 1] = t, this.data.array[e + 2] = i, this.data.array[e + 3] = r, this;
  },
  clone: function(e) {
    if (e === void 0) {
      console.log("THREE.InterleavedBufferAttribute.clone(): Cloning an interlaved buffer attribute will deinterleave buffer data.");
      const n = [];
      for (let t = 0; t < this.count; t++) {
        const i = t * this.data.stride + this.offset;
        for (let r = 0; r < this.itemSize; r++)
          n.push(this.data.array[i + r]);
      }
      return new Jt(new this.array.constructor(n), this.itemSize, this.normalized);
    } else
      return e.interleavedBuffers === void 0 && (e.interleavedBuffers = {}), e.interleavedBuffers[this.data.uuid] === void 0 && (e.interleavedBuffers[this.data.uuid] = this.data.clone(e)), new va(e.interleavedBuffers[this.data.uuid], this.itemSize, this.offset, this.normalized);
  },
  toJSON: function(e) {
    if (e === void 0) {
      console.log("THREE.InterleavedBufferAttribute.toJSON(): Serializing an interlaved buffer attribute will deinterleave buffer data.");
      const n = [];
      for (let t = 0; t < this.count; t++) {
        const i = t * this.data.stride + this.offset;
        for (let r = 0; r < this.itemSize; r++)
          n.push(this.data.array[i + r]);
      }
      return {
        itemSize: this.itemSize,
        type: this.array.constructor.name,
        array: n,
        normalized: this.normalized
      };
    } else
      return e.interleavedBuffers === void 0 && (e.interleavedBuffers = {}), e.interleavedBuffers[this.data.uuid] === void 0 && (e.interleavedBuffers[this.data.uuid] = this.data.toJSON(e)), {
        isInterleavedBufferAttribute: !0,
        itemSize: this.itemSize,
        data: this.data.uuid,
        offset: this.offset,
        normalized: this.normalized
      };
  }
});
function wa(e) {
  rn.call(this), this.type = "SpriteMaterial", this.color = new Wt(16777215), this.map = null, this.alphaMap = null, this.rotation = 0, this.sizeAttenuation = !0, this.transparent = !0, this.setValues(e);
}
wa.prototype = Object.create(rn.prototype);
wa.prototype.constructor = wa;
wa.prototype.isSpriteMaterial = !0;
wa.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this.map = e.map, this.alphaMap = e.alphaMap, this.rotation = e.rotation, this.sizeAttenuation = e.sizeAttenuation, this;
};
let Vc;
const fm = new ve(), jc = new ve(), Wc = new ve(), Hc = new vt(), pm = new vt(), tb = new dn(), w_ = new ve(), mm = new ve(), x_ = new ve(), kw = new vt(), Mv = new vt(), Ow = new vt();
function qv(e) {
  if (Ft.call(this), this.type = "Sprite", Vc === void 0) {
    Vc = new Gt();
    const n = new Float32Array([
      -0.5,
      -0.5,
      0,
      0,
      0,
      0.5,
      -0.5,
      0,
      1,
      0,
      0.5,
      0.5,
      0,
      1,
      1,
      -0.5,
      0.5,
      0,
      0,
      1
    ]), t = new vs(n, 5);
    Vc.setIndex([0, 1, 2, 0, 2, 3]), Vc.setAttribute("position", new va(t, 3, 0, !1)), Vc.setAttribute("uv", new va(t, 2, 3, !1));
  }
  this.geometry = Vc, this.material = e !== void 0 ? e : new wa(), this.center = new vt(0.5, 0.5);
}
qv.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: qv,
  isSprite: !0,
  raycast: function(e, n) {
    e.camera === null && console.error('THREE.Sprite: "Raycaster.camera" needs to be set in order to raycast against sprites.'), jc.setFromMatrixScale(this.matrixWorld), tb.copy(e.camera.matrixWorld), this.modelViewMatrix.multiplyMatrices(e.camera.matrixWorldInverse, this.matrixWorld), Wc.setFromMatrixPosition(this.modelViewMatrix), e.camera.isPerspectiveCamera && this.material.sizeAttenuation === !1 && jc.multiplyScalar(-Wc.z);
    const t = this.material.rotation;
    let i, r;
    t !== 0 && (r = Math.cos(t), i = Math.sin(t));
    const a = this.center;
    b_(w_.set(-0.5, -0.5, 0), Wc, a, jc, i, r), b_(mm.set(0.5, -0.5, 0), Wc, a, jc, i, r), b_(x_.set(0.5, 0.5, 0), Wc, a, jc, i, r), kw.set(0, 0), Mv.set(1, 0), Ow.set(1, 1);
    let c = e.ray.intersectTriangle(w_, mm, x_, !1, fm);
    if (c === null && (b_(mm.set(-0.5, 0.5, 0), Wc, a, jc, i, r), Mv.set(0, 1), c = e.ray.intersectTriangle(w_, x_, mm, !1, fm), c === null))
      return;
    const u = e.ray.origin.distanceTo(fm);
    u < e.near || u > e.far || n.push({
      distance: u,
      point: fm.clone(),
      uv: Ei.getUV(fm, w_, mm, x_, kw, Mv, Ow, new vt()),
      face: null,
      object: this
    });
  },
  copy: function(e) {
    return Ft.prototype.copy.call(this, e), e.center !== void 0 && this.center.copy(e.center), this.material = e.material, this;
  }
});
function b_(e, n, t, i, r, a) {
  Hc.subVectors(e, t).addScalar(0.5).multiply(i), r !== void 0 ? (pm.x = a * Hc.x - r * Hc.y, pm.y = r * Hc.x + a * Hc.y) : pm.copy(Hc), e.copy(n), e.x += pm.x, e.y += pm.y, e.applyMatrix4(tb);
}
const M_ = new ve(), Fw = new ve();
function iy() {
  Ft.call(this), this._currentLevel = 0, this.type = "LOD", Object.defineProperties(this, {
    levels: {
      enumerable: !0,
      value: []
    }
  }), this.autoUpdate = !0;
}
iy.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: iy,
  isLOD: !0,
  copy: function(e) {
    Ft.prototype.copy.call(this, e, !1);
    const n = e.levels;
    for (let t = 0, i = n.length; t < i; t++) {
      const r = n[t];
      this.addLevel(r.object.clone(), r.distance);
    }
    return this.autoUpdate = e.autoUpdate, this;
  },
  addLevel: function(e, n) {
    n === void 0 && (n = 0), n = Math.abs(n);
    const t = this.levels;
    let i;
    for (i = 0; i < t.length && !(n < t[i].distance); i++)
      ;
    return t.splice(i, 0, { distance: n, object: e }), this.add(e), this;
  },
  getCurrentLevel: function() {
    return this._currentLevel;
  },
  getObjectForDistance: function(e) {
    const n = this.levels;
    if (n.length > 0) {
      let t, i;
      for (t = 1, i = n.length; t < i && !(e < n[t].distance); t++)
        ;
      return n[t - 1].object;
    }
    return null;
  },
  raycast: function(e, n) {
    if (this.levels.length > 0) {
      M_.setFromMatrixPosition(this.matrixWorld);
      const i = e.ray.origin.distanceTo(M_);
      this.getObjectForDistance(i).raycast(e, n);
    }
  },
  update: function(e) {
    const n = this.levels;
    if (n.length > 1) {
      M_.setFromMatrixPosition(e.matrixWorld), Fw.setFromMatrixPosition(this.matrixWorld);
      const t = M_.distanceTo(Fw) / e.zoom;
      n[0].object.visible = !0;
      let i, r;
      for (i = 1, r = n.length; i < r && t >= n[i].distance; i++)
        n[i - 1].object.visible = !1, n[i].object.visible = !0;
      for (this._currentLevel = i - 1; i < r; i++)
        n[i].object.visible = !1;
    }
  },
  toJSON: function(e) {
    const n = Ft.prototype.toJSON.call(this, e);
    this.autoUpdate === !1 && (n.object.autoUpdate = !1), n.object.levels = [];
    const t = this.levels;
    for (let i = 0, r = t.length; i < r; i++) {
      const a = t[i];
      n.object.levels.push({
        object: a.object.uuid,
        distance: a.distance
      });
    }
    return n;
  }
});
function Kv(e, n) {
  e && e.isGeometry && console.error("THREE.SkinnedMesh no longer supports THREE.Geometry. Use THREE.BufferGeometry instead."), Ln.call(this, e, n), this.type = "SkinnedMesh", this.bindMode = "attached", this.bindMatrix = new dn(), this.bindMatrixInverse = new dn();
}
Kv.prototype = Object.assign(Object.create(Ln.prototype), {
  constructor: Kv,
  isSkinnedMesh: !0,
  copy: function(e) {
    return Ln.prototype.copy.call(this, e), this.bindMode = e.bindMode, this.bindMatrix.copy(e.bindMatrix), this.bindMatrixInverse.copy(e.bindMatrixInverse), this.skeleton = e.skeleton, this;
  },
  bind: function(e, n) {
    this.skeleton = e, n === void 0 && (this.updateMatrixWorld(!0), this.skeleton.calculateInverses(), n = this.matrixWorld), this.bindMatrix.copy(n), this.bindMatrixInverse.getInverse(n);
  },
  pose: function() {
    this.skeleton.pose();
  },
  normalizeSkinWeights: function() {
    const e = new In(), n = this.geometry.attributes.skinWeight;
    for (let t = 0, i = n.count; t < i; t++) {
      e.x = n.getX(t), e.y = n.getY(t), e.z = n.getZ(t), e.w = n.getW(t);
      const r = 1 / e.manhattanLength();
      r !== 1 / 0 ? e.multiplyScalar(r) : e.set(1, 0, 0, 0), n.setXYZW(t, e.x, e.y, e.z, e.w);
    }
  },
  updateMatrixWorld: function(e) {
    Ln.prototype.updateMatrixWorld.call(this, e), this.bindMode === "attached" ? this.bindMatrixInverse.getInverse(this.matrixWorld) : this.bindMode === "detached" ? this.bindMatrixInverse.getInverse(this.bindMatrix) : console.warn("THREE.SkinnedMesh: Unrecognized bindMode: " + this.bindMode);
  },
  boneTransform: function() {
    const e = new ve(), n = new In(), t = new In(), i = new ve(), r = new dn();
    return function(a, c) {
      const u = this.skeleton, l = this.geometry;
      n.fromBufferAttribute(l.attributes.skinIndex, a), t.fromBufferAttribute(l.attributes.skinWeight, a), e.fromBufferAttribute(l.attributes.position, a).applyMatrix4(this.bindMatrix), c.set(0, 0, 0);
      for (let f = 0; f < 4; f++) {
        const m = t.getComponent(f);
        if (m !== 0) {
          const h = n.getComponent(f);
          r.multiplyMatrices(u.bones[h].matrixWorld, u.boneInverses[h]), c.addScaledVector(i.copy(e).applyMatrix4(r), m);
        }
      }
      return c.applyMatrix4(this.bindMatrixInverse);
    };
  }()
});
const Rw = new dn(), IS = new dn();
function Xv(e, n) {
  if (e = e || [], this.bones = e.slice(0), this.boneMatrices = new Float32Array(this.bones.length * 16), this.frame = -1, n === void 0)
    this.calculateInverses();
  else if (this.bones.length === n.length)
    this.boneInverses = n.slice(0);
  else {
    console.warn("THREE.Skeleton boneInverses is the wrong length."), this.boneInverses = [];
    for (let t = 0, i = this.bones.length; t < i; t++)
      this.boneInverses.push(new dn());
  }
}
Object.assign(Xv.prototype, {
  calculateInverses: function() {
    this.boneInverses = [];
    for (let e = 0, n = this.bones.length; e < n; e++) {
      const t = new dn();
      this.bones[e] && t.getInverse(this.bones[e].matrixWorld), this.boneInverses.push(t);
    }
  },
  pose: function() {
    for (let e = 0, n = this.bones.length; e < n; e++) {
      const t = this.bones[e];
      t && t.matrixWorld.getInverse(this.boneInverses[e]);
    }
    for (let e = 0, n = this.bones.length; e < n; e++) {
      const t = this.bones[e];
      t && (t.parent && t.parent.isBone ? (t.matrix.getInverse(t.parent.matrixWorld), t.matrix.multiply(t.matrixWorld)) : t.matrix.copy(t.matrixWorld), t.matrix.decompose(t.position, t.quaternion, t.scale));
    }
  },
  update: function() {
    const e = this.bones, n = this.boneInverses, t = this.boneMatrices, i = this.boneTexture;
    for (let r = 0, a = e.length; r < a; r++) {
      const c = e[r] ? e[r].matrixWorld : IS;
      Rw.multiplyMatrices(c, n[r]), Rw.toArray(t, r * 16);
    }
    i !== void 0 && (i.needsUpdate = !0);
  },
  clone: function() {
    return new Xv(this.bones, this.boneInverses);
  },
  getBoneByName: function(e) {
    for (let n = 0, t = this.bones.length; n < t; n++) {
      const i = this.bones[n];
      if (i.name === e)
        return i;
    }
  },
  dispose: function() {
    this.boneTexture && (this.boneTexture.dispose(), this.boneTexture = void 0);
  }
});
function Bw() {
  Ft.call(this), this.type = "Bone";
}
Bw.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: Bw,
  isBone: !0
});
const zw = new dn(), $w = new dn(), T_ = [], gm = new Ln();
function Yv(e, n, t) {
  Ln.call(this, e, n), this.instanceMatrix = new Jt(new Float32Array(t * 16), 16), this.count = t, this.frustumCulled = !1;
}
Yv.prototype = Object.assign(Object.create(Ln.prototype), {
  constructor: Yv,
  isInstancedMesh: !0,
  copy: function(e) {
    return Ln.prototype.copy.call(this, e), this.instanceMatrix.copy(e.instanceMatrix), this.count = e.count, this;
  },
  getMatrixAt: function(e, n) {
    n.fromArray(this.instanceMatrix.array, e * 16);
  },
  raycast: function(e, n) {
    const t = this.matrixWorld, i = this.count;
    if (gm.geometry = this.geometry, gm.material = this.material, gm.material !== void 0)
      for (let r = 0; r < i; r++) {
        this.getMatrixAt(r, zw), $w.multiplyMatrices(t, zw), gm.matrixWorld = $w, gm.raycast(e, T_);
        for (let a = 0, c = T_.length; a < c; a++) {
          const u = T_[a];
          u.instanceId = r, u.object = this, n.push(u);
        }
        T_.length = 0;
      }
  },
  setMatrixAt: function(e, n) {
    n.toArray(this.instanceMatrix.array, e * 16);
  },
  updateMorphTargets: function() {
  }
});
function Zn(e) {
  rn.call(this), this.type = "LineBasicMaterial", this.color = new Wt(16777215), this.linewidth = 1, this.linecap = "round", this.linejoin = "round", this.morphTargets = !1, this.setValues(e);
}
Zn.prototype = Object.create(rn.prototype);
Zn.prototype.constructor = Zn;
Zn.prototype.isLineBasicMaterial = !0;
Zn.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this.linewidth = e.linewidth, this.linecap = e.linecap, this.linejoin = e.linejoin, this.morphTargets = e.morphTargets, this;
};
const Nw = new ve(), Uw = new ve(), Gw = new dn(), E_ = new Au(), S_ = new Rr();
function Es(e, n, t) {
  t === 1 && console.error("THREE.Line: parameter THREE.LinePieces no longer supported. Use THREE.LineSegments instead."), Ft.call(this), this.type = "Line", this.geometry = e !== void 0 ? e : new Gt(), this.material = n !== void 0 ? n : new Zn(), this.updateMorphTargets();
}
Es.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: Es,
  isLine: !0,
  copy: function(e) {
    return Ft.prototype.copy.call(this, e), this.material = e.material, this.geometry = e.geometry, this;
  },
  computeLineDistances: function() {
    const e = this.geometry;
    if (e.isBufferGeometry)
      if (e.index === null) {
        const n = e.attributes.position, t = [0];
        for (let i = 1, r = n.count; i < r; i++)
          Nw.fromBufferAttribute(n, i - 1), Uw.fromBufferAttribute(n, i), t[i] = t[i - 1], t[i] += Nw.distanceTo(Uw);
        e.setAttribute("lineDistance", new zt(t, 1));
      } else
        console.warn("THREE.Line.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.");
    else if (e.isGeometry) {
      const n = e.vertices, t = e.lineDistances;
      t[0] = 0;
      for (let i = 1, r = n.length; i < r; i++)
        t[i] = t[i - 1], t[i] += n[i - 1].distanceTo(n[i]);
    }
    return this;
  },
  raycast: function(e, n) {
    const t = this.geometry, i = this.matrixWorld, r = e.params.Line.threshold;
    if (t.boundingSphere === null && t.computeBoundingSphere(), S_.copy(t.boundingSphere), S_.applyMatrix4(i), S_.radius += r, e.ray.intersectsSphere(S_) === !1)
      return;
    Gw.getInverse(i), E_.copy(e.ray).applyMatrix4(Gw);
    const a = r / ((this.scale.x + this.scale.y + this.scale.z) / 3), c = a * a, u = new ve(), l = new ve(), f = new ve(), m = new ve(), h = this && this.isLineSegments ? 2 : 1;
    if (t.isBufferGeometry) {
      const p = t.index, v = t.attributes.position.array;
      if (p !== null) {
        const S = p.array;
        for (let D = 0, w = S.length - 1; D < w; D += h) {
          const T = S[D], F = S[D + 1];
          if (u.fromArray(v, T * 3), l.fromArray(v, F * 3), E_.distanceSqToSegment(u, l, m, f) > c)
            continue;
          m.applyMatrix4(this.matrixWorld);
          const A = e.ray.origin.distanceTo(m);
          A < e.near || A > e.far || n.push({
            distance: A,
            // What do we want? intersection point on the ray or on the segment??
            // point: raycaster.ray.at( distance ),
            point: f.clone().applyMatrix4(this.matrixWorld),
            index: D,
            face: null,
            faceIndex: null,
            object: this
          });
        }
      } else
        for (let S = 0, D = v.length / 3 - 1; S < D; S += h) {
          if (u.fromArray(v, 3 * S), l.fromArray(v, 3 * S + 3), E_.distanceSqToSegment(u, l, m, f) > c)
            continue;
          m.applyMatrix4(this.matrixWorld);
          const T = e.ray.origin.distanceTo(m);
          T < e.near || T > e.far || n.push({
            distance: T,
            // What do we want? intersection point on the ray or on the segment??
            // point: raycaster.ray.at( distance ),
            point: f.clone().applyMatrix4(this.matrixWorld),
            index: S,
            face: null,
            faceIndex: null,
            object: this
          });
        }
    } else if (t.isGeometry) {
      const p = t.vertices, _ = p.length;
      for (let v = 0; v < _ - 1; v += h) {
        if (E_.distanceSqToSegment(p[v], p[v + 1], m, f) > c)
          continue;
        m.applyMatrix4(this.matrixWorld);
        const D = e.ray.origin.distanceTo(m);
        D < e.near || D > e.far || n.push({
          distance: D,
          // What do we want? intersection point on the ray or on the segment??
          // point: raycaster.ray.at( distance ),
          point: f.clone().applyMatrix4(this.matrixWorld),
          index: v,
          face: null,
          faceIndex: null,
          object: this
        });
      }
    }
  },
  updateMorphTargets: function() {
    const e = this.geometry;
    if (e.isBufferGeometry) {
      const n = e.morphAttributes, t = Object.keys(n);
      if (t.length > 0) {
        const i = n[t[0]];
        if (i !== void 0) {
          this.morphTargetInfluences = [], this.morphTargetDictionary = {};
          for (let r = 0, a = i.length; r < a; r++) {
            const c = i[r].name || String(r);
            this.morphTargetInfluences.push(0), this.morphTargetDictionary[c] = r;
          }
        }
      }
    } else {
      const n = e.morphTargets;
      n !== void 0 && n.length > 0 && console.error("THREE.Line.updateMorphTargets() does not support THREE.Geometry. Use THREE.BufferGeometry instead.");
    }
  }
});
const P_ = new ve(), A_ = new ve();
function ai(e, n) {
  Es.call(this, e, n), this.type = "LineSegments";
}
ai.prototype = Object.assign(Object.create(Es.prototype), {
  constructor: ai,
  isLineSegments: !0,
  computeLineDistances: function() {
    const e = this.geometry;
    if (e.isBufferGeometry)
      if (e.index === null) {
        const n = e.attributes.position, t = [];
        for (let i = 0, r = n.count; i < r; i += 2)
          P_.fromBufferAttribute(n, i), A_.fromBufferAttribute(n, i + 1), t[i] = i === 0 ? 0 : t[i - 1], t[i + 1] = t[i] + P_.distanceTo(A_);
        e.setAttribute("lineDistance", new zt(t, 1));
      } else
        console.warn("THREE.LineSegments.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.");
    else if (e.isGeometry) {
      const n = e.vertices, t = e.lineDistances;
      for (let i = 0, r = n.length; i < r; i += 2)
        P_.copy(n[i]), A_.copy(n[i + 1]), t[i] = i === 0 ? 0 : t[i - 1], t[i + 1] = t[i] + P_.distanceTo(A_);
    }
    return this;
  }
});
function Jv(e, n) {
  Es.call(this, e, n), this.type = "LineLoop";
}
Jv.prototype = Object.assign(Object.create(Es.prototype), {
  constructor: Jv,
  isLineLoop: !0
});
function mo(e) {
  rn.call(this), this.type = "PointsMaterial", this.color = new Wt(16777215), this.map = null, this.alphaMap = null, this.size = 1, this.sizeAttenuation = !0, this.morphTargets = !1, this.setValues(e);
}
mo.prototype = Object.create(rn.prototype);
mo.prototype.constructor = mo;
mo.prototype.isPointsMaterial = !0;
mo.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this.map = e.map, this.alphaMap = e.alphaMap, this.size = e.size, this.sizeAttenuation = e.sizeAttenuation, this.morphTargets = e.morphTargets, this;
};
const Vw = new dn(), Qv = new Au(), C_ = new Rr(), I_ = new ve();
function sy(e, n) {
  Ft.call(this), this.type = "Points", this.geometry = e !== void 0 ? e : new Gt(), this.material = n !== void 0 ? n : new mo(), this.updateMorphTargets();
}
sy.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: sy,
  isPoints: !0,
  copy: function(e) {
    return Ft.prototype.copy.call(this, e), this.material = e.material, this.geometry = e.geometry, this;
  },
  raycast: function(e, n) {
    const t = this.geometry, i = this.matrixWorld, r = e.params.Points.threshold;
    if (t.boundingSphere === null && t.computeBoundingSphere(), C_.copy(t.boundingSphere), C_.applyMatrix4(i), C_.radius += r, e.ray.intersectsSphere(C_) === !1)
      return;
    Vw.getInverse(i), Qv.copy(e.ray).applyMatrix4(Vw);
    const a = r / ((this.scale.x + this.scale.y + this.scale.z) / 3), c = a * a;
    if (t.isBufferGeometry) {
      const u = t.index, f = t.attributes.position.array;
      if (u !== null) {
        const m = u.array;
        for (let h = 0, p = m.length; h < p; h++) {
          const _ = m[h];
          I_.fromArray(f, _ * 3), Tv(I_, _, c, i, e, n, this);
        }
      } else
        for (let m = 0, h = f.length / 3; m < h; m++)
          I_.fromArray(f, m * 3), Tv(I_, m, c, i, e, n, this);
    } else {
      const u = t.vertices;
      for (let l = 0, f = u.length; l < f; l++)
        Tv(u[l], l, c, i, e, n, this);
    }
  },
  updateMorphTargets: function() {
    const e = this.geometry;
    if (e.isBufferGeometry) {
      const n = e.morphAttributes, t = Object.keys(n);
      if (t.length > 0) {
        const i = n[t[0]];
        if (i !== void 0) {
          this.morphTargetInfluences = [], this.morphTargetDictionary = {};
          for (let r = 0, a = i.length; r < a; r++) {
            const c = i[r].name || String(r);
            this.morphTargetInfluences.push(0), this.morphTargetDictionary[c] = r;
          }
        }
      }
    } else {
      const n = e.morphTargets;
      n !== void 0 && n.length > 0 && console.error("THREE.Points.updateMorphTargets() does not support THREE.Geometry. Use THREE.BufferGeometry instead.");
    }
  }
});
function Tv(e, n, t, i, r, a, c) {
  const u = Qv.distanceSqToPoint(e);
  if (u < t) {
    const l = new ve();
    Qv.closestPointToPoint(e, l), l.applyMatrix4(i);
    const f = r.ray.origin.distanceTo(l);
    if (f < r.near || f > r.far)
      return;
    a.push({
      distance: f,
      distanceToRay: Math.sqrt(u),
      point: l,
      index: n,
      face: null,
      object: c
    });
  }
}
function jw(e, n, t, i, r, a, c, u, l) {
  Fn.call(this, e, n, t, i, r, a, c, u, l), this.format = c !== void 0 ? c : pa, this.minFilter = a !== void 0 ? a : Li, this.magFilter = r !== void 0 ? r : Li, this.generateMipmaps = !1;
  const f = this;
  function m() {
    f.needsUpdate = !0, e.requestVideoFrameCallback(m);
  }
  "requestVideoFrameCallback" in e && e.requestVideoFrameCallback(m);
}
jw.prototype = Object.assign(Object.create(Fn.prototype), {
  constructor: jw,
  isVideoTexture: !0,
  update: function() {
    const e = this.image;
    "requestVideoFrameCallback" in e === !1 && e.readyState >= e.HAVE_CURRENT_DATA && (this.needsUpdate = !0);
  }
});
function Rm(e, n, t, i, r, a, c, u, l, f, m, h) {
  Fn.call(this, null, a, c, u, l, f, i, r, m, h), this.image = { width: n, height: t }, this.mipmaps = e, this.flipY = !1, this.generateMipmaps = !1;
}
Rm.prototype = Object.create(Fn.prototype);
Rm.prototype.constructor = Rm;
Rm.prototype.isCompressedTexture = !0;
function Bm(e, n, t, i, r, a, c, u, l) {
  Fn.call(this, e, n, t, i, r, a, c, u, l), this.needsUpdate = !0;
}
Bm.prototype = Object.create(Fn.prototype);
Bm.prototype.constructor = Bm;
Bm.prototype.isCanvasTexture = !0;
function ry(e, n, t, i, r, a, c, u, l, f) {
  if (f = f !== void 0 ? f : ru, f !== ru && f !== Pm)
    throw new Error("DepthTexture format must be either THREE.DepthFormat or THREE.DepthStencilFormat");
  t === void 0 && f === ru && (t = J_), t === void 0 && f === Pm && (t = bm), Fn.call(this, null, i, r, a, c, u, f, t, l), this.image = { width: e, height: n }, this.magFilter = c !== void 0 ? c : _i, this.minFilter = u !== void 0 ? u : _i, this.flipY = !1, this.generateMipmaps = !1;
}
ry.prototype = Object.create(Fn.prototype);
ry.prototype.constructor = ry;
ry.prototype.isDepthTexture = !0;
function oy(e) {
  Gt.call(this), this.type = "WireframeGeometry";
  const n = [], t = [0, 0], i = {}, r = ["a", "b", "c"];
  if (e && e.isGeometry) {
    const a = e.faces;
    for (let c = 0, u = a.length; c < u; c++) {
      const l = a[c];
      for (let f = 0; f < 3; f++) {
        const m = l[r[f]], h = l[r[(f + 1) % 3]];
        t[0] = Math.min(m, h), t[1] = Math.max(m, h);
        const p = t[0] + "," + t[1];
        i[p] === void 0 && (i[p] = { index1: t[0], index2: t[1] });
      }
    }
    for (const c in i) {
      const u = i[c];
      let l = e.vertices[u.index1];
      n.push(l.x, l.y, l.z), l = e.vertices[u.index2], n.push(l.x, l.y, l.z);
    }
  } else if (e && e.isBufferGeometry) {
    let a = new ve();
    if (e.index !== null) {
      const c = e.attributes.position, u = e.index;
      let l = e.groups;
      l.length === 0 && (l = [{ start: 0, count: u.count, materialIndex: 0 }]);
      for (let f = 0, m = l.length; f < m; ++f) {
        const h = l[f], p = h.start, _ = h.count;
        for (let v = p, S = p + _; v < S; v += 3)
          for (let D = 0; D < 3; D++) {
            const w = u.getX(v + D), T = u.getX(v + (D + 1) % 3);
            t[0] = Math.min(w, T), t[1] = Math.max(w, T);
            const F = t[0] + "," + t[1];
            i[F] === void 0 && (i[F] = { index1: t[0], index2: t[1] });
          }
      }
      for (const f in i) {
        const m = i[f];
        a.fromBufferAttribute(c, m.index1), n.push(a.x, a.y, a.z), a.fromBufferAttribute(c, m.index2), n.push(a.x, a.y, a.z);
      }
    } else {
      const c = e.attributes.position;
      for (let u = 0, l = c.count / 3; u < l; u++)
        for (let f = 0; f < 3; f++) {
          const m = 3 * u + f;
          a.fromBufferAttribute(c, m), n.push(a.x, a.y, a.z);
          const h = 3 * u + (f + 1) % 3;
          a.fromBufferAttribute(c, h), n.push(a.x, a.y, a.z);
        }
    }
  }
  this.setAttribute("position", new zt(n, 3));
}
oy.prototype = Object.create(Gt.prototype);
oy.prototype.constructor = oy;
function ay(e, n, t) {
  an.call(this), this.type = "ParametricGeometry", this.parameters = {
    func: e,
    slices: n,
    stacks: t
  }, this.fromBufferGeometry(new zm(e, n, t)), this.mergeVertices();
}
ay.prototype = Object.create(an.prototype);
ay.prototype.constructor = ay;
function zm(e, n, t) {
  Gt.call(this), this.type = "ParametricBufferGeometry", this.parameters = {
    func: e,
    slices: n,
    stacks: t
  };
  const i = [], r = [], a = [], c = [], u = 1e-5, l = new ve(), f = new ve(), m = new ve(), h = new ve(), p = new ve();
  e.length < 3 && console.error("THREE.ParametricGeometry: Function must now modify a Vector3 as third parameter.");
  const _ = n + 1;
  for (let v = 0; v <= t; v++) {
    const S = v / t;
    for (let D = 0; D <= n; D++) {
      const w = D / n;
      e(w, S, f), r.push(f.x, f.y, f.z), w - u >= 0 ? (e(w - u, S, m), h.subVectors(f, m)) : (e(w + u, S, m), h.subVectors(m, f)), S - u >= 0 ? (e(w, S - u, m), p.subVectors(f, m)) : (e(w, S + u, m), p.subVectors(m, f)), l.crossVectors(h, p).normalize(), a.push(l.x, l.y, l.z), c.push(w, S);
    }
  }
  for (let v = 0; v < t; v++)
    for (let S = 0; S < n; S++) {
      const D = v * _ + S, w = v * _ + S + 1, T = (v + 1) * _ + S + 1, F = (v + 1) * _ + S;
      i.push(D, w, F), i.push(w, T, F);
    }
  this.setIndex(i), this.setAttribute("position", new zt(r, 3)), this.setAttribute("normal", new zt(a, 3)), this.setAttribute("uv", new zt(c, 2));
}
zm.prototype = Object.create(Gt.prototype);
zm.prototype.constructor = zm;
function ly(e, n, t, i) {
  an.call(this), this.type = "PolyhedronGeometry", this.parameters = {
    vertices: e,
    indices: n,
    radius: t,
    detail: i
  }, this.fromBufferGeometry(new ls(e, n, t, i)), this.mergeVertices();
}
ly.prototype = Object.create(an.prototype);
ly.prototype.constructor = ly;
function ls(e, n, t, i) {
  Gt.call(this), this.type = "PolyhedronBufferGeometry", this.parameters = {
    vertices: e,
    indices: n,
    radius: t,
    detail: i
  }, t = t || 1, i = i || 0;
  const r = [], a = [];
  c(i), l(t), f(), this.setAttribute("position", new zt(r, 3)), this.setAttribute("normal", new zt(r.slice(), 3)), this.setAttribute("uv", new zt(a, 2)), i === 0 ? this.computeVertexNormals() : this.normalizeNormals();
  function c(w) {
    const T = new ve(), F = new ve(), E = new ve();
    for (let A = 0; A < n.length; A += 3)
      p(n[A + 0], T), p(n[A + 1], F), p(n[A + 2], E), u(T, F, E, w);
  }
  function u(w, T, F, E) {
    const A = Math.pow(2, E), L = [];
    for (let I = 0; I <= A; I++) {
      L[I] = [];
      const R = w.clone().lerp(F, I / A), N = T.clone().lerp(F, I / A), q = A - I;
      for (let ne = 0; ne <= q; ne++)
        ne === 0 && I === A ? L[I][ne] = R : L[I][ne] = R.clone().lerp(N, ne / q);
    }
    for (let I = 0; I < A; I++)
      for (let R = 0; R < 2 * (A - I) - 1; R++) {
        const N = Math.floor(R / 2);
        R % 2 === 0 ? (h(L[I][N + 1]), h(L[I + 1][N]), h(L[I][N])) : (h(L[I][N + 1]), h(L[I + 1][N + 1]), h(L[I + 1][N]));
      }
  }
  function l(w) {
    const T = new ve();
    for (let F = 0; F < r.length; F += 3)
      T.x = r[F + 0], T.y = r[F + 1], T.z = r[F + 2], T.normalize().multiplyScalar(w), r[F + 0] = T.x, r[F + 1] = T.y, r[F + 2] = T.z;
  }
  function f() {
    const w = new ve();
    for (let T = 0; T < r.length; T += 3) {
      w.x = r[T + 0], w.y = r[T + 1], w.z = r[T + 2];
      const F = S(w) / 2 / Math.PI + 0.5, E = D(w) / Math.PI + 0.5;
      a.push(F, 1 - E);
    }
    _(), m();
  }
  function m() {
    for (let w = 0; w < a.length; w += 6) {
      const T = a[w + 0], F = a[w + 2], E = a[w + 4], A = Math.max(T, F, E), L = Math.min(T, F, E);
      A > 0.9 && L < 0.1 && (T < 0.2 && (a[w + 0] += 1), F < 0.2 && (a[w + 2] += 1), E < 0.2 && (a[w + 4] += 1));
    }
  }
  function h(w) {
    r.push(w.x, w.y, w.z);
  }
  function p(w, T) {
    const F = w * 3;
    T.x = e[F + 0], T.y = e[F + 1], T.z = e[F + 2];
  }
  function _() {
    const w = new ve(), T = new ve(), F = new ve(), E = new ve(), A = new vt(), L = new vt(), I = new vt();
    for (let R = 0, N = 0; R < r.length; R += 9, N += 6) {
      w.set(r[R + 0], r[R + 1], r[R + 2]), T.set(r[R + 3], r[R + 4], r[R + 5]), F.set(r[R + 6], r[R + 7], r[R + 8]), A.set(a[N + 0], a[N + 1]), L.set(a[N + 2], a[N + 3]), I.set(a[N + 4], a[N + 5]), E.copy(w).add(T).add(F).divideScalar(3);
      const q = S(E);
      v(A, N + 0, w, q), v(L, N + 2, T, q), v(I, N + 4, F, q);
    }
  }
  function v(w, T, F, E) {
    E < 0 && w.x === 1 && (a[T] = w.x - 1), F.x === 0 && F.z === 0 && (a[T] = E / 2 / Math.PI + 0.5);
  }
  function S(w) {
    return Math.atan2(w.z, -w.x);
  }
  function D(w) {
    return Math.atan2(-w.y, Math.sqrt(w.x * w.x + w.z * w.z));
  }
}
ls.prototype = Object.create(Gt.prototype);
ls.prototype.constructor = ls;
function cy(e, n) {
  an.call(this), this.type = "TetrahedronGeometry", this.parameters = {
    radius: e,
    detail: n
  }, this.fromBufferGeometry(new $m(e, n)), this.mergeVertices();
}
cy.prototype = Object.create(an.prototype);
cy.prototype.constructor = cy;
function $m(e, n) {
  const t = [
    1,
    1,
    1,
    -1,
    -1,
    1,
    -1,
    1,
    -1,
    1,
    -1,
    -1
  ], i = [
    2,
    1,
    0,
    0,
    3,
    2,
    1,
    3,
    0,
    2,
    3,
    1
  ];
  ls.call(this, t, i, e, n), this.type = "TetrahedronBufferGeometry", this.parameters = {
    radius: e,
    detail: n
  };
}
$m.prototype = Object.create(ls.prototype);
$m.prototype.constructor = $m;
function uy(e, n) {
  an.call(this), this.type = "OctahedronGeometry", this.parameters = {
    radius: e,
    detail: n
  }, this.fromBufferGeometry(new du(e, n)), this.mergeVertices();
}
uy.prototype = Object.create(an.prototype);
uy.prototype.constructor = uy;
function du(e, n) {
  const t = [
    1,
    0,
    0,
    -1,
    0,
    0,
    0,
    1,
    0,
    0,
    -1,
    0,
    0,
    0,
    1,
    0,
    0,
    -1
  ], i = [
    0,
    2,
    4,
    0,
    4,
    3,
    0,
    3,
    5,
    0,
    5,
    2,
    1,
    2,
    5,
    1,
    5,
    3,
    1,
    3,
    4,
    1,
    4,
    2
  ];
  ls.call(this, t, i, e, n), this.type = "OctahedronBufferGeometry", this.parameters = {
    radius: e,
    detail: n
  };
}
du.prototype = Object.create(ls.prototype);
du.prototype.constructor = du;
function dy(e, n) {
  an.call(this), this.type = "IcosahedronGeometry", this.parameters = {
    radius: e,
    detail: n
  }, this.fromBufferGeometry(new Nm(e, n)), this.mergeVertices();
}
dy.prototype = Object.create(an.prototype);
dy.prototype.constructor = dy;
function Nm(e, n) {
  const t = (1 + Math.sqrt(5)) / 2, i = [
    -1,
    t,
    0,
    1,
    t,
    0,
    -1,
    -t,
    0,
    1,
    -t,
    0,
    0,
    -1,
    t,
    0,
    1,
    t,
    0,
    -1,
    -t,
    0,
    1,
    -t,
    t,
    0,
    -1,
    t,
    0,
    1,
    -t,
    0,
    -1,
    -t,
    0,
    1
  ], r = [
    0,
    11,
    5,
    0,
    5,
    1,
    0,
    1,
    7,
    0,
    7,
    10,
    0,
    10,
    11,
    1,
    5,
    9,
    5,
    11,
    4,
    11,
    10,
    2,
    10,
    7,
    6,
    7,
    1,
    8,
    3,
    9,
    4,
    3,
    4,
    2,
    3,
    2,
    6,
    3,
    6,
    8,
    3,
    8,
    9,
    4,
    9,
    5,
    2,
    4,
    11,
    6,
    2,
    10,
    8,
    6,
    7,
    9,
    8,
    1
  ];
  ls.call(this, i, r, e, n), this.type = "IcosahedronBufferGeometry", this.parameters = {
    radius: e,
    detail: n
  };
}
Nm.prototype = Object.create(ls.prototype);
Nm.prototype.constructor = Nm;
function hy(e, n) {
  an.call(this), this.type = "DodecahedronGeometry", this.parameters = {
    radius: e,
    detail: n
  }, this.fromBufferGeometry(new Um(e, n)), this.mergeVertices();
}
hy.prototype = Object.create(an.prototype);
hy.prototype.constructor = hy;
function Um(e, n) {
  const t = (1 + Math.sqrt(5)) / 2, i = 1 / t, r = [
    // (1, 1, 1)
    -1,
    -1,
    -1,
    -1,
    -1,
    1,
    -1,
    1,
    -1,
    -1,
    1,
    1,
    1,
    -1,
    -1,
    1,
    -1,
    1,
    1,
    1,
    -1,
    1,
    1,
    1,
    // (0, 1/, )
    0,
    -i,
    -t,
    0,
    -i,
    t,
    0,
    i,
    -t,
    0,
    i,
    t,
    // (1/, , 0)
    -i,
    -t,
    0,
    -i,
    t,
    0,
    i,
    -t,
    0,
    i,
    t,
    0,
    // (, 0, 1/)
    -t,
    0,
    -i,
    t,
    0,
    -i,
    -t,
    0,
    i,
    t,
    0,
    i
  ], a = [
    3,
    11,
    7,
    3,
    7,
    15,
    3,
    15,
    13,
    7,
    19,
    17,
    7,
    17,
    6,
    7,
    6,
    15,
    17,
    4,
    8,
    17,
    8,
    10,
    17,
    10,
    6,
    8,
    0,
    16,
    8,
    16,
    2,
    8,
    2,
    10,
    0,
    12,
    1,
    0,
    1,
    18,
    0,
    18,
    16,
    6,
    10,
    2,
    6,
    2,
    13,
    6,
    13,
    15,
    2,
    16,
    18,
    2,
    18,
    3,
    2,
    3,
    13,
    18,
    1,
    9,
    18,
    9,
    11,
    18,
    11,
    3,
    4,
    14,
    12,
    4,
    12,
    0,
    4,
    0,
    8,
    11,
    9,
    5,
    11,
    5,
    19,
    11,
    19,
    7,
    19,
    5,
    14,
    19,
    14,
    4,
    19,
    4,
    17,
    1,
    12,
    14,
    1,
    14,
    5,
    1,
    5,
    9
  ];
  ls.call(this, r, a, e, n), this.type = "DodecahedronBufferGeometry", this.parameters = {
    radius: e,
    detail: n
  };
}
Um.prototype = Object.create(ls.prototype);
Um.prototype.constructor = Um;
function fy(e, n, t, i, r, a) {
  an.call(this), this.type = "TubeGeometry", this.parameters = {
    path: e,
    tubularSegments: n,
    radius: t,
    radialSegments: i,
    closed: r
  }, a !== void 0 && console.warn("THREE.TubeGeometry: taper has been removed.");
  const c = new hu(e, n, t, i, r);
  this.tangents = c.tangents, this.normals = c.normals, this.binormals = c.binormals, this.fromBufferGeometry(c), this.mergeVertices();
}
fy.prototype = Object.create(an.prototype);
fy.prototype.constructor = fy;
function hu(e, n, t, i, r) {
  Gt.call(this), this.type = "TubeBufferGeometry", this.parameters = {
    path: e,
    tubularSegments: n,
    radius: t,
    radialSegments: i,
    closed: r
  }, n = n || 64, t = t || 1, i = i || 8, r = r || !1;
  const a = e.computeFrenetFrames(n, r);
  this.tangents = a.tangents, this.normals = a.normals, this.binormals = a.binormals;
  const c = new ve(), u = new ve(), l = new vt();
  let f = new ve();
  const m = [], h = [], p = [], _ = [];
  v(), this.setIndex(_), this.setAttribute("position", new zt(m, 3)), this.setAttribute("normal", new zt(h, 3)), this.setAttribute("uv", new zt(p, 2));
  function v() {
    for (let T = 0; T < n; T++)
      S(T);
    S(r === !1 ? n : 0), w(), D();
  }
  function S(T) {
    f = e.getPointAt(T / n, f);
    const F = a.normals[T], E = a.binormals[T];
    for (let A = 0; A <= i; A++) {
      const L = A / i * Math.PI * 2, I = Math.sin(L), R = -Math.cos(L);
      u.x = R * F.x + I * E.x, u.y = R * F.y + I * E.y, u.z = R * F.z + I * E.z, u.normalize(), h.push(u.x, u.y, u.z), c.x = f.x + t * u.x, c.y = f.y + t * u.y, c.z = f.z + t * u.z, m.push(c.x, c.y, c.z);
    }
  }
  function D() {
    for (let T = 1; T <= n; T++)
      for (let F = 1; F <= i; F++) {
        const E = (i + 1) * (T - 1) + (F - 1), A = (i + 1) * T + (F - 1), L = (i + 1) * T + F, I = (i + 1) * (T - 1) + F;
        _.push(E, A, I), _.push(A, L, I);
      }
  }
  function w() {
    for (let T = 0; T <= n; T++)
      for (let F = 0; F <= i; F++)
        l.x = T / n, l.y = F / i, p.push(l.x, l.y);
  }
}
hu.prototype = Object.create(Gt.prototype);
hu.prototype.constructor = hu;
hu.prototype.toJSON = function() {
  const e = Gt.prototype.toJSON.call(this);
  return e.path = this.parameters.path.toJSON(), e;
};
function py(e, n, t, i, r, a, c) {
  an.call(this), this.type = "TorusKnotGeometry", this.parameters = {
    radius: e,
    tube: n,
    tubularSegments: t,
    radialSegments: i,
    p: r,
    q: a
  }, c !== void 0 && console.warn("THREE.TorusKnotGeometry: heightScale has been deprecated. Use .scale( x, y, z ) instead."), this.fromBufferGeometry(new Gm(e, n, t, i, r, a)), this.mergeVertices();
}
py.prototype = Object.create(an.prototype);
py.prototype.constructor = py;
function Gm(e, n, t, i, r, a) {
  Gt.call(this), this.type = "TorusKnotBufferGeometry", this.parameters = {
    radius: e,
    tube: n,
    tubularSegments: t,
    radialSegments: i,
    p: r,
    q: a
  }, e = e || 1, n = n || 0.4, t = Math.floor(t) || 64, i = Math.floor(i) || 8, r = r || 2, a = a || 3;
  const c = [], u = [], l = [], f = [], m = new ve(), h = new ve(), p = new ve(), _ = new ve(), v = new ve(), S = new ve(), D = new ve();
  for (let T = 0; T <= t; ++T) {
    const F = T / t * r * Math.PI * 2;
    w(F, r, a, e, p), w(F + 0.01, r, a, e, _), S.subVectors(_, p), D.addVectors(_, p), v.crossVectors(S, D), D.crossVectors(v, S), v.normalize(), D.normalize();
    for (let E = 0; E <= i; ++E) {
      const A = E / i * Math.PI * 2, L = -n * Math.cos(A), I = n * Math.sin(A);
      m.x = p.x + (L * D.x + I * v.x), m.y = p.y + (L * D.y + I * v.y), m.z = p.z + (L * D.z + I * v.z), u.push(m.x, m.y, m.z), h.subVectors(m, p).normalize(), l.push(h.x, h.y, h.z), f.push(T / t), f.push(E / i);
    }
  }
  for (let T = 1; T <= t; T++)
    for (let F = 1; F <= i; F++) {
      const E = (i + 1) * (T - 1) + (F - 1), A = (i + 1) * T + (F - 1), L = (i + 1) * T + F, I = (i + 1) * (T - 1) + F;
      c.push(E, A, I), c.push(A, L, I);
    }
  this.setIndex(c), this.setAttribute("position", new zt(u, 3)), this.setAttribute("normal", new zt(l, 3)), this.setAttribute("uv", new zt(f, 2));
  function w(T, F, E, A, L) {
    const I = Math.cos(T), R = Math.sin(T), N = E / F * T, q = Math.cos(N);
    L.x = A * (2 + q) * 0.5 * I, L.y = A * (2 + q) * R * 0.5, L.z = A * Math.sin(N) * 0.5;
  }
}
Gm.prototype = Object.create(Gt.prototype);
Gm.prototype.constructor = Gm;
function my(e, n, t, i, r) {
  an.call(this), this.type = "TorusGeometry", this.parameters = {
    radius: e,
    tube: n,
    radialSegments: t,
    tubularSegments: i,
    arc: r
  }, this.fromBufferGeometry(new Vm(e, n, t, i, r)), this.mergeVertices();
}
my.prototype = Object.create(an.prototype);
my.prototype.constructor = my;
function Vm(e, n, t, i, r) {
  Gt.call(this), this.type = "TorusBufferGeometry", this.parameters = {
    radius: e,
    tube: n,
    radialSegments: t,
    tubularSegments: i,
    arc: r
  }, e = e || 1, n = n || 0.4, t = Math.floor(t) || 8, i = Math.floor(i) || 6, r = r || Math.PI * 2;
  const a = [], c = [], u = [], l = [], f = new ve(), m = new ve(), h = new ve();
  for (let p = 0; p <= t; p++)
    for (let _ = 0; _ <= i; _++) {
      const v = _ / i * r, S = p / t * Math.PI * 2;
      m.x = (e + n * Math.cos(S)) * Math.cos(v), m.y = (e + n * Math.cos(S)) * Math.sin(v), m.z = n * Math.sin(S), c.push(m.x, m.y, m.z), f.x = e * Math.cos(v), f.y = e * Math.sin(v), h.subVectors(m, f).normalize(), u.push(h.x, h.y, h.z), l.push(_ / i), l.push(p / t);
    }
  for (let p = 1; p <= t; p++)
    for (let _ = 1; _ <= i; _++) {
      const v = (i + 1) * p + _ - 1, S = (i + 1) * (p - 1) + _ - 1, D = (i + 1) * (p - 1) + _, w = (i + 1) * p + _;
      a.push(v, S, w), a.push(S, D, w);
    }
  this.setIndex(a), this.setAttribute("position", new zt(c, 3)), this.setAttribute("normal", new zt(u, 3)), this.setAttribute("uv", new zt(l, 2));
}
Vm.prototype = Object.create(Gt.prototype);
Vm.prototype.constructor = Vm;
const LS = {
  triangulate: function(e, n, t) {
    t = t || 2;
    let i = n && n.length, r = i ? n[0] * t : e.length, a = nb(e, 0, r, t, !0), c = [];
    if (!a || a.next === a.prev)
      return c;
    let u, l, f, m, h, p, _;
    if (i && (a = RS(e, n, a, t)), e.length > 80 * t) {
      u = f = e[0], l = m = e[1];
      for (let v = t; v < r; v += t)
        h = e[v], p = e[v + 1], h < u && (u = h), p < l && (l = p), h > f && (f = h), p > m && (m = p);
      _ = Math.max(f - u, m - l), _ = _ !== 0 ? 1 / _ : 0;
    }
    return jm(a, c, t, u, l, _), c;
  }
};
function nb(e, n, t, i, r) {
  let a, c;
  if (r === qS(e, n, t, i) > 0)
    for (a = n; a < t; a += i)
      c = Ww(a, e[a], e[a + 1], c);
  else
    for (a = t - i; a >= n; a -= i)
      c = Ww(a, e[a], e[a + 1], c);
  return c && Gy(c, c.next) && (Hm(c), c = c.next), c;
}
function go(e, n) {
  if (!e)
    return e;
  n || (n = e);
  let t = e, i;
  do
    if (i = !1, !t.steiner && (Gy(t, t.next) || Xn(t.prev, t, t.next) === 0)) {
      if (Hm(t), t = n = t.prev, t === t.next)
        break;
      i = !0;
    } else
      t = t.next;
  while (i || t !== n);
  return n;
}
function jm(e, n, t, i, r, a, c) {
  if (!e)
    return;
  !c && a && US(e, i, r, a);
  let u = e, l, f;
  for (; e.prev !== e.next; ) {
    if (l = e.prev, f = e.next, a ? kS(e, i, r, a) : DS(e)) {
      n.push(l.i / t), n.push(e.i / t), n.push(f.i / t), Hm(e), e = f.next, u = f.next;
      continue;
    }
    if (e = f, e === u) {
      c ? c === 1 ? (e = OS(go(e), n, t), jm(e, n, t, i, r, a, 2)) : c === 2 && FS(e, n, t, i, r, a) : jm(go(e), n, t, i, r, a, 1);
      break;
    }
  }
}
function DS(e) {
  let n = e.prev, t = e, i = e.next;
  if (Xn(n, t, i) >= 0)
    return !1;
  let r = e.next.next;
  for (; r !== e.prev; ) {
    if (nu(n.x, n.y, t.x, t.y, i.x, i.y, r.x, r.y) && Xn(r.prev, r, r.next) >= 0)
      return !1;
    r = r.next;
  }
  return !0;
}
function kS(e, n, t, i) {
  let r = e.prev, a = e, c = e.next;
  if (Xn(r, a, c) >= 0)
    return !1;
  let u = r.x < a.x ? r.x < c.x ? r.x : c.x : a.x < c.x ? a.x : c.x, l = r.y < a.y ? r.y < c.y ? r.y : c.y : a.y < c.y ? a.y : c.y, f = r.x > a.x ? r.x > c.x ? r.x : c.x : a.x > c.x ? a.x : c.x, m = r.y > a.y ? r.y > c.y ? r.y : c.y : a.y > c.y ? a.y : c.y, h = Zv(u, l, n, t, i), p = Zv(f, m, n, t, i), _ = e.prevZ, v = e.nextZ;
  for (; _ && _.z >= h && v && v.z <= p; ) {
    if (_ !== e.prev && _ !== e.next && nu(r.x, r.y, a.x, a.y, c.x, c.y, _.x, _.y) && Xn(_.prev, _, _.next) >= 0 || (_ = _.prevZ, v !== e.prev && v !== e.next && nu(r.x, r.y, a.x, a.y, c.x, c.y, v.x, v.y) && Xn(v.prev, v, v.next) >= 0))
      return !1;
    v = v.nextZ;
  }
  for (; _ && _.z >= h; ) {
    if (_ !== e.prev && _ !== e.next && nu(r.x, r.y, a.x, a.y, c.x, c.y, _.x, _.y) && Xn(_.prev, _, _.next) >= 0)
      return !1;
    _ = _.prevZ;
  }
  for (; v && v.z <= p; ) {
    if (v !== e.prev && v !== e.next && nu(r.x, r.y, a.x, a.y, c.x, c.y, v.x, v.y) && Xn(v.prev, v, v.next) >= 0)
      return !1;
    v = v.nextZ;
  }
  return !0;
}
function OS(e, n, t) {
  let i = e;
  do {
    let r = i.prev, a = i.next.next;
    !Gy(r, a) && ib(r, i, i.next, a) && Wm(r, a) && Wm(a, r) && (n.push(r.i / t), n.push(i.i / t), n.push(a.i / t), Hm(i), Hm(i.next), i = e = a), i = i.next;
  } while (i !== e);
  return go(i);
}
function FS(e, n, t, i, r, a) {
  let c = e;
  do {
    let u = c.next.next;
    for (; u !== c.prev; ) {
      if (c.i !== u.i && jS(c, u)) {
        let l = sb(c, u);
        c = go(c, c.next), l = go(l, l.next), jm(c, n, t, i, r, a), jm(l, n, t, i, r, a);
        return;
      }
      u = u.next;
    }
    c = c.next;
  } while (c !== e);
}
function RS(e, n, t, i) {
  let r = [], a, c, u, l, f;
  for (a = 0, c = n.length; a < c; a++)
    u = n[a] * i, l = a < c - 1 ? n[a + 1] * i : e.length, f = nb(e, u, l, i, !1), f === f.next && (f.steiner = !0), r.push(VS(f));
  for (r.sort(BS), a = 0; a < r.length; a++)
    zS(r[a], t), t = go(t, t.next);
  return t;
}
function BS(e, n) {
  return e.x - n.x;
}
function zS(e, n) {
  if (n = $S(e, n), n) {
    const t = sb(n, e);
    go(n, n.next), go(t, t.next);
  }
}
function $S(e, n) {
  let t = n, i = e.x, r = e.y, a = -1 / 0, c;
  do {
    if (r <= t.y && r >= t.next.y && t.next.y !== t.y) {
      let p = t.x + (r - t.y) * (t.next.x - t.x) / (t.next.y - t.y);
      if (p <= i && p > a) {
        if (a = p, p === i) {
          if (r === t.y)
            return t;
          if (r === t.next.y)
            return t.next;
        }
        c = t.x < t.next.x ? t : t.next;
      }
    }
    t = t.next;
  } while (t !== n);
  if (!c)
    return null;
  if (i === a)
    return c;
  let u = c, l = c.x, f = c.y, m = 1 / 0, h;
  t = c;
  do
    i >= t.x && t.x >= l && i !== t.x && nu(r < f ? i : a, r, l, f, r < f ? a : i, r, t.x, t.y) && (h = Math.abs(r - t.y) / (i - t.x), Wm(t, e) && (h < m || h === m && (t.x > c.x || t.x === c.x && NS(c, t))) && (c = t, m = h)), t = t.next;
  while (t !== u);
  return c;
}
function NS(e, n) {
  return Xn(e.prev, e, n.prev) < 0 && Xn(n.next, e, e.next) < 0;
}
function US(e, n, t, i) {
  let r = e;
  do
    r.z === null && (r.z = Zv(r.x, r.y, n, t, i)), r.prevZ = r.prev, r.nextZ = r.next, r = r.next;
  while (r !== e);
  r.prevZ.nextZ = null, r.prevZ = null, GS(r);
}
function GS(e) {
  let n, t, i, r, a, c, u, l, f = 1;
  do {
    for (t = e, e = null, a = null, c = 0; t; ) {
      for (c++, i = t, u = 0, n = 0; n < f && (u++, i = i.nextZ, !!i); n++)
        ;
      for (l = f; u > 0 || l > 0 && i; )
        u !== 0 && (l === 0 || !i || t.z <= i.z) ? (r = t, t = t.nextZ, u--) : (r = i, i = i.nextZ, l--), a ? a.nextZ = r : e = r, r.prevZ = a, a = r;
      t = i;
    }
    a.nextZ = null, f *= 2;
  } while (c > 1);
  return e;
}
function Zv(e, n, t, i, r) {
  return e = 32767 * (e - t) * r, n = 32767 * (n - i) * r, e = (e | e << 8) & 16711935, e = (e | e << 4) & 252645135, e = (e | e << 2) & 858993459, e = (e | e << 1) & 1431655765, n = (n | n << 8) & 16711935, n = (n | n << 4) & 252645135, n = (n | n << 2) & 858993459, n = (n | n << 1) & 1431655765, e | n << 1;
}
function VS(e) {
  let n = e, t = e;
  do
    (n.x < t.x || n.x === t.x && n.y < t.y) && (t = n), n = n.next;
  while (n !== e);
  return t;
}
function nu(e, n, t, i, r, a, c, u) {
  return (r - c) * (n - u) - (e - c) * (a - u) >= 0 && (e - c) * (i - u) - (t - c) * (n - u) >= 0 && (t - c) * (a - u) - (r - c) * (i - u) >= 0;
}
function jS(e, n) {
  return e.next.i !== n.i && e.prev.i !== n.i && !WS(e, n) && // dones't intersect other edges
  (Wm(e, n) && Wm(n, e) && HS(e, n) && // locally visible
  (Xn(e.prev, e, n.prev) || Xn(e, n.prev, n)) || // does not create opposite-facing sectors
  Gy(e, n) && Xn(e.prev, e, e.next) > 0 && Xn(n.prev, n, n.next) > 0);
}
function Xn(e, n, t) {
  return (n.y - e.y) * (t.x - n.x) - (n.x - e.x) * (t.y - n.y);
}
function Gy(e, n) {
  return e.x === n.x && e.y === n.y;
}
function ib(e, n, t, i) {
  const r = D_(Xn(e, n, t)), a = D_(Xn(e, n, i)), c = D_(Xn(t, i, e)), u = D_(Xn(t, i, n));
  return !!(r !== a && c !== u || r === 0 && L_(e, t, n) || a === 0 && L_(e, i, n) || c === 0 && L_(t, e, i) || u === 0 && L_(t, n, i));
}
function L_(e, n, t) {
  return n.x <= Math.max(e.x, t.x) && n.x >= Math.min(e.x, t.x) && n.y <= Math.max(e.y, t.y) && n.y >= Math.min(e.y, t.y);
}
function D_(e) {
  return e > 0 ? 1 : e < 0 ? -1 : 0;
}
function WS(e, n) {
  let t = e;
  do {
    if (t.i !== e.i && t.next.i !== e.i && t.i !== n.i && t.next.i !== n.i && ib(t, t.next, e, n))
      return !0;
    t = t.next;
  } while (t !== e);
  return !1;
}
function Wm(e, n) {
  return Xn(e.prev, e, e.next) < 0 ? Xn(e, n, e.next) >= 0 && Xn(e, e.prev, n) >= 0 : Xn(e, n, e.prev) < 0 || Xn(e, e.next, n) < 0;
}
function HS(e, n) {
  let t = e, i = !1, r = (e.x + n.x) / 2, a = (e.y + n.y) / 2;
  do
    t.y > a != t.next.y > a && t.next.y !== t.y && r < (t.next.x - t.x) * (a - t.y) / (t.next.y - t.y) + t.x && (i = !i), t = t.next;
  while (t !== e);
  return i;
}
function sb(e, n) {
  let t = new e0(e.i, e.x, e.y), i = new e0(n.i, n.x, n.y), r = e.next, a = n.prev;
  return e.next = n, n.prev = e, t.next = r, r.prev = t, i.next = t, t.prev = i, a.next = i, i.prev = a, i;
}
function Ww(e, n, t, i) {
  const r = new e0(e, n, t);
  return i ? (r.next = i.next, r.prev = i, i.next.prev = r, i.next = r) : (r.prev = r, r.next = r), r;
}
function Hm(e) {
  e.next.prev = e.prev, e.prev.next = e.next, e.prevZ && (e.prevZ.nextZ = e.nextZ), e.nextZ && (e.nextZ.prevZ = e.prevZ);
}
function e0(e, n, t) {
  this.i = e, this.x = n, this.y = t, this.prev = null, this.next = null, this.z = null, this.prevZ = null, this.nextZ = null, this.steiner = !1;
}
function qS(e, n, t, i) {
  let r = 0;
  for (let a = n, c = t - i; a < t; a += i)
    r += (e[c] - e[a]) * (e[a + 1] + e[c + 1]), c = a;
  return r;
}
const ho = {
  // calculate area of the contour polygon
  area: function(e) {
    const n = e.length;
    let t = 0;
    for (let i = n - 1, r = 0; r < n; i = r++)
      t += e[i].x * e[r].y - e[r].x * e[i].y;
    return t * 0.5;
  },
  isClockWise: function(e) {
    return ho.area(e) < 0;
  },
  triangulateShape: function(e, n) {
    const t = [], i = [], r = [];
    Hw(e), qw(t, e);
    let a = e.length;
    n.forEach(Hw);
    for (let u = 0; u < n.length; u++)
      i.push(a), a += n[u].length, qw(t, n[u]);
    const c = LS.triangulate(t, i);
    for (let u = 0; u < c.length; u += 3)
      r.push(c.slice(u, u + 3));
    return r;
  }
};
function Hw(e) {
  const n = e.length;
  n > 2 && e[n - 1].equals(e[0]) && e.pop();
}
function qw(e, n) {
  for (let t = 0; t < n.length; t++)
    e.push(n[t].x), e.push(n[t].y);
}
function fu(e, n) {
  an.call(this), this.type = "ExtrudeGeometry", this.parameters = {
    shapes: e,
    options: n
  }, this.fromBufferGeometry(new Lr(e, n)), this.mergeVertices();
}
fu.prototype = Object.create(an.prototype);
fu.prototype.constructor = fu;
fu.prototype.toJSON = function() {
  const e = an.prototype.toJSON.call(this), n = this.parameters.shapes, t = this.parameters.options;
  return rb(n, t, e);
};
function Lr(e, n) {
  Gt.call(this), this.type = "ExtrudeBufferGeometry", this.parameters = {
    shapes: e,
    options: n
  }, e = Array.isArray(e) ? e : [e];
  const t = this, i = [], r = [];
  for (let c = 0, u = e.length; c < u; c++) {
    const l = e[c];
    a(l);
  }
  this.setAttribute("position", new zt(i, 3)), this.setAttribute("uv", new zt(r, 2)), this.computeVertexNormals();
  function a(c) {
    const u = [], l = n.curveSegments !== void 0 ? n.curveSegments : 12, f = n.steps !== void 0 ? n.steps : 1;
    let m = n.depth !== void 0 ? n.depth : 100, h = n.bevelEnabled !== void 0 ? n.bevelEnabled : !0, p = n.bevelThickness !== void 0 ? n.bevelThickness : 6, _ = n.bevelSize !== void 0 ? n.bevelSize : p - 2, v = n.bevelOffset !== void 0 ? n.bevelOffset : 0, S = n.bevelSegments !== void 0 ? n.bevelSegments : 3;
    const D = n.extrudePath, w = n.UVGenerator !== void 0 ? n.UVGenerator : KS;
    n.amount !== void 0 && (console.warn("THREE.ExtrudeBufferGeometry: amount has been renamed to depth."), m = n.amount);
    let T, F = !1, E, A, L, I;
    D && (T = D.getSpacedPoints(f), F = !0, h = !1, E = D.computeFrenetFrames(f, !1), A = new ve(), L = new ve(), I = new ve()), h || (S = 0, p = 0, _ = 0, v = 0);
    const R = c.extractPoints(l);
    let N = R.shape;
    const q = R.holes;
    if (!ho.isClockWise(N)) {
      N = N.reverse();
      for (let ae = 0, U = q.length; ae < U; ae++) {
        const Se = q[ae];
        ho.isClockWise(Se) && (q[ae] = Se.reverse());
      }
    }
    const Q = ho.triangulateShape(N, q), W = N;
    for (let ae = 0, U = q.length; ae < U; ae++) {
      const Se = q[ae];
      N = N.concat(Se);
    }
    function te(ae, U, Se) {
      return U || console.error("THREE.ExtrudeGeometry: vec does not exist"), U.clone().multiplyScalar(Se).add(ae);
    }
    const K = N.length, pe = Q.length;
    function be(ae, U, Se) {
      let ze, Oe, Ye;
      const H = ae.x - U.x, Y = ae.y - U.y, $e = Se.x - ae.x, Ie = Se.y - ae.y, fe = H * H + Y * Y, Qe = H * Ie - Y * $e;
      if (Math.abs(Qe) > Number.EPSILON) {
        const Ne = Math.sqrt(fe), ut = Math.sqrt($e * $e + Ie * Ie), de = U.x - Y / Ne, qe = U.y + H / Ne, tt = Se.x - Ie / ut, He = Se.y + $e / ut, je = ((tt - de) * Ie - (He - qe) * $e) / (H * Ie - Y * $e);
        ze = de + H * je - ae.x, Oe = qe + Y * je - ae.y;
        const lt = ze * ze + Oe * Oe;
        if (lt <= 2)
          return new vt(ze, Oe);
        Ye = Math.sqrt(lt / 2);
      } else {
        let Ne = !1;
        H > Number.EPSILON ? $e > Number.EPSILON && (Ne = !0) : H < -Number.EPSILON ? $e < -Number.EPSILON && (Ne = !0) : Math.sign(Y) === Math.sign(Ie) && (Ne = !0), Ne ? (ze = -Y, Oe = H, Ye = Math.sqrt(fe)) : (ze = H, Oe = Y, Ye = Math.sqrt(fe / 2));
      }
      return new vt(ze / Ye, Oe / Ye);
    }
    const Ee = [];
    for (let ae = 0, U = W.length, Se = U - 1, ze = ae + 1; ae < U; ae++, Se++, ze++)
      Se === U && (Se = 0), ze === U && (ze = 0), Ee[ae] = be(W[ae], W[Se], W[ze]);
    const Ge = [];
    let _e, De = Ee.concat();
    for (let ae = 0, U = q.length; ae < U; ae++) {
      const Se = q[ae];
      _e = [];
      for (let ze = 0, Oe = Se.length, Ye = Oe - 1, H = ze + 1; ze < Oe; ze++, Ye++, H++)
        Ye === Oe && (Ye = 0), H === Oe && (H = 0), _e[ze] = be(Se[ze], Se[Ye], Se[H]);
      Ge.push(_e), De = De.concat(_e);
    }
    for (let ae = 0; ae < S; ae++) {
      const U = ae / S, Se = p * Math.cos(U * Math.PI / 2), ze = _ * Math.sin(U * Math.PI / 2) + v;
      for (let Oe = 0, Ye = W.length; Oe < Ye; Oe++) {
        const H = te(W[Oe], Ee[Oe], ze);
        xe(H.x, H.y, -Se);
      }
      for (let Oe = 0, Ye = q.length; Oe < Ye; Oe++) {
        const H = q[Oe];
        _e = Ge[Oe];
        for (let Y = 0, $e = H.length; Y < $e; Y++) {
          const Ie = te(H[Y], _e[Y], ze);
          xe(Ie.x, Ie.y, -Se);
        }
      }
    }
    const he = _ + v;
    for (let ae = 0; ae < K; ae++) {
      const U = h ? te(N[ae], De[ae], he) : N[ae];
      F ? (L.copy(E.normals[0]).multiplyScalar(U.x), A.copy(E.binormals[0]).multiplyScalar(U.y), I.copy(T[0]).add(L).add(A), xe(I.x, I.y, I.z)) : xe(U.x, U.y, 0);
    }
    for (let ae = 1; ae <= f; ae++)
      for (let U = 0; U < K; U++) {
        const Se = h ? te(N[U], De[U], he) : N[U];
        F ? (L.copy(E.normals[ae]).multiplyScalar(Se.x), A.copy(E.binormals[ae]).multiplyScalar(Se.y), I.copy(T[ae]).add(L).add(A), xe(I.x, I.y, I.z)) : xe(Se.x, Se.y, m / f * ae);
      }
    for (let ae = S - 1; ae >= 0; ae--) {
      const U = ae / S, Se = p * Math.cos(U * Math.PI / 2), ze = _ * Math.sin(U * Math.PI / 2) + v;
      for (let Oe = 0, Ye = W.length; Oe < Ye; Oe++) {
        const H = te(W[Oe], Ee[Oe], ze);
        xe(H.x, H.y, m + Se);
      }
      for (let Oe = 0, Ye = q.length; Oe < Ye; Oe++) {
        const H = q[Oe];
        _e = Ge[Oe];
        for (let Y = 0, $e = H.length; Y < $e; Y++) {
          const Ie = te(H[Y], _e[Y], ze);
          F ? xe(Ie.x, Ie.y + T[f - 1].y, T[f - 1].x + Se) : xe(Ie.x, Ie.y, m + Se);
        }
      }
    }
    Z(), me();
    function Z() {
      const ae = i.length / 3;
      if (h) {
        let U = 0, Se = K * U;
        for (let ze = 0; ze < pe; ze++) {
          const Oe = Q[ze];
          et(Oe[2] + Se, Oe[1] + Se, Oe[0] + Se);
        }
        U = f + S * 2, Se = K * U;
        for (let ze = 0; ze < pe; ze++) {
          const Oe = Q[ze];
          et(Oe[0] + Se, Oe[1] + Se, Oe[2] + Se);
        }
      } else {
        for (let U = 0; U < pe; U++) {
          const Se = Q[U];
          et(Se[2], Se[1], Se[0]);
        }
        for (let U = 0; U < pe; U++) {
          const Se = Q[U];
          et(Se[0] + K * f, Se[1] + K * f, Se[2] + K * f);
        }
      }
      t.addGroup(ae, i.length / 3 - ae, 0);
    }
    function me() {
      const ae = i.length / 3;
      let U = 0;
      we(W, U), U += W.length;
      for (let Se = 0, ze = q.length; Se < ze; Se++) {
        const Oe = q[Se];
        we(Oe, U), U += Oe.length;
      }
      t.addGroup(ae, i.length / 3 - ae, 1);
    }
    function we(ae, U) {
      let Se = ae.length;
      for (; --Se >= 0; ) {
        const ze = Se;
        let Oe = Se - 1;
        Oe < 0 && (Oe = ae.length - 1);
        for (let Ye = 0, H = f + S * 2; Ye < H; Ye++) {
          const Y = K * Ye, $e = K * (Ye + 1), Ie = U + ze + Y, fe = U + Oe + Y, Qe = U + Oe + $e, Ne = U + ze + $e;
          Ve(Ie, fe, Qe, Ne);
        }
      }
    }
    function xe(ae, U, Se) {
      u.push(ae), u.push(U), u.push(Se);
    }
    function et(ae, U, Se) {
      nt(ae), nt(U), nt(Se);
      const ze = i.length / 3, Oe = w.generateTopUV(t, i, ze - 3, ze - 2, ze - 1);
      Be(Oe[0]), Be(Oe[1]), Be(Oe[2]);
    }
    function Ve(ae, U, Se, ze) {
      nt(ae), nt(U), nt(ze), nt(U), nt(Se), nt(ze);
      const Oe = i.length / 3, Ye = w.generateSideWallUV(t, i, Oe - 6, Oe - 3, Oe - 2, Oe - 1);
      Be(Ye[0]), Be(Ye[1]), Be(Ye[3]), Be(Ye[1]), Be(Ye[2]), Be(Ye[3]);
    }
    function nt(ae) {
      i.push(u[ae * 3 + 0]), i.push(u[ae * 3 + 1]), i.push(u[ae * 3 + 2]);
    }
    function Be(ae) {
      r.push(ae.x), r.push(ae.y);
    }
  }
}
Lr.prototype = Object.create(Gt.prototype);
Lr.prototype.constructor = Lr;
Lr.prototype.toJSON = function() {
  const e = Gt.prototype.toJSON.call(this), n = this.parameters.shapes, t = this.parameters.options;
  return rb(n, t, e);
};
const KS = {
  generateTopUV: function(e, n, t, i, r) {
    const a = n[t * 3], c = n[t * 3 + 1], u = n[i * 3], l = n[i * 3 + 1], f = n[r * 3], m = n[r * 3 + 1];
    return [
      new vt(a, c),
      new vt(u, l),
      new vt(f, m)
    ];
  },
  generateSideWallUV: function(e, n, t, i, r, a) {
    const c = n[t * 3], u = n[t * 3 + 1], l = n[t * 3 + 2], f = n[i * 3], m = n[i * 3 + 1], h = n[i * 3 + 2], p = n[r * 3], _ = n[r * 3 + 1], v = n[r * 3 + 2], S = n[a * 3], D = n[a * 3 + 1], w = n[a * 3 + 2];
    return Math.abs(u - m) < 0.01 ? [
      new vt(c, 1 - l),
      new vt(f, 1 - h),
      new vt(p, 1 - v),
      new vt(S, 1 - w)
    ] : [
      new vt(u, 1 - l),
      new vt(m, 1 - h),
      new vt(_, 1 - v),
      new vt(D, 1 - w)
    ];
  }
};
function rb(e, n, t) {
  if (t.shapes = [], Array.isArray(e))
    for (let i = 0, r = e.length; i < r; i++) {
      const a = e[i];
      t.shapes.push(a.uuid);
    }
  else
    t.shapes.push(e.uuid);
  return n.extrudePath !== void 0 && (t.options.extrudePath = n.extrudePath.toJSON()), t;
}
function gy(e, n) {
  an.call(this), this.type = "TextGeometry", this.parameters = {
    text: e,
    parameters: n
  }, this.fromBufferGeometry(new qm(e, n)), this.mergeVertices();
}
gy.prototype = Object.create(an.prototype);
gy.prototype.constructor = gy;
function qm(e, n) {
  n = n || {};
  const t = n.font;
  if (!(t && t.isFont))
    return console.error("THREE.TextGeometry: font parameter is not an instance of THREE.Font."), new an();
  const i = t.generateShapes(e, n.size);
  n.depth = n.height !== void 0 ? n.height : 50, n.bevelThickness === void 0 && (n.bevelThickness = 10), n.bevelSize === void 0 && (n.bevelSize = 8), n.bevelEnabled === void 0 && (n.bevelEnabled = !1), Lr.call(this, i, n), this.type = "TextBufferGeometry";
}
qm.prototype = Object.create(Lr.prototype);
qm.prototype.constructor = qm;
function Km(e, n, t, i, r, a, c) {
  an.call(this), this.type = "SphereGeometry", this.parameters = {
    radius: e,
    widthSegments: n,
    heightSegments: t,
    phiStart: i,
    phiLength: r,
    thetaStart: a,
    thetaLength: c
  }, this.fromBufferGeometry(new pu(e, n, t, i, r, a, c)), this.mergeVertices();
}
Km.prototype = Object.create(an.prototype);
Km.prototype.constructor = Km;
function pu(e, n, t, i, r, a, c) {
  Gt.call(this), this.type = "SphereBufferGeometry", this.parameters = {
    radius: e,
    widthSegments: n,
    heightSegments: t,
    phiStart: i,
    phiLength: r,
    thetaStart: a,
    thetaLength: c
  }, e = e || 1, n = Math.max(3, Math.floor(n) || 8), t = Math.max(2, Math.floor(t) || 6), i = i !== void 0 ? i : 0, r = r !== void 0 ? r : Math.PI * 2, a = a !== void 0 ? a : 0, c = c !== void 0 ? c : Math.PI;
  const u = Math.min(a + c, Math.PI);
  let l = 0;
  const f = [], m = new ve(), h = new ve(), p = [], _ = [], v = [], S = [];
  for (let D = 0; D <= t; D++) {
    const w = [], T = D / t;
    let F = 0;
    D == 0 && a == 0 ? F = 0.5 / n : D == t && u == Math.PI && (F = -0.5 / n);
    for (let E = 0; E <= n; E++) {
      const A = E / n;
      m.x = -e * Math.cos(i + A * r) * Math.sin(a + T * c), m.y = e * Math.cos(a + T * c), m.z = e * Math.sin(i + A * r) * Math.sin(a + T * c), _.push(m.x, m.y, m.z), h.copy(m).normalize(), v.push(h.x, h.y, h.z), S.push(A + F, 1 - T), w.push(l++);
    }
    f.push(w);
  }
  for (let D = 0; D < t; D++)
    for (let w = 0; w < n; w++) {
      const T = f[D][w + 1], F = f[D][w], E = f[D + 1][w], A = f[D + 1][w + 1];
      (D !== 0 || a > 0) && p.push(T, F, A), (D !== t - 1 || u < Math.PI) && p.push(F, E, A);
    }
  this.setIndex(p), this.setAttribute("position", new zt(_, 3)), this.setAttribute("normal", new zt(v, 3)), this.setAttribute("uv", new zt(S, 2));
}
pu.prototype = Object.create(Gt.prototype);
pu.prototype.constructor = pu;
function _y(e, n, t, i, r, a) {
  an.call(this), this.type = "RingGeometry", this.parameters = {
    innerRadius: e,
    outerRadius: n,
    thetaSegments: t,
    phiSegments: i,
    thetaStart: r,
    thetaLength: a
  }, this.fromBufferGeometry(new Xm(e, n, t, i, r, a)), this.mergeVertices();
}
_y.prototype = Object.create(an.prototype);
_y.prototype.constructor = _y;
function Xm(e, n, t, i, r, a) {
  Gt.call(this), this.type = "RingBufferGeometry", this.parameters = {
    innerRadius: e,
    outerRadius: n,
    thetaSegments: t,
    phiSegments: i,
    thetaStart: r,
    thetaLength: a
  }, e = e || 0.5, n = n || 1, r = r !== void 0 ? r : 0, a = a !== void 0 ? a : Math.PI * 2, t = t !== void 0 ? Math.max(3, t) : 8, i = i !== void 0 ? Math.max(1, i) : 1;
  const c = [], u = [], l = [], f = [];
  let m = e;
  const h = (n - e) / i, p = new ve(), _ = new vt();
  for (let v = 0; v <= i; v++) {
    for (let S = 0; S <= t; S++) {
      const D = r + S / t * a;
      p.x = m * Math.cos(D), p.y = m * Math.sin(D), u.push(p.x, p.y, p.z), l.push(0, 0, 1), _.x = (p.x / n + 1) / 2, _.y = (p.y / n + 1) / 2, f.push(_.x, _.y);
    }
    m += h;
  }
  for (let v = 0; v < i; v++) {
    const S = v * (t + 1);
    for (let D = 0; D < t; D++) {
      const w = D + S, T = w, F = w + t + 1, E = w + t + 2, A = w + 1;
      c.push(T, F, A), c.push(F, E, A);
    }
  }
  this.setIndex(c), this.setAttribute("position", new zt(u, 3)), this.setAttribute("normal", new zt(l, 3)), this.setAttribute("uv", new zt(f, 2));
}
Xm.prototype = Object.create(Gt.prototype);
Xm.prototype.constructor = Xm;
function yy(e, n, t, i) {
  an.call(this), this.type = "LatheGeometry", this.parameters = {
    points: e,
    segments: n,
    phiStart: t,
    phiLength: i
  }, this.fromBufferGeometry(new Ym(e, n, t, i)), this.mergeVertices();
}
yy.prototype = Object.create(an.prototype);
yy.prototype.constructor = yy;
function Ym(e, n, t, i) {
  Gt.call(this), this.type = "LatheBufferGeometry", this.parameters = {
    points: e,
    segments: n,
    phiStart: t,
    phiLength: i
  }, n = Math.floor(n) || 12, t = t || 0, i = i || Math.PI * 2, i = un.clamp(i, 0, Math.PI * 2);
  const r = [], a = [], c = [], u = 1 / n, l = new ve(), f = new vt();
  for (let m = 0; m <= n; m++) {
    const h = t + m * u * i, p = Math.sin(h), _ = Math.cos(h);
    for (let v = 0; v <= e.length - 1; v++)
      l.x = e[v].x * p, l.y = e[v].y, l.z = e[v].x * _, a.push(l.x, l.y, l.z), f.x = m / n, f.y = v / (e.length - 1), c.push(f.x, f.y);
  }
  for (let m = 0; m < n; m++)
    for (let h = 0; h < e.length - 1; h++) {
      const p = h + m * e.length, _ = p, v = p + e.length, S = p + e.length + 1, D = p + 1;
      r.push(_, v, D), r.push(v, S, D);
    }
  if (this.setIndex(r), this.setAttribute("position", new zt(a, 3)), this.setAttribute("uv", new zt(c, 2)), this.computeVertexNormals(), i === Math.PI * 2) {
    const m = this.attributes.normal.array, h = new ve(), p = new ve(), _ = new ve(), v = n * e.length * 3;
    for (let S = 0, D = 0; S < e.length; S++, D += 3)
      h.x = m[D + 0], h.y = m[D + 1], h.z = m[D + 2], p.x = m[v + D + 0], p.y = m[v + D + 1], p.z = m[v + D + 2], _.addVectors(h, p).normalize(), m[D + 0] = m[v + D + 0] = _.x, m[D + 1] = m[v + D + 1] = _.y, m[D + 2] = m[v + D + 2] = _.z;
  }
}
Ym.prototype = Object.create(Gt.prototype);
Ym.prototype.constructor = Ym;
function mu(e, n) {
  an.call(this), this.type = "ShapeGeometry", typeof n == "object" && (console.warn("THREE.ShapeGeometry: Options parameter has been removed."), n = n.curveSegments), this.parameters = {
    shapes: e,
    curveSegments: n
  }, this.fromBufferGeometry(new gu(e, n)), this.mergeVertices();
}
mu.prototype = Object.create(an.prototype);
mu.prototype.constructor = mu;
mu.prototype.toJSON = function() {
  const e = an.prototype.toJSON.call(this), n = this.parameters.shapes;
  return ob(n, e);
};
function gu(e, n) {
  Gt.call(this), this.type = "ShapeBufferGeometry", this.parameters = {
    shapes: e,
    curveSegments: n
  }, n = n || 12;
  const t = [], i = [], r = [], a = [];
  let c = 0, u = 0;
  if (Array.isArray(e) === !1)
    l(e);
  else
    for (let f = 0; f < e.length; f++)
      l(e[f]), this.addGroup(c, u, f), c += u, u = 0;
  this.setIndex(t), this.setAttribute("position", new zt(i, 3)), this.setAttribute("normal", new zt(r, 3)), this.setAttribute("uv", new zt(a, 2));
  function l(f) {
    const m = i.length / 3, h = f.extractPoints(n);
    let p = h.shape;
    const _ = h.holes;
    ho.isClockWise(p) === !1 && (p = p.reverse());
    for (let S = 0, D = _.length; S < D; S++) {
      const w = _[S];
      ho.isClockWise(w) === !0 && (_[S] = w.reverse());
    }
    const v = ho.triangulateShape(p, _);
    for (let S = 0, D = _.length; S < D; S++) {
      const w = _[S];
      p = p.concat(w);
    }
    for (let S = 0, D = p.length; S < D; S++) {
      const w = p[S];
      i.push(w.x, w.y, 0), r.push(0, 0, 1), a.push(w.x, w.y);
    }
    for (let S = 0, D = v.length; S < D; S++) {
      const w = v[S], T = w[0] + m, F = w[1] + m, E = w[2] + m;
      t.push(T, F, E), u += 3;
    }
  }
}
gu.prototype = Object.create(Gt.prototype);
gu.prototype.constructor = gu;
gu.prototype.toJSON = function() {
  const e = Gt.prototype.toJSON.call(this), n = this.parameters.shapes;
  return ob(n, e);
};
function ob(e, n) {
  if (n.shapes = [], Array.isArray(e))
    for (let t = 0, i = e.length; t < i; t++) {
      const r = e[t];
      n.shapes.push(r.uuid);
    }
  else
    n.shapes.push(e.uuid);
  return n;
}
function vy(e, n) {
  Gt.call(this), this.type = "EdgesGeometry", this.parameters = {
    thresholdAngle: n
  }, n = n !== void 0 ? n : 1;
  const t = [], i = Math.cos(un.DEG2RAD * n), r = [0, 0], a = {};
  let c, u, l;
  const f = ["a", "b", "c"];
  let m;
  e.isBufferGeometry ? (m = new an(), m.fromBufferGeometry(e)) : m = e.clone(), m.mergeVertices(), m.computeFaceNormals();
  const h = m.vertices, p = m.faces;
  for (let _ = 0, v = p.length; _ < v; _++) {
    const S = p[_];
    for (let D = 0; D < 3; D++)
      c = S[f[D]], u = S[f[(D + 1) % 3]], r[0] = Math.min(c, u), r[1] = Math.max(c, u), l = r[0] + "," + r[1], a[l] === void 0 ? a[l] = { index1: r[0], index2: r[1], face1: _, face2: void 0 } : a[l].face2 = _;
  }
  for (l in a) {
    const _ = a[l];
    if (_.face2 === void 0 || p[_.face1].normal.dot(p[_.face2].normal) <= i) {
      let v = h[_.index1];
      t.push(v.x, v.y, v.z), v = h[_.index2], t.push(v.x, v.y, v.z);
    }
  }
  this.setAttribute("position", new zt(t, 3));
}
vy.prototype = Object.create(Gt.prototype);
vy.prototype.constructor = vy;
function _u(e, n, t, i, r, a, c, u) {
  an.call(this), this.type = "CylinderGeometry", this.parameters = {
    radiusTop: e,
    radiusBottom: n,
    height: t,
    radialSegments: i,
    heightSegments: r,
    openEnded: a,
    thetaStart: c,
    thetaLength: u
  }, this.fromBufferGeometry(new _o(e, n, t, i, r, a, c, u)), this.mergeVertices();
}
_u.prototype = Object.create(an.prototype);
_u.prototype.constructor = _u;
function _o(e, n, t, i, r, a, c, u) {
  Gt.call(this), this.type = "CylinderBufferGeometry", this.parameters = {
    radiusTop: e,
    radiusBottom: n,
    height: t,
    radialSegments: i,
    heightSegments: r,
    openEnded: a,
    thetaStart: c,
    thetaLength: u
  };
  const l = this;
  e = e !== void 0 ? e : 1, n = n !== void 0 ? n : 1, t = t || 1, i = Math.floor(i) || 8, r = Math.floor(r) || 1, a = a !== void 0 ? a : !1, c = c !== void 0 ? c : 0, u = u !== void 0 ? u : Math.PI * 2;
  const f = [], m = [], h = [], p = [];
  let _ = 0;
  const v = [], S = t / 2;
  let D = 0;
  w(), a === !1 && (e > 0 && T(!0), n > 0 && T(!1)), this.setIndex(f), this.setAttribute("position", new zt(m, 3)), this.setAttribute("normal", new zt(h, 3)), this.setAttribute("uv", new zt(p, 2));
  function w() {
    const F = new ve(), E = new ve();
    let A = 0;
    const L = (n - e) / t;
    for (let I = 0; I <= r; I++) {
      const R = [], N = I / r, q = N * (n - e) + e;
      for (let ne = 0; ne <= i; ne++) {
        const Q = ne / i, W = Q * u + c, te = Math.sin(W), K = Math.cos(W);
        E.x = q * te, E.y = -N * t + S, E.z = q * K, m.push(E.x, E.y, E.z), F.set(te, L, K).normalize(), h.push(F.x, F.y, F.z), p.push(Q, 1 - N), R.push(_++);
      }
      v.push(R);
    }
    for (let I = 0; I < i; I++)
      for (let R = 0; R < r; R++) {
        const N = v[R][I], q = v[R + 1][I], ne = v[R + 1][I + 1], Q = v[R][I + 1];
        f.push(N, q, Q), f.push(q, ne, Q), A += 6;
      }
    l.addGroup(D, A, 0), D += A;
  }
  function T(F) {
    let E, A;
    const L = new vt(), I = new ve();
    let R = 0;
    const N = F === !0 ? e : n, q = F === !0 ? 1 : -1;
    E = _;
    for (let ne = 1; ne <= i; ne++)
      m.push(0, S * q, 0), h.push(0, q, 0), p.push(0.5, 0.5), _++;
    A = _;
    for (let ne = 0; ne <= i; ne++) {
      const W = ne / i * u + c, te = Math.cos(W), K = Math.sin(W);
      I.x = N * K, I.y = S * q, I.z = N * te, m.push(I.x, I.y, I.z), h.push(0, q, 0), L.x = te * 0.5 + 0.5, L.y = K * 0.5 * q + 0.5, p.push(L.x, L.y), _++;
    }
    for (let ne = 0; ne < i; ne++) {
      const Q = E + ne, W = A + ne;
      F === !0 ? f.push(W, W + 1, Q) : f.push(W + 1, W, Q), R += 3;
    }
    l.addGroup(D, R, F === !0 ? 1 : 2), D += R;
  }
}
_o.prototype = Object.create(Gt.prototype);
_o.prototype.constructor = _o;
function wy(e, n, t, i, r, a, c) {
  _u.call(this, 0, e, n, t, i, r, a, c), this.type = "ConeGeometry", this.parameters = {
    radius: e,
    height: n,
    radialSegments: t,
    heightSegments: i,
    openEnded: r,
    thetaStart: a,
    thetaLength: c
  };
}
wy.prototype = Object.create(_u.prototype);
wy.prototype.constructor = wy;
function xy(e, n, t, i, r, a, c) {
  _o.call(this, 0, e, n, t, i, r, a, c), this.type = "ConeBufferGeometry", this.parameters = {
    radius: e,
    height: n,
    radialSegments: t,
    heightSegments: i,
    openEnded: r,
    thetaStart: a,
    thetaLength: c
  };
}
xy.prototype = Object.create(_o.prototype);
xy.prototype.constructor = xy;
function by(e, n, t, i) {
  an.call(this), this.type = "CircleGeometry", this.parameters = {
    radius: e,
    segments: n,
    thetaStart: t,
    thetaLength: i
  }, this.fromBufferGeometry(new Jm(e, n, t, i)), this.mergeVertices();
}
by.prototype = Object.create(an.prototype);
by.prototype.constructor = by;
function Jm(e, n, t, i) {
  Gt.call(this), this.type = "CircleBufferGeometry", this.parameters = {
    radius: e,
    segments: n,
    thetaStart: t,
    thetaLength: i
  }, e = e || 1, n = n !== void 0 ? Math.max(3, n) : 8, t = t !== void 0 ? t : 0, i = i !== void 0 ? i : Math.PI * 2;
  const r = [], a = [], c = [], u = [], l = new ve(), f = new vt();
  a.push(0, 0, 0), c.push(0, 0, 1), u.push(0.5, 0.5);
  for (let m = 0, h = 3; m <= n; m++, h += 3) {
    const p = t + m / n * i;
    l.x = e * Math.cos(p), l.y = e * Math.sin(p), a.push(l.x, l.y, l.z), c.push(0, 0, 1), f.x = (a[h] / e + 1) / 2, f.y = (a[h + 1] / e + 1) / 2, u.push(f.x, f.y);
  }
  for (let m = 1; m <= n; m++)
    r.push(m, m + 1, 0);
  this.setIndex(r), this.setAttribute("position", new zt(a, 3)), this.setAttribute("normal", new zt(c, 3)), this.setAttribute("uv", new zt(u, 2));
}
Jm.prototype = Object.create(Gt.prototype);
Jm.prototype.constructor = Jm;
var Ri = /* @__PURE__ */ Object.freeze({
  __proto__: null,
  WireframeGeometry: oy,
  ParametricGeometry: ay,
  ParametricBufferGeometry: zm,
  TetrahedronGeometry: cy,
  TetrahedronBufferGeometry: $m,
  OctahedronGeometry: uy,
  OctahedronBufferGeometry: du,
  IcosahedronGeometry: dy,
  IcosahedronBufferGeometry: Nm,
  DodecahedronGeometry: hy,
  DodecahedronBufferGeometry: Um,
  PolyhedronGeometry: ly,
  PolyhedronBufferGeometry: ls,
  TubeGeometry: fy,
  TubeBufferGeometry: hu,
  TorusKnotGeometry: py,
  TorusKnotBufferGeometry: Gm,
  TorusGeometry: my,
  TorusBufferGeometry: Vm,
  TextGeometry: gy,
  TextBufferGeometry: qm,
  SphereGeometry: Km,
  SphereBufferGeometry: pu,
  RingGeometry: _y,
  RingBufferGeometry: Xm,
  PlaneGeometry: ny,
  PlaneBufferGeometry: uu,
  LatheGeometry: yy,
  LatheBufferGeometry: Ym,
  ShapeGeometry: mu,
  ShapeBufferGeometry: gu,
  ExtrudeGeometry: fu,
  ExtrudeBufferGeometry: Lr,
  EdgesGeometry: vy,
  ConeGeometry: wy,
  ConeBufferGeometry: xy,
  CylinderGeometry: _u,
  CylinderBufferGeometry: _o,
  CircleGeometry: by,
  CircleBufferGeometry: Jm,
  BoxGeometry: I1,
  BoxBufferGeometry: Uy
});
function yu(e) {
  rn.call(this), this.type = "ShadowMaterial", this.color = new Wt(0), this.transparent = !0, this.setValues(e);
}
yu.prototype = Object.create(rn.prototype);
yu.prototype.constructor = yu;
yu.prototype.isShadowMaterial = !0;
yu.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this;
};
function yo(e) {
  Xi.call(this, e), this.type = "RawShaderMaterial";
}
yo.prototype = Object.create(Xi.prototype);
yo.prototype.constructor = yo;
yo.prototype.isRawShaderMaterial = !0;
function Vs(e) {
  rn.call(this), this.defines = { STANDARD: "" }, this.type = "MeshStandardMaterial", this.color = new Wt(16777215), this.roughness = 1, this.metalness = 0, this.map = null, this.lightMap = null, this.lightMapIntensity = 1, this.aoMap = null, this.aoMapIntensity = 1, this.emissive = new Wt(0), this.emissiveIntensity = 1, this.emissiveMap = null, this.bumpMap = null, this.bumpScale = 1, this.normalMap = null, this.normalMapType = Su, this.normalScale = new vt(1, 1), this.displacementMap = null, this.displacementScale = 1, this.displacementBias = 0, this.roughnessMap = null, this.metalnessMap = null, this.alphaMap = null, this.envMap = null, this.envMapIntensity = 1, this.refractionRatio = 0.98, this.wireframe = !1, this.wireframeLinewidth = 1, this.wireframeLinecap = "round", this.wireframeLinejoin = "round", this.skinning = !1, this.morphTargets = !1, this.morphNormals = !1, this.vertexTangents = !1, this.setValues(e);
}
Vs.prototype = Object.create(rn.prototype);
Vs.prototype.constructor = Vs;
Vs.prototype.isMeshStandardMaterial = !0;
Vs.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.defines = { STANDARD: "" }, this.color.copy(e.color), this.roughness = e.roughness, this.metalness = e.metalness, this.map = e.map, this.lightMap = e.lightMap, this.lightMapIntensity = e.lightMapIntensity, this.aoMap = e.aoMap, this.aoMapIntensity = e.aoMapIntensity, this.emissive.copy(e.emissive), this.emissiveMap = e.emissiveMap, this.emissiveIntensity = e.emissiveIntensity, this.bumpMap = e.bumpMap, this.bumpScale = e.bumpScale, this.normalMap = e.normalMap, this.normalMapType = e.normalMapType, this.normalScale.copy(e.normalScale), this.displacementMap = e.displacementMap, this.displacementScale = e.displacementScale, this.displacementBias = e.displacementBias, this.roughnessMap = e.roughnessMap, this.metalnessMap = e.metalnessMap, this.alphaMap = e.alphaMap, this.envMap = e.envMap, this.envMapIntensity = e.envMapIntensity, this.refractionRatio = e.refractionRatio, this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this.wireframeLinecap = e.wireframeLinecap, this.wireframeLinejoin = e.wireframeLinejoin, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.morphNormals = e.morphNormals, this.vertexTangents = e.vertexTangents, this;
};
function xa(e) {
  Vs.call(this), this.defines = {
    STANDARD: "",
    PHYSICAL: ""
  }, this.type = "MeshPhysicalMaterial", this.clearcoat = 0, this.clearcoatMap = null, this.clearcoatRoughness = 0, this.clearcoatRoughnessMap = null, this.clearcoatNormalScale = new vt(1, 1), this.clearcoatNormalMap = null, this.reflectivity = 0.5, this.sheen = null, this.transmission = 0, this.transmissionMap = null, this.setValues(e);
}
xa.prototype = Object.create(Vs.prototype);
xa.prototype.constructor = xa;
xa.prototype.isMeshPhysicalMaterial = !0;
xa.prototype.copy = function(e) {
  return Vs.prototype.copy.call(this, e), this.defines = {
    STANDARD: "",
    PHYSICAL: ""
  }, this.clearcoat = e.clearcoat, this.clearcoatMap = e.clearcoatMap, this.clearcoatRoughness = e.clearcoatRoughness, this.clearcoatRoughnessMap = e.clearcoatRoughnessMap, this.clearcoatNormalMap = e.clearcoatNormalMap, this.clearcoatNormalScale.copy(e.clearcoatNormalScale), this.reflectivity = e.reflectivity, e.sheen ? this.sheen = (this.sheen || new Wt()).copy(e.sheen) : this.sheen = null, this.transmission = e.transmission, this.transmissionMap = e.transmissionMap, this;
};
function ba(e) {
  rn.call(this), this.type = "MeshPhongMaterial", this.color = new Wt(16777215), this.specular = new Wt(1118481), this.shininess = 30, this.map = null, this.lightMap = null, this.lightMapIntensity = 1, this.aoMap = null, this.aoMapIntensity = 1, this.emissive = new Wt(0), this.emissiveIntensity = 1, this.emissiveMap = null, this.bumpMap = null, this.bumpScale = 1, this.normalMap = null, this.normalMapType = Su, this.normalScale = new vt(1, 1), this.displacementMap = null, this.displacementScale = 1, this.displacementBias = 0, this.specularMap = null, this.alphaMap = null, this.envMap = null, this.combine = Ry, this.reflectivity = 1, this.refractionRatio = 0.98, this.wireframe = !1, this.wireframeLinewidth = 1, this.wireframeLinecap = "round", this.wireframeLinejoin = "round", this.skinning = !1, this.morphTargets = !1, this.morphNormals = !1, this.setValues(e);
}
ba.prototype = Object.create(rn.prototype);
ba.prototype.constructor = ba;
ba.prototype.isMeshPhongMaterial = !0;
ba.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this.specular.copy(e.specular), this.shininess = e.shininess, this.map = e.map, this.lightMap = e.lightMap, this.lightMapIntensity = e.lightMapIntensity, this.aoMap = e.aoMap, this.aoMapIntensity = e.aoMapIntensity, this.emissive.copy(e.emissive), this.emissiveMap = e.emissiveMap, this.emissiveIntensity = e.emissiveIntensity, this.bumpMap = e.bumpMap, this.bumpScale = e.bumpScale, this.normalMap = e.normalMap, this.normalMapType = e.normalMapType, this.normalScale.copy(e.normalScale), this.displacementMap = e.displacementMap, this.displacementScale = e.displacementScale, this.displacementBias = e.displacementBias, this.specularMap = e.specularMap, this.alphaMap = e.alphaMap, this.envMap = e.envMap, this.combine = e.combine, this.reflectivity = e.reflectivity, this.refractionRatio = e.refractionRatio, this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this.wireframeLinecap = e.wireframeLinecap, this.wireframeLinejoin = e.wireframeLinejoin, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.morphNormals = e.morphNormals, this;
};
function vu(e) {
  rn.call(this), this.defines = { TOON: "" }, this.type = "MeshToonMaterial", this.color = new Wt(16777215), this.map = null, this.gradientMap = null, this.lightMap = null, this.lightMapIntensity = 1, this.aoMap = null, this.aoMapIntensity = 1, this.emissive = new Wt(0), this.emissiveIntensity = 1, this.emissiveMap = null, this.bumpMap = null, this.bumpScale = 1, this.normalMap = null, this.normalMapType = Su, this.normalScale = new vt(1, 1), this.displacementMap = null, this.displacementScale = 1, this.displacementBias = 0, this.alphaMap = null, this.wireframe = !1, this.wireframeLinewidth = 1, this.wireframeLinecap = "round", this.wireframeLinejoin = "round", this.skinning = !1, this.morphTargets = !1, this.morphNormals = !1, this.setValues(e);
}
vu.prototype = Object.create(rn.prototype);
vu.prototype.constructor = vu;
vu.prototype.isMeshToonMaterial = !0;
vu.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this.map = e.map, this.gradientMap = e.gradientMap, this.lightMap = e.lightMap, this.lightMapIntensity = e.lightMapIntensity, this.aoMap = e.aoMap, this.aoMapIntensity = e.aoMapIntensity, this.emissive.copy(e.emissive), this.emissiveMap = e.emissiveMap, this.emissiveIntensity = e.emissiveIntensity, this.bumpMap = e.bumpMap, this.bumpScale = e.bumpScale, this.normalMap = e.normalMap, this.normalMapType = e.normalMapType, this.normalScale.copy(e.normalScale), this.displacementMap = e.displacementMap, this.displacementScale = e.displacementScale, this.displacementBias = e.displacementBias, this.alphaMap = e.alphaMap, this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this.wireframeLinecap = e.wireframeLinecap, this.wireframeLinejoin = e.wireframeLinejoin, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.morphNormals = e.morphNormals, this;
};
function wu(e) {
  rn.call(this), this.type = "MeshNormalMaterial", this.bumpMap = null, this.bumpScale = 1, this.normalMap = null, this.normalMapType = Su, this.normalScale = new vt(1, 1), this.displacementMap = null, this.displacementScale = 1, this.displacementBias = 0, this.wireframe = !1, this.wireframeLinewidth = 1, this.fog = !1, this.skinning = !1, this.morphTargets = !1, this.morphNormals = !1, this.setValues(e);
}
wu.prototype = Object.create(rn.prototype);
wu.prototype.constructor = wu;
wu.prototype.isMeshNormalMaterial = !0;
wu.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.bumpMap = e.bumpMap, this.bumpScale = e.bumpScale, this.normalMap = e.normalMap, this.normalMapType = e.normalMapType, this.normalScale.copy(e.normalScale), this.displacementMap = e.displacementMap, this.displacementScale = e.displacementScale, this.displacementBias = e.displacementBias, this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.morphNormals = e.morphNormals, this;
};
function xu(e) {
  rn.call(this), this.type = "MeshLambertMaterial", this.color = new Wt(16777215), this.map = null, this.lightMap = null, this.lightMapIntensity = 1, this.aoMap = null, this.aoMapIntensity = 1, this.emissive = new Wt(0), this.emissiveIntensity = 1, this.emissiveMap = null, this.specularMap = null, this.alphaMap = null, this.envMap = null, this.combine = Ry, this.reflectivity = 1, this.refractionRatio = 0.98, this.wireframe = !1, this.wireframeLinewidth = 1, this.wireframeLinecap = "round", this.wireframeLinejoin = "round", this.skinning = !1, this.morphTargets = !1, this.morphNormals = !1, this.setValues(e);
}
xu.prototype = Object.create(rn.prototype);
xu.prototype.constructor = xu;
xu.prototype.isMeshLambertMaterial = !0;
xu.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.color.copy(e.color), this.map = e.map, this.lightMap = e.lightMap, this.lightMapIntensity = e.lightMapIntensity, this.aoMap = e.aoMap, this.aoMapIntensity = e.aoMapIntensity, this.emissive.copy(e.emissive), this.emissiveMap = e.emissiveMap, this.emissiveIntensity = e.emissiveIntensity, this.specularMap = e.specularMap, this.alphaMap = e.alphaMap, this.envMap = e.envMap, this.combine = e.combine, this.reflectivity = e.reflectivity, this.refractionRatio = e.refractionRatio, this.wireframe = e.wireframe, this.wireframeLinewidth = e.wireframeLinewidth, this.wireframeLinecap = e.wireframeLinecap, this.wireframeLinejoin = e.wireframeLinejoin, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.morphNormals = e.morphNormals, this;
};
function bu(e) {
  rn.call(this), this.defines = { MATCAP: "" }, this.type = "MeshMatcapMaterial", this.color = new Wt(16777215), this.matcap = null, this.map = null, this.bumpMap = null, this.bumpScale = 1, this.normalMap = null, this.normalMapType = Su, this.normalScale = new vt(1, 1), this.displacementMap = null, this.displacementScale = 1, this.displacementBias = 0, this.alphaMap = null, this.skinning = !1, this.morphTargets = !1, this.morphNormals = !1, this.setValues(e);
}
bu.prototype = Object.create(rn.prototype);
bu.prototype.constructor = bu;
bu.prototype.isMeshMatcapMaterial = !0;
bu.prototype.copy = function(e) {
  return rn.prototype.copy.call(this, e), this.defines = { MATCAP: "" }, this.color.copy(e.color), this.matcap = e.matcap, this.map = e.map, this.bumpMap = e.bumpMap, this.bumpScale = e.bumpScale, this.normalMap = e.normalMap, this.normalMapType = e.normalMapType, this.normalScale.copy(e.normalScale), this.displacementMap = e.displacementMap, this.displacementScale = e.displacementScale, this.displacementBias = e.displacementBias, this.alphaMap = e.alphaMap, this.skinning = e.skinning, this.morphTargets = e.morphTargets, this.morphNormals = e.morphNormals, this;
};
function Mu(e) {
  Zn.call(this), this.type = "LineDashedMaterial", this.scale = 1, this.dashSize = 3, this.gapSize = 1, this.setValues(e);
}
Mu.prototype = Object.create(Zn.prototype);
Mu.prototype.constructor = Mu;
Mu.prototype.isLineDashedMaterial = !0;
Mu.prototype.copy = function(e) {
  return Zn.prototype.copy.call(this, e), this.scale = e.scale, this.dashSize = e.dashSize, this.gapSize = e.gapSize, this;
};
var XS = /* @__PURE__ */ Object.freeze({
  __proto__: null,
  ShadowMaterial: yu,
  SpriteMaterial: wa,
  RawShaderMaterial: yo,
  ShaderMaterial: Xi,
  PointsMaterial: mo,
  MeshPhysicalMaterial: xa,
  MeshStandardMaterial: Vs,
  MeshPhongMaterial: ba,
  MeshToonMaterial: vu,
  MeshNormalMaterial: wu,
  MeshLambertMaterial: xu,
  MeshDepthMaterial: _a,
  MeshDistanceMaterial: ya,
  MeshBasicMaterial: Ms,
  MeshMatcapMaterial: bu,
  LineDashedMaterial: Mu,
  LineBasicMaterial: Zn,
  Material: rn
});
const Kn = {
  // same as Array.prototype.slice, but also works on typed arrays
  arraySlice: function(e, n, t) {
    return Kn.isTypedArray(e) ? new e.constructor(e.subarray(n, t !== void 0 ? t : e.length)) : e.slice(n, t);
  },
  // converts an array to a specific type
  convertArray: function(e, n, t) {
    return !e || // let 'undefined' and 'null' pass
    !t && e.constructor === n ? e : typeof n.BYTES_PER_ELEMENT == "number" ? new n(e) : Array.prototype.slice.call(e);
  },
  isTypedArray: function(e) {
    return ArrayBuffer.isView(e) && !(e instanceof DataView);
  },
  // returns an array by which times and values can be sorted
  getKeyframeOrder: function(e) {
    function n(r, a) {
      return e[r] - e[a];
    }
    const t = e.length, i = new Array(t);
    for (let r = 0; r !== t; ++r)
      i[r] = r;
    return i.sort(n), i;
  },
  // uses the array previously returned by 'getKeyframeOrder' to sort data
  sortedArray: function(e, n, t) {
    const i = e.length, r = new e.constructor(i);
    for (let a = 0, c = 0; c !== i; ++a) {
      const u = t[a] * n;
      for (let l = 0; l !== n; ++l)
        r[c++] = e[u + l];
    }
    return r;
  },
  // function for parsing AOS keyframe formats
  flattenJSON: function(e, n, t, i) {
    let r = 1, a = e[0];
    for (; a !== void 0 && a[i] === void 0; )
      a = e[r++];
    if (a === void 0)
      return;
    let c = a[i];
    if (c !== void 0)
      if (Array.isArray(c))
        do
          c = a[i], c !== void 0 && (n.push(a.time), t.push.apply(t, c)), a = e[r++];
        while (a !== void 0);
      else if (c.toArray !== void 0)
        do
          c = a[i], c !== void 0 && (n.push(a.time), c.toArray(t, t.length)), a = e[r++];
        while (a !== void 0);
      else
        do
          c = a[i], c !== void 0 && (n.push(a.time), t.push(c)), a = e[r++];
        while (a !== void 0);
  },
  subclip: function(e, n, t, i, r) {
    r = r || 30;
    const a = e.clone();
    a.name = n;
    const c = [];
    for (let l = 0; l < a.tracks.length; ++l) {
      const f = a.tracks[l], m = f.getValueSize(), h = [], p = [];
      for (let _ = 0; _ < f.times.length; ++_) {
        const v = f.times[_] * r;
        if (!(v < t || v >= i)) {
          h.push(f.times[_]);
          for (let S = 0; S < m; ++S)
            p.push(f.values[_ * m + S]);
        }
      }
      h.length !== 0 && (f.times = Kn.convertArray(h, f.times.constructor), f.values = Kn.convertArray(p, f.values.constructor), c.push(f));
    }
    a.tracks = c;
    let u = 1 / 0;
    for (let l = 0; l < a.tracks.length; ++l)
      u > a.tracks[l].times[0] && (u = a.tracks[l].times[0]);
    for (let l = 0; l < a.tracks.length; ++l)
      a.tracks[l].shift(-1 * u);
    return a.resetDuration(), a;
  },
  makeClipAdditive: function(e, n, t, i) {
    n === void 0 && (n = 0), t === void 0 && (t = e), (i === void 0 || i <= 0) && (i = 30);
    const r = e.tracks.length, a = n / i;
    for (let c = 0; c < r; ++c) {
      const u = t.tracks[c], l = u.ValueTypeName;
      if (l === "bool" || l === "string")
        continue;
      const f = e.tracks.find(function(v) {
        return v.name === u.name && v.ValueTypeName === l;
      });
      if (f === void 0)
        continue;
      const m = u.getValueSize(), h = u.times.length - 1;
      let p;
      if (a <= u.times[0])
        p = Kn.arraySlice(u.values, 0, u.valueSize);
      else if (a >= u.times[h]) {
        const v = h * m;
        p = Kn.arraySlice(u.values, v);
      } else {
        const v = u.createInterpolant();
        v.evaluate(a), p = v.resultBuffer;
      }
      l === "quaternion" && new yi(
        p[0],
        p[1],
        p[2],
        p[3]
      ).normalize().conjugate().toArray(p);
      const _ = f.times.length;
      for (let v = 0; v < _; ++v) {
        const S = v * m;
        if (l === "quaternion")
          yi.multiplyQuaternionsFlat(
            f.values,
            S,
            p,
            0,
            f.values,
            S
          );
        else
          for (let D = 0; D < m; ++D)
            f.values[S + D] -= p[D];
      }
    }
    return e.blendMode = Bx, e;
  }
};
function bs(e, n, t, i) {
  this.parameterPositions = e, this._cachedIndex = 0, this.resultBuffer = i !== void 0 ? i : new n.constructor(t), this.sampleValues = n, this.valueSize = t;
}
Object.assign(bs.prototype, {
  evaluate: function(e) {
    let n = this.parameterPositions, t = this._cachedIndex, i = n[t], r = n[t - 1];
    e: {
      t: {
        let a;
        n: {
          i:
            if (!(e < i)) {
              for (let c = t + 2; ; ) {
                if (i === void 0) {
                  if (e < r)
                    break i;
                  return t = n.length, this._cachedIndex = t, this.afterEnd_(t - 1, e, r);
                }
                if (t === c)
                  break;
                if (r = i, i = n[++t], e < i)
                  break t;
              }
              a = n.length;
              break n;
            }
          if (!(e >= r)) {
            const c = n[1];
            e < c && (t = 2, r = c);
            for (let u = t - 2; ; ) {
              if (r === void 0)
                return this._cachedIndex = 0, this.beforeStart_(0, e, i);
              if (t === u)
                break;
              if (i = r, r = n[--t - 1], e >= r)
                break t;
            }
            a = t, t = 0;
            break n;
          }
          break e;
        }
        for (; t < a; ) {
          const c = t + a >>> 1;
          e < n[c] ? a = c : t = c + 1;
        }
        if (i = n[t], r = n[t - 1], r === void 0)
          return this._cachedIndex = 0, this.beforeStart_(0, e, i);
        if (i === void 0)
          return t = n.length, this._cachedIndex = t, this.afterEnd_(t - 1, r, e);
      }
      this._cachedIndex = t, this.intervalChanged_(t, r, i);
    }
    return this.interpolate_(t, r, e, i);
  },
  settings: null,
  // optional, subclass-specific settings structure
  // Note: The indirection allows central control of many interpolants.
  // --- Protected interface
  DefaultSettings_: {},
  getSettings_: function() {
    return this.settings || this.DefaultSettings_;
  },
  copySampleValue_: function(e) {
    const n = this.resultBuffer, t = this.sampleValues, i = this.valueSize, r = e * i;
    for (let a = 0; a !== i; ++a)
      n[a] = t[r + a];
    return n;
  },
  // Template methods for derived classes:
  interpolate_: function() {
    throw new Error("call to abstract method");
  },
  intervalChanged_: function() {
  }
});
Object.assign(bs.prototype, {
  //( 0, t, t0 ), returns this.resultBuffer
  beforeStart_: bs.prototype.copySampleValue_,
  //( N-1, tN-1, t ), returns this.resultBuffer
  afterEnd_: bs.prototype.copySampleValue_
});
function t0(e, n, t, i) {
  bs.call(this, e, n, t, i), this._weightPrev = -0, this._offsetPrev = -0, this._weightNext = -0, this._offsetNext = -0;
}
t0.prototype = Object.assign(Object.create(bs.prototype), {
  constructor: t0,
  DefaultSettings_: {
    endingStart: au,
    endingEnd: au
  },
  intervalChanged_: function(e, n, t) {
    let i = this.parameterPositions, r = e - 2, a = e + 1, c = i[r], u = i[a];
    if (c === void 0)
      switch (this.getSettings_().endingStart) {
        case Qc:
          r = e, c = 2 * n - t;
          break;
        case ey:
          r = i.length - 2, c = n + i[r] - i[r + 1];
          break;
        default:
          r = e, c = t;
      }
    if (u === void 0)
      switch (this.getSettings_().endingEnd) {
        case Qc:
          a = e, u = 2 * t - n;
          break;
        case ey:
          a = 1, u = t + i[1] - i[0];
          break;
        default:
          a = e - 1, u = n;
      }
    const l = (t - n) * 0.5, f = this.valueSize;
    this._weightPrev = l / (n - c), this._weightNext = l / (u - t), this._offsetPrev = r * f, this._offsetNext = a * f;
  },
  interpolate_: function(e, n, t, i) {
    const r = this.resultBuffer, a = this.sampleValues, c = this.valueSize, u = e * c, l = u - c, f = this._offsetPrev, m = this._offsetNext, h = this._weightPrev, p = this._weightNext, _ = (t - n) / (i - n), v = _ * _, S = v * _, D = -h * S + 2 * h * v - h * _, w = (1 + h) * S + (-1.5 - 2 * h) * v + (-0.5 + h) * _ + 1, T = (-1 - p) * S + (1.5 + p) * v + 0.5 * _, F = p * S - p * v;
    for (let E = 0; E !== c; ++E)
      r[E] = D * a[f + E] + w * a[l + E] + T * a[u + E] + F * a[m + E];
    return r;
  }
});
function My(e, n, t, i) {
  bs.call(this, e, n, t, i);
}
My.prototype = Object.assign(Object.create(bs.prototype), {
  constructor: My,
  interpolate_: function(e, n, t, i) {
    const r = this.resultBuffer, a = this.sampleValues, c = this.valueSize, u = e * c, l = u - c, f = (t - n) / (i - n), m = 1 - f;
    for (let h = 0; h !== c; ++h)
      r[h] = a[l + h] * m + a[u + h] * f;
    return r;
  }
});
function n0(e, n, t, i) {
  bs.call(this, e, n, t, i);
}
n0.prototype = Object.assign(Object.create(bs.prototype), {
  constructor: n0,
  interpolate_: function(e) {
    return this.copySampleValue_(e - 1);
  }
});
function Di(e, n, t, i) {
  if (e === void 0)
    throw new Error("THREE.KeyframeTrack: track name is undefined");
  if (n === void 0 || n.length === 0)
    throw new Error("THREE.KeyframeTrack: no keyframes in track named " + e);
  this.name = e, this.times = Kn.convertArray(n, this.TimeBufferType), this.values = Kn.convertArray(t, this.ValueBufferType), this.setInterpolation(i || this.DefaultInterpolation);
}
Object.assign(Di, {
  // Serialization (in static context, because of constructor invocation
  // and automatic invocation of .toJSON):
  toJSON: function(e) {
    const n = e.constructor;
    let t;
    if (n.toJSON !== void 0)
      t = n.toJSON(e);
    else {
      t = {
        name: e.name,
        times: Kn.convertArray(e.times, Array),
        values: Kn.convertArray(e.values, Array)
      };
      const i = e.getInterpolation();
      i !== e.DefaultInterpolation && (t.interpolation = i);
    }
    return t.type = e.ValueTypeName, t;
  }
});
Object.assign(Di.prototype, {
  constructor: Di,
  TimeBufferType: Float32Array,
  ValueBufferType: Float32Array,
  DefaultInterpolation: W_,
  InterpolantFactoryMethodDiscrete: function(e) {
    return new n0(this.times, this.values, this.getValueSize(), e);
  },
  InterpolantFactoryMethodLinear: function(e) {
    return new My(this.times, this.values, this.getValueSize(), e);
  },
  InterpolantFactoryMethodSmooth: function(e) {
    return new t0(this.times, this.values, this.getValueSize(), e);
  },
  setInterpolation: function(e) {
    let n;
    switch (e) {
      case Z_:
        n = this.InterpolantFactoryMethodDiscrete;
        break;
      case W_:
        n = this.InterpolantFactoryMethodLinear;
        break;
      case ev:
        n = this.InterpolantFactoryMethodSmooth;
        break;
    }
    if (n === void 0) {
      const t = "unsupported interpolation for " + this.ValueTypeName + " keyframe track named " + this.name;
      if (this.createInterpolant === void 0)
        if (e !== this.DefaultInterpolation)
          this.setInterpolation(this.DefaultInterpolation);
        else
          throw new Error(t);
      return console.warn("THREE.KeyframeTrack:", t), this;
    }
    return this.createInterpolant = n, this;
  },
  getInterpolation: function() {
    switch (this.createInterpolant) {
      case this.InterpolantFactoryMethodDiscrete:
        return Z_;
      case this.InterpolantFactoryMethodLinear:
        return W_;
      case this.InterpolantFactoryMethodSmooth:
        return ev;
    }
  },
  getValueSize: function() {
    return this.values.length / this.times.length;
  },
  // move all keyframes either forwards or backwards in time
  shift: function(e) {
    if (e !== 0) {
      const n = this.times;
      for (let t = 0, i = n.length; t !== i; ++t)
        n[t] += e;
    }
    return this;
  },
  // scale all keyframe times by a factor (useful for frame <-> seconds conversions)
  scale: function(e) {
    if (e !== 1) {
      const n = this.times;
      for (let t = 0, i = n.length; t !== i; ++t)
        n[t] *= e;
    }
    return this;
  },
  // removes keyframes before and after animation without changing any values within the range [startTime, endTime].
  // IMPORTANT: We do not shift around keys to the start of the track time, because for interpolated keys this will change their values
  trim: function(e, n) {
    const t = this.times, i = t.length;
    let r = 0, a = i - 1;
    for (; r !== i && t[r] < e; )
      ++r;
    for (; a !== -1 && t[a] > n; )
      --a;
    if (++a, r !== 0 || a !== i) {
      r >= a && (a = Math.max(a, 1), r = a - 1);
      const c = this.getValueSize();
      this.times = Kn.arraySlice(t, r, a), this.values = Kn.arraySlice(this.values, r * c, a * c);
    }
    return this;
  },
  // ensure we do not get a GarbageInGarbageOut situation, make sure tracks are at least minimally viable
  validate: function() {
    let e = !0;
    const n = this.getValueSize();
    n - Math.floor(n) !== 0 && (console.error("THREE.KeyframeTrack: Invalid value size in track.", this), e = !1);
    const t = this.times, i = this.values, r = t.length;
    r === 0 && (console.error("THREE.KeyframeTrack: Track is empty.", this), e = !1);
    let a = null;
    for (let c = 0; c !== r; c++) {
      const u = t[c];
      if (typeof u == "number" && isNaN(u)) {
        console.error("THREE.KeyframeTrack: Time is not a valid number.", this, c, u), e = !1;
        break;
      }
      if (a !== null && a > u) {
        console.error("THREE.KeyframeTrack: Out of order keys.", this, c, u, a), e = !1;
        break;
      }
      a = u;
    }
    if (i !== void 0 && Kn.isTypedArray(i))
      for (let c = 0, u = i.length; c !== u; ++c) {
        const l = i[c];
        if (isNaN(l)) {
          console.error("THREE.KeyframeTrack: Value is not a valid number.", this, c, l), e = !1;
          break;
        }
      }
    return e;
  },
  // removes equivalent sequential keys as common in morph target sequences
  // (0,0,0,0,1,1,1,0,0,0,0,0,0,0) --> (0,0,1,1,0,0)
  optimize: function() {
    const e = Kn.arraySlice(this.times), n = Kn.arraySlice(this.values), t = this.getValueSize(), i = this.getInterpolation() === ev, r = e.length - 1;
    let a = 1;
    for (let c = 1; c < r; ++c) {
      let u = !1;
      const l = e[c], f = e[c + 1];
      if (l !== f && (c !== 1 || l !== l[0]))
        if (i)
          u = !0;
        else {
          const m = c * t, h = m - t, p = m + t;
          for (let _ = 0; _ !== t; ++_) {
            const v = n[m + _];
            if (v !== n[h + _] || v !== n[p + _]) {
              u = !0;
              break;
            }
          }
        }
      if (u) {
        if (c !== a) {
          e[a] = e[c];
          const m = c * t, h = a * t;
          for (let p = 0; p !== t; ++p)
            n[h + p] = n[m + p];
        }
        ++a;
      }
    }
    if (r > 0) {
      e[a] = e[r];
      for (let c = r * t, u = a * t, l = 0; l !== t; ++l)
        n[u + l] = n[c + l];
      ++a;
    }
    return a !== e.length ? (this.times = Kn.arraySlice(e, 0, a), this.values = Kn.arraySlice(n, 0, a * t)) : (this.times = e, this.values = n), this;
  },
  clone: function() {
    const e = Kn.arraySlice(this.times, 0), n = Kn.arraySlice(this.values, 0), t = this.constructor, i = new t(this.name, e, n);
    return i.createInterpolant = this.createInterpolant, i;
  }
});
function i0(e, n, t) {
  Di.call(this, e, n, t);
}
i0.prototype = Object.assign(Object.create(Di.prototype), {
  constructor: i0,
  ValueTypeName: "bool",
  ValueBufferType: Array,
  DefaultInterpolation: Z_,
  InterpolantFactoryMethodLinear: void 0,
  InterpolantFactoryMethodSmooth: void 0
  // Note: Actually this track could have a optimized / compressed
  // representation of a single value and a custom interpolant that
  // computes "firstValue ^ isOdd( index )".
});
function s0(e, n, t, i) {
  Di.call(this, e, n, t, i);
}
s0.prototype = Object.assign(Object.create(Di.prototype), {
  constructor: s0,
  ValueTypeName: "color"
  // ValueBufferType is inherited
  // DefaultInterpolation is inherited
  // Note: Very basic implementation and nothing special yet.
  // However, this is the place for color space parameterization.
});
function Qm(e, n, t, i) {
  Di.call(this, e, n, t, i);
}
Qm.prototype = Object.assign(Object.create(Di.prototype), {
  constructor: Qm,
  ValueTypeName: "number"
  // ValueBufferType is inherited
  // DefaultInterpolation is inherited
});
function r0(e, n, t, i) {
  bs.call(this, e, n, t, i);
}
r0.prototype = Object.assign(Object.create(bs.prototype), {
  constructor: r0,
  interpolate_: function(e, n, t, i) {
    const r = this.resultBuffer, a = this.sampleValues, c = this.valueSize, u = (t - n) / (i - n);
    let l = e * c;
    for (let f = l + c; l !== f; l += 4)
      yi.slerpFlat(r, 0, a, l - c, a, l, u);
    return r;
  }
});
function Ty(e, n, t, i) {
  Di.call(this, e, n, t, i);
}
Ty.prototype = Object.assign(Object.create(Di.prototype), {
  constructor: Ty,
  ValueTypeName: "quaternion",
  // ValueBufferType is inherited
  DefaultInterpolation: W_,
  InterpolantFactoryMethodLinear: function(e) {
    return new r0(this.times, this.values, this.getValueSize(), e);
  },
  InterpolantFactoryMethodSmooth: void 0
  // not yet implemented
});
function o0(e, n, t, i) {
  Di.call(this, e, n, t, i);
}
o0.prototype = Object.assign(Object.create(Di.prototype), {
  constructor: o0,
  ValueTypeName: "string",
  ValueBufferType: Array,
  DefaultInterpolation: Z_,
  InterpolantFactoryMethodLinear: void 0,
  InterpolantFactoryMethodSmooth: void 0
});
function Zm(e, n, t, i) {
  Di.call(this, e, n, t, i);
}
Zm.prototype = Object.assign(Object.create(Di.prototype), {
  constructor: Zm,
  ValueTypeName: "vector"
  // ValueBufferType is inherited
  // DefaultInterpolation is inherited
});
function Ns(e, n, t, i) {
  this.name = e, this.tracks = t, this.duration = n !== void 0 ? n : -1, this.blendMode = i !== void 0 ? i : O0, this.uuid = un.generateUUID(), this.duration < 0 && this.resetDuration();
}
function YS(e) {
  switch (e.toLowerCase()) {
    case "scalar":
    case "double":
    case "float":
    case "number":
    case "integer":
      return Qm;
    case "vector":
    case "vector2":
    case "vector3":
    case "vector4":
      return Zm;
    case "color":
      return s0;
    case "quaternion":
      return Ty;
    case "bool":
    case "boolean":
      return i0;
    case "string":
      return o0;
  }
  throw new Error("THREE.KeyframeTrack: Unsupported typeName: " + e);
}
function JS(e) {
  if (e.type === void 0)
    throw new Error("THREE.KeyframeTrack: track type undefined, can not parse");
  const n = YS(e.type);
  if (e.times === void 0) {
    const t = [], i = [];
    Kn.flattenJSON(e.keys, t, i, "value"), e.times = t, e.values = i;
  }
  return n.parse !== void 0 ? n.parse(e) : new n(e.name, e.times, e.values, e.interpolation);
}
Object.assign(Ns, {
  parse: function(e) {
    const n = [], t = e.tracks, i = 1 / (e.fps || 1);
    for (let r = 0, a = t.length; r !== a; ++r)
      n.push(JS(t[r]).scale(i));
    return new Ns(e.name, e.duration, n, e.blendMode);
  },
  toJSON: function(e) {
    const n = [], t = e.tracks, i = {
      name: e.name,
      duration: e.duration,
      tracks: n,
      uuid: e.uuid,
      blendMode: e.blendMode
    };
    for (let r = 0, a = t.length; r !== a; ++r)
      n.push(Di.toJSON(t[r]));
    return i;
  },
  CreateFromMorphTargetSequence: function(e, n, t, i) {
    const r = n.length, a = [];
    for (let c = 0; c < r; c++) {
      let u = [], l = [];
      u.push(
        (c + r - 1) % r,
        c,
        (c + 1) % r
      ), l.push(0, 1, 0);
      const f = Kn.getKeyframeOrder(u);
      u = Kn.sortedArray(u, 1, f), l = Kn.sortedArray(l, 1, f), !i && u[0] === 0 && (u.push(r), l.push(l[0])), a.push(
        new Qm(
          ".morphTargetInfluences[" + n[c].name + "]",
          u,
          l
        ).scale(1 / t)
      );
    }
    return new Ns(e, -1, a);
  },
  findByName: function(e, n) {
    let t = e;
    if (!Array.isArray(e)) {
      const i = e;
      t = i.geometry && i.geometry.animations || i.animations;
    }
    for (let i = 0; i < t.length; i++)
      if (t[i].name === n)
        return t[i];
    return null;
  },
  CreateClipsFromMorphTargetSequences: function(e, n, t) {
    const i = {}, r = /^([\w-]*?)([\d]+)$/;
    for (let c = 0, u = e.length; c < u; c++) {
      const l = e[c], f = l.name.match(r);
      if (f && f.length > 1) {
        const m = f[1];
        let h = i[m];
        h || (i[m] = h = []), h.push(l);
      }
    }
    const a = [];
    for (const c in i)
      a.push(Ns.CreateFromMorphTargetSequence(c, i[c], n, t));
    return a;
  },
  // parse the animation.hierarchy format
  parseAnimation: function(e, n) {
    if (!e)
      return console.error("THREE.AnimationClip: No animation in JSONLoader data."), null;
    const t = function(m, h, p, _, v) {
      if (p.length !== 0) {
        const S = [], D = [];
        Kn.flattenJSON(p, S, D, _), S.length !== 0 && v.push(new m(h, S, D));
      }
    }, i = [], r = e.name || "default", a = e.fps || 30, c = e.blendMode;
    let u = e.length || -1;
    const l = e.hierarchy || [];
    for (let m = 0; m < l.length; m++) {
      const h = l[m].keys;
      if (!(!h || h.length === 0))
        if (h[0].morphTargets) {
          const p = {};
          let _;
          for (_ = 0; _ < h.length; _++)
            if (h[_].morphTargets)
              for (let v = 0; v < h[_].morphTargets.length; v++)
                p[h[_].morphTargets[v]] = -1;
          for (const v in p) {
            const S = [], D = [];
            for (let w = 0; w !== h[_].morphTargets.length; ++w) {
              const T = h[_];
              S.push(T.time), D.push(T.morphTarget === v ? 1 : 0);
            }
            i.push(new Qm(".morphTargetInfluence[" + v + "]", S, D));
          }
          u = p.length * (a || 1);
        } else {
          const p = ".bones[" + n[m].name + "]";
          t(
            Zm,
            p + ".position",
            h,
            "pos",
            i
          ), t(
            Ty,
            p + ".quaternion",
            h,
            "rot",
            i
          ), t(
            Zm,
            p + ".scale",
            h,
            "scl",
            i
          );
        }
    }
    return i.length === 0 ? null : new Ns(r, u, i, c);
  }
});
Object.assign(Ns.prototype, {
  resetDuration: function() {
    const e = this.tracks;
    let n = 0;
    for (let t = 0, i = e.length; t !== i; ++t) {
      const r = this.tracks[t];
      n = Math.max(n, r.times[r.times.length - 1]);
    }
    return this.duration = n, this;
  },
  trim: function() {
    for (let e = 0; e < this.tracks.length; e++)
      this.tracks[e].trim(0, this.duration);
    return this;
  },
  validate: function() {
    let e = !0;
    for (let n = 0; n < this.tracks.length; n++)
      e = e && this.tracks[n].validate();
    return e;
  },
  optimize: function() {
    for (let e = 0; e < this.tracks.length; e++)
      this.tracks[e].optimize();
    return this;
  },
  clone: function() {
    const e = [];
    for (let n = 0; n < this.tracks.length; n++)
      e.push(this.tracks[n].clone());
    return new Ns(this.name, this.duration, e, this.blendMode);
  }
});
const ur = {
  enabled: !1,
  files: {},
  add: function(e, n) {
    this.enabled !== !1 && (this.files[e] = n);
  },
  get: function(e) {
    if (this.enabled !== !1)
      return this.files[e];
  },
  remove: function(e) {
    delete this.files[e];
  },
  clear: function() {
    this.files = {};
  }
};
function ab(e, n, t) {
  const i = this;
  let r = !1, a = 0, c = 0, u;
  const l = [];
  this.onStart = void 0, this.onLoad = e, this.onProgress = n, this.onError = t, this.itemStart = function(f) {
    c++, r === !1 && i.onStart !== void 0 && i.onStart(f, a, c), r = !0;
  }, this.itemEnd = function(f) {
    a++, i.onProgress !== void 0 && i.onProgress(f, a, c), a === c && (r = !1, i.onLoad !== void 0 && i.onLoad());
  }, this.itemError = function(f) {
    i.onError !== void 0 && i.onError(f);
  }, this.resolveURL = function(f) {
    return u ? u(f) : f;
  }, this.setURLModifier = function(f) {
    return u = f, this;
  }, this.addHandler = function(f, m) {
    return l.push(f, m), this;
  }, this.removeHandler = function(f) {
    const m = l.indexOf(f);
    return m !== -1 && l.splice(m, 2), this;
  }, this.getHandler = function(f) {
    for (let m = 0, h = l.length; m < h; m += 2) {
      const p = l[m], _ = l[m + 1];
      if (p.global && (p.lastIndex = 0), p.test(f))
        return _;
    }
    return null;
  };
}
const QS = new ab();
function Tn(e) {
  this.manager = e !== void 0 ? e : QS, this.crossOrigin = "anonymous", this.path = "", this.resourcePath = "", this.requestHeader = {};
}
Object.assign(Tn.prototype, {
  load: function() {
  },
  loadAsync: function(e, n) {
    const t = this;
    return new Promise(function(i, r) {
      t.load(e, i, n, r);
    });
  },
  parse: function() {
  },
  setCrossOrigin: function(e) {
    return this.crossOrigin = e, this;
  },
  setPath: function(e) {
    return this.path = e, this;
  },
  setResourcePath: function(e) {
    return this.resourcePath = e, this;
  },
  setRequestHeader: function(e) {
    return this.requestHeader = e, this;
  }
});
const zs = {};
function js(e) {
  Tn.call(this, e);
}
js.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: js,
  load: function(e, n, t, i) {
    e === void 0 && (e = ""), this.path !== void 0 && (e = this.path + e), e = this.manager.resolveURL(e);
    const r = this, a = ur.get(e);
    if (a !== void 0)
      return r.manager.itemStart(e), setTimeout(function() {
        n && n(a), r.manager.itemEnd(e);
      }, 0), a;
    if (zs[e] !== void 0) {
      zs[e].push({
        onLoad: n,
        onProgress: t,
        onError: i
      });
      return;
    }
    const c = /^data:(.*?)(;base64)?,(.*)$/, u = e.match(c);
    let l;
    if (u) {
      const f = u[1], m = !!u[2];
      let h = u[3];
      h = decodeURIComponent(h), m && (h = atob(h));
      try {
        let p;
        const _ = (this.responseType || "").toLowerCase();
        switch (_) {
          case "arraybuffer":
          case "blob":
            const v = new Uint8Array(h.length);
            for (let D = 0; D < h.length; D++)
              v[D] = h.charCodeAt(D);
            _ === "blob" ? p = new Blob([v.buffer], { type: f }) : p = v.buffer;
            break;
          case "document":
            p = new DOMParser().parseFromString(h, f);
            break;
          case "json":
            p = JSON.parse(h);
            break;
          default:
            p = h;
            break;
        }
        setTimeout(function() {
          n && n(p), r.manager.itemEnd(e);
        }, 0);
      } catch (p) {
        setTimeout(function() {
          i && i(p), r.manager.itemError(e), r.manager.itemEnd(e);
        }, 0);
      }
    } else {
      zs[e] = [], zs[e].push({
        onLoad: n,
        onProgress: t,
        onError: i
      }), l = new XMLHttpRequest(), l.open("GET", e, !0), l.addEventListener("load", function(f) {
        const m = this.response, h = zs[e];
        if (delete zs[e], this.status === 200 || this.status === 0) {
          this.status === 0 && console.warn("THREE.FileLoader: HTTP Status 0 received."), ur.add(e, m);
          for (let p = 0, _ = h.length; p < _; p++) {
            const v = h[p];
            v.onLoad && v.onLoad(m);
          }
          r.manager.itemEnd(e);
        } else {
          for (let p = 0, _ = h.length; p < _; p++) {
            const v = h[p];
            v.onError && v.onError(f);
          }
          r.manager.itemError(e), r.manager.itemEnd(e);
        }
      }, !1), l.addEventListener("progress", function(f) {
        const m = zs[e];
        for (let h = 0, p = m.length; h < p; h++) {
          const _ = m[h];
          _.onProgress && _.onProgress(f);
        }
      }, !1), l.addEventListener("error", function(f) {
        const m = zs[e];
        delete zs[e];
        for (let h = 0, p = m.length; h < p; h++) {
          const _ = m[h];
          _.onError && _.onError(f);
        }
        r.manager.itemError(e), r.manager.itemEnd(e);
      }, !1), l.addEventListener("abort", function(f) {
        const m = zs[e];
        delete zs[e];
        for (let h = 0, p = m.length; h < p; h++) {
          const _ = m[h];
          _.onError && _.onError(f);
        }
        r.manager.itemError(e), r.manager.itemEnd(e);
      }, !1), this.responseType !== void 0 && (l.responseType = this.responseType), this.withCredentials !== void 0 && (l.withCredentials = this.withCredentials), l.overrideMimeType && l.overrideMimeType(this.mimeType !== void 0 ? this.mimeType : "text/plain");
      for (const f in this.requestHeader)
        l.setRequestHeader(f, this.requestHeader[f]);
      l.send(null);
    }
    return r.manager.itemStart(e), l;
  },
  setResponseType: function(e) {
    return this.responseType = e, this;
  },
  setWithCredentials: function(e) {
    return this.withCredentials = e, this;
  },
  setMimeType: function(e) {
    return this.mimeType = e, this;
  }
});
function Kw(e) {
  Tn.call(this, e);
}
Kw.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: Kw,
  load: function(e, n, t, i) {
    const r = this, a = new js(r.manager);
    a.setPath(r.path), a.setRequestHeader(r.requestHeader), a.load(e, function(c) {
      try {
        n(r.parse(JSON.parse(c)));
      } catch (u) {
        i ? i(u) : console.error(u), r.manager.itemError(e);
      }
    }, t, i);
  },
  parse: function(e) {
    const n = [];
    for (let t = 0; t < e.length; t++) {
      const i = Ns.parse(e[t]);
      n.push(i);
    }
    return n;
  }
});
function Xw(e) {
  Tn.call(this, e);
}
Xw.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: Xw,
  load: function(e, n, t, i) {
    const r = this, a = [], c = new Rm();
    c.image = a;
    const u = new js(this.manager);
    u.setPath(this.path), u.setResponseType("arraybuffer"), u.setRequestHeader(this.requestHeader);
    let l = 0;
    function f(m) {
      u.load(e[m], function(h) {
        const p = r.parse(h, !0);
        a[m] = {
          width: p.width,
          height: p.height,
          format: p.format,
          mipmaps: p.mipmaps
        }, l += 1, l === 6 && (p.mipmapCount === 1 && (c.minFilter = Li), c.format = p.format, c.needsUpdate = !0, n && n(c));
      }, t, i);
    }
    if (Array.isArray(e))
      for (let m = 0, h = e.length; m < h; ++m)
        f(m);
    else
      u.load(e, function(m) {
        const h = r.parse(m, !0);
        if (h.isCubemap) {
          const p = h.mipmaps.length / h.mipmapCount;
          for (let _ = 0; _ < p; _++) {
            a[_] = { mipmaps: [] };
            for (let v = 0; v < h.mipmapCount; v++)
              a[_].mipmaps.push(h.mipmaps[_ * h.mipmapCount + v]), a[_].format = h.format, a[_].width = h.width, a[_].height = h.height;
          }
        } else
          c.image.width = h.width, c.image.height = h.height, c.mipmaps = h.mipmaps;
        h.mipmapCount === 1 && (c.minFilter = Li), c.format = h.format, c.needsUpdate = !0, n && n(c);
      }, t, i);
    return c;
  }
});
function Yw(e) {
  Tn.call(this, e);
}
Yw.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: Yw,
  load: function(e, n, t, i) {
    const r = this, a = new cu(), c = new js(this.manager);
    return c.setResponseType("arraybuffer"), c.setRequestHeader(this.requestHeader), c.setPath(this.path), c.load(e, function(u) {
      const l = r.parse(u);
      l && (l.image !== void 0 ? a.image = l.image : l.data !== void 0 && (a.image.width = l.width, a.image.height = l.height, a.image.data = l.data), a.wrapS = l.wrapS !== void 0 ? l.wrapS : qi, a.wrapT = l.wrapT !== void 0 ? l.wrapT : qi, a.magFilter = l.magFilter !== void 0 ? l.magFilter : Li, a.minFilter = l.minFilter !== void 0 ? l.minFilter : Li, a.anisotropy = l.anisotropy !== void 0 ? l.anisotropy : 1, l.format !== void 0 && (a.format = l.format), l.type !== void 0 && (a.type = l.type), l.mipmaps !== void 0 && (a.mipmaps = l.mipmaps, a.minFilter = zy), l.mipmapCount === 1 && (a.minFilter = Li), a.needsUpdate = !0, n && n(a, l));
    }, t, i), a;
  }
});
function eg(e) {
  Tn.call(this, e);
}
eg.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: eg,
  load: function(e, n, t, i) {
    this.path !== void 0 && (e = this.path + e), e = this.manager.resolveURL(e);
    const r = this, a = ur.get(e);
    if (a !== void 0)
      return r.manager.itemStart(e), setTimeout(function() {
        n && n(a), r.manager.itemEnd(e);
      }, 0), a;
    const c = document.createElementNS("http://www.w3.org/1999/xhtml", "img");
    function u() {
      c.removeEventListener("load", u, !1), c.removeEventListener("error", l, !1), ur.add(e, this), n && n(this), r.manager.itemEnd(e);
    }
    function l(f) {
      c.removeEventListener("load", u, !1), c.removeEventListener("error", l, !1), i && i(f), r.manager.itemError(e), r.manager.itemEnd(e);
    }
    return c.addEventListener("load", u, !1), c.addEventListener("error", l, !1), e.substr(0, 5) !== "data:" && this.crossOrigin !== void 0 && (c.crossOrigin = this.crossOrigin), r.manager.itemStart(e), c.src = e, c;
  }
});
function a0(e) {
  Tn.call(this, e);
}
a0.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: a0,
  load: function(e, n, t, i) {
    const r = new po(), a = new eg(this.manager);
    a.setCrossOrigin(this.crossOrigin), a.setPath(this.path);
    let c = 0;
    function u(l) {
      a.load(e[l], function(f) {
        r.images[l] = f, c++, c === 6 && (r.needsUpdate = !0, n && n(r));
      }, void 0, i);
    }
    for (let l = 0; l < e.length; ++l)
      u(l);
    return r;
  }
});
function Ey(e) {
  Tn.call(this, e);
}
Ey.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: Ey,
  load: function(e, n, t, i) {
    const r = new Fn(), a = new eg(this.manager);
    return a.setCrossOrigin(this.crossOrigin), a.setPath(this.path), a.load(e, function(c) {
      r.image = c;
      const u = e.search(/\.jpe?g($|\?)/i) > 0 || e.search(/^data\:image\/jpeg/) === 0;
      r.format = u ? pa : ws, r.needsUpdate = !0, n !== void 0 && n(r);
    }, t, i), r;
  }
});
function Qt() {
  this.type = "Curve", this.arcLengthDivisions = 200;
}
Object.assign(Qt.prototype, {
  // Virtual base class method to overwrite and implement in subclasses
  //	- t [0 .. 1]
  getPoint: function() {
    return console.warn("THREE.Curve: .getPoint() not implemented."), null;
  },
  // Get point at relative position in curve according to arc length
  // - u [0 .. 1]
  getPointAt: function(e, n) {
    const t = this.getUtoTmapping(e);
    return this.getPoint(t, n);
  },
  // Get sequence of points using getPoint( t )
  getPoints: function(e) {
    e === void 0 && (e = 5);
    const n = [];
    for (let t = 0; t <= e; t++)
      n.push(this.getPoint(t / e));
    return n;
  },
  // Get sequence of points using getPointAt( u )
  getSpacedPoints: function(e) {
    e === void 0 && (e = 5);
    const n = [];
    for (let t = 0; t <= e; t++)
      n.push(this.getPointAt(t / e));
    return n;
  },
  // Get total curve arc length
  getLength: function() {
    const e = this.getLengths();
    return e[e.length - 1];
  },
  // Get list of cumulative segment lengths
  getLengths: function(e) {
    if (e === void 0 && (e = this.arcLengthDivisions), this.cacheArcLengths && this.cacheArcLengths.length === e + 1 && !this.needsUpdate)
      return this.cacheArcLengths;
    this.needsUpdate = !1;
    const n = [];
    let t, i = this.getPoint(0), r = 0;
    n.push(0);
    for (let a = 1; a <= e; a++)
      t = this.getPoint(a / e), r += t.distanceTo(i), n.push(r), i = t;
    return this.cacheArcLengths = n, n;
  },
  updateArcLengths: function() {
    this.needsUpdate = !0, this.getLengths();
  },
  // Given u ( 0 .. 1 ), get a t to find p. This gives you points which are equidistant
  getUtoTmapping: function(e, n) {
    const t = this.getLengths();
    let i = 0, r = t.length, a;
    n ? a = n : a = e * t[r - 1];
    let c = 0, u = r - 1, l;
    for (; c <= u; )
      if (i = Math.floor(c + (u - c) / 2), l = t[i] - a, l < 0)
        c = i + 1;
      else if (l > 0)
        u = i - 1;
      else {
        u = i;
        break;
      }
    if (i = u, t[i] === a)
      return i / (r - 1);
    const f = t[i], h = t[i + 1] - f, p = (a - f) / h;
    return (i + p) / (r - 1);
  },
  // Returns a unit vector tangent at t
  // In case any sub curve does not implement its tangent derivation,
  // 2 points a small delta apart will be used to find its gradient
  // which seems to give a reasonable approximation
  getTangent: function(e, n) {
    let i = e - 1e-4, r = e + 1e-4;
    i < 0 && (i = 0), r > 1 && (r = 1);
    const a = this.getPoint(i), c = this.getPoint(r), u = n || (a.isVector2 ? new vt() : new ve());
    return u.copy(c).sub(a).normalize(), u;
  },
  getTangentAt: function(e, n) {
    const t = this.getUtoTmapping(e);
    return this.getTangent(t, n);
  },
  computeFrenetFrames: function(e, n) {
    const t = new ve(), i = [], r = [], a = [], c = new ve(), u = new dn();
    for (let p = 0; p <= e; p++) {
      const _ = p / e;
      i[p] = this.getTangentAt(_, new ve()), i[p].normalize();
    }
    r[0] = new ve(), a[0] = new ve();
    let l = Number.MAX_VALUE;
    const f = Math.abs(i[0].x), m = Math.abs(i[0].y), h = Math.abs(i[0].z);
    f <= l && (l = f, t.set(1, 0, 0)), m <= l && (l = m, t.set(0, 1, 0)), h <= l && t.set(0, 0, 1), c.crossVectors(i[0], t).normalize(), r[0].crossVectors(i[0], c), a[0].crossVectors(i[0], r[0]);
    for (let p = 1; p <= e; p++) {
      if (r[p] = r[p - 1].clone(), a[p] = a[p - 1].clone(), c.crossVectors(i[p - 1], i[p]), c.length() > Number.EPSILON) {
        c.normalize();
        const _ = Math.acos(un.clamp(i[p - 1].dot(i[p]), -1, 1));
        r[p].applyMatrix4(u.makeRotationAxis(c, _));
      }
      a[p].crossVectors(i[p], r[p]);
    }
    if (n === !0) {
      let p = Math.acos(un.clamp(r[0].dot(r[e]), -1, 1));
      p /= e, i[0].dot(c.crossVectors(r[0], r[e])) > 0 && (p = -p);
      for (let _ = 1; _ <= e; _++)
        r[_].applyMatrix4(u.makeRotationAxis(i[_], p * _)), a[_].crossVectors(i[_], r[_]);
    }
    return {
      tangents: i,
      normals: r,
      binormals: a
    };
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.arcLengthDivisions = e.arcLengthDivisions, this;
  },
  toJSON: function() {
    const e = {
      metadata: {
        version: 4.5,
        type: "Curve",
        generator: "Curve.toJSON"
      }
    };
    return e.arcLengthDivisions = this.arcLengthDivisions, e.type = this.type, e;
  },
  fromJSON: function(e) {
    return this.arcLengthDivisions = e.arcLengthDivisions, this;
  }
});
function Ss(e, n, t, i, r, a, c, u) {
  Qt.call(this), this.type = "EllipseCurve", this.aX = e || 0, this.aY = n || 0, this.xRadius = t || 1, this.yRadius = i || 1, this.aStartAngle = r || 0, this.aEndAngle = a || 2 * Math.PI, this.aClockwise = c || !1, this.aRotation = u || 0;
}
Ss.prototype = Object.create(Qt.prototype);
Ss.prototype.constructor = Ss;
Ss.prototype.isEllipseCurve = !0;
Ss.prototype.getPoint = function(e, n) {
  const t = n || new vt(), i = Math.PI * 2;
  let r = this.aEndAngle - this.aStartAngle;
  const a = Math.abs(r) < Number.EPSILON;
  for (; r < 0; )
    r += i;
  for (; r > i; )
    r -= i;
  r < Number.EPSILON && (a ? r = 0 : r = i), this.aClockwise === !0 && !a && (r === i ? r = -i : r = r - i);
  const c = this.aStartAngle + e * r;
  let u = this.aX + this.xRadius * Math.cos(c), l = this.aY + this.yRadius * Math.sin(c);
  if (this.aRotation !== 0) {
    const f = Math.cos(this.aRotation), m = Math.sin(this.aRotation), h = u - this.aX, p = l - this.aY;
    u = h * f - p * m + this.aX, l = h * m + p * f + this.aY;
  }
  return t.set(u, l);
};
Ss.prototype.copy = function(e) {
  return Qt.prototype.copy.call(this, e), this.aX = e.aX, this.aY = e.aY, this.xRadius = e.xRadius, this.yRadius = e.yRadius, this.aStartAngle = e.aStartAngle, this.aEndAngle = e.aEndAngle, this.aClockwise = e.aClockwise, this.aRotation = e.aRotation, this;
};
Ss.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  return e.aX = this.aX, e.aY = this.aY, e.xRadius = this.xRadius, e.yRadius = this.yRadius, e.aStartAngle = this.aStartAngle, e.aEndAngle = this.aEndAngle, e.aClockwise = this.aClockwise, e.aRotation = this.aRotation, e;
};
Ss.prototype.fromJSON = function(e) {
  return Qt.prototype.fromJSON.call(this, e), this.aX = e.aX, this.aY = e.aY, this.xRadius = e.xRadius, this.yRadius = e.yRadius, this.aStartAngle = e.aStartAngle, this.aEndAngle = e.aEndAngle, this.aClockwise = e.aClockwise, this.aRotation = e.aRotation, this;
};
function tg(e, n, t, i, r, a) {
  Ss.call(this, e, n, t, t, i, r, a), this.type = "ArcCurve";
}
tg.prototype = Object.create(Ss.prototype);
tg.prototype.constructor = tg;
tg.prototype.isArcCurve = !0;
function z0() {
  let e = 0, n = 0, t = 0, i = 0;
  function r(a, c, u, l) {
    e = a, n = u, t = -3 * a + 3 * c - 2 * u - l, i = 2 * a - 2 * c + u + l;
  }
  return {
    initCatmullRom: function(a, c, u, l, f) {
      r(c, u, f * (u - a), f * (l - c));
    },
    initNonuniformCatmullRom: function(a, c, u, l, f, m, h) {
      let p = (c - a) / f - (u - a) / (f + m) + (u - c) / m, _ = (u - c) / m - (l - c) / (m + h) + (l - u) / h;
      p *= m, _ *= m, r(c, u, p, _);
    },
    calc: function(a) {
      const c = a * a, u = c * a;
      return e + n * a + t * c + i * u;
    }
  };
}
const k_ = new ve(), Ev = new z0(), Sv = new z0(), Pv = new z0();
function cs(e, n, t, i) {
  Qt.call(this), this.type = "CatmullRomCurve3", this.points = e || [], this.closed = n || !1, this.curveType = t || "centripetal", this.tension = i !== void 0 ? i : 0.5;
}
cs.prototype = Object.create(Qt.prototype);
cs.prototype.constructor = cs;
cs.prototype.isCatmullRomCurve3 = !0;
cs.prototype.getPoint = function(e, n) {
  const t = n || new ve(), i = this.points, r = i.length, a = (r - (this.closed ? 0 : 1)) * e;
  let c = Math.floor(a), u = a - c;
  this.closed ? c += c > 0 ? 0 : (Math.floor(Math.abs(c) / r) + 1) * r : u === 0 && c === r - 1 && (c = r - 2, u = 1);
  let l, f, m, h;
  if (this.closed || c > 0 ? l = i[(c - 1) % r] : (k_.subVectors(i[0], i[1]).add(i[0]), l = k_), f = i[c % r], m = i[(c + 1) % r], this.closed || c + 2 < r ? h = i[(c + 2) % r] : (k_.subVectors(i[r - 1], i[r - 2]).add(i[r - 1]), h = k_), this.curveType === "centripetal" || this.curveType === "chordal") {
    const p = this.curveType === "chordal" ? 0.5 : 0.25;
    let _ = Math.pow(l.distanceToSquared(f), p), v = Math.pow(f.distanceToSquared(m), p), S = Math.pow(m.distanceToSquared(h), p);
    v < 1e-4 && (v = 1), _ < 1e-4 && (_ = v), S < 1e-4 && (S = v), Ev.initNonuniformCatmullRom(l.x, f.x, m.x, h.x, _, v, S), Sv.initNonuniformCatmullRom(l.y, f.y, m.y, h.y, _, v, S), Pv.initNonuniformCatmullRom(l.z, f.z, m.z, h.z, _, v, S);
  } else
    this.curveType === "catmullrom" && (Ev.initCatmullRom(l.x, f.x, m.x, h.x, this.tension), Sv.initCatmullRom(l.y, f.y, m.y, h.y, this.tension), Pv.initCatmullRom(l.z, f.z, m.z, h.z, this.tension));
  return t.set(
    Ev.calc(u),
    Sv.calc(u),
    Pv.calc(u)
  ), t;
};
cs.prototype.copy = function(e) {
  Qt.prototype.copy.call(this, e), this.points = [];
  for (let n = 0, t = e.points.length; n < t; n++) {
    const i = e.points[n];
    this.points.push(i.clone());
  }
  return this.closed = e.closed, this.curveType = e.curveType, this.tension = e.tension, this;
};
cs.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  e.points = [];
  for (let n = 0, t = this.points.length; n < t; n++) {
    const i = this.points[n];
    e.points.push(i.toArray());
  }
  return e.closed = this.closed, e.curveType = this.curveType, e.tension = this.tension, e;
};
cs.prototype.fromJSON = function(e) {
  Qt.prototype.fromJSON.call(this, e), this.points = [];
  for (let n = 0, t = e.points.length; n < t; n++) {
    const i = e.points[n];
    this.points.push(new ve().fromArray(i));
  }
  return this.closed = e.closed, this.curveType = e.curveType, this.tension = e.tension, this;
};
function Jw(e, n, t, i, r) {
  const a = (i - n) * 0.5, c = (r - t) * 0.5, u = e * e, l = e * u;
  return (2 * t - 2 * i + a + c) * l + (-3 * t + 3 * i - 2 * a - c) * u + a * e + t;
}
function ZS(e, n) {
  const t = 1 - e;
  return t * t * n;
}
function eP(e, n) {
  return 2 * (1 - e) * e * n;
}
function tP(e, n) {
  return e * e * n;
}
function Em(e, n, t, i) {
  return ZS(e, n) + eP(e, t) + tP(e, i);
}
function nP(e, n) {
  const t = 1 - e;
  return t * t * t * n;
}
function iP(e, n) {
  const t = 1 - e;
  return 3 * t * t * e * n;
}
function sP(e, n) {
  return 3 * (1 - e) * e * e * n;
}
function rP(e, n) {
  return e * e * e * n;
}
function Sm(e, n, t, i, r) {
  return nP(e, n) + iP(e, t) + sP(e, i) + rP(e, r);
}
function dr(e, n, t, i) {
  Qt.call(this), this.type = "CubicBezierCurve", this.v0 = e || new vt(), this.v1 = n || new vt(), this.v2 = t || new vt(), this.v3 = i || new vt();
}
dr.prototype = Object.create(Qt.prototype);
dr.prototype.constructor = dr;
dr.prototype.isCubicBezierCurve = !0;
dr.prototype.getPoint = function(e, n) {
  const t = n || new vt(), i = this.v0, r = this.v1, a = this.v2, c = this.v3;
  return t.set(
    Sm(e, i.x, r.x, a.x, c.x),
    Sm(e, i.y, r.y, a.y, c.y)
  ), t;
};
dr.prototype.copy = function(e) {
  return Qt.prototype.copy.call(this, e), this.v0.copy(e.v0), this.v1.copy(e.v1), this.v2.copy(e.v2), this.v3.copy(e.v3), this;
};
dr.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  return e.v0 = this.v0.toArray(), e.v1 = this.v1.toArray(), e.v2 = this.v2.toArray(), e.v3 = this.v3.toArray(), e;
};
dr.prototype.fromJSON = function(e) {
  return Qt.prototype.fromJSON.call(this, e), this.v0.fromArray(e.v0), this.v1.fromArray(e.v1), this.v2.fromArray(e.v2), this.v3.fromArray(e.v3), this;
};
function Dr(e, n, t, i) {
  Qt.call(this), this.type = "CubicBezierCurve3", this.v0 = e || new ve(), this.v1 = n || new ve(), this.v2 = t || new ve(), this.v3 = i || new ve();
}
Dr.prototype = Object.create(Qt.prototype);
Dr.prototype.constructor = Dr;
Dr.prototype.isCubicBezierCurve3 = !0;
Dr.prototype.getPoint = function(e, n) {
  const t = n || new ve(), i = this.v0, r = this.v1, a = this.v2, c = this.v3;
  return t.set(
    Sm(e, i.x, r.x, a.x, c.x),
    Sm(e, i.y, r.y, a.y, c.y),
    Sm(e, i.z, r.z, a.z, c.z)
  ), t;
};
Dr.prototype.copy = function(e) {
  return Qt.prototype.copy.call(this, e), this.v0.copy(e.v0), this.v1.copy(e.v1), this.v2.copy(e.v2), this.v3.copy(e.v3), this;
};
Dr.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  return e.v0 = this.v0.toArray(), e.v1 = this.v1.toArray(), e.v2 = this.v2.toArray(), e.v3 = this.v3.toArray(), e;
};
Dr.prototype.fromJSON = function(e) {
  return Qt.prototype.fromJSON.call(this, e), this.v0.fromArray(e.v0), this.v1.fromArray(e.v1), this.v2.fromArray(e.v2), this.v3.fromArray(e.v3), this;
};
function us(e, n) {
  Qt.call(this), this.type = "LineCurve", this.v1 = e || new vt(), this.v2 = n || new vt();
}
us.prototype = Object.create(Qt.prototype);
us.prototype.constructor = us;
us.prototype.isLineCurve = !0;
us.prototype.getPoint = function(e, n) {
  const t = n || new vt();
  return e === 1 ? t.copy(this.v2) : (t.copy(this.v2).sub(this.v1), t.multiplyScalar(e).add(this.v1)), t;
};
us.prototype.getPointAt = function(e, n) {
  return this.getPoint(e, n);
};
us.prototype.getTangent = function(e, n) {
  const t = n || new vt();
  return t.copy(this.v2).sub(this.v1).normalize(), t;
};
us.prototype.copy = function(e) {
  return Qt.prototype.copy.call(this, e), this.v1.copy(e.v1), this.v2.copy(e.v2), this;
};
us.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  return e.v1 = this.v1.toArray(), e.v2 = this.v2.toArray(), e;
};
us.prototype.fromJSON = function(e) {
  return Qt.prototype.fromJSON.call(this, e), this.v1.fromArray(e.v1), this.v2.fromArray(e.v2), this;
};
function hr(e, n) {
  Qt.call(this), this.type = "LineCurve3", this.v1 = e || new ve(), this.v2 = n || new ve();
}
hr.prototype = Object.create(Qt.prototype);
hr.prototype.constructor = hr;
hr.prototype.isLineCurve3 = !0;
hr.prototype.getPoint = function(e, n) {
  const t = n || new ve();
  return e === 1 ? t.copy(this.v2) : (t.copy(this.v2).sub(this.v1), t.multiplyScalar(e).add(this.v1)), t;
};
hr.prototype.getPointAt = function(e, n) {
  return this.getPoint(e, n);
};
hr.prototype.copy = function(e) {
  return Qt.prototype.copy.call(this, e), this.v1.copy(e.v1), this.v2.copy(e.v2), this;
};
hr.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  return e.v1 = this.v1.toArray(), e.v2 = this.v2.toArray(), e;
};
hr.prototype.fromJSON = function(e) {
  return Qt.prototype.fromJSON.call(this, e), this.v1.fromArray(e.v1), this.v2.fromArray(e.v2), this;
};
function fr(e, n, t) {
  Qt.call(this), this.type = "QuadraticBezierCurve", this.v0 = e || new vt(), this.v1 = n || new vt(), this.v2 = t || new vt();
}
fr.prototype = Object.create(Qt.prototype);
fr.prototype.constructor = fr;
fr.prototype.isQuadraticBezierCurve = !0;
fr.prototype.getPoint = function(e, n) {
  const t = n || new vt(), i = this.v0, r = this.v1, a = this.v2;
  return t.set(
    Em(e, i.x, r.x, a.x),
    Em(e, i.y, r.y, a.y)
  ), t;
};
fr.prototype.copy = function(e) {
  return Qt.prototype.copy.call(this, e), this.v0.copy(e.v0), this.v1.copy(e.v1), this.v2.copy(e.v2), this;
};
fr.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  return e.v0 = this.v0.toArray(), e.v1 = this.v1.toArray(), e.v2 = this.v2.toArray(), e;
};
fr.prototype.fromJSON = function(e) {
  return Qt.prototype.fromJSON.call(this, e), this.v0.fromArray(e.v0), this.v1.fromArray(e.v1), this.v2.fromArray(e.v2), this;
};
function kr(e, n, t) {
  Qt.call(this), this.type = "QuadraticBezierCurve3", this.v0 = e || new ve(), this.v1 = n || new ve(), this.v2 = t || new ve();
}
kr.prototype = Object.create(Qt.prototype);
kr.prototype.constructor = kr;
kr.prototype.isQuadraticBezierCurve3 = !0;
kr.prototype.getPoint = function(e, n) {
  const t = n || new ve(), i = this.v0, r = this.v1, a = this.v2;
  return t.set(
    Em(e, i.x, r.x, a.x),
    Em(e, i.y, r.y, a.y),
    Em(e, i.z, r.z, a.z)
  ), t;
};
kr.prototype.copy = function(e) {
  return Qt.prototype.copy.call(this, e), this.v0.copy(e.v0), this.v1.copy(e.v1), this.v2.copy(e.v2), this;
};
kr.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  return e.v0 = this.v0.toArray(), e.v1 = this.v1.toArray(), e.v2 = this.v2.toArray(), e;
};
kr.prototype.fromJSON = function(e) {
  return Qt.prototype.fromJSON.call(this, e), this.v0.fromArray(e.v0), this.v1.fromArray(e.v1), this.v2.fromArray(e.v2), this;
};
function pr(e) {
  Qt.call(this), this.type = "SplineCurve", this.points = e || [];
}
pr.prototype = Object.create(Qt.prototype);
pr.prototype.constructor = pr;
pr.prototype.isSplineCurve = !0;
pr.prototype.getPoint = function(e, n) {
  const t = n || new vt(), i = this.points, r = (i.length - 1) * e, a = Math.floor(r), c = r - a, u = i[a === 0 ? a : a - 1], l = i[a], f = i[a > i.length - 2 ? i.length - 1 : a + 1], m = i[a > i.length - 3 ? i.length - 1 : a + 2];
  return t.set(
    Jw(c, u.x, l.x, f.x, m.x),
    Jw(c, u.y, l.y, f.y, m.y)
  ), t;
};
pr.prototype.copy = function(e) {
  Qt.prototype.copy.call(this, e), this.points = [];
  for (let n = 0, t = e.points.length; n < t; n++) {
    const i = e.points[n];
    this.points.push(i.clone());
  }
  return this;
};
pr.prototype.toJSON = function() {
  const e = Qt.prototype.toJSON.call(this);
  e.points = [];
  for (let n = 0, t = this.points.length; n < t; n++) {
    const i = this.points[n];
    e.points.push(i.toArray());
  }
  return e;
};
pr.prototype.fromJSON = function(e) {
  Qt.prototype.fromJSON.call(this, e), this.points = [];
  for (let n = 0, t = e.points.length; n < t; n++) {
    const i = e.points[n];
    this.points.push(new vt().fromArray(i));
  }
  return this;
};
var l0 = /* @__PURE__ */ Object.freeze({
  __proto__: null,
  ArcCurve: tg,
  CatmullRomCurve3: cs,
  CubicBezierCurve: dr,
  CubicBezierCurve3: Dr,
  EllipseCurve: Ss,
  LineCurve: us,
  LineCurve3: hr,
  QuadraticBezierCurve: fr,
  QuadraticBezierCurve3: kr,
  SplineCurve: pr
});
function lo() {
  Qt.call(this), this.type = "CurvePath", this.curves = [], this.autoClose = !1;
}
lo.prototype = Object.assign(Object.create(Qt.prototype), {
  constructor: lo,
  add: function(e) {
    this.curves.push(e);
  },
  closePath: function() {
    const e = this.curves[0].getPoint(0), n = this.curves[this.curves.length - 1].getPoint(1);
    e.equals(n) || this.curves.push(new us(n, e));
  },
  // To get accurate point with reference to
  // entire path distance at time t,
  // following has to be done:
  // 1. Length of each sub path have to be known
  // 2. Locate and identify type of curve
  // 3. Get t for the curve
  // 4. Return curve.getPointAt(t')
  getPoint: function(e) {
    const n = e * this.getLength(), t = this.getCurveLengths();
    let i = 0;
    for (; i < t.length; ) {
      if (t[i] >= n) {
        const r = t[i] - n, a = this.curves[i], c = a.getLength(), u = c === 0 ? 0 : 1 - r / c;
        return a.getPointAt(u);
      }
      i++;
    }
    return null;
  },
  // We cannot use the default THREE.Curve getPoint() with getLength() because in
  // THREE.Curve, getLength() depends on getPoint() but in THREE.CurvePath
  // getPoint() depends on getLength
  getLength: function() {
    const e = this.getCurveLengths();
    return e[e.length - 1];
  },
  // cacheLengths must be recalculated.
  updateArcLengths: function() {
    this.needsUpdate = !0, this.cacheLengths = null, this.getCurveLengths();
  },
  // Compute lengths and cache them
  // We cannot overwrite getLengths() because UtoT mapping uses it.
  getCurveLengths: function() {
    if (this.cacheLengths && this.cacheLengths.length === this.curves.length)
      return this.cacheLengths;
    const e = [];
    let n = 0;
    for (let t = 0, i = this.curves.length; t < i; t++)
      n += this.curves[t].getLength(), e.push(n);
    return this.cacheLengths = e, e;
  },
  getSpacedPoints: function(e) {
    e === void 0 && (e = 40);
    const n = [];
    for (let t = 0; t <= e; t++)
      n.push(this.getPoint(t / e));
    return this.autoClose && n.push(n[0]), n;
  },
  getPoints: function(e) {
    e = e || 12;
    const n = [];
    let t;
    for (let i = 0, r = this.curves; i < r.length; i++) {
      const a = r[i], c = a && a.isEllipseCurve ? e * 2 : a && (a.isLineCurve || a.isLineCurve3) ? 1 : a && a.isSplineCurve ? e * a.points.length : e, u = a.getPoints(c);
      for (let l = 0; l < u.length; l++) {
        const f = u[l];
        t && t.equals(f) || (n.push(f), t = f);
      }
    }
    return this.autoClose && n.length > 1 && !n[n.length - 1].equals(n[0]) && n.push(n[0]), n;
  },
  copy: function(e) {
    Qt.prototype.copy.call(this, e), this.curves = [];
    for (let n = 0, t = e.curves.length; n < t; n++) {
      const i = e.curves[n];
      this.curves.push(i.clone());
    }
    return this.autoClose = e.autoClose, this;
  },
  toJSON: function() {
    const e = Qt.prototype.toJSON.call(this);
    e.autoClose = this.autoClose, e.curves = [];
    for (let n = 0, t = this.curves.length; n < t; n++) {
      const i = this.curves[n];
      e.curves.push(i.toJSON());
    }
    return e;
  },
  fromJSON: function(e) {
    Qt.prototype.fromJSON.call(this, e), this.autoClose = e.autoClose, this.curves = [];
    for (let n = 0, t = e.curves.length; n < t; n++) {
      const i = e.curves[n];
      this.curves.push(new l0[i.type]().fromJSON(i));
    }
    return this;
  }
});
function lr(e) {
  lo.call(this), this.type = "Path", this.currentPoint = new vt(), e && this.setFromPoints(e);
}
lr.prototype = Object.assign(Object.create(lo.prototype), {
  constructor: lr,
  setFromPoints: function(e) {
    this.moveTo(e[0].x, e[0].y);
    for (let n = 1, t = e.length; n < t; n++)
      this.lineTo(e[n].x, e[n].y);
    return this;
  },
  moveTo: function(e, n) {
    return this.currentPoint.set(e, n), this;
  },
  lineTo: function(e, n) {
    const t = new us(this.currentPoint.clone(), new vt(e, n));
    return this.curves.push(t), this.currentPoint.set(e, n), this;
  },
  quadraticCurveTo: function(e, n, t, i) {
    const r = new fr(
      this.currentPoint.clone(),
      new vt(e, n),
      new vt(t, i)
    );
    return this.curves.push(r), this.currentPoint.set(t, i), this;
  },
  bezierCurveTo: function(e, n, t, i, r, a) {
    const c = new dr(
      this.currentPoint.clone(),
      new vt(e, n),
      new vt(t, i),
      new vt(r, a)
    );
    return this.curves.push(c), this.currentPoint.set(r, a), this;
  },
  splineThru: function(e) {
    const n = [this.currentPoint.clone()].concat(e), t = new pr(n);
    return this.curves.push(t), this.currentPoint.copy(e[e.length - 1]), this;
  },
  arc: function(e, n, t, i, r, a) {
    const c = this.currentPoint.x, u = this.currentPoint.y;
    return this.absarc(
      e + c,
      n + u,
      t,
      i,
      r,
      a
    ), this;
  },
  absarc: function(e, n, t, i, r, a) {
    return this.absellipse(e, n, t, t, i, r, a), this;
  },
  ellipse: function(e, n, t, i, r, a, c, u) {
    const l = this.currentPoint.x, f = this.currentPoint.y;
    return this.absellipse(e + l, n + f, t, i, r, a, c, u), this;
  },
  absellipse: function(e, n, t, i, r, a, c, u) {
    const l = new Ss(e, n, t, i, r, a, c, u);
    if (this.curves.length > 0) {
      const m = l.getPoint(0);
      m.equals(this.currentPoint) || this.lineTo(m.x, m.y);
    }
    this.curves.push(l);
    const f = l.getPoint(1);
    return this.currentPoint.copy(f), this;
  },
  copy: function(e) {
    return lo.prototype.copy.call(this, e), this.currentPoint.copy(e.currentPoint), this;
  },
  toJSON: function() {
    const e = lo.prototype.toJSON.call(this);
    return e.currentPoint = this.currentPoint.toArray(), e;
  },
  fromJSON: function(e) {
    return lo.prototype.fromJSON.call(this, e), this.currentPoint.fromArray(e.currentPoint), this;
  }
});
function ma(e) {
  lr.call(this, e), this.uuid = un.generateUUID(), this.type = "Shape", this.holes = [];
}
ma.prototype = Object.assign(Object.create(lr.prototype), {
  constructor: ma,
  getPointsHoles: function(e) {
    const n = [];
    for (let t = 0, i = this.holes.length; t < i; t++)
      n[t] = this.holes[t].getPoints(e);
    return n;
  },
  // get points of shape and holes (keypoints based on segments parameter)
  extractPoints: function(e) {
    return {
      shape: this.getPoints(e),
      holes: this.getPointsHoles(e)
    };
  },
  copy: function(e) {
    lr.prototype.copy.call(this, e), this.holes = [];
    for (let n = 0, t = e.holes.length; n < t; n++) {
      const i = e.holes[n];
      this.holes.push(i.clone());
    }
    return this;
  },
  toJSON: function() {
    const e = lr.prototype.toJSON.call(this);
    e.uuid = this.uuid, e.holes = [];
    for (let n = 0, t = this.holes.length; n < t; n++) {
      const i = this.holes[n];
      e.holes.push(i.toJSON());
    }
    return e;
  },
  fromJSON: function(e) {
    lr.prototype.fromJSON.call(this, e), this.uuid = e.uuid, this.holes = [];
    for (let n = 0, t = e.holes.length; n < t; n++) {
      const i = e.holes[n];
      this.holes.push(new lr().fromJSON(i));
    }
    return this;
  }
});
function Nn(e, n) {
  Ft.call(this), this.type = "Light", this.color = new Wt(e), this.intensity = n !== void 0 ? n : 1, this.receiveShadow = void 0;
}
Nn.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: Nn,
  isLight: !0,
  copy: function(e) {
    return Ft.prototype.copy.call(this, e), this.color.copy(e.color), this.intensity = e.intensity, this;
  },
  toJSON: function(e) {
    const n = Ft.prototype.toJSON.call(this, e);
    return n.object.color = this.color.getHex(), n.object.intensity = this.intensity, this.groundColor !== void 0 && (n.object.groundColor = this.groundColor.getHex()), this.distance !== void 0 && (n.object.distance = this.distance), this.angle !== void 0 && (n.object.angle = this.angle), this.decay !== void 0 && (n.object.decay = this.decay), this.penumbra !== void 0 && (n.object.penumbra = this.penumbra), this.shadow !== void 0 && (n.object.shadow = this.shadow.toJSON()), n;
  }
});
function c0(e, n, t) {
  Nn.call(this, e, t), this.type = "HemisphereLight", this.castShadow = void 0, this.position.copy(Ft.DefaultUp), this.updateMatrix(), this.groundColor = new Wt(n);
}
c0.prototype = Object.assign(Object.create(Nn.prototype), {
  constructor: c0,
  isHemisphereLight: !0,
  copy: function(e) {
    return Nn.prototype.copy.call(this, e), this.groundColor.copy(e.groundColor), this;
  }
});
function Or(e) {
  this.camera = e, this.bias = 0, this.normalBias = 0, this.radius = 1, this.mapSize = new vt(512, 512), this.map = null, this.mapPass = null, this.matrix = new dn(), this.autoUpdate = !0, this.needsUpdate = !1, this._frustum = new hg(), this._frameExtents = new vt(1, 1), this._viewportCount = 1, this._viewports = [
    new In(0, 0, 1, 1)
  ];
}
Object.assign(Or.prototype, {
  _projScreenMatrix: new dn(),
  _lightPositionWorld: new ve(),
  _lookTarget: new ve(),
  getViewportCount: function() {
    return this._viewportCount;
  },
  getFrustum: function() {
    return this._frustum;
  },
  updateMatrices: function(e) {
    const n = this.camera, t = this.matrix, i = this._projScreenMatrix, r = this._lookTarget, a = this._lightPositionWorld;
    a.setFromMatrixPosition(e.matrixWorld), n.position.copy(a), r.setFromMatrixPosition(e.target.matrixWorld), n.lookAt(r), n.updateMatrixWorld(), i.multiplyMatrices(n.projectionMatrix, n.matrixWorldInverse), this._frustum.setFromProjectionMatrix(i), t.set(
      0.5,
      0,
      0,
      0.5,
      0,
      0.5,
      0,
      0.5,
      0,
      0,
      0.5,
      0.5,
      0,
      0,
      0,
      1
    ), t.multiply(n.projectionMatrix), t.multiply(n.matrixWorldInverse);
  },
  getViewport: function(e) {
    return this._viewports[e];
  },
  getFrameExtents: function() {
    return this._frameExtents;
  },
  copy: function(e) {
    return this.camera = e.camera.clone(), this.bias = e.bias, this.radius = e.radius, this.mapSize.copy(e.mapSize), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  toJSON: function() {
    const e = {};
    return this.bias !== 0 && (e.bias = this.bias), this.normalBias !== 0 && (e.normalBias = this.normalBias), this.radius !== 1 && (e.radius = this.radius), (this.mapSize.x !== 512 || this.mapSize.y !== 512) && (e.mapSize = this.mapSize.toArray()), e.camera = this.camera.toJSON(!1).object, delete e.camera.matrix, e;
  }
});
function u0() {
  Or.call(this, new oi(50, 1, 0.5, 500));
}
u0.prototype = Object.assign(Object.create(Or.prototype), {
  constructor: u0,
  isSpotLightShadow: !0,
  updateMatrices: function(e) {
    const n = this.camera, t = un.RAD2DEG * 2 * e.angle, i = this.mapSize.width / this.mapSize.height, r = e.distance || n.far;
    (t !== n.fov || i !== n.aspect || r !== n.far) && (n.fov = t, n.aspect = i, n.far = r, n.updateProjectionMatrix()), Or.prototype.updateMatrices.call(this, e);
  }
});
function d0(e, n, t, i, r, a) {
  Nn.call(this, e, n), this.type = "SpotLight", this.position.copy(Ft.DefaultUp), this.updateMatrix(), this.target = new Ft(), Object.defineProperty(this, "power", {
    get: function() {
      return this.intensity * Math.PI;
    },
    set: function(c) {
      this.intensity = c / Math.PI;
    }
  }), this.distance = t !== void 0 ? t : 0, this.angle = i !== void 0 ? i : Math.PI / 3, this.penumbra = r !== void 0 ? r : 0, this.decay = a !== void 0 ? a : 1, this.shadow = new u0();
}
d0.prototype = Object.assign(Object.create(Nn.prototype), {
  constructor: d0,
  isSpotLight: !0,
  copy: function(e) {
    return Nn.prototype.copy.call(this, e), this.distance = e.distance, this.angle = e.angle, this.penumbra = e.penumbra, this.decay = e.decay, this.target = e.target.clone(), this.shadow = e.shadow.clone(), this;
  }
});
function h0() {
  Or.call(this, new oi(90, 1, 0.5, 500)), this._frameExtents = new vt(4, 2), this._viewportCount = 6, this._viewports = [
    // These viewports map a cube-map onto a 2D texture with the
    // following orientation:
    //
    //  xzXZ
    //   y Y
    //
    // X - Positive x direction
    // x - Negative x direction
    // Y - Positive y direction
    // y - Negative y direction
    // Z - Positive z direction
    // z - Negative z direction
    // positive X
    new In(2, 1, 1, 1),
    // negative X
    new In(0, 1, 1, 1),
    // positive Z
    new In(3, 1, 1, 1),
    // negative Z
    new In(1, 1, 1, 1),
    // positive Y
    new In(3, 0, 1, 1),
    // negative Y
    new In(1, 0, 1, 1)
  ], this._cubeDirections = [
    new ve(1, 0, 0),
    new ve(-1, 0, 0),
    new ve(0, 0, 1),
    new ve(0, 0, -1),
    new ve(0, 1, 0),
    new ve(0, -1, 0)
  ], this._cubeUps = [
    new ve(0, 1, 0),
    new ve(0, 1, 0),
    new ve(0, 1, 0),
    new ve(0, 1, 0),
    new ve(0, 0, 1),
    new ve(0, 0, -1)
  ];
}
h0.prototype = Object.assign(Object.create(Or.prototype), {
  constructor: h0,
  isPointLightShadow: !0,
  updateMatrices: function(e, n) {
    n === void 0 && (n = 0);
    const t = this.camera, i = this.matrix, r = this._lightPositionWorld, a = this._lookTarget, c = this._projScreenMatrix;
    r.setFromMatrixPosition(e.matrixWorld), t.position.copy(r), a.copy(t.position), a.add(this._cubeDirections[n]), t.up.copy(this._cubeUps[n]), t.lookAt(a), t.updateMatrixWorld(), i.makeTranslation(-r.x, -r.y, -r.z), c.multiplyMatrices(t.projectionMatrix, t.matrixWorldInverse), this._frustum.setFromProjectionMatrix(c);
  }
});
function f0(e, n, t, i) {
  Nn.call(this, e, n), this.type = "PointLight", Object.defineProperty(this, "power", {
    get: function() {
      return this.intensity * 4 * Math.PI;
    },
    set: function(r) {
      this.intensity = r / (4 * Math.PI);
    }
  }), this.distance = t !== void 0 ? t : 0, this.decay = i !== void 0 ? i : 1, this.shadow = new h0();
}
f0.prototype = Object.assign(Object.create(Nn.prototype), {
  constructor: f0,
  isPointLight: !0,
  copy: function(e) {
    return Nn.prototype.copy.call(this, e), this.distance = e.distance, this.decay = e.decay, this.shadow = e.shadow.clone(), this;
  }
});
function ng(e, n, t, i, r, a) {
  Ir.call(this), this.type = "OrthographicCamera", this.zoom = 1, this.view = null, this.left = e !== void 0 ? e : -1, this.right = n !== void 0 ? n : 1, this.top = t !== void 0 ? t : 1, this.bottom = i !== void 0 ? i : -1, this.near = r !== void 0 ? r : 0.1, this.far = a !== void 0 ? a : 2e3, this.updateProjectionMatrix();
}
ng.prototype = Object.assign(Object.create(Ir.prototype), {
  constructor: ng,
  isOrthographicCamera: !0,
  copy: function(e, n) {
    return Ir.prototype.copy.call(this, e, n), this.left = e.left, this.right = e.right, this.top = e.top, this.bottom = e.bottom, this.near = e.near, this.far = e.far, this.zoom = e.zoom, this.view = e.view === null ? null : Object.assign({}, e.view), this;
  },
  setViewOffset: function(e, n, t, i, r, a) {
    this.view === null && (this.view = {
      enabled: !0,
      fullWidth: 1,
      fullHeight: 1,
      offsetX: 0,
      offsetY: 0,
      width: 1,
      height: 1
    }), this.view.enabled = !0, this.view.fullWidth = e, this.view.fullHeight = n, this.view.offsetX = t, this.view.offsetY = i, this.view.width = r, this.view.height = a, this.updateProjectionMatrix();
  },
  clearViewOffset: function() {
    this.view !== null && (this.view.enabled = !1), this.updateProjectionMatrix();
  },
  updateProjectionMatrix: function() {
    const e = (this.right - this.left) / (2 * this.zoom), n = (this.top - this.bottom) / (2 * this.zoom), t = (this.right + this.left) / 2, i = (this.top + this.bottom) / 2;
    let r = t - e, a = t + e, c = i + n, u = i - n;
    if (this.view !== null && this.view.enabled) {
      const l = (this.right - this.left) / this.view.fullWidth / this.zoom, f = (this.top - this.bottom) / this.view.fullHeight / this.zoom;
      r += l * this.view.offsetX, a = r + l * this.view.width, c -= f * this.view.offsetY, u = c - f * this.view.height;
    }
    this.projectionMatrix.makeOrthographic(r, a, c, u, this.near, this.far), this.projectionMatrixInverse.getInverse(this.projectionMatrix);
  },
  toJSON: function(e) {
    const n = Ft.prototype.toJSON.call(this, e);
    return n.object.zoom = this.zoom, n.object.left = this.left, n.object.right = this.right, n.object.top = this.top, n.object.bottom = this.bottom, n.object.near = this.near, n.object.far = this.far, this.view !== null && (n.object.view = Object.assign({}, this.view)), n;
  }
});
function p0() {
  Or.call(this, new ng(-5, 5, 5, -5, 0.5, 500));
}
p0.prototype = Object.assign(Object.create(Or.prototype), {
  constructor: p0,
  isDirectionalLightShadow: !0,
  updateMatrices: function(e) {
    Or.prototype.updateMatrices.call(this, e);
  }
});
function m0(e, n) {
  Nn.call(this, e, n), this.type = "DirectionalLight", this.position.copy(Ft.DefaultUp), this.updateMatrix(), this.target = new Ft(), this.shadow = new p0();
}
m0.prototype = Object.assign(Object.create(Nn.prototype), {
  constructor: m0,
  isDirectionalLight: !0,
  copy: function(e) {
    return Nn.prototype.copy.call(this, e), this.target = e.target.clone(), this.shadow = e.shadow.clone(), this;
  }
});
function Sy(e, n) {
  Nn.call(this, e, n), this.type = "AmbientLight", this.castShadow = void 0;
}
Sy.prototype = Object.assign(Object.create(Nn.prototype), {
  constructor: Sy,
  isAmbientLight: !0
});
function g0(e, n, t, i) {
  Nn.call(this, e, n), this.type = "RectAreaLight", this.width = t !== void 0 ? t : 10, this.height = i !== void 0 ? i : 10;
}
g0.prototype = Object.assign(Object.create(Nn.prototype), {
  constructor: g0,
  isRectAreaLight: !0,
  copy: function(e) {
    return Nn.prototype.copy.call(this, e), this.width = e.width, this.height = e.height, this;
  },
  toJSON: function(e) {
    const n = Nn.prototype.toJSON.call(this, e);
    return n.object.width = this.width, n.object.height = this.height, n;
  }
});
function $0() {
  this.coefficients = [];
  for (let e = 0; e < 9; e++)
    this.coefficients.push(new ve());
}
Object.assign($0.prototype, {
  isSphericalHarmonics3: !0,
  set: function(e) {
    for (let n = 0; n < 9; n++)
      this.coefficients[n].copy(e[n]);
    return this;
  },
  zero: function() {
    for (let e = 0; e < 9; e++)
      this.coefficients[e].set(0, 0, 0);
    return this;
  },
  // get the radiance in the direction of the normal
  // target is a Vector3
  getAt: function(e, n) {
    const t = e.x, i = e.y, r = e.z, a = this.coefficients;
    return n.copy(a[0]).multiplyScalar(0.282095), n.addScaledVector(a[1], 0.488603 * i), n.addScaledVector(a[2], 0.488603 * r), n.addScaledVector(a[3], 0.488603 * t), n.addScaledVector(a[4], 1.092548 * (t * i)), n.addScaledVector(a[5], 1.092548 * (i * r)), n.addScaledVector(a[6], 0.315392 * (3 * r * r - 1)), n.addScaledVector(a[7], 1.092548 * (t * r)), n.addScaledVector(a[8], 0.546274 * (t * t - i * i)), n;
  },
  // get the irradiance (radiance convolved with cosine lobe) in the direction of the normal
  // target is a Vector3
  // https://graphics.stanford.edu/papers/envmap/envmap.pdf
  getIrradianceAt: function(e, n) {
    const t = e.x, i = e.y, r = e.z, a = this.coefficients;
    return n.copy(a[0]).multiplyScalar(0.886227), n.addScaledVector(a[1], 2 * 0.511664 * i), n.addScaledVector(a[2], 2 * 0.511664 * r), n.addScaledVector(a[3], 2 * 0.511664 * t), n.addScaledVector(a[4], 2 * 0.429043 * t * i), n.addScaledVector(a[5], 2 * 0.429043 * i * r), n.addScaledVector(a[6], 0.743125 * r * r - 0.247708), n.addScaledVector(a[7], 2 * 0.429043 * t * r), n.addScaledVector(a[8], 0.429043 * (t * t - i * i)), n;
  },
  add: function(e) {
    for (let n = 0; n < 9; n++)
      this.coefficients[n].add(e.coefficients[n]);
    return this;
  },
  addScaledSH: function(e, n) {
    for (let t = 0; t < 9; t++)
      this.coefficients[t].addScaledVector(e.coefficients[t], n);
    return this;
  },
  scale: function(e) {
    for (let n = 0; n < 9; n++)
      this.coefficients[n].multiplyScalar(e);
    return this;
  },
  lerp: function(e, n) {
    for (let t = 0; t < 9; t++)
      this.coefficients[t].lerp(e.coefficients[t], n);
    return this;
  },
  equals: function(e) {
    for (let n = 0; n < 9; n++)
      if (!this.coefficients[n].equals(e.coefficients[n]))
        return !1;
    return !0;
  },
  copy: function(e) {
    return this.set(e.coefficients);
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  fromArray: function(e, n) {
    n === void 0 && (n = 0);
    const t = this.coefficients;
    for (let i = 0; i < 9; i++)
      t[i].fromArray(e, n + i * 3);
    return this;
  },
  toArray: function(e, n) {
    e === void 0 && (e = []), n === void 0 && (n = 0);
    const t = this.coefficients;
    for (let i = 0; i < 9; i++)
      t[i].toArray(e, n + i * 3);
    return e;
  }
});
Object.assign($0, {
  // evaluate the basis functions
  // shBasis is an Array[ 9 ]
  getBasisAt: function(e, n) {
    const t = e.x, i = e.y, r = e.z;
    n[0] = 0.282095, n[1] = 0.488603 * i, n[2] = 0.488603 * r, n[3] = 0.488603 * t, n[4] = 1.092548 * t * i, n[5] = 1.092548 * i * r, n[6] = 0.315392 * (3 * r * r - 1), n[7] = 1.092548 * t * r, n[8] = 0.546274 * (t * t - i * i);
  }
});
function Us(e, n) {
  Nn.call(this, void 0, n), this.type = "LightProbe", this.sh = e !== void 0 ? e : new $0();
}
Us.prototype = Object.assign(Object.create(Nn.prototype), {
  constructor: Us,
  isLightProbe: !0,
  copy: function(e) {
    return Nn.prototype.copy.call(this, e), this.sh.copy(e.sh), this;
  },
  fromJSON: function(e) {
    return this.intensity = e.intensity, this.sh.fromArray(e.sh), this;
  },
  toJSON: function(e) {
    const n = Nn.prototype.toJSON.call(this, e);
    return n.object.sh = this.sh.toArray(), n;
  }
});
function Py(e) {
  Tn.call(this, e), this.textures = {};
}
Py.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: Py,
  load: function(e, n, t, i) {
    const r = this, a = new js(r.manager);
    a.setPath(r.path), a.setRequestHeader(r.requestHeader), a.load(e, function(c) {
      try {
        n(r.parse(JSON.parse(c)));
      } catch (u) {
        i ? i(u) : console.error(u), r.manager.itemError(e);
      }
    }, t, i);
  },
  parse: function(e) {
    const n = this.textures;
    function t(r) {
      return n[r] === void 0 && console.warn("THREE.MaterialLoader: Undefined texture", r), n[r];
    }
    const i = new XS[e.type]();
    if (e.uuid !== void 0 && (i.uuid = e.uuid), e.name !== void 0 && (i.name = e.name), e.color !== void 0 && i.color.setHex(e.color), e.roughness !== void 0 && (i.roughness = e.roughness), e.metalness !== void 0 && (i.metalness = e.metalness), e.sheen !== void 0 && (i.sheen = new Wt().setHex(e.sheen)), e.emissive !== void 0 && i.emissive.setHex(e.emissive), e.specular !== void 0 && i.specular.setHex(e.specular), e.shininess !== void 0 && (i.shininess = e.shininess), e.clearcoat !== void 0 && (i.clearcoat = e.clearcoat), e.clearcoatRoughness !== void 0 && (i.clearcoatRoughness = e.clearcoatRoughness), e.fog !== void 0 && (i.fog = e.fog), e.flatShading !== void 0 && (i.flatShading = e.flatShading), e.blending !== void 0 && (i.blending = e.blending), e.combine !== void 0 && (i.combine = e.combine), e.side !== void 0 && (i.side = e.side), e.opacity !== void 0 && (i.opacity = e.opacity), e.transparent !== void 0 && (i.transparent = e.transparent), e.alphaTest !== void 0 && (i.alphaTest = e.alphaTest), e.depthTest !== void 0 && (i.depthTest = e.depthTest), e.depthWrite !== void 0 && (i.depthWrite = e.depthWrite), e.colorWrite !== void 0 && (i.colorWrite = e.colorWrite), e.stencilWrite !== void 0 && (i.stencilWrite = e.stencilWrite), e.stencilWriteMask !== void 0 && (i.stencilWriteMask = e.stencilWriteMask), e.stencilFunc !== void 0 && (i.stencilFunc = e.stencilFunc), e.stencilRef !== void 0 && (i.stencilRef = e.stencilRef), e.stencilFuncMask !== void 0 && (i.stencilFuncMask = e.stencilFuncMask), e.stencilFail !== void 0 && (i.stencilFail = e.stencilFail), e.stencilZFail !== void 0 && (i.stencilZFail = e.stencilZFail), e.stencilZPass !== void 0 && (i.stencilZPass = e.stencilZPass), e.wireframe !== void 0 && (i.wireframe = e.wireframe), e.wireframeLinewidth !== void 0 && (i.wireframeLinewidth = e.wireframeLinewidth), e.wireframeLinecap !== void 0 && (i.wireframeLinecap = e.wireframeLinecap), e.wireframeLinejoin !== void 0 && (i.wireframeLinejoin = e.wireframeLinejoin), e.rotation !== void 0 && (i.rotation = e.rotation), e.linewidth !== 1 && (i.linewidth = e.linewidth), e.dashSize !== void 0 && (i.dashSize = e.dashSize), e.gapSize !== void 0 && (i.gapSize = e.gapSize), e.scale !== void 0 && (i.scale = e.scale), e.polygonOffset !== void 0 && (i.polygonOffset = e.polygonOffset), e.polygonOffsetFactor !== void 0 && (i.polygonOffsetFactor = e.polygonOffsetFactor), e.polygonOffsetUnits !== void 0 && (i.polygonOffsetUnits = e.polygonOffsetUnits), e.skinning !== void 0 && (i.skinning = e.skinning), e.morphTargets !== void 0 && (i.morphTargets = e.morphTargets), e.morphNormals !== void 0 && (i.morphNormals = e.morphNormals), e.dithering !== void 0 && (i.dithering = e.dithering), e.vertexTangents !== void 0 && (i.vertexTangents = e.vertexTangents), e.visible !== void 0 && (i.visible = e.visible), e.toneMapped !== void 0 && (i.toneMapped = e.toneMapped), e.userData !== void 0 && (i.userData = e.userData), e.vertexColors !== void 0 && (typeof e.vertexColors == "number" ? i.vertexColors = e.vertexColors > 0 : i.vertexColors = e.vertexColors), e.uniforms !== void 0)
      for (const r in e.uniforms) {
        const a = e.uniforms[r];
        switch (i.uniforms[r] = {}, a.type) {
          case "t":
            i.uniforms[r].value = t(a.value);
            break;
          case "c":
            i.uniforms[r].value = new Wt().setHex(a.value);
            break;
          case "v2":
            i.uniforms[r].value = new vt().fromArray(a.value);
            break;
          case "v3":
            i.uniforms[r].value = new ve().fromArray(a.value);
            break;
          case "v4":
            i.uniforms[r].value = new In().fromArray(a.value);
            break;
          case "m3":
            i.uniforms[r].value = new Bi().fromArray(a.value);
          case "m4":
            i.uniforms[r].value = new dn().fromArray(a.value);
            break;
          default:
            i.uniforms[r].value = a.value;
        }
      }
    if (e.defines !== void 0 && (i.defines = e.defines), e.vertexShader !== void 0 && (i.vertexShader = e.vertexShader), e.fragmentShader !== void 0 && (i.fragmentShader = e.fragmentShader), e.extensions !== void 0)
      for (const r in e.extensions)
        i.extensions[r] = e.extensions[r];
    if (e.shading !== void 0 && (i.flatShading = e.shading === 1), e.size !== void 0 && (i.size = e.size), e.sizeAttenuation !== void 0 && (i.sizeAttenuation = e.sizeAttenuation), e.map !== void 0 && (i.map = t(e.map)), e.matcap !== void 0 && (i.matcap = t(e.matcap)), e.alphaMap !== void 0 && (i.alphaMap = t(e.alphaMap)), e.bumpMap !== void 0 && (i.bumpMap = t(e.bumpMap)), e.bumpScale !== void 0 && (i.bumpScale = e.bumpScale), e.normalMap !== void 0 && (i.normalMap = t(e.normalMap)), e.normalMapType !== void 0 && (i.normalMapType = e.normalMapType), e.normalScale !== void 0) {
      let r = e.normalScale;
      Array.isArray(r) === !1 && (r = [r, r]), i.normalScale = new vt().fromArray(r);
    }
    return e.displacementMap !== void 0 && (i.displacementMap = t(e.displacementMap)), e.displacementScale !== void 0 && (i.displacementScale = e.displacementScale), e.displacementBias !== void 0 && (i.displacementBias = e.displacementBias), e.roughnessMap !== void 0 && (i.roughnessMap = t(e.roughnessMap)), e.metalnessMap !== void 0 && (i.metalnessMap = t(e.metalnessMap)), e.emissiveMap !== void 0 && (i.emissiveMap = t(e.emissiveMap)), e.emissiveIntensity !== void 0 && (i.emissiveIntensity = e.emissiveIntensity), e.specularMap !== void 0 && (i.specularMap = t(e.specularMap)), e.envMap !== void 0 && (i.envMap = t(e.envMap)), e.envMapIntensity !== void 0 && (i.envMapIntensity = e.envMapIntensity), e.reflectivity !== void 0 && (i.reflectivity = e.reflectivity), e.refractionRatio !== void 0 && (i.refractionRatio = e.refractionRatio), e.lightMap !== void 0 && (i.lightMap = t(e.lightMap)), e.lightMapIntensity !== void 0 && (i.lightMapIntensity = e.lightMapIntensity), e.aoMap !== void 0 && (i.aoMap = t(e.aoMap)), e.aoMapIntensity !== void 0 && (i.aoMapIntensity = e.aoMapIntensity), e.gradientMap !== void 0 && (i.gradientMap = t(e.gradientMap)), e.clearcoatMap !== void 0 && (i.clearcoatMap = t(e.clearcoatMap)), e.clearcoatRoughnessMap !== void 0 && (i.clearcoatRoughnessMap = t(e.clearcoatRoughnessMap)), e.clearcoatNormalMap !== void 0 && (i.clearcoatNormalMap = t(e.clearcoatNormalMap)), e.clearcoatNormalScale !== void 0 && (i.clearcoatNormalScale = new vt().fromArray(e.clearcoatNormalScale)), e.transmission !== void 0 && (i.transmission = e.transmission), e.transmissionMap !== void 0 && (i.transmissionMap = t(e.transmissionMap)), i;
  },
  setTextures: function(e) {
    return this.textures = e, this;
  }
});
const lb = {
  decodeText: function(e) {
    if (typeof TextDecoder < "u")
      return new TextDecoder().decode(e);
    let n = "";
    for (let t = 0, i = e.length; t < i; t++)
      n += String.fromCharCode(e[t]);
    try {
      return decodeURIComponent(escape(n));
    } catch {
      return n;
    }
  },
  extractUrlBase: function(e) {
    const n = e.lastIndexOf("/");
    return n === -1 ? "./" : e.substr(0, n + 1);
  }
};
function Ay() {
  Gt.call(this), this.type = "InstancedBufferGeometry", this.instanceCount = 1 / 0;
}
Ay.prototype = Object.assign(Object.create(Gt.prototype), {
  constructor: Ay,
  isInstancedBufferGeometry: !0,
  copy: function(e) {
    return Gt.prototype.copy.call(this, e), this.instanceCount = e.instanceCount, this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  toJSON: function() {
    const e = Gt.prototype.toJSON.call(this);
    return e.instanceCount = this.instanceCount, e.isInstancedBufferGeometry = !0, e;
  }
});
function _0(e, n, t, i) {
  typeof t == "number" && (i = t, t = !1, console.error("THREE.InstancedBufferAttribute: The constructor now expects normalized as the third argument.")), Jt.call(this, e, n, t), this.meshPerAttribute = i || 1;
}
_0.prototype = Object.assign(Object.create(Jt.prototype), {
  constructor: _0,
  isInstancedBufferAttribute: !0,
  copy: function(e) {
    return Jt.prototype.copy.call(this, e), this.meshPerAttribute = e.meshPerAttribute, this;
  },
  toJSON: function() {
    const e = Jt.prototype.toJSON.call(this);
    return e.meshPerAttribute = this.meshPerAttribute, e.isInstancedBufferAttribute = !0, e;
  }
});
function y0(e) {
  Tn.call(this, e);
}
y0.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: y0,
  load: function(e, n, t, i) {
    const r = this, a = new js(r.manager);
    a.setPath(r.path), a.setRequestHeader(r.requestHeader), a.load(e, function(c) {
      try {
        n(r.parse(JSON.parse(c)));
      } catch (u) {
        i ? i(u) : console.error(u), r.manager.itemError(e);
      }
    }, t, i);
  },
  parse: function(e) {
    const n = {}, t = {};
    function i(p, _) {
      if (n[_] !== void 0)
        return n[_];
      const S = p.interleavedBuffers[_], D = r(p, S.buffer), w = new O_[S.type](D), T = new vs(w, S.stride);
      return T.uuid = S.uuid, n[_] = T, T;
    }
    function r(p, _) {
      if (t[_] !== void 0)
        return t[_];
      const S = p.arrayBuffers[_], D = new Uint32Array(S).buffer;
      return t[_] = D, D;
    }
    const a = e.isInstancedBufferGeometry ? new Ay() : new Gt(), c = e.data.index;
    if (c !== void 0) {
      const p = new O_[c.type](c.array);
      a.setIndex(new Jt(p, 1));
    }
    const u = e.data.attributes;
    for (const p in u) {
      const _ = u[p];
      let v;
      if (_.isInterleavedBufferAttribute) {
        const S = i(e.data, _.data);
        v = new va(S, _.itemSize, _.offset, _.normalized);
      } else {
        const S = new O_[_.type](_.array), D = _.isInstancedBufferAttribute ? _0 : Jt;
        v = new D(S, _.itemSize, _.normalized);
      }
      _.name !== void 0 && (v.name = _.name), a.setAttribute(p, v);
    }
    const l = e.data.morphAttributes;
    if (l)
      for (const p in l) {
        const _ = l[p], v = [];
        for (let S = 0, D = _.length; S < D; S++) {
          const w = _[S];
          let T;
          if (w.isInterleavedBufferAttribute) {
            const F = i(e.data, w.data);
            T = new va(F, w.itemSize, w.offset, w.normalized);
          } else {
            const F = new O_[w.type](w.array);
            T = new Jt(F, w.itemSize, w.normalized);
          }
          w.name !== void 0 && (T.name = w.name), v.push(T);
        }
        a.morphAttributes[p] = v;
      }
    e.data.morphTargetsRelative && (a.morphTargetsRelative = !0);
    const m = e.data.groups || e.data.drawcalls || e.data.offsets;
    if (m !== void 0)
      for (let p = 0, _ = m.length; p !== _; ++p) {
        const v = m[p];
        a.addGroup(v.start, v.count, v.materialIndex);
      }
    const h = e.data.boundingSphere;
    if (h !== void 0) {
      const p = new ve();
      h.center !== void 0 && p.fromArray(h.center), a.boundingSphere = new Rr(p, h.radius);
    }
    return e.name && (a.name = e.name), e.userData && (a.userData = e.userData), a;
  }
});
const O_ = {
  Int8Array,
  Uint8Array,
  // Workaround for IE11 pre KB2929437. See #11440
  Uint8ClampedArray: typeof Uint8ClampedArray < "u" ? Uint8ClampedArray : Uint8Array,
  Int16Array,
  Uint16Array,
  Int32Array,
  Uint32Array,
  Float32Array,
  Float64Array
};
function v0(e) {
  Tn.call(this, e);
}
v0.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: v0,
  load: function(e, n, t, i) {
    const r = this, a = this.path === "" ? lb.extractUrlBase(e) : this.path;
    this.resourcePath = this.resourcePath || a;
    const c = new js(r.manager);
    c.setPath(this.path), c.setRequestHeader(this.requestHeader), c.load(e, function(u) {
      let l = null;
      try {
        l = JSON.parse(u);
      } catch (m) {
        i !== void 0 && i(m), console.error("THREE:ObjectLoader: Can't parse " + e + ".", m.message);
        return;
      }
      const f = l.metadata;
      if (f === void 0 || f.type === void 0 || f.type.toLowerCase() === "geometry") {
        console.error("THREE.ObjectLoader: Can't load " + e);
        return;
      }
      r.parse(l, n);
    }, t, i);
  },
  parse: function(e, n) {
    const t = this.parseShape(e.shapes), i = this.parseGeometries(e.geometries, t), r = this.parseImages(e.images, function() {
      n !== void 0 && n(u);
    }), a = this.parseTextures(e.textures, r), c = this.parseMaterials(e.materials, a), u = this.parseObject(e.object, i, c);
    return e.animations && (u.animations = this.parseAnimations(e.animations)), (e.images === void 0 || e.images.length === 0) && n !== void 0 && n(u), u;
  },
  parseShape: function(e) {
    const n = {};
    if (e !== void 0)
      for (let t = 0, i = e.length; t < i; t++) {
        const r = new ma().fromJSON(e[t]);
        n[r.uuid] = r;
      }
    return n;
  },
  parseGeometries: function(e, n) {
    const t = {};
    let i;
    if (e !== void 0) {
      const r = new y0();
      for (let a = 0, c = e.length; a < c; a++) {
        let u;
        const l = e[a];
        switch (l.type) {
          case "PlaneGeometry":
          case "PlaneBufferGeometry":
            u = new Ri[l.type](
              l.width,
              l.height,
              l.widthSegments,
              l.heightSegments
            );
            break;
          case "BoxGeometry":
          case "BoxBufferGeometry":
          case "CubeGeometry":
            u = new Ri[l.type](
              l.width,
              l.height,
              l.depth,
              l.widthSegments,
              l.heightSegments,
              l.depthSegments
            );
            break;
          case "CircleGeometry":
          case "CircleBufferGeometry":
            u = new Ri[l.type](
              l.radius,
              l.segments,
              l.thetaStart,
              l.thetaLength
            );
            break;
          case "CylinderGeometry":
          case "CylinderBufferGeometry":
            u = new Ri[l.type](
              l.radiusTop,
              l.radiusBottom,
              l.height,
              l.radialSegments,
              l.heightSegments,
              l.openEnded,
              l.thetaStart,
              l.thetaLength
            );
            break;
          case "ConeGeometry":
          case "ConeBufferGeometry":
            u = new Ri[l.type](
              l.radius,
              l.height,
              l.radialSegments,
              l.heightSegments,
              l.openEnded,
              l.thetaStart,
              l.thetaLength
            );
            break;
          case "SphereGeometry":
          case "SphereBufferGeometry":
            u = new Ri[l.type](
              l.radius,
              l.widthSegments,
              l.heightSegments,
              l.phiStart,
              l.phiLength,
              l.thetaStart,
              l.thetaLength
            );
            break;
          case "DodecahedronGeometry":
          case "DodecahedronBufferGeometry":
          case "IcosahedronGeometry":
          case "IcosahedronBufferGeometry":
          case "OctahedronGeometry":
          case "OctahedronBufferGeometry":
          case "TetrahedronGeometry":
          case "TetrahedronBufferGeometry":
            u = new Ri[l.type](
              l.radius,
              l.detail
            );
            break;
          case "RingGeometry":
          case "RingBufferGeometry":
            u = new Ri[l.type](
              l.innerRadius,
              l.outerRadius,
              l.thetaSegments,
              l.phiSegments,
              l.thetaStart,
              l.thetaLength
            );
            break;
          case "TorusGeometry":
          case "TorusBufferGeometry":
            u = new Ri[l.type](
              l.radius,
              l.tube,
              l.radialSegments,
              l.tubularSegments,
              l.arc
            );
            break;
          case "TorusKnotGeometry":
          case "TorusKnotBufferGeometry":
            u = new Ri[l.type](
              l.radius,
              l.tube,
              l.tubularSegments,
              l.radialSegments,
              l.p,
              l.q
            );
            break;
          case "TubeGeometry":
          case "TubeBufferGeometry":
            u = new Ri[l.type](
              new l0[l.path.type]().fromJSON(l.path),
              l.tubularSegments,
              l.radius,
              l.radialSegments,
              l.closed
            );
            break;
          case "LatheGeometry":
          case "LatheBufferGeometry":
            u = new Ri[l.type](
              l.points,
              l.segments,
              l.phiStart,
              l.phiLength
            );
            break;
          case "PolyhedronGeometry":
          case "PolyhedronBufferGeometry":
            u = new Ri[l.type](
              l.vertices,
              l.indices,
              l.radius,
              l.details
            );
            break;
          case "ShapeGeometry":
          case "ShapeBufferGeometry":
            i = [];
            for (let m = 0, h = l.shapes.length; m < h; m++) {
              const p = n[l.shapes[m]];
              i.push(p);
            }
            u = new Ri[l.type](
              i,
              l.curveSegments
            );
            break;
          case "ExtrudeGeometry":
          case "ExtrudeBufferGeometry":
            i = [];
            for (let m = 0, h = l.shapes.length; m < h; m++) {
              const p = n[l.shapes[m]];
              i.push(p);
            }
            const f = l.options.extrudePath;
            f !== void 0 && (l.options.extrudePath = new l0[f.type]().fromJSON(f)), u = new Ri[l.type](
              i,
              l.options
            );
            break;
          case "BufferGeometry":
          case "InstancedBufferGeometry":
            u = r.parse(l);
            break;
          case "Geometry":
            console.error('THREE.ObjectLoader: Loading "Geometry" is not supported anymore.');
            break;
          default:
            console.warn('THREE.ObjectLoader: Unsupported geometry type "' + l.type + '"');
            continue;
        }
        u.uuid = l.uuid, l.name !== void 0 && (u.name = l.name), u.isBufferGeometry === !0 && l.userData !== void 0 && (u.userData = l.userData), t[l.uuid] = u;
      }
    }
    return t;
  },
  parseMaterials: function(e, n) {
    const t = {}, i = {};
    if (e !== void 0) {
      const r = new Py();
      r.setTextures(n);
      for (let a = 0, c = e.length; a < c; a++) {
        const u = e[a];
        if (u.type === "MultiMaterial") {
          const l = [];
          for (let f = 0; f < u.materials.length; f++) {
            const m = u.materials[f];
            t[m.uuid] === void 0 && (t[m.uuid] = r.parse(m)), l.push(t[m.uuid]);
          }
          i[u.uuid] = l;
        } else
          t[u.uuid] === void 0 && (t[u.uuid] = r.parse(u)), i[u.uuid] = t[u.uuid];
      }
    }
    return i;
  },
  parseAnimations: function(e) {
    const n = [];
    for (let t = 0; t < e.length; t++) {
      const i = e[t], r = Ns.parse(i);
      i.uuid !== void 0 && (r.uuid = i.uuid), n.push(r);
    }
    return n;
  },
  parseImages: function(e, n) {
    const t = this, i = {};
    let r;
    function a(c) {
      return t.manager.itemStart(c), r.load(c, function() {
        t.manager.itemEnd(c);
      }, void 0, function() {
        t.manager.itemError(c), t.manager.itemEnd(c);
      });
    }
    if (e !== void 0 && e.length > 0) {
      const c = new ab(n);
      r = new eg(c), r.setCrossOrigin(this.crossOrigin);
      for (let u = 0, l = e.length; u < l; u++) {
        const f = e[u], m = f.url;
        if (Array.isArray(m)) {
          i[f.uuid] = [];
          for (let h = 0, p = m.length; h < p; h++) {
            const _ = m[h], v = /^(\/\/)|([a-z]+:(\/\/)?)/i.test(_) ? _ : t.resourcePath + _;
            i[f.uuid].push(a(v));
          }
        } else {
          const h = /^(\/\/)|([a-z]+:(\/\/)?)/i.test(f.url) ? f.url : t.resourcePath + f.url;
          i[f.uuid] = a(h);
        }
      }
    }
    return i;
  },
  parseTextures: function(e, n) {
    function t(r, a) {
      return typeof r == "number" ? r : (console.warn("THREE.ObjectLoader.parseTexture: Constant should be in numeric form.", r), a[r]);
    }
    const i = {};
    if (e !== void 0)
      for (let r = 0, a = e.length; r < a; r++) {
        const c = e[r];
        c.image === void 0 && console.warn('THREE.ObjectLoader: No "image" specified for', c.uuid), n[c.image] === void 0 && console.warn("THREE.ObjectLoader: Undefined image", c.image);
        let u;
        Array.isArray(n[c.image]) ? u = new po(n[c.image]) : u = new Fn(n[c.image]), u.needsUpdate = !0, u.uuid = c.uuid, c.name !== void 0 && (u.name = c.name), c.mapping !== void 0 && (u.mapping = t(c.mapping, oP)), c.offset !== void 0 && u.offset.fromArray(c.offset), c.repeat !== void 0 && u.repeat.fromArray(c.repeat), c.center !== void 0 && u.center.fromArray(c.center), c.rotation !== void 0 && (u.rotation = c.rotation), c.wrap !== void 0 && (u.wrapS = t(c.wrap[0], Qw), u.wrapT = t(c.wrap[1], Qw)), c.format !== void 0 && (u.format = c.format), c.type !== void 0 && (u.type = c.type), c.encoding !== void 0 && (u.encoding = c.encoding), c.minFilter !== void 0 && (u.minFilter = t(c.minFilter, Zw)), c.magFilter !== void 0 && (u.magFilter = t(c.magFilter, Zw)), c.anisotropy !== void 0 && (u.anisotropy = c.anisotropy), c.flipY !== void 0 && (u.flipY = c.flipY), c.premultiplyAlpha !== void 0 && (u.premultiplyAlpha = c.premultiplyAlpha), c.unpackAlignment !== void 0 && (u.unpackAlignment = c.unpackAlignment), i[c.uuid] = u;
      }
    return i;
  },
  parseObject: function(e, n, t) {
    let i;
    function r(l) {
      return n[l] === void 0 && console.warn("THREE.ObjectLoader: Undefined geometry", l), n[l];
    }
    function a(l) {
      if (l !== void 0) {
        if (Array.isArray(l)) {
          const f = [];
          for (let m = 0, h = l.length; m < h; m++) {
            const p = l[m];
            t[p] === void 0 && console.warn("THREE.ObjectLoader: Undefined material", p), f.push(t[p]);
          }
          return f;
        }
        return t[l] === void 0 && console.warn("THREE.ObjectLoader: Undefined material", l), t[l];
      }
    }
    let c, u;
    switch (e.type) {
      case "Scene":
        i = new Cm(), e.background !== void 0 && Number.isInteger(e.background) && (i.background = new Wt(e.background)), e.fog !== void 0 && (e.fog.type === "Fog" ? i.fog = new Hv(e.fog.color, e.fog.near, e.fog.far) : e.fog.type === "FogExp2" && (i.fog = new Wv(e.fog.color, e.fog.density)));
        break;
      case "PerspectiveCamera":
        i = new oi(e.fov, e.aspect, e.near, e.far), e.focus !== void 0 && (i.focus = e.focus), e.zoom !== void 0 && (i.zoom = e.zoom), e.filmGauge !== void 0 && (i.filmGauge = e.filmGauge), e.filmOffset !== void 0 && (i.filmOffset = e.filmOffset), e.view !== void 0 && (i.view = Object.assign({}, e.view));
        break;
      case "OrthographicCamera":
        i = new ng(e.left, e.right, e.top, e.bottom, e.near, e.far), e.zoom !== void 0 && (i.zoom = e.zoom), e.view !== void 0 && (i.view = Object.assign({}, e.view));
        break;
      case "AmbientLight":
        i = new Sy(e.color, e.intensity);
        break;
      case "DirectionalLight":
        i = new m0(e.color, e.intensity);
        break;
      case "PointLight":
        i = new f0(e.color, e.intensity, e.distance, e.decay);
        break;
      case "RectAreaLight":
        i = new g0(e.color, e.intensity, e.width, e.height);
        break;
      case "SpotLight":
        i = new d0(e.color, e.intensity, e.distance, e.angle, e.penumbra, e.decay);
        break;
      case "HemisphereLight":
        i = new c0(e.color, e.groundColor, e.intensity);
        break;
      case "LightProbe":
        i = new Us().fromJSON(e);
        break;
      case "SkinnedMesh":
        console.warn("THREE.ObjectLoader.parseObject() does not support SkinnedMesh yet.");
      case "Mesh":
        c = r(e.geometry), u = a(e.material), i = new Ln(c, u);
        break;
      case "InstancedMesh":
        c = r(e.geometry), u = a(e.material);
        const l = e.count, f = e.instanceMatrix;
        i = new Yv(c, u, l), i.instanceMatrix = new Jt(new Float32Array(f.array), 16);
        break;
      case "LOD":
        i = new iy();
        break;
      case "Line":
        i = new Es(r(e.geometry), a(e.material), e.mode);
        break;
      case "LineLoop":
        i = new Jv(r(e.geometry), a(e.material));
        break;
      case "LineSegments":
        i = new ai(r(e.geometry), a(e.material));
        break;
      case "PointCloud":
      case "Points":
        i = new sy(r(e.geometry), a(e.material));
        break;
      case "Sprite":
        i = new qv(a(e.material));
        break;
      case "Group":
        i = new ao();
        break;
      default:
        i = new Ft();
    }
    if (i.uuid = e.uuid, e.name !== void 0 && (i.name = e.name), e.matrix !== void 0 ? (i.matrix.fromArray(e.matrix), e.matrixAutoUpdate !== void 0 && (i.matrixAutoUpdate = e.matrixAutoUpdate), i.matrixAutoUpdate && i.matrix.decompose(i.position, i.quaternion, i.scale)) : (e.position !== void 0 && i.position.fromArray(e.position), e.rotation !== void 0 && i.rotation.fromArray(e.rotation), e.quaternion !== void 0 && i.quaternion.fromArray(e.quaternion), e.scale !== void 0 && i.scale.fromArray(e.scale)), e.castShadow !== void 0 && (i.castShadow = e.castShadow), e.receiveShadow !== void 0 && (i.receiveShadow = e.receiveShadow), e.shadow && (e.shadow.bias !== void 0 && (i.shadow.bias = e.shadow.bias), e.shadow.normalBias !== void 0 && (i.shadow.normalBias = e.shadow.normalBias), e.shadow.radius !== void 0 && (i.shadow.radius = e.shadow.radius), e.shadow.mapSize !== void 0 && i.shadow.mapSize.fromArray(e.shadow.mapSize), e.shadow.camera !== void 0 && (i.shadow.camera = this.parseObject(e.shadow.camera))), e.visible !== void 0 && (i.visible = e.visible), e.frustumCulled !== void 0 && (i.frustumCulled = e.frustumCulled), e.renderOrder !== void 0 && (i.renderOrder = e.renderOrder), e.userData !== void 0 && (i.userData = e.userData), e.layers !== void 0 && (i.layers.mask = e.layers), e.children !== void 0) {
      const l = e.children;
      for (let f = 0; f < l.length; f++)
        i.add(this.parseObject(l[f], n, t));
    }
    if (e.type === "LOD") {
      e.autoUpdate !== void 0 && (i.autoUpdate = e.autoUpdate);
      const l = e.levels;
      for (let f = 0; f < l.length; f++) {
        const m = l[f], h = i.getObjectByProperty("uuid", m.object);
        h !== void 0 && i.addLevel(h, m.distance);
      }
    }
    return i;
  }
});
const oP = {
  UVMapping: I0,
  CubeReflectionMapping: L0,
  CubeRefractionMapping: D0,
  EquirectangularReflectionMapping: Fx,
  EquirectangularRefractionMapping: k0,
  CubeUVReflectionMapping: ug,
  CubeUVRefractionMapping: By
}, Qw = {
  RepeatWrapping: X_,
  ClampToEdgeWrapping: qi,
  MirroredRepeatWrapping: Y_
}, Zw = {
  NearestFilter: _i,
  NearestMipmapNearestFilter: Fv,
  NearestMipmapLinearFilter: Rv,
  LinearFilter: Li,
  LinearMipmapNearestFilter: Rx,
  LinearMipmapLinearFilter: zy
};
function ex(e) {
  typeof createImageBitmap > "u" && console.warn("THREE.ImageBitmapLoader: createImageBitmap() not supported."), typeof fetch > "u" && console.warn("THREE.ImageBitmapLoader: fetch() not supported."), Tn.call(this, e), this.options = { premultiplyAlpha: "none" };
}
ex.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: ex,
  isImageBitmapLoader: !0,
  setOptions: function(n) {
    return this.options = n, this;
  },
  load: function(e, n, t, i) {
    e === void 0 && (e = ""), this.path !== void 0 && (e = this.path + e), e = this.manager.resolveURL(e);
    const r = this, a = ur.get(e);
    if (a !== void 0)
      return r.manager.itemStart(e), setTimeout(function() {
        n && n(a), r.manager.itemEnd(e);
      }, 0), a;
    fetch(e).then(function(c) {
      return c.blob();
    }).then(function(c) {
      return createImageBitmap(c, r.options);
    }).then(function(c) {
      ur.add(e, c), n && n(c), r.manager.itemEnd(e);
    }).catch(function(c) {
      i && i(c), r.manager.itemError(e), r.manager.itemEnd(e);
    }), r.manager.itemStart(e);
  }
});
function cb() {
  this.type = "ShapePath", this.color = new Wt(), this.subPaths = [], this.currentPath = null;
}
Object.assign(cb.prototype, {
  moveTo: function(e, n) {
    return this.currentPath = new lr(), this.subPaths.push(this.currentPath), this.currentPath.moveTo(e, n), this;
  },
  lineTo: function(e, n) {
    return this.currentPath.lineTo(e, n), this;
  },
  quadraticCurveTo: function(e, n, t, i) {
    return this.currentPath.quadraticCurveTo(e, n, t, i), this;
  },
  bezierCurveTo: function(e, n, t, i, r, a) {
    return this.currentPath.bezierCurveTo(e, n, t, i, r, a), this;
  },
  splineThru: function(e) {
    return this.currentPath.splineThru(e), this;
  },
  toShapes: function(e, n) {
    function t(w) {
      const T = [];
      for (let F = 0, E = w.length; F < E; F++) {
        const A = w[F], L = new ma();
        L.curves = A.curves, T.push(L);
      }
      return T;
    }
    function i(w, T) {
      const F = T.length;
      let E = !1;
      for (let A = F - 1, L = 0; L < F; A = L++) {
        let I = T[A], R = T[L], N = R.x - I.x, q = R.y - I.y;
        if (Math.abs(q) > Number.EPSILON) {
          if (q < 0 && (I = T[L], N = -N, R = T[A], q = -q), w.y < I.y || w.y > R.y)
            continue;
          if (w.y === I.y) {
            if (w.x === I.x)
              return !0;
          } else {
            const ne = q * (w.x - I.x) - N * (w.y - I.y);
            if (ne === 0)
              return !0;
            if (ne < 0)
              continue;
            E = !E;
          }
        } else {
          if (w.y !== I.y)
            continue;
          if (R.x <= w.x && w.x <= I.x || I.x <= w.x && w.x <= R.x)
            return !0;
        }
      }
      return E;
    }
    const r = ho.isClockWise, a = this.subPaths;
    if (a.length === 0)
      return [];
    if (n === !0)
      return t(a);
    let c, u, l, f = [];
    if (a.length === 1)
      return u = a[0], l = new ma(), l.curves = u.curves, f.push(l), f;
    let m = !r(a[0].getPoints());
    m = e ? !m : m;
    const h = [], p = [];
    let _ = [], v = 0, S;
    p[v] = void 0, _[v] = [];
    for (let w = 0, T = a.length; w < T; w++)
      u = a[w], S = u.getPoints(), c = r(S), c = e ? !c : c, c ? (!m && p[v] && v++, p[v] = { s: new ma(), p: S }, p[v].s.curves = u.curves, m && v++, _[v] = []) : _[v].push({ h: u, p: S[0] });
    if (!p[0])
      return t(a);
    if (p.length > 1) {
      let w = !1;
      const T = [];
      for (let F = 0, E = p.length; F < E; F++)
        h[F] = [];
      for (let F = 0, E = p.length; F < E; F++) {
        const A = _[F];
        for (let L = 0; L < A.length; L++) {
          const I = A[L];
          let R = !0;
          for (let N = 0; N < p.length; N++)
            i(I.p, p[N].p) && (F !== N && T.push({ froms: F, tos: N, hole: L }), R ? (R = !1, h[N].push(I)) : w = !0);
          R && h[F].push(I);
        }
      }
      T.length > 0 && (w || (_ = h));
    }
    let D;
    for (let w = 0, T = p.length; w < T; w++) {
      l = p[w].s, f.push(l), D = _[w];
      for (let F = 0, E = D.length; F < E; F++)
        l.holes.push(D[F].h);
    }
    return f;
  }
});
function ub(e) {
  this.type = "Font", this.data = e;
}
Object.assign(ub.prototype, {
  isFont: !0,
  generateShapes: function(e, n) {
    n === void 0 && (n = 100);
    const t = [], i = aP(e, n, this.data);
    for (let r = 0, a = i.length; r < a; r++)
      Array.prototype.push.apply(t, i[r].toShapes());
    return t;
  }
});
function aP(e, n, t) {
  const i = Array.from ? Array.from(e) : String(e).split(""), r = n / t.resolution, a = (t.boundingBox.yMax - t.boundingBox.yMin + t.underlineThickness) * r, c = [];
  let u = 0, l = 0;
  for (let f = 0; f < i.length; f++) {
    const m = i[f];
    if (m === `
`)
      u = 0, l -= a;
    else {
      const h = lP(m, r, u, l, t);
      u += h.offsetX, c.push(h.path);
    }
  }
  return c;
}
function lP(e, n, t, i, r) {
  const a = r.glyphs[e] || r.glyphs["?"];
  if (!a) {
    console.error('THREE.Font: character "' + e + '" does not exists in font family ' + r.familyName + ".");
    return;
  }
  const c = new cb();
  let u, l, f, m, h, p, _, v;
  if (a.o) {
    const S = a._cachedOutline || (a._cachedOutline = a.o.split(" "));
    for (let D = 0, w = S.length; D < w; )
      switch (S[D++]) {
        case "m":
          u = S[D++] * n + t, l = S[D++] * n + i, c.moveTo(u, l);
          break;
        case "l":
          u = S[D++] * n + t, l = S[D++] * n + i, c.lineTo(u, l);
          break;
        case "q":
          f = S[D++] * n + t, m = S[D++] * n + i, h = S[D++] * n + t, p = S[D++] * n + i, c.quadraticCurveTo(h, p, f, m);
          break;
        case "b":
          f = S[D++] * n + t, m = S[D++] * n + i, h = S[D++] * n + t, p = S[D++] * n + i, _ = S[D++] * n + t, v = S[D++] * n + i, c.bezierCurveTo(h, p, _, v, f, m);
          break;
      }
  }
  return { offsetX: a.ha * n, path: c };
}
function tx(e) {
  Tn.call(this, e);
}
tx.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: tx,
  load: function(e, n, t, i) {
    const r = this, a = new js(this.manager);
    a.setPath(this.path), a.setRequestHeader(this.requestHeader), a.load(e, function(c) {
      let u;
      try {
        u = JSON.parse(c);
      } catch {
        console.warn("THREE.FontLoader: typeface.js support is being deprecated. Use typeface.json instead."), u = JSON.parse(c.substring(65, c.length - 2));
      }
      const l = r.parse(u);
      n && n(l);
    }, t, i);
  },
  parse: function(e) {
    return new ub(e);
  }
});
let F_;
const db = {
  getContext: function() {
    return F_ === void 0 && (F_ = new (window.AudioContext || window.webkitAudioContext)()), F_;
  },
  setContext: function(e) {
    F_ = e;
  }
};
function w0(e) {
  Tn.call(this, e);
}
w0.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: w0,
  load: function(e, n, t, i) {
    const r = this, a = new js(r.manager);
    a.setResponseType("arraybuffer"), a.setPath(r.path), a.setRequestHeader(r.requestHeader), a.load(e, function(c) {
      try {
        const u = c.slice(0);
        db.getContext().decodeAudioData(u, function(f) {
          n(f);
        });
      } catch (u) {
        i ? i(u) : console.error(u), r.manager.itemError(e);
      }
    }, t, i);
  }
});
function nx(e, n, t) {
  Us.call(this, void 0, t);
  const i = new Wt().set(e), r = new Wt().set(n), a = new ve(i.r, i.g, i.b), c = new ve(r.r, r.g, r.b), u = Math.sqrt(Math.PI), l = u * Math.sqrt(0.75);
  this.sh.coefficients[0].copy(a).add(c).multiplyScalar(u), this.sh.coefficients[1].copy(a).sub(c).multiplyScalar(l);
}
nx.prototype = Object.assign(Object.create(Us.prototype), {
  constructor: nx,
  isHemisphereLightProbe: !0,
  copy: function(e) {
    return Us.prototype.copy.call(this, e), this;
  },
  toJSON: function(e) {
    return Us.prototype.toJSON.call(this, e);
  }
});
function ix(e, n) {
  Us.call(this, void 0, n);
  const t = new Wt().set(e);
  this.sh.coefficients[0].set(t.r, t.g, t.b).multiplyScalar(2 * Math.sqrt(Math.PI));
}
ix.prototype = Object.assign(Object.create(Us.prototype), {
  constructor: ix,
  isAmbientLightProbe: !0,
  copy: function(e) {
    return Us.prototype.copy.call(this, e), this;
  },
  toJSON: function(e) {
    return Us.prototype.toJSON.call(this, e);
  }
});
const sx = new dn(), rx = new dn();
function cP() {
  this.type = "StereoCamera", this.aspect = 1, this.eyeSep = 0.064, this.cameraL = new oi(), this.cameraL.layers.enable(1), this.cameraL.matrixAutoUpdate = !1, this.cameraR = new oi(), this.cameraR.layers.enable(2), this.cameraR.matrixAutoUpdate = !1, this._cache = {
    focus: null,
    fov: null,
    aspect: null,
    near: null,
    far: null,
    zoom: null,
    eyeSep: null
  };
}
Object.assign(cP.prototype, {
  update: function(e) {
    const n = this._cache;
    if (n.focus !== e.focus || n.fov !== e.fov || n.aspect !== e.aspect * this.aspect || n.near !== e.near || n.far !== e.far || n.zoom !== e.zoom || n.eyeSep !== this.eyeSep) {
      n.focus = e.focus, n.fov = e.fov, n.aspect = e.aspect * this.aspect, n.near = e.near, n.far = e.far, n.zoom = e.zoom, n.eyeSep = this.eyeSep;
      const i = e.projectionMatrix.clone(), r = n.eyeSep / 2, a = r * n.near / n.focus, c = n.near * Math.tan(un.DEG2RAD * n.fov * 0.5) / n.zoom;
      let u, l;
      rx.elements[12] = -r, sx.elements[12] = r, u = -c * n.aspect + a, l = c * n.aspect + a, i.elements[0] = 2 * n.near / (l - u), i.elements[8] = (l + u) / (l - u), this.cameraL.projectionMatrix.copy(i), u = -c * n.aspect - a, l = c * n.aspect - a, i.elements[0] = 2 * n.near / (l - u), i.elements[8] = (l + u) / (l - u), this.cameraR.projectionMatrix.copy(i);
    }
    this.cameraL.matrixWorld.copy(e.matrixWorld).multiply(rx), this.cameraR.matrixWorld.copy(e.matrixWorld).multiply(sx);
  }
});
function hb(e) {
  this.autoStart = e !== void 0 ? e : !0, this.startTime = 0, this.oldTime = 0, this.elapsedTime = 0, this.running = !1;
}
Object.assign(hb.prototype, {
  start: function() {
    this.startTime = (typeof performance > "u" ? Date : performance).now(), this.oldTime = this.startTime, this.elapsedTime = 0, this.running = !0;
  },
  stop: function() {
    this.getElapsedTime(), this.running = !1, this.autoStart = !1;
  },
  getElapsedTime: function() {
    return this.getDelta(), this.elapsedTime;
  },
  getDelta: function() {
    let e = 0;
    if (this.autoStart && !this.running)
      return this.start(), 0;
    if (this.running) {
      const n = (typeof performance > "u" ? Date : performance).now();
      e = (n - this.oldTime) / 1e3, this.oldTime = n, this.elapsedTime += e;
    }
    return e;
  }
});
const la = new ve(), ox = new yi(), uP = new ve(), ca = new ve();
function ax() {
  Ft.call(this), this.type = "AudioListener", this.context = db.getContext(), this.gain = this.context.createGain(), this.gain.connect(this.context.destination), this.filter = null, this.timeDelta = 0, this._clock = new hb();
}
ax.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: ax,
  getInput: function() {
    return this.gain;
  },
  removeFilter: function() {
    return this.filter !== null && (this.gain.disconnect(this.filter), this.filter.disconnect(this.context.destination), this.gain.connect(this.context.destination), this.filter = null), this;
  },
  getFilter: function() {
    return this.filter;
  },
  setFilter: function(e) {
    return this.filter !== null ? (this.gain.disconnect(this.filter), this.filter.disconnect(this.context.destination)) : this.gain.disconnect(this.context.destination), this.filter = e, this.gain.connect(this.filter), this.filter.connect(this.context.destination), this;
  },
  getMasterVolume: function() {
    return this.gain.gain.value;
  },
  setMasterVolume: function(e) {
    return this.gain.gain.setTargetAtTime(e, this.context.currentTime, 0.01), this;
  },
  updateMatrixWorld: function(e) {
    Ft.prototype.updateMatrixWorld.call(this, e);
    const n = this.context.listener, t = this.up;
    if (this.timeDelta = this._clock.getDelta(), this.matrixWorld.decompose(la, ox, uP), ca.set(0, 0, -1).applyQuaternion(ox), n.positionX) {
      const i = this.context.currentTime + this.timeDelta;
      n.positionX.linearRampToValueAtTime(la.x, i), n.positionY.linearRampToValueAtTime(la.y, i), n.positionZ.linearRampToValueAtTime(la.z, i), n.forwardX.linearRampToValueAtTime(ca.x, i), n.forwardY.linearRampToValueAtTime(ca.y, i), n.forwardZ.linearRampToValueAtTime(ca.z, i), n.upX.linearRampToValueAtTime(t.x, i), n.upY.linearRampToValueAtTime(t.y, i), n.upZ.linearRampToValueAtTime(t.z, i);
    } else
      n.setPosition(la.x, la.y, la.z), n.setOrientation(ca.x, ca.y, ca.z, t.x, t.y, t.z);
  }
});
function ig(e) {
  Ft.call(this), this.type = "Audio", this.listener = e, this.context = e.context, this.gain = this.context.createGain(), this.gain.connect(e.getInput()), this.autoplay = !1, this.buffer = null, this.detune = 0, this.loop = !1, this.loopStart = 0, this.loopEnd = 0, this.offset = 0, this.duration = void 0, this.playbackRate = 1, this.isPlaying = !1, this.hasPlaybackControl = !0, this.sourceType = "empty", this._startedAt = 0, this._progress = 0, this.filters = [];
}
ig.prototype = Object.assign(Object.create(Ft.prototype), {
  constructor: ig,
  getOutput: function() {
    return this.gain;
  },
  setNodeSource: function(e) {
    return this.hasPlaybackControl = !1, this.sourceType = "audioNode", this.source = e, this.connect(), this;
  },
  setMediaElementSource: function(e) {
    return this.hasPlaybackControl = !1, this.sourceType = "mediaNode", this.source = this.context.createMediaElementSource(e), this.connect(), this;
  },
  setMediaStreamSource: function(e) {
    return this.hasPlaybackControl = !1, this.sourceType = "mediaStreamNode", this.source = this.context.createMediaStreamSource(e), this.connect(), this;
  },
  setBuffer: function(e) {
    return this.buffer = e, this.sourceType = "buffer", this.autoplay && this.play(), this;
  },
  play: function(e) {
    if (e === void 0 && (e = 0), this.isPlaying === !0) {
      console.warn("THREE.Audio: Audio is already playing.");
      return;
    }
    if (this.hasPlaybackControl === !1) {
      console.warn("THREE.Audio: this Audio has no playback control.");
      return;
    }
    this._startedAt = this.context.currentTime + e;
    const n = this.context.createBufferSource();
    return n.buffer = this.buffer, n.loop = this.loop, n.loopStart = this.loopStart, n.loopEnd = this.loopEnd, n.onended = this.onEnded.bind(this), n.start(this._startedAt, this._progress + this.offset, this.duration), this.isPlaying = !0, this.source = n, this.setDetune(this.detune), this.setPlaybackRate(this.playbackRate), this.connect();
  },
  pause: function() {
    if (this.hasPlaybackControl === !1) {
      console.warn("THREE.Audio: this Audio has no playback control.");
      return;
    }
    return this.isPlaying === !0 && (this._progress += Math.max(this.context.currentTime - this._startedAt, 0) * this.playbackRate, this.loop === !0 && (this._progress = this._progress % (this.duration || this.buffer.duration)), this.source.stop(), this.source.onended = null, this.isPlaying = !1), this;
  },
  stop: function() {
    if (this.hasPlaybackControl === !1) {
      console.warn("THREE.Audio: this Audio has no playback control.");
      return;
    }
    return this._progress = 0, this.source.stop(), this.source.onended = null, this.isPlaying = !1, this;
  },
  connect: function() {
    if (this.filters.length > 0) {
      this.source.connect(this.filters[0]);
      for (let e = 1, n = this.filters.length; e < n; e++)
        this.filters[e - 1].connect(this.filters[e]);
      this.filters[this.filters.length - 1].connect(this.getOutput());
    } else
      this.source.connect(this.getOutput());
    return this;
  },
  disconnect: function() {
    if (this.filters.length > 0) {
      this.source.disconnect(this.filters[0]);
      for (let e = 1, n = this.filters.length; e < n; e++)
        this.filters[e - 1].disconnect(this.filters[e]);
      this.filters[this.filters.length - 1].disconnect(this.getOutput());
    } else
      this.source.disconnect(this.getOutput());
    return this;
  },
  getFilters: function() {
    return this.filters;
  },
  setFilters: function(e) {
    return e || (e = []), this.isPlaying === !0 ? (this.disconnect(), this.filters = e, this.connect()) : this.filters = e, this;
  },
  setDetune: function(e) {
    if (this.detune = e, this.source.detune !== void 0)
      return this.isPlaying === !0 && this.source.detune.setTargetAtTime(this.detune, this.context.currentTime, 0.01), this;
  },
  getDetune: function() {
    return this.detune;
  },
  getFilter: function() {
    return this.getFilters()[0];
  },
  setFilter: function(e) {
    return this.setFilters(e ? [e] : []);
  },
  setPlaybackRate: function(e) {
    if (this.hasPlaybackControl === !1) {
      console.warn("THREE.Audio: this Audio has no playback control.");
      return;
    }
    return this.playbackRate = e, this.isPlaying === !0 && this.source.playbackRate.setTargetAtTime(this.playbackRate, this.context.currentTime, 0.01), this;
  },
  getPlaybackRate: function() {
    return this.playbackRate;
  },
  onEnded: function() {
    this.isPlaying = !1;
  },
  getLoop: function() {
    return this.hasPlaybackControl === !1 ? (console.warn("THREE.Audio: this Audio has no playback control."), !1) : this.loop;
  },
  setLoop: function(e) {
    if (this.hasPlaybackControl === !1) {
      console.warn("THREE.Audio: this Audio has no playback control.");
      return;
    }
    return this.loop = e, this.isPlaying === !0 && (this.source.loop = this.loop), this;
  },
  setLoopStart: function(e) {
    return this.loopStart = e, this;
  },
  setLoopEnd: function(e) {
    return this.loopEnd = e, this;
  },
  getVolume: function() {
    return this.gain.gain.value;
  },
  setVolume: function(e) {
    return this.gain.gain.setTargetAtTime(e, this.context.currentTime, 0.01), this;
  }
});
const ua = new ve(), lx = new yi(), dP = new ve(), da = new ve();
function cx(e) {
  ig.call(this, e), this.panner = this.context.createPanner(), this.panner.panningModel = "HRTF", this.panner.connect(this.gain);
}
cx.prototype = Object.assign(Object.create(ig.prototype), {
  constructor: cx,
  getOutput: function() {
    return this.panner;
  },
  getRefDistance: function() {
    return this.panner.refDistance;
  },
  setRefDistance: function(e) {
    return this.panner.refDistance = e, this;
  },
  getRolloffFactor: function() {
    return this.panner.rolloffFactor;
  },
  setRolloffFactor: function(e) {
    return this.panner.rolloffFactor = e, this;
  },
  getDistanceModel: function() {
    return this.panner.distanceModel;
  },
  setDistanceModel: function(e) {
    return this.panner.distanceModel = e, this;
  },
  getMaxDistance: function() {
    return this.panner.maxDistance;
  },
  setMaxDistance: function(e) {
    return this.panner.maxDistance = e, this;
  },
  setDirectionalCone: function(e, n, t) {
    return this.panner.coneInnerAngle = e, this.panner.coneOuterAngle = n, this.panner.coneOuterGain = t, this;
  },
  updateMatrixWorld: function(e) {
    if (Ft.prototype.updateMatrixWorld.call(this, e), this.hasPlaybackControl === !0 && this.isPlaying === !1)
      return;
    this.matrixWorld.decompose(ua, lx, dP), da.set(0, 0, 1).applyQuaternion(lx);
    const n = this.panner;
    if (n.positionX) {
      const t = this.context.currentTime + this.listener.timeDelta;
      n.positionX.linearRampToValueAtTime(ua.x, t), n.positionY.linearRampToValueAtTime(ua.y, t), n.positionZ.linearRampToValueAtTime(ua.z, t), n.orientationX.linearRampToValueAtTime(da.x, t), n.orientationY.linearRampToValueAtTime(da.y, t), n.orientationZ.linearRampToValueAtTime(da.z, t);
    } else
      n.setPosition(ua.x, ua.y, ua.z), n.setOrientation(da.x, da.y, da.z);
  }
});
function fb(e, n) {
  this.analyser = e.context.createAnalyser(), this.analyser.fftSize = n !== void 0 ? n : 2048, this.data = new Uint8Array(this.analyser.frequencyBinCount), e.getOutput().connect(this.analyser);
}
Object.assign(fb.prototype, {
  getFrequencyData: function() {
    return this.analyser.getByteFrequencyData(this.data), this.data;
  },
  getAverageFrequency: function() {
    let e = 0;
    const n = this.getFrequencyData();
    for (let t = 0; t < n.length; t++)
      e += n[t];
    return e / n.length;
  }
});
function pb(e, n, t) {
  this.binding = e, this.valueSize = t;
  let i, r, a;
  switch (n) {
    case "quaternion":
      i = this._slerp, r = this._slerpAdditive, a = this._setAdditiveIdentityQuaternion, this.buffer = new Float64Array(t * 6), this._workIndex = 5;
      break;
    case "string":
    case "bool":
      i = this._select, r = this._select, a = this._setAdditiveIdentityOther, this.buffer = new Array(t * 5);
      break;
    default:
      i = this._lerp, r = this._lerpAdditive, a = this._setAdditiveIdentityNumeric, this.buffer = new Float64Array(t * 5);
  }
  this._mixBufferRegion = i, this._mixBufferRegionAdditive = r, this._setIdentity = a, this._origIndex = 3, this._addIndex = 4, this.cumulativeWeight = 0, this.cumulativeWeightAdditive = 0, this.useCount = 0, this.referenceCount = 0;
}
Object.assign(pb.prototype, {
  // accumulate data in the 'incoming' region into 'accu<i>'
  accumulate: function(e, n) {
    const t = this.buffer, i = this.valueSize, r = e * i + i;
    let a = this.cumulativeWeight;
    if (a === 0) {
      for (let c = 0; c !== i; ++c)
        t[r + c] = t[c];
      a = n;
    } else {
      a += n;
      const c = n / a;
      this._mixBufferRegion(t, r, 0, c, i);
    }
    this.cumulativeWeight = a;
  },
  // accumulate data in the 'incoming' region into 'add'
  accumulateAdditive: function(e) {
    const n = this.buffer, t = this.valueSize, i = t * this._addIndex;
    this.cumulativeWeightAdditive === 0 && this._setIdentity(), this._mixBufferRegionAdditive(n, i, 0, e, t), this.cumulativeWeightAdditive += e;
  },
  // apply the state of 'accu<i>' to the binding when accus differ
  apply: function(e) {
    const n = this.valueSize, t = this.buffer, i = e * n + n, r = this.cumulativeWeight, a = this.cumulativeWeightAdditive, c = this.binding;
    if (this.cumulativeWeight = 0, this.cumulativeWeightAdditive = 0, r < 1) {
      const u = n * this._origIndex;
      this._mixBufferRegion(
        t,
        i,
        u,
        1 - r,
        n
      );
    }
    a > 0 && this._mixBufferRegionAdditive(t, i, this._addIndex * n, 1, n);
    for (let u = n, l = n + n; u !== l; ++u)
      if (t[u] !== t[u + n]) {
        c.setValue(t, i);
        break;
      }
  },
  // remember the state of the bound property and copy it to both accus
  saveOriginalState: function() {
    const e = this.binding, n = this.buffer, t = this.valueSize, i = t * this._origIndex;
    e.getValue(n, i);
    for (let r = t, a = i; r !== a; ++r)
      n[r] = n[i + r % t];
    this._setIdentity(), this.cumulativeWeight = 0, this.cumulativeWeightAdditive = 0;
  },
  // apply the state previously taken via 'saveOriginalState' to the binding
  restoreOriginalState: function() {
    const e = this.valueSize * 3;
    this.binding.setValue(this.buffer, e);
  },
  _setAdditiveIdentityNumeric: function() {
    const e = this._addIndex * this.valueSize, n = e + this.valueSize;
    for (let t = e; t < n; t++)
      this.buffer[t] = 0;
  },
  _setAdditiveIdentityQuaternion: function() {
    this._setAdditiveIdentityNumeric(), this.buffer[this._addIndex * 4 + 3] = 1;
  },
  _setAdditiveIdentityOther: function() {
    const e = this._origIndex * this.valueSize, n = this._addIndex * this.valueSize;
    for (let t = 0; t < this.valueSize; t++)
      this.buffer[n + t] = this.buffer[e + t];
  },
  // mix functions
  _select: function(e, n, t, i, r) {
    if (i >= 0.5)
      for (let a = 0; a !== r; ++a)
        e[n + a] = e[t + a];
  },
  _slerp: function(e, n, t, i) {
    yi.slerpFlat(e, n, e, n, e, t, i);
  },
  _slerpAdditive: function(e, n, t, i, r) {
    const a = this._workIndex * r;
    yi.multiplyQuaternionsFlat(e, a, e, n, e, t), yi.slerpFlat(e, n, e, n, e, a, i);
  },
  _lerp: function(e, n, t, i, r) {
    const a = 1 - i;
    for (let c = 0; c !== r; ++c) {
      const u = n + c;
      e[u] = e[u] * a + e[t + c] * i;
    }
  },
  _lerpAdditive: function(e, n, t, i, r) {
    for (let a = 0; a !== r; ++a) {
      const c = n + a;
      e[c] = e[c] + e[t + a] * i;
    }
  }
});
const N0 = "\\[\\]\\.:\\/", hP = new RegExp("[" + N0 + "]", "g"), U0 = "[^" + N0 + "]", fP = "[^" + N0.replace("\\.", "") + "]", pP = /((?:WC+[\/:])*)/.source.replace("WC", U0), mP = /(WCOD+)?/.source.replace("WCOD", fP), gP = /(?:\.(WC+)(?:\[(.+)\])?)?/.source.replace("WC", U0), _P = /\.(WC+)(?:\[(.+)\])?/.source.replace("WC", U0), yP = new RegExp(
  "^" + pP + mP + gP + _P + "$"
), vP = ["material", "materials", "bones"];
function mb(e, n, t) {
  const i = t || zi.parseTrackName(n);
  this._targetGroup = e, this._bindings = e.subscribe_(n, i);
}
Object.assign(mb.prototype, {
  getValue: function(e, n) {
    this.bind();
    const t = this._targetGroup.nCachedObjects_, i = this._bindings[t];
    i !== void 0 && i.getValue(e, n);
  },
  setValue: function(e, n) {
    const t = this._bindings;
    for (let i = this._targetGroup.nCachedObjects_, r = t.length; i !== r; ++i)
      t[i].setValue(e, n);
  },
  bind: function() {
    const e = this._bindings;
    for (let n = this._targetGroup.nCachedObjects_, t = e.length; n !== t; ++n)
      e[n].bind();
  },
  unbind: function() {
    const e = this._bindings;
    for (let n = this._targetGroup.nCachedObjects_, t = e.length; n !== t; ++n)
      e[n].unbind();
  }
});
function zi(e, n, t) {
  this.path = n, this.parsedPath = t || zi.parseTrackName(n), this.node = zi.findNode(e, this.parsedPath.nodeName) || e, this.rootNode = e;
}
Object.assign(zi, {
  Composite: mb,
  create: function(e, n, t) {
    return e && e.isAnimationObjectGroup ? new zi.Composite(e, n, t) : new zi(e, n, t);
  },
  /**
   * Replaces spaces with underscores and removes unsupported characters from
   * node names, to ensure compatibility with parseTrackName().
   *
   * @param {string} name Node name to be sanitized.
   * @return {string}
   */
  sanitizeNodeName: function(e) {
    return e.replace(/\s/g, "_").replace(hP, "");
  },
  parseTrackName: function(e) {
    const n = yP.exec(e);
    if (!n)
      throw new Error("PropertyBinding: Cannot parse trackName: " + e);
    const t = {
      // directoryName: matches[ 1 ], // (tschw) currently unused
      nodeName: n[2],
      objectName: n[3],
      objectIndex: n[4],
      propertyName: n[5],
      // required
      propertyIndex: n[6]
    }, i = t.nodeName && t.nodeName.lastIndexOf(".");
    if (i !== void 0 && i !== -1) {
      const r = t.nodeName.substring(i + 1);
      vP.indexOf(r) !== -1 && (t.nodeName = t.nodeName.substring(0, i), t.objectName = r);
    }
    if (t.propertyName === null || t.propertyName.length === 0)
      throw new Error("PropertyBinding: can not parse propertyName from trackName: " + e);
    return t;
  },
  findNode: function(e, n) {
    if (!n || n === "" || n === "." || n === -1 || n === e.name || n === e.uuid)
      return e;
    if (e.skeleton) {
      const t = e.skeleton.getBoneByName(n);
      if (t !== void 0)
        return t;
    }
    if (e.children) {
      const t = function(r) {
        for (let a = 0; a < r.length; a++) {
          const c = r[a];
          if (c.name === n || c.uuid === n)
            return c;
          const u = t(c.children);
          if (u)
            return u;
        }
        return null;
      }, i = t(e.children);
      if (i)
        return i;
    }
    return null;
  }
});
Object.assign(zi.prototype, {
  // prototype, continued
  // these are used to "bind" a nonexistent property
  _getValue_unavailable: function() {
  },
  _setValue_unavailable: function() {
  },
  BindingType: {
    Direct: 0,
    EntireArray: 1,
    ArrayElement: 2,
    HasFromToArray: 3
  },
  Versioning: {
    None: 0,
    NeedsUpdate: 1,
    MatrixWorldNeedsUpdate: 2
  },
  GetterByBindingType: [
    function(n, t) {
      n[t] = this.node[this.propertyName];
    },
    function(n, t) {
      const i = this.resolvedProperty;
      for (let r = 0, a = i.length; r !== a; ++r)
        n[t++] = i[r];
    },
    function(n, t) {
      n[t] = this.resolvedProperty[this.propertyIndex];
    },
    function(n, t) {
      this.resolvedProperty.toArray(n, t);
    }
  ],
  SetterByBindingTypeAndVersioning: [
    [
      // Direct
      function(n, t) {
        this.targetObject[this.propertyName] = n[t];
      },
      function(n, t) {
        this.targetObject[this.propertyName] = n[t], this.targetObject.needsUpdate = !0;
      },
      function(n, t) {
        this.targetObject[this.propertyName] = n[t], this.targetObject.matrixWorldNeedsUpdate = !0;
      }
    ],
    [
      // EntireArray
      function(n, t) {
        const i = this.resolvedProperty;
        for (let r = 0, a = i.length; r !== a; ++r)
          i[r] = n[t++];
      },
      function(n, t) {
        const i = this.resolvedProperty;
        for (let r = 0, a = i.length; r !== a; ++r)
          i[r] = n[t++];
        this.targetObject.needsUpdate = !0;
      },
      function(n, t) {
        const i = this.resolvedProperty;
        for (let r = 0, a = i.length; r !== a; ++r)
          i[r] = n[t++];
        this.targetObject.matrixWorldNeedsUpdate = !0;
      }
    ],
    [
      // ArrayElement
      function(n, t) {
        this.resolvedProperty[this.propertyIndex] = n[t];
      },
      function(n, t) {
        this.resolvedProperty[this.propertyIndex] = n[t], this.targetObject.needsUpdate = !0;
      },
      function(n, t) {
        this.resolvedProperty[this.propertyIndex] = n[t], this.targetObject.matrixWorldNeedsUpdate = !0;
      }
    ],
    [
      // HasToFromArray
      function(n, t) {
        this.resolvedProperty.fromArray(n, t);
      },
      function(n, t) {
        this.resolvedProperty.fromArray(n, t), this.targetObject.needsUpdate = !0;
      },
      function(n, t) {
        this.resolvedProperty.fromArray(n, t), this.targetObject.matrixWorldNeedsUpdate = !0;
      }
    ]
  ],
  getValue: function(n, t) {
    this.bind(), this.getValue(n, t);
  },
  setValue: function(n, t) {
    this.bind(), this.setValue(n, t);
  },
  // create getter / setter pair for a property in the scene graph
  bind: function() {
    let e = this.node, n = this.parsedPath, t = n.objectName, i = n.propertyName, r = n.propertyIndex;
    if (e || (e = zi.findNode(this.rootNode, n.nodeName) || this.rootNode, this.node = e), this.getValue = this._getValue_unavailable, this.setValue = this._setValue_unavailable, !e) {
      console.error("THREE.PropertyBinding: Trying to update node for track: " + this.path + " but it wasn't found.");
      return;
    }
    if (t) {
      let l = n.objectIndex;
      switch (t) {
        case "materials":
          if (!e.material) {
            console.error("THREE.PropertyBinding: Can not bind to material as node does not have a material.", this);
            return;
          }
          if (!e.material.materials) {
            console.error("THREE.PropertyBinding: Can not bind to material.materials as node.material does not have a materials array.", this);
            return;
          }
          e = e.material.materials;
          break;
        case "bones":
          if (!e.skeleton) {
            console.error("THREE.PropertyBinding: Can not bind to bones as node does not have a skeleton.", this);
            return;
          }
          e = e.skeleton.bones;
          for (let f = 0; f < e.length; f++)
            if (e[f].name === l) {
              l = f;
              break;
            }
          break;
        default:
          if (e[t] === void 0) {
            console.error("THREE.PropertyBinding: Can not bind to objectName of node undefined.", this);
            return;
          }
          e = e[t];
      }
      if (l !== void 0) {
        if (e[l] === void 0) {
          console.error("THREE.PropertyBinding: Trying to bind to objectIndex of objectName, but is undefined.", this, e);
          return;
        }
        e = e[l];
      }
    }
    const a = e[i];
    if (a === void 0) {
      const l = n.nodeName;
      console.error("THREE.PropertyBinding: Trying to update property for track: " + l + "." + i + " but it wasn't found.", e);
      return;
    }
    let c = this.Versioning.None;
    this.targetObject = e, e.needsUpdate !== void 0 ? c = this.Versioning.NeedsUpdate : e.matrixWorldNeedsUpdate !== void 0 && (c = this.Versioning.MatrixWorldNeedsUpdate);
    let u = this.BindingType.Direct;
    if (r !== void 0) {
      if (i === "morphTargetInfluences") {
        if (!e.geometry) {
          console.error("THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.", this);
          return;
        }
        if (e.geometry.isBufferGeometry) {
          if (!e.geometry.morphAttributes) {
            console.error("THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.morphAttributes.", this);
            return;
          }
          e.morphTargetDictionary[r] !== void 0 && (r = e.morphTargetDictionary[r]);
        } else {
          console.error("THREE.PropertyBinding: Can not bind to morphTargetInfluences on THREE.Geometry. Use THREE.BufferGeometry instead.", this);
          return;
        }
      }
      u = this.BindingType.ArrayElement, this.resolvedProperty = a, this.propertyIndex = r;
    } else
      a.fromArray !== void 0 && a.toArray !== void 0 ? (u = this.BindingType.HasFromToArray, this.resolvedProperty = a) : Array.isArray(a) ? (u = this.BindingType.EntireArray, this.resolvedProperty = a) : this.propertyName = i;
    this.getValue = this.GetterByBindingType[u], this.setValue = this.SetterByBindingTypeAndVersioning[u][c];
  },
  unbind: function() {
    this.node = null, this.getValue = this._getValue_unbound, this.setValue = this._setValue_unbound;
  }
});
Object.assign(zi.prototype, {
  // initial state of these methods that calls 'bind'
  _getValue_unbound: zi.prototype.getValue,
  _setValue_unbound: zi.prototype.setValue
});
function wP() {
  this.uuid = un.generateUUID(), this._objects = Array.prototype.slice.call(arguments), this.nCachedObjects_ = 0;
  const e = {};
  this._indicesByUUID = e;
  for (let t = 0, i = arguments.length; t !== i; ++t)
    e[arguments[t].uuid] = t;
  this._paths = [], this._parsedPaths = [], this._bindings = [], this._bindingsIndicesByPath = {};
  const n = this;
  this.stats = {
    objects: {
      get total() {
        return n._objects.length;
      },
      get inUse() {
        return this.total - n.nCachedObjects_;
      }
    },
    get bindingsPerObject() {
      return n._bindings.length;
    }
  };
}
Object.assign(wP.prototype, {
  isAnimationObjectGroup: !0,
  add: function() {
    const e = this._objects, n = this._indicesByUUID, t = this._paths, i = this._parsedPaths, r = this._bindings, a = r.length;
    let c, u = e.length, l = this.nCachedObjects_;
    for (let f = 0, m = arguments.length; f !== m; ++f) {
      const h = arguments[f], p = h.uuid;
      let _ = n[p];
      if (_ === void 0) {
        _ = u++, n[p] = _, e.push(h);
        for (let v = 0, S = a; v !== S; ++v)
          r[v].push(new zi(h, t[v], i[v]));
      } else if (_ < l) {
        c = e[_];
        const v = --l, S = e[v];
        n[S.uuid] = _, e[_] = S, n[p] = v, e[v] = h;
        for (let D = 0, w = a; D !== w; ++D) {
          const T = r[D], F = T[v];
          let E = T[_];
          T[_] = F, E === void 0 && (E = new zi(h, t[D], i[D])), T[v] = E;
        }
      } else
        e[_] !== c && console.error("THREE.AnimationObjectGroup: Different objects with the same UUID detected. Clean the caches or recreate your infrastructure when reloading scenes.");
    }
    this.nCachedObjects_ = l;
  },
  remove: function() {
    const e = this._objects, n = this._indicesByUUID, t = this._bindings, i = t.length;
    let r = this.nCachedObjects_;
    for (let a = 0, c = arguments.length; a !== c; ++a) {
      const u = arguments[a], l = u.uuid, f = n[l];
      if (f !== void 0 && f >= r) {
        const m = r++, h = e[m];
        n[h.uuid] = f, e[f] = h, n[l] = m, e[m] = u;
        for (let p = 0, _ = i; p !== _; ++p) {
          const v = t[p], S = v[m], D = v[f];
          v[f] = S, v[m] = D;
        }
      }
    }
    this.nCachedObjects_ = r;
  },
  // remove & forget
  uncache: function() {
    const e = this._objects, n = this._indicesByUUID, t = this._bindings, i = t.length;
    let r = this.nCachedObjects_, a = e.length;
    for (let c = 0, u = arguments.length; c !== u; ++c) {
      const l = arguments[c], f = l.uuid, m = n[f];
      if (m !== void 0)
        if (delete n[f], m < r) {
          const h = --r, p = e[h], _ = --a, v = e[_];
          n[p.uuid] = m, e[m] = p, n[v.uuid] = h, e[h] = v, e.pop();
          for (let S = 0, D = i; S !== D; ++S) {
            const w = t[S], T = w[h], F = w[_];
            w[m] = T, w[h] = F, w.pop();
          }
        } else {
          const h = --a, p = e[h];
          n[p.uuid] = m, e[m] = p, e.pop();
          for (let _ = 0, v = i; _ !== v; ++_) {
            const S = t[_];
            S[m] = S[h], S.pop();
          }
        }
    }
    this.nCachedObjects_ = r;
  },
  // Internal interface used by befriended PropertyBinding.Composite:
  subscribe_: function(e, n) {
    let t = this._bindingsIndicesByPath, i = t[e], r = this._bindings;
    if (i !== void 0)
      return r[i];
    const a = this._paths, c = this._parsedPaths, u = this._objects, l = u.length, f = this.nCachedObjects_, m = new Array(l);
    i = r.length, t[e] = i, a.push(e), c.push(n), r.push(m);
    for (let h = f, p = u.length; h !== p; ++h) {
      const _ = u[h];
      m[h] = new zi(_, e, n);
    }
    return m;
  },
  unsubscribe_: function(e) {
    const n = this._bindingsIndicesByPath, t = n[e];
    if (t !== void 0) {
      const i = this._paths, r = this._parsedPaths, a = this._bindings, c = a.length - 1, u = a[c], l = e[c];
      n[l] = t, a[t] = u, a.pop(), r[t] = r[c], r.pop(), i[t] = i[c], i.pop();
    }
  }
});
function gb(e, n, t, i) {
  this._mixer = e, this._clip = n, this._localRoot = t || null, this.blendMode = i || n.blendMode;
  const r = n.tracks, a = r.length, c = new Array(a), u = {
    endingStart: au,
    endingEnd: au
  };
  for (let l = 0; l !== a; ++l) {
    const f = r[l].createInterpolant(null);
    c[l] = f, f.settings = u;
  }
  this._interpolantSettings = u, this._interpolants = c, this._propertyBindings = new Array(a), this._cacheIndex = null, this._byClipCacheIndex = null, this._timeScaleInterpolant = null, this._weightInterpolant = null, this.loop = l1, this._loopCount = -1, this._startTime = null, this.time = 0, this.timeScale = 1, this._effectiveTimeScale = 1, this.weight = 1, this._effectiveWeight = 1, this.repetitions = 1 / 0, this.paused = !1, this.enabled = !0, this.clampWhenFinished = !1, this.zeroSlopeAtStart = !0, this.zeroSlopeAtEnd = !0;
}
Object.assign(gb.prototype, {
  // State & Scheduling
  play: function() {
    return this._mixer._activateAction(this), this;
  },
  stop: function() {
    return this._mixer._deactivateAction(this), this.reset();
  },
  reset: function() {
    return this.paused = !1, this.enabled = !0, this.time = 0, this._loopCount = -1, this._startTime = null, this.stopFading().stopWarping();
  },
  isRunning: function() {
    return this.enabled && !this.paused && this.timeScale !== 0 && this._startTime === null && this._mixer._isActiveAction(this);
  },
  // return true when play has been called
  isScheduled: function() {
    return this._mixer._isActiveAction(this);
  },
  startAt: function(e) {
    return this._startTime = e, this;
  },
  setLoop: function(e, n) {
    return this.loop = e, this.repetitions = n, this;
  },
  // Weight
  // set the weight stopping any scheduled fading
  // although .enabled = false yields an effective weight of zero, this
  // method does *not* change .enabled, because it would be confusing
  setEffectiveWeight: function(e) {
    return this.weight = e, this._effectiveWeight = this.enabled ? e : 0, this.stopFading();
  },
  // return the weight considering fading and .enabled
  getEffectiveWeight: function() {
    return this._effectiveWeight;
  },
  fadeIn: function(e) {
    return this._scheduleFading(e, 0, 1);
  },
  fadeOut: function(e) {
    return this._scheduleFading(e, 1, 0);
  },
  crossFadeFrom: function(e, n, t) {
    if (e.fadeOut(n), this.fadeIn(n), t) {
      const i = this._clip.duration, r = e._clip.duration, a = r / i, c = i / r;
      e.warp(1, a, n), this.warp(c, 1, n);
    }
    return this;
  },
  crossFadeTo: function(e, n, t) {
    return e.crossFadeFrom(this, n, t);
  },
  stopFading: function() {
    let e = this._weightInterpolant;
    return e !== null && (this._weightInterpolant = null, this._mixer._takeBackControlInterpolant(e)), this;
  },
  // Time Scale Control
  // set the time scale stopping any scheduled warping
  // although .paused = true yields an effective time scale of zero, this
  // method does *not* change .paused, because it would be confusing
  setEffectiveTimeScale: function(e) {
    return this.timeScale = e, this._effectiveTimeScale = this.paused ? 0 : e, this.stopWarping();
  },
  // return the time scale considering warping and .paused
  getEffectiveTimeScale: function() {
    return this._effectiveTimeScale;
  },
  setDuration: function(e) {
    return this.timeScale = this._clip.duration / e, this.stopWarping();
  },
  syncWith: function(e) {
    return this.time = e.time, this.timeScale = e.timeScale, this.stopWarping();
  },
  halt: function(e) {
    return this.warp(this._effectiveTimeScale, 0, e);
  },
  warp: function(e, n, t) {
    const i = this._mixer, r = i.time, a = this.timeScale;
    let c = this._timeScaleInterpolant;
    c === null && (c = i._lendControlInterpolant(), this._timeScaleInterpolant = c);
    const u = c.parameterPositions, l = c.sampleValues;
    return u[0] = r, u[1] = r + t, l[0] = e / a, l[1] = n / a, this;
  },
  stopWarping: function() {
    let e = this._timeScaleInterpolant;
    return e !== null && (this._timeScaleInterpolant = null, this._mixer._takeBackControlInterpolant(e)), this;
  },
  // Object Accessors
  getMixer: function() {
    return this._mixer;
  },
  getClip: function() {
    return this._clip;
  },
  getRoot: function() {
    return this._localRoot || this._mixer._root;
  },
  // Interna
  _update: function(e, n, t, i) {
    if (!this.enabled) {
      this._updateWeight(e);
      return;
    }
    const r = this._startTime;
    if (r !== null) {
      const u = (e - r) * t;
      if (u < 0 || t === 0)
        return;
      this._startTime = null, n = t * u;
    }
    n *= this._updateTimeScale(e);
    const a = this._updateTime(n), c = this._updateWeight(e);
    if (c > 0) {
      const u = this._interpolants, l = this._propertyBindings;
      switch (this.blendMode) {
        case Bx:
          for (let f = 0, m = u.length; f !== m; ++f)
            u[f].evaluate(a), l[f].accumulateAdditive(c);
          break;
        case O0:
        default:
          for (let f = 0, m = u.length; f !== m; ++f)
            u[f].evaluate(a), l[f].accumulate(i, c);
      }
    }
  },
  _updateWeight: function(e) {
    let n = 0;
    if (this.enabled) {
      n = this.weight;
      const t = this._weightInterpolant;
      if (t !== null) {
        const i = t.evaluate(e)[0];
        n *= i, e > t.parameterPositions[1] && (this.stopFading(), i === 0 && (this.enabled = !1));
      }
    }
    return this._effectiveWeight = n, n;
  },
  _updateTimeScale: function(e) {
    let n = 0;
    if (!this.paused) {
      n = this.timeScale;
      const t = this._timeScaleInterpolant;
      if (t !== null) {
        const i = t.evaluate(e)[0];
        n *= i, e > t.parameterPositions[1] && (this.stopWarping(), n === 0 ? this.paused = !0 : this.timeScale = n);
      }
    }
    return this._effectiveTimeScale = n, n;
  },
  _updateTime: function(e) {
    const n = this._clip.duration, t = this.loop;
    let i = this.time + e, r = this._loopCount;
    const a = t === c1;
    if (e === 0)
      return r === -1 ? i : a && (r & 1) === 1 ? n - i : i;
    if (t === a1) {
      r === -1 && (this._loopCount = 0, this._setEndings(!0, !0, !1));
      e: {
        if (i >= n)
          i = n;
        else if (i < 0)
          i = 0;
        else {
          this.time = i;
          break e;
        }
        this.clampWhenFinished ? this.paused = !0 : this.enabled = !1, this.time = i, this._mixer.dispatchEvent({
          type: "finished",
          action: this,
          direction: e < 0 ? -1 : 1
        });
      }
    } else {
      if (r === -1 && (e >= 0 ? (r = 0, this._setEndings(!0, this.repetitions === 0, a)) : this._setEndings(this.repetitions === 0, !0, a)), i >= n || i < 0) {
        const c = Math.floor(i / n);
        i -= n * c, r += Math.abs(c);
        const u = this.repetitions - r;
        if (u <= 0)
          this.clampWhenFinished ? this.paused = !0 : this.enabled = !1, i = e > 0 ? n : 0, this.time = i, this._mixer.dispatchEvent({
            type: "finished",
            action: this,
            direction: e > 0 ? 1 : -1
          });
        else {
          if (u === 1) {
            const l = e < 0;
            this._setEndings(l, !l, a);
          } else
            this._setEndings(!1, !1, a);
          this._loopCount = r, this.time = i, this._mixer.dispatchEvent({
            type: "loop",
            action: this,
            loopDelta: c
          });
        }
      } else
        this.time = i;
      if (a && (r & 1) === 1)
        return n - i;
    }
    return i;
  },
  _setEndings: function(e, n, t) {
    const i = this._interpolantSettings;
    t ? (i.endingStart = Qc, i.endingEnd = Qc) : (e ? i.endingStart = this.zeroSlopeAtStart ? Qc : au : i.endingStart = ey, n ? i.endingEnd = this.zeroSlopeAtEnd ? Qc : au : i.endingEnd = ey);
  },
  _scheduleFading: function(e, n, t) {
    const i = this._mixer, r = i.time;
    let a = this._weightInterpolant;
    a === null && (a = i._lendControlInterpolant(), this._weightInterpolant = a);
    const c = a.parameterPositions, u = a.sampleValues;
    return c[0] = r, u[0] = n, c[1] = r + e, u[1] = t, this;
  }
});
function ux(e) {
  this._root = e, this._initMemoryManager(), this._accuIndex = 0, this.time = 0, this.timeScale = 1;
}
ux.prototype = Object.assign(Object.create(Fr.prototype), {
  constructor: ux,
  _bindAction: function(e, n) {
    const t = e._localRoot || this._root, i = e._clip.tracks, r = i.length, a = e._propertyBindings, c = e._interpolants, u = t.uuid, l = this._bindingsByRootAndName;
    let f = l[u];
    f === void 0 && (f = {}, l[u] = f);
    for (let m = 0; m !== r; ++m) {
      const h = i[m], p = h.name;
      let _ = f[p];
      if (_ !== void 0)
        a[m] = _;
      else {
        if (_ = a[m], _ !== void 0) {
          _._cacheIndex === null && (++_.referenceCount, this._addInactiveBinding(_, u, p));
          continue;
        }
        const v = n && n._propertyBindings[m].binding.parsedPath;
        _ = new pb(
          zi.create(t, p, v),
          h.ValueTypeName,
          h.getValueSize()
        ), ++_.referenceCount, this._addInactiveBinding(_, u, p), a[m] = _;
      }
      c[m].resultBuffer = _.buffer;
    }
  },
  _activateAction: function(e) {
    if (!this._isActiveAction(e)) {
      if (e._cacheIndex === null) {
        const t = (e._localRoot || this._root).uuid, i = e._clip.uuid, r = this._actionsByClip[i];
        this._bindAction(
          e,
          r && r.knownActions[0]
        ), this._addInactiveAction(e, i, t);
      }
      const n = e._propertyBindings;
      for (let t = 0, i = n.length; t !== i; ++t) {
        const r = n[t];
        r.useCount++ === 0 && (this._lendBinding(r), r.saveOriginalState());
      }
      this._lendAction(e);
    }
  },
  _deactivateAction: function(e) {
    if (this._isActiveAction(e)) {
      const n = e._propertyBindings;
      for (let t = 0, i = n.length; t !== i; ++t) {
        const r = n[t];
        --r.useCount === 0 && (r.restoreOriginalState(), this._takeBackBinding(r));
      }
      this._takeBackAction(e);
    }
  },
  // Memory manager
  _initMemoryManager: function() {
    this._actions = [], this._nActiveActions = 0, this._actionsByClip = {}, this._bindings = [], this._nActiveBindings = 0, this._bindingsByRootAndName = {}, this._controlInterpolants = [], this._nActiveControlInterpolants = 0;
    const e = this;
    this.stats = {
      actions: {
        get total() {
          return e._actions.length;
        },
        get inUse() {
          return e._nActiveActions;
        }
      },
      bindings: {
        get total() {
          return e._bindings.length;
        },
        get inUse() {
          return e._nActiveBindings;
        }
      },
      controlInterpolants: {
        get total() {
          return e._controlInterpolants.length;
        },
        get inUse() {
          return e._nActiveControlInterpolants;
        }
      }
    };
  },
  // Memory management for AnimationAction objects
  _isActiveAction: function(e) {
    const n = e._cacheIndex;
    return n !== null && n < this._nActiveActions;
  },
  _addInactiveAction: function(e, n, t) {
    const i = this._actions, r = this._actionsByClip;
    let a = r[n];
    if (a === void 0)
      a = {
        knownActions: [e],
        actionByRoot: {}
      }, e._byClipCacheIndex = 0, r[n] = a;
    else {
      const c = a.knownActions;
      e._byClipCacheIndex = c.length, c.push(e);
    }
    e._cacheIndex = i.length, i.push(e), a.actionByRoot[t] = e;
  },
  _removeInactiveAction: function(e) {
    const n = this._actions, t = n[n.length - 1], i = e._cacheIndex;
    t._cacheIndex = i, n[i] = t, n.pop(), e._cacheIndex = null;
    const r = e._clip.uuid, a = this._actionsByClip, c = a[r], u = c.knownActions, l = u[u.length - 1], f = e._byClipCacheIndex;
    l._byClipCacheIndex = f, u[f] = l, u.pop(), e._byClipCacheIndex = null;
    const m = c.actionByRoot, h = (e._localRoot || this._root).uuid;
    delete m[h], u.length === 0 && delete a[r], this._removeInactiveBindingsForAction(e);
  },
  _removeInactiveBindingsForAction: function(e) {
    const n = e._propertyBindings;
    for (let t = 0, i = n.length; t !== i; ++t) {
      const r = n[t];
      --r.referenceCount === 0 && this._removeInactiveBinding(r);
    }
  },
  _lendAction: function(e) {
    const n = this._actions, t = e._cacheIndex, i = this._nActiveActions++, r = n[i];
    e._cacheIndex = i, n[i] = e, r._cacheIndex = t, n[t] = r;
  },
  _takeBackAction: function(e) {
    const n = this._actions, t = e._cacheIndex, i = --this._nActiveActions, r = n[i];
    e._cacheIndex = i, n[i] = e, r._cacheIndex = t, n[t] = r;
  },
  // Memory management for PropertyMixer objects
  _addInactiveBinding: function(e, n, t) {
    const i = this._bindingsByRootAndName, r = this._bindings;
    let a = i[n];
    a === void 0 && (a = {}, i[n] = a), a[t] = e, e._cacheIndex = r.length, r.push(e);
  },
  _removeInactiveBinding: function(e) {
    const n = this._bindings, t = e.binding, i = t.rootNode.uuid, r = t.path, a = this._bindingsByRootAndName, c = a[i], u = n[n.length - 1], l = e._cacheIndex;
    u._cacheIndex = l, n[l] = u, n.pop(), delete c[r], Object.keys(c).length === 0 && delete a[i];
  },
  _lendBinding: function(e) {
    const n = this._bindings, t = e._cacheIndex, i = this._nActiveBindings++, r = n[i];
    e._cacheIndex = i, n[i] = e, r._cacheIndex = t, n[t] = r;
  },
  _takeBackBinding: function(e) {
    const n = this._bindings, t = e._cacheIndex, i = --this._nActiveBindings, r = n[i];
    e._cacheIndex = i, n[i] = e, r._cacheIndex = t, n[t] = r;
  },
  // Memory management of Interpolants for weight and time scale
  _lendControlInterpolant: function() {
    const e = this._controlInterpolants, n = this._nActiveControlInterpolants++;
    let t = e[n];
    return t === void 0 && (t = new My(
      new Float32Array(2),
      new Float32Array(2),
      1,
      this._controlInterpolantsResultBuffer
    ), t.__cacheIndex = n, e[n] = t), t;
  },
  _takeBackControlInterpolant: function(e) {
    const n = this._controlInterpolants, t = e.__cacheIndex, i = --this._nActiveControlInterpolants, r = n[i];
    e.__cacheIndex = i, n[i] = e, r.__cacheIndex = t, n[t] = r;
  },
  _controlInterpolantsResultBuffer: new Float32Array(1),
  // return an action for a clip optionally using a custom root target
  // object (this method allocates a lot of dynamic memory in case a
  // previously unknown clip/root combination is specified)
  clipAction: function(e, n, t) {
    const i = n || this._root, r = i.uuid;
    let a = typeof e == "string" ? Ns.findByName(i, e) : e;
    const c = a !== null ? a.uuid : e;
    let u = this._actionsByClip[c], l = null;
    if (t === void 0 && (a !== null ? t = a.blendMode : t = O0), u !== void 0) {
      const m = u.actionByRoot[r];
      if (m !== void 0 && m.blendMode === t)
        return m;
      l = u.knownActions[0], a === null && (a = l._clip);
    }
    if (a === null)
      return null;
    const f = new gb(this, a, n, t);
    return this._bindAction(f, l), this._addInactiveAction(f, c, r), f;
  },
  // get an existing action
  existingAction: function(e, n) {
    const t = n || this._root, i = t.uuid, r = typeof e == "string" ? Ns.findByName(t, e) : e, a = r ? r.uuid : e, c = this._actionsByClip[a];
    return c !== void 0 && c.actionByRoot[i] || null;
  },
  // deactivates all previously scheduled actions
  stopAllAction: function() {
    const e = this._actions, n = this._nActiveActions;
    for (let t = n - 1; t >= 0; --t)
      e[t].stop();
    return this;
  },
  // advance the time and update apply the animation
  update: function(e) {
    e *= this.timeScale;
    const n = this._actions, t = this._nActiveActions, i = this.time += e, r = Math.sign(e), a = this._accuIndex ^= 1;
    for (let l = 0; l !== t; ++l)
      n[l]._update(i, e, r, a);
    const c = this._bindings, u = this._nActiveBindings;
    for (let l = 0; l !== u; ++l)
      c[l].apply(a);
    return this;
  },
  // Allows you to seek to a specific time in an animation.
  setTime: function(e) {
    this.time = 0;
    for (let n = 0; n < this._actions.length; n++)
      this._actions[n].time = 0;
    return this.update(e);
  },
  // return this mixer's root target object
  getRoot: function() {
    return this._root;
  },
  // free all resources specific to a particular clip
  uncacheClip: function(e) {
    const n = this._actions, t = e.uuid, i = this._actionsByClip, r = i[t];
    if (r !== void 0) {
      const a = r.knownActions;
      for (let c = 0, u = a.length; c !== u; ++c) {
        const l = a[c];
        this._deactivateAction(l);
        const f = l._cacheIndex, m = n[n.length - 1];
        l._cacheIndex = null, l._byClipCacheIndex = null, m._cacheIndex = f, n[f] = m, n.pop(), this._removeInactiveBindingsForAction(l);
      }
      delete i[t];
    }
  },
  // free all resources specific to a particular root target object
  uncacheRoot: function(e) {
    const n = e.uuid, t = this._actionsByClip;
    for (const a in t) {
      const c = t[a].actionByRoot, u = c[n];
      u !== void 0 && (this._deactivateAction(u), this._removeInactiveAction(u));
    }
    const i = this._bindingsByRootAndName, r = i[n];
    if (r !== void 0)
      for (const a in r) {
        const c = r[a];
        c.restoreOriginalState(), this._removeInactiveBinding(c);
      }
  },
  // remove a targeted clip from the cache
  uncacheAction: function(e, n) {
    const t = this.existingAction(e, n);
    t !== null && (this._deactivateAction(t), this._removeInactiveAction(t));
  }
});
function x0(e) {
  typeof e == "string" && (console.warn("THREE.Uniform: Type parameter is no longer needed."), e = arguments[1]), this.value = e;
}
x0.prototype.clone = function() {
  return new x0(this.value.clone === void 0 ? this.value : this.value.clone());
};
function dx(e, n, t) {
  vs.call(this, e, n), this.meshPerAttribute = t || 1;
}
dx.prototype = Object.assign(Object.create(vs.prototype), {
  constructor: dx,
  isInstancedInterleavedBuffer: !0,
  copy: function(e) {
    return vs.prototype.copy.call(this, e), this.meshPerAttribute = e.meshPerAttribute, this;
  },
  clone: function(e) {
    const n = vs.prototype.clone.call(this, e);
    return n.meshPerAttribute = this.meshPerAttribute, n;
  },
  toJSON: function(e) {
    const n = vs.prototype.toJSON.call(this, e);
    return n.isInstancedInterleavedBuffer = !0, n.meshPerAttribute = this.meshPerAttribute, n;
  }
});
function G0(e, n, t, i) {
  this.ray = new Au(e, n), this.near = t || 0, this.far = i || 1 / 0, this.camera = null, this.layers = new B0(), this.params = {
    Mesh: {},
    Line: { threshold: 1 },
    LOD: {},
    Points: { threshold: 1 },
    Sprite: {}
  }, Object.defineProperties(this.params, {
    PointCloud: {
      get: function() {
        return console.warn("THREE.Raycaster: params.PointCloud has been renamed to params.Points."), this.Points;
      }
    }
  });
}
function hx(e, n) {
  return e.distance - n.distance;
}
function b0(e, n, t, i) {
  if (e.layers.test(n.layers) && e.raycast(n, t), i === !0) {
    const r = e.children;
    for (let a = 0, c = r.length; a < c; a++)
      b0(r[a], n, t, !0);
  }
}
Object.assign(G0.prototype, {
  set: function(e, n) {
    this.ray.set(e, n);
  },
  setFromCamera: function(e, n) {
    n && n.isPerspectiveCamera ? (this.ray.origin.setFromMatrixPosition(n.matrixWorld), this.ray.direction.set(e.x, e.y, 0.5).unproject(n).sub(this.ray.origin).normalize(), this.camera = n) : n && n.isOrthographicCamera ? (this.ray.origin.set(e.x, e.y, (n.near + n.far) / (n.near - n.far)).unproject(n), this.ray.direction.set(0, 0, -1).transformDirection(n.matrixWorld), this.camera = n) : console.error("THREE.Raycaster: Unsupported camera type.");
  },
  intersectObject: function(e, n, t) {
    const i = t || [];
    return b0(e, this, i, n), i.sort(hx), i;
  },
  intersectObjects: function(e, n, t) {
    const i = t || [];
    if (Array.isArray(e) === !1)
      return console.warn("THREE.Raycaster.intersectObjects: objects is not an Array."), i;
    for (let r = 0, a = e.length; r < a; r++)
      b0(e[r], this, i, n);
    return i.sort(hx), i;
  }
});
function xP(e, n, t) {
  return this.radius = e !== void 0 ? e : 1, this.theta = n !== void 0 ? n : 0, this.y = t !== void 0 ? t : 0, this;
}
Object.assign(xP.prototype, {
  set: function(e, n, t) {
    return this.radius = e, this.theta = n, this.y = t, this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.radius = e.radius, this.theta = e.theta, this.y = e.y, this;
  },
  setFromVector3: function(e) {
    return this.setFromCartesianCoords(e.x, e.y, e.z);
  },
  setFromCartesianCoords: function(e, n, t) {
    return this.radius = Math.sqrt(e * e + t * t), this.theta = Math.atan2(e, t), this.y = n, this;
  }
});
const fx = new vt();
function _b(e, n) {
  this.min = e !== void 0 ? e : new vt(1 / 0, 1 / 0), this.max = n !== void 0 ? n : new vt(-1 / 0, -1 / 0);
}
Object.assign(_b.prototype, {
  set: function(e, n) {
    return this.min.copy(e), this.max.copy(n), this;
  },
  setFromPoints: function(e) {
    this.makeEmpty();
    for (let n = 0, t = e.length; n < t; n++)
      this.expandByPoint(e[n]);
    return this;
  },
  setFromCenterAndSize: function(e, n) {
    const t = fx.copy(n).multiplyScalar(0.5);
    return this.min.copy(e).sub(t), this.max.copy(e).add(t), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.min.copy(e.min), this.max.copy(e.max), this;
  },
  makeEmpty: function() {
    return this.min.x = this.min.y = 1 / 0, this.max.x = this.max.y = -1 / 0, this;
  },
  isEmpty: function() {
    return this.max.x < this.min.x || this.max.y < this.min.y;
  },
  getCenter: function(e) {
    return e === void 0 && (console.warn("THREE.Box2: .getCenter() target is now required"), e = new vt()), this.isEmpty() ? e.set(0, 0) : e.addVectors(this.min, this.max).multiplyScalar(0.5);
  },
  getSize: function(e) {
    return e === void 0 && (console.warn("THREE.Box2: .getSize() target is now required"), e = new vt()), this.isEmpty() ? e.set(0, 0) : e.subVectors(this.max, this.min);
  },
  expandByPoint: function(e) {
    return this.min.min(e), this.max.max(e), this;
  },
  expandByVector: function(e) {
    return this.min.sub(e), this.max.add(e), this;
  },
  expandByScalar: function(e) {
    return this.min.addScalar(-e), this.max.addScalar(e), this;
  },
  containsPoint: function(e) {
    return !(e.x < this.min.x || e.x > this.max.x || e.y < this.min.y || e.y > this.max.y);
  },
  containsBox: function(e) {
    return this.min.x <= e.min.x && e.max.x <= this.max.x && this.min.y <= e.min.y && e.max.y <= this.max.y;
  },
  getParameter: function(e, n) {
    return n === void 0 && (console.warn("THREE.Box2: .getParameter() target is now required"), n = new vt()), n.set(
      (e.x - this.min.x) / (this.max.x - this.min.x),
      (e.y - this.min.y) / (this.max.y - this.min.y)
    );
  },
  intersectsBox: function(e) {
    return !(e.max.x < this.min.x || e.min.x > this.max.x || e.max.y < this.min.y || e.min.y > this.max.y);
  },
  clampPoint: function(e, n) {
    return n === void 0 && (console.warn("THREE.Box2: .clampPoint() target is now required"), n = new vt()), n.copy(e).clamp(this.min, this.max);
  },
  distanceToPoint: function(e) {
    return fx.copy(e).clamp(this.min, this.max).sub(e).length();
  },
  intersect: function(e) {
    return this.min.max(e.min), this.max.min(e.max), this;
  },
  union: function(e) {
    return this.min.min(e.min), this.max.max(e.max), this;
  },
  translate: function(e) {
    return this.min.add(e), this.max.add(e), this;
  },
  equals: function(e) {
    return e.min.equals(this.min) && e.max.equals(this.max);
  }
});
const px = new ve(), R_ = new ve();
function yb(e, n) {
  this.start = e !== void 0 ? e : new ve(), this.end = n !== void 0 ? n : new ve();
}
Object.assign(yb.prototype, {
  set: function(e, n) {
    return this.start.copy(e), this.end.copy(n), this;
  },
  clone: function() {
    return new this.constructor().copy(this);
  },
  copy: function(e) {
    return this.start.copy(e.start), this.end.copy(e.end), this;
  },
  getCenter: function(e) {
    return e === void 0 && (console.warn("THREE.Line3: .getCenter() target is now required"), e = new ve()), e.addVectors(this.start, this.end).multiplyScalar(0.5);
  },
  delta: function(e) {
    return e === void 0 && (console.warn("THREE.Line3: .delta() target is now required"), e = new ve()), e.subVectors(this.end, this.start);
  },
  distanceSq: function() {
    return this.start.distanceToSquared(this.end);
  },
  distance: function() {
    return this.start.distanceTo(this.end);
  },
  at: function(e, n) {
    return n === void 0 && (console.warn("THREE.Line3: .at() target is now required"), n = new ve()), this.delta(n).multiplyScalar(e).add(this.start);
  },
  closestPointToPointParameter: function(e, n) {
    px.subVectors(e, this.start), R_.subVectors(this.end, this.start);
    const t = R_.dot(R_);
    let r = R_.dot(px) / t;
    return n && (r = un.clamp(r, 0, 1)), r;
  },
  closestPointToPoint: function(e, n, t) {
    const i = this.closestPointToPointParameter(e, n);
    return t === void 0 && (console.warn("THREE.Line3: .closestPointToPoint() target is now required"), t = new ve()), this.delta(t).multiplyScalar(i).add(this.start);
  },
  applyMatrix4: function(e) {
    return this.start.applyMatrix4(e), this.end.applyMatrix4(e), this;
  },
  equals: function(e) {
    return e.start.equals(this.start) && e.end.equals(this.end);
  }
});
function Cy(e) {
  Ft.call(this), this.material = e, this.render = function() {
  }, this.hasPositions = !1, this.hasNormals = !1, this.hasColors = !1, this.hasUvs = !1, this.positionArray = null, this.normalArray = null, this.colorArray = null, this.uvArray = null, this.count = 0;
}
Cy.prototype = Object.create(Ft.prototype);
Cy.prototype.constructor = Cy;
Cy.prototype.isImmediateRenderObject = !0;
const mx = new ve();
function sg(e, n) {
  Ft.call(this), this.light = e, this.light.updateMatrixWorld(), this.matrix = e.matrixWorld, this.matrixAutoUpdate = !1, this.color = n;
  const t = new Gt(), i = [
    0,
    0,
    0,
    0,
    0,
    1,
    0,
    0,
    0,
    1,
    0,
    1,
    0,
    0,
    0,
    -1,
    0,
    1,
    0,
    0,
    0,
    0,
    1,
    1,
    0,
    0,
    0,
    0,
    -1,
    1
  ];
  for (let a = 0, c = 1, u = 32; a < u; a++, c++) {
    const l = a / u * Math.PI * 2, f = c / u * Math.PI * 2;
    i.push(
      Math.cos(l),
      Math.sin(l),
      1,
      Math.cos(f),
      Math.sin(f),
      1
    );
  }
  t.setAttribute("position", new zt(i, 3));
  const r = new Zn({ fog: !1, toneMapped: !1 });
  this.cone = new ai(t, r), this.add(this.cone), this.update();
}
sg.prototype = Object.create(Ft.prototype);
sg.prototype.constructor = sg;
sg.prototype.dispose = function() {
  this.cone.geometry.dispose(), this.cone.material.dispose();
};
sg.prototype.update = function() {
  this.light.updateMatrixWorld();
  const e = this.light.distance ? this.light.distance : 1e3, n = e * Math.tan(this.light.angle);
  this.cone.scale.set(n, n, e), mx.setFromMatrixPosition(this.light.target.matrixWorld), this.cone.lookAt(mx), this.color !== void 0 ? this.cone.material.color.set(this.color) : this.cone.material.color.copy(this.light.color);
};
const ro = new ve(), B_ = new dn(), Av = new dn();
function vb(e) {
  const n = [];
  e && e.isBone && n.push(e);
  for (let t = 0; t < e.children.length; t++)
    n.push.apply(n, vb(e.children[t]));
  return n;
}
function Tu(e) {
  const n = vb(e), t = new Gt(), i = [], r = [], a = new Wt(0, 0, 1), c = new Wt(0, 1, 0);
  for (let l = 0; l < n.length; l++) {
    const f = n[l];
    f.parent && f.parent.isBone && (i.push(0, 0, 0), i.push(0, 0, 0), r.push(a.r, a.g, a.b), r.push(c.r, c.g, c.b));
  }
  t.setAttribute("position", new zt(i, 3)), t.setAttribute("color", new zt(r, 3));
  const u = new Zn({ vertexColors: !0, depthTest: !1, depthWrite: !1, toneMapped: !1, transparent: !0 });
  ai.call(this, t, u), this.type = "SkeletonHelper", this.root = e, this.bones = n, this.matrix = e.matrixWorld, this.matrixAutoUpdate = !1;
}
Tu.prototype = Object.create(ai.prototype);
Tu.prototype.constructor = Tu;
Tu.prototype.isSkeletonHelper = !0;
Tu.prototype.updateMatrixWorld = function(e) {
  const n = this.bones, t = this.geometry, i = t.getAttribute("position");
  Av.getInverse(this.root.matrixWorld);
  for (let r = 0, a = 0; r < n.length; r++) {
    const c = n[r];
    c.parent && c.parent.isBone && (B_.multiplyMatrices(Av, c.matrixWorld), ro.setFromMatrixPosition(B_), i.setXYZ(a, ro.x, ro.y, ro.z), B_.multiplyMatrices(Av, c.parent.matrixWorld), ro.setFromMatrixPosition(B_), i.setXYZ(a + 1, ro.x, ro.y, ro.z), a += 2);
  }
  t.getAttribute("position").needsUpdate = !0, Ft.prototype.updateMatrixWorld.call(this, e);
};
function rg(e, n, t) {
  this.light = e, this.light.updateMatrixWorld(), this.color = t;
  const i = new pu(n, 4, 2), r = new Ms({ wireframe: !0, fog: !1, toneMapped: !1 });
  Ln.call(this, i, r), this.type = "PointLightHelper", this.matrix = this.light.matrixWorld, this.matrixAutoUpdate = !1, this.update();
}
rg.prototype = Object.create(Ln.prototype);
rg.prototype.constructor = rg;
rg.prototype.dispose = function() {
  this.geometry.dispose(), this.material.dispose();
};
rg.prototype.update = function() {
  this.color !== void 0 ? this.material.color.set(this.color) : this.material.color.copy(this.light.color);
};
const bP = new ve(), gx = new Wt(), _x = new Wt();
function og(e, n, t) {
  Ft.call(this), this.light = e, this.light.updateMatrixWorld(), this.matrix = e.matrixWorld, this.matrixAutoUpdate = !1, this.color = t;
  const i = new du(n);
  i.rotateY(Math.PI * 0.5), this.material = new Ms({ wireframe: !0, fog: !1, toneMapped: !1 }), this.color === void 0 && (this.material.vertexColors = !0);
  const r = i.getAttribute("position"), a = new Float32Array(r.count * 3);
  i.setAttribute("color", new Jt(a, 3)), this.add(new Ln(i, this.material)), this.update();
}
og.prototype = Object.create(Ft.prototype);
og.prototype.constructor = og;
og.prototype.dispose = function() {
  this.children[0].geometry.dispose(), this.children[0].material.dispose();
};
og.prototype.update = function() {
  const e = this.children[0];
  if (this.color !== void 0)
    this.material.color.set(this.color);
  else {
    const n = e.geometry.getAttribute("color");
    gx.copy(this.light.color), _x.copy(this.light.groundColor);
    for (let t = 0, i = n.count; t < i; t++) {
      const r = t < i / 2 ? gx : _x;
      n.setXYZ(t, r.r, r.g, r.b);
    }
    n.needsUpdate = !0;
  }
  e.lookAt(bP.setFromMatrixPosition(this.light.matrixWorld).negate());
};
function Iy(e, n, t, i) {
  e = e || 10, n = n || 10, t = new Wt(t !== void 0 ? t : 4473924), i = new Wt(i !== void 0 ? i : 8947848);
  const r = n / 2, a = e / n, c = e / 2, u = [], l = [];
  for (let h = 0, p = 0, _ = -c; h <= n; h++, _ += a) {
    u.push(-c, 0, _, c, 0, _), u.push(_, 0, -c, _, 0, c);
    const v = h === r ? t : i;
    v.toArray(l, p), p += 3, v.toArray(l, p), p += 3, v.toArray(l, p), p += 3, v.toArray(l, p), p += 3;
  }
  const f = new Gt();
  f.setAttribute("position", new zt(u, 3)), f.setAttribute("color", new zt(l, 3));
  const m = new Zn({ vertexColors: !0, toneMapped: !1 });
  ai.call(this, f, m), this.type = "GridHelper";
}
Iy.prototype = Object.create(ai.prototype);
Iy.prototype.constructor = Iy;
function M0(e, n, t, i, r, a) {
  e = e || 10, n = n || 16, t = t || 8, i = i || 64, r = new Wt(r !== void 0 ? r : 4473924), a = new Wt(a !== void 0 ? a : 8947848);
  const c = [], u = [];
  for (let m = 0; m <= n; m++) {
    const h = m / n * (Math.PI * 2), p = Math.sin(h) * e, _ = Math.cos(h) * e;
    c.push(0, 0, 0), c.push(p, 0, _);
    const v = m & 1 ? r : a;
    u.push(v.r, v.g, v.b), u.push(v.r, v.g, v.b);
  }
  for (let m = 0; m <= t; m++) {
    const h = m & 1 ? r : a, p = e - e / t * m;
    for (let _ = 0; _ < i; _++) {
      let v = _ / i * (Math.PI * 2), S = Math.sin(v) * p, D = Math.cos(v) * p;
      c.push(S, 0, D), u.push(h.r, h.g, h.b), v = (_ + 1) / i * (Math.PI * 2), S = Math.sin(v) * p, D = Math.cos(v) * p, c.push(S, 0, D), u.push(h.r, h.g, h.b);
    }
  }
  const l = new Gt();
  l.setAttribute("position", new zt(c, 3)), l.setAttribute("color", new zt(u, 3));
  const f = new Zn({ vertexColors: !0, toneMapped: !1 });
  ai.call(this, l, f), this.type = "PolarGridHelper";
}
M0.prototype = Object.create(ai.prototype);
M0.prototype.constructor = M0;
const yx = new ve(), z_ = new ve(), vx = new ve();
function ag(e, n, t) {
  Ft.call(this), this.light = e, this.light.updateMatrixWorld(), this.matrix = e.matrixWorld, this.matrixAutoUpdate = !1, this.color = t, n === void 0 && (n = 1);
  let i = new Gt();
  i.setAttribute("position", new zt([
    -n,
    n,
    0,
    n,
    n,
    0,
    n,
    -n,
    0,
    -n,
    -n,
    0,
    -n,
    n,
    0
  ], 3));
  const r = new Zn({ fog: !1, toneMapped: !1 });
  this.lightPlane = new Es(i, r), this.add(this.lightPlane), i = new Gt(), i.setAttribute("position", new zt([0, 0, 0, 0, 0, 1], 3)), this.targetLine = new Es(i, r), this.add(this.targetLine), this.update();
}
ag.prototype = Object.create(Ft.prototype);
ag.prototype.constructor = ag;
ag.prototype.dispose = function() {
  this.lightPlane.geometry.dispose(), this.lightPlane.material.dispose(), this.targetLine.geometry.dispose(), this.targetLine.material.dispose();
};
ag.prototype.update = function() {
  yx.setFromMatrixPosition(this.light.matrixWorld), z_.setFromMatrixPosition(this.light.target.matrixWorld), vx.subVectors(z_, yx), this.lightPlane.lookAt(z_), this.color !== void 0 ? (this.lightPlane.material.color.set(this.color), this.targetLine.material.color.set(this.color)) : (this.lightPlane.material.color.copy(this.light.color), this.targetLine.material.color.copy(this.light.color)), this.targetLine.lookAt(z_), this.targetLine.scale.z = vx.length();
};
const $_ = new ve(), Qn = new Ir();
function Ly(e) {
  const n = new Gt(), t = new Zn({ color: 16777215, vertexColors: !0, toneMapped: !1 }), i = [], r = [], a = {}, c = new Wt(16755200), u = new Wt(16711680), l = new Wt(43775), f = new Wt(16777215), m = new Wt(3355443);
  h("n1", "n2", c), h("n2", "n4", c), h("n4", "n3", c), h("n3", "n1", c), h("f1", "f2", c), h("f2", "f4", c), h("f4", "f3", c), h("f3", "f1", c), h("n1", "f1", c), h("n2", "f2", c), h("n3", "f3", c), h("n4", "f4", c), h("p", "n1", u), h("p", "n2", u), h("p", "n3", u), h("p", "n4", u), h("u1", "u2", l), h("u2", "u3", l), h("u3", "u1", l), h("c", "t", f), h("p", "c", m), h("cn1", "cn2", m), h("cn3", "cn4", m), h("cf1", "cf2", m), h("cf3", "cf4", m);
  function h(_, v, S) {
    p(_, S), p(v, S);
  }
  function p(_, v) {
    i.push(0, 0, 0), r.push(v.r, v.g, v.b), a[_] === void 0 && (a[_] = []), a[_].push(i.length / 3 - 1);
  }
  n.setAttribute("position", new zt(i, 3)), n.setAttribute("color", new zt(r, 3)), ai.call(this, n, t), this.type = "CameraHelper", this.camera = e, this.camera.updateProjectionMatrix && this.camera.updateProjectionMatrix(), this.matrix = e.matrixWorld, this.matrixAutoUpdate = !1, this.pointMap = a, this.update();
}
Ly.prototype = Object.create(ai.prototype);
Ly.prototype.constructor = Ly;
Ly.prototype.update = function() {
  const e = this.geometry, n = this.pointMap, t = 1, i = 1;
  Qn.projectionMatrixInverse.copy(this.camera.projectionMatrixInverse), ni("c", n, e, Qn, 0, 0, -1), ni("t", n, e, Qn, 0, 0, 1), ni("n1", n, e, Qn, -t, -i, -1), ni("n2", n, e, Qn, t, -i, -1), ni("n3", n, e, Qn, -t, i, -1), ni("n4", n, e, Qn, t, i, -1), ni("f1", n, e, Qn, -t, -i, 1), ni("f2", n, e, Qn, t, -i, 1), ni("f3", n, e, Qn, -t, i, 1), ni("f4", n, e, Qn, t, i, 1), ni("u1", n, e, Qn, t * 0.7, i * 1.1, -1), ni("u2", n, e, Qn, -t * 0.7, i * 1.1, -1), ni("u3", n, e, Qn, 0, i * 2, -1), ni("cf1", n, e, Qn, -t, 0, 1), ni("cf2", n, e, Qn, t, 0, 1), ni("cf3", n, e, Qn, 0, -i, 1), ni("cf4", n, e, Qn, 0, i, 1), ni("cn1", n, e, Qn, -t, 0, -1), ni("cn2", n, e, Qn, t, 0, -1), ni("cn3", n, e, Qn, 0, -i, -1), ni("cn4", n, e, Qn, 0, i, -1), e.getAttribute("position").needsUpdate = !0;
};
function ni(e, n, t, i, r, a, c) {
  $_.set(r, a, c).unproject(i);
  const u = n[e];
  if (u !== void 0) {
    const l = t.getAttribute("position");
    for (let f = 0, m = u.length; f < m; f++)
      l.setXYZ(u[f], $_.x, $_.y, $_.z);
  }
}
const N_ = new mr();
function Eu(e, n) {
  this.object = e, n === void 0 && (n = 16776960);
  const t = new Uint16Array([0, 1, 1, 2, 2, 3, 3, 0, 4, 5, 5, 6, 6, 7, 7, 4, 0, 4, 1, 5, 2, 6, 3, 7]), i = new Float32Array(8 * 3), r = new Gt();
  r.setIndex(new Jt(t, 1)), r.setAttribute("position", new Jt(i, 3)), ai.call(this, r, new Zn({ color: n, toneMapped: !1 })), this.type = "BoxHelper", this.matrixAutoUpdate = !1, this.update();
}
Eu.prototype = Object.create(ai.prototype);
Eu.prototype.constructor = Eu;
Eu.prototype.update = function(e) {
  if (e !== void 0 && console.warn("THREE.BoxHelper: .update() has no longer arguments."), this.object !== void 0 && N_.setFromObject(this.object), N_.isEmpty())
    return;
  const n = N_.min, t = N_.max, i = this.geometry.attributes.position, r = i.array;
  r[0] = t.x, r[1] = t.y, r[2] = t.z, r[3] = n.x, r[4] = t.y, r[5] = t.z, r[6] = n.x, r[7] = n.y, r[8] = t.z, r[9] = t.x, r[10] = n.y, r[11] = t.z, r[12] = t.x, r[13] = t.y, r[14] = n.z, r[15] = n.x, r[16] = t.y, r[17] = n.z, r[18] = n.x, r[19] = n.y, r[20] = n.z, r[21] = t.x, r[22] = n.y, r[23] = n.z, i.needsUpdate = !0, this.geometry.computeBoundingSphere();
};
Eu.prototype.setFromObject = function(e) {
  return this.object = e, this.update(), this;
};
Eu.prototype.copy = function(e) {
  return ai.prototype.copy.call(this, e), this.object = e.object, this;
};
function Dy(e, n) {
  this.type = "Box3Helper", this.box = e, n === void 0 && (n = 16776960);
  const t = new Uint16Array([0, 1, 1, 2, 2, 3, 3, 0, 4, 5, 5, 6, 6, 7, 7, 4, 0, 4, 1, 5, 2, 6, 3, 7]), i = [1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1], r = new Gt();
  r.setIndex(new Jt(t, 1)), r.setAttribute("position", new zt(i, 3)), ai.call(this, r, new Zn({ color: n, toneMapped: !1 })), this.type = "Box3Helper", this.geometry.computeBoundingSphere();
}
Dy.prototype = Object.create(ai.prototype);
Dy.prototype.constructor = Dy;
Dy.prototype.updateMatrixWorld = function(e) {
  const n = this.box;
  n.isEmpty() || (n.getCenter(this.position), n.getSize(this.scale), this.scale.multiplyScalar(0.5), Ft.prototype.updateMatrixWorld.call(this, e));
};
function ky(e, n, t) {
  this.plane = e, this.size = n === void 0 ? 1 : n;
  const i = t !== void 0 ? t : 16776960, r = [1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0], a = new Gt();
  a.setAttribute("position", new zt(r, 3)), a.computeBoundingSphere(), Es.call(this, a, new Zn({ color: i, toneMapped: !1 })), this.type = "PlaneHelper";
  const c = [1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1], u = new Gt();
  u.setAttribute("position", new zt(c, 3)), u.computeBoundingSphere(), this.add(new Ln(u, new Ms({ color: i, opacity: 0.2, transparent: !0, depthWrite: !1, toneMapped: !1 })));
}
ky.prototype = Object.create(Es.prototype);
ky.prototype.constructor = ky;
ky.prototype.updateMatrixWorld = function(e) {
  let n = -this.plane.constant;
  Math.abs(n) < 1e-8 && (n = 1e-8), this.scale.set(0.5 * this.size, 0.5 * this.size, n), this.children[0].material.side = n < 0 ? hi : cg, this.lookAt(this.plane.normal), Ft.prototype.updateMatrixWorld.call(this, e);
};
const wx = new ve();
let U_, Cv;
function Ma(e, n, t, i, r, a) {
  Ft.call(this), this.type = "ArrowHelper", e === void 0 && (e = new ve(0, 0, 1)), n === void 0 && (n = new ve(0, 0, 0)), t === void 0 && (t = 1), i === void 0 && (i = 16776960), r === void 0 && (r = 0.2 * t), a === void 0 && (a = 0.2 * r), U_ === void 0 && (U_ = new Gt(), U_.setAttribute("position", new zt([0, 0, 0, 0, 1, 0], 3)), Cv = new _o(0, 0.5, 1, 5, 1), Cv.translate(0, -0.5, 0)), this.position.copy(n), this.line = new Es(U_, new Zn({ color: i, toneMapped: !1 })), this.line.matrixAutoUpdate = !1, this.add(this.line), this.cone = new Ln(Cv, new Ms({ color: i, toneMapped: !1 })), this.cone.matrixAutoUpdate = !1, this.add(this.cone), this.setDirection(e), this.setLength(t, r, a);
}
Ma.prototype = Object.create(Ft.prototype);
Ma.prototype.constructor = Ma;
Ma.prototype.setDirection = function(e) {
  if (e.y > 0.99999)
    this.quaternion.set(0, 0, 0, 1);
  else if (e.y < -0.99999)
    this.quaternion.set(1, 0, 0, 0);
  else {
    wx.set(e.z, 0, -e.x).normalize();
    const n = Math.acos(e.y);
    this.quaternion.setFromAxisAngle(wx, n);
  }
};
Ma.prototype.setLength = function(e, n, t) {
  n === void 0 && (n = 0.2 * e), t === void 0 && (t = 0.2 * n), this.line.scale.set(1, Math.max(1e-4, e - n), 1), this.line.updateMatrix(), this.cone.scale.set(t, n, t), this.cone.position.y = e, this.cone.updateMatrix();
};
Ma.prototype.setColor = function(e) {
  this.line.material.color.set(e), this.cone.material.color.set(e);
};
Ma.prototype.copy = function(e) {
  return Ft.prototype.copy.call(this, e, !1), this.line.copy(e.line), this.cone.copy(e.cone), this;
};
function T0(e) {
  e = e || 1;
  const n = [
    0,
    0,
    0,
    e,
    0,
    0,
    0,
    0,
    0,
    0,
    e,
    0,
    0,
    0,
    0,
    0,
    0,
    e
  ], t = [
    1,
    0,
    0,
    1,
    0.6,
    0,
    0,
    1,
    0,
    0.6,
    1,
    0,
    0,
    0,
    1,
    0,
    0.6,
    1
  ], i = new Gt();
  i.setAttribute("position", new zt(n, 3)), i.setAttribute("color", new zt(t, 3));
  const r = new Zn({ vertexColors: !0, toneMapped: !1 });
  ai.call(this, i, r), this.type = "AxesHelper";
}
T0.prototype = Object.create(ai.prototype);
T0.prototype.constructor = T0;
const ou = 4, fo = 8, rr = Math.pow(2, fo), wb = [0.125, 0.215, 0.35, 0.446, 0.526, 0.582], xb = fo - ou + 1 + wb.length, Yc = 20, cr = {
  [Ki]: 0,
  [$y]: 1,
  [R0]: 2,
  [zx]: 3,
  [$x]: 4,
  [Nx]: 5,
  [F0]: 6
}, Iv = new ng(), { _lodPlanes: _m, _sizeLods: xx, _sigmas: G_ } = TP();
let Lv = null;
const ha = (1 + Math.sqrt(5)) / 2, qc = 1 / ha, bx = [
  new ve(1, 1, 1),
  new ve(-1, 1, 1),
  new ve(1, 1, -1),
  new ve(-1, 1, -1),
  new ve(0, ha, qc),
  new ve(0, ha, -qc),
  new ve(qc, 0, ha),
  new ve(-qc, 0, ha),
  new ve(ha, qc, 0),
  new ve(-ha, qc, 0)
];
function Mx(e) {
  this._renderer = e, this._pingPongRenderTarget = null, this._blurMaterial = EP(Yc), this._equirectShader = null, this._cubemapShader = null, this._compileMaterial(this._blurMaterial);
}
Mx.prototype = {
  constructor: Mx,
  /**
   * Generates a PMREM from a supplied Scene, which can be faster than using an
   * image if networking bandwidth is low. Optional sigma specifies a blur radius
   * in radians to be applied to the scene before PMREM generation. Optional near
   * and far planes ensure the scene is rendered in its entirety (the cubeCamera
   * is placed at the origin).
   */
  fromScene: function(e, n = 0, t = 0.1, i = 100) {
    Lv = this._renderer.getRenderTarget();
    const r = this._allocateTargets();
    return this._sceneToCubeUV(e, t, i, r), n > 0 && this._blur(r, 0, 0, n), this._applyPMREM(r), this._cleanup(r), r;
  },
  /**
   * Generates a PMREM from an equirectangular texture, which can be either LDR
   * (RGBFormat) or HDR (RGBEFormat). The ideal input image size is 1k (1024 x 512),
   * as this matches best with the 256 x 256 cubemap output.
   */
  fromEquirectangular: function(e) {
    return this._fromTexture(e);
  },
  /**
   * Generates a PMREM from an cubemap texture, which can be either LDR
   * (RGBFormat) or HDR (RGBEFormat). The ideal input cube size is 256 x 256,
   * as this matches best with the 256 x 256 cubemap output.
   */
  fromCubemap: function(e) {
    return this._fromTexture(e);
  },
  /**
   * Pre-compiles the cubemap shader. You can get faster start-up by invoking this method during
   * your texture's network fetch for increased concurrency.
   */
  compileCubemapShader: function() {
    this._cubemapShader === null && (this._cubemapShader = Sx(), this._compileMaterial(this._cubemapShader));
  },
  /**
   * Pre-compiles the equirectangular shader. You can get faster start-up by invoking this method during
   * your texture's network fetch for increased concurrency.
   */
  compileEquirectangularShader: function() {
    this._equirectShader === null && (this._equirectShader = Ex(), this._compileMaterial(this._equirectShader));
  },
  /**
   * Disposes of the PMREMGenerator's internal memory. Note that PMREMGenerator is a static class,
   * so you should not need more than one PMREMGenerator object. If you do, calling dispose() on
   * one of them will cause any others to also become unusable.
   */
  dispose: function() {
    this._blurMaterial.dispose(), this._cubemapShader !== null && this._cubemapShader.dispose(), this._equirectShader !== null && this._equirectShader.dispose();
    for (let e = 0; e < _m.length; e++)
      _m[e].dispose();
  },
  // private interface
  _cleanup: function(e) {
    this._pingPongRenderTarget.dispose(), this._renderer.setRenderTarget(Lv), e.scissorTest = !1, V_(e, 0, 0, e.width, e.height);
  },
  _fromTexture: function(e) {
    Lv = this._renderer.getRenderTarget();
    const n = this._allocateTargets(e);
    return this._textureToCubeUV(e, n), this._applyPMREM(n), this._cleanup(n), n;
  },
  _allocateTargets: function(e) {
    const n = {
      magFilter: _i,
      minFilter: _i,
      generateMipmaps: !1,
      type: dg,
      format: TM,
      encoding: MP(e) ? e.encoding : R0,
      depthBuffer: !1,
      stencilBuffer: !1
    }, t = Tx(n);
    return t.depthBuffer = !e, this._pingPongRenderTarget = Tx(n), t;
  },
  _compileMaterial: function(e) {
    const n = new Ln(_m[0], e);
    this._renderer.compile(n, Iv);
  },
  _sceneToCubeUV: function(e, n, t, i) {
    const c = new oi(90, 1, n, t), u = [1, -1, 1, 1, 1, 1], l = [1, 1, 1, -1, -1, -1], f = this._renderer, m = f.outputEncoding, h = f.toneMapping, p = f.getClearColor(), _ = f.getClearAlpha();
    f.toneMapping = su, f.outputEncoding = Ki;
    let v = e.background;
    if (v && v.isColor) {
      v.convertSRGBToLinear();
      const S = Math.max(v.r, v.g, v.b), D = Math.min(Math.max(Math.ceil(Math.log2(S)), -128), 127);
      v = v.multiplyScalar(Math.pow(2, -D));
      const w = (D + 128) / 255;
      f.setClearColor(v, w), e.background = null;
    }
    for (let S = 0; S < 6; S++) {
      const D = S % 3;
      D == 0 ? (c.up.set(0, u[S], 0), c.lookAt(l[S], 0, 0)) : D == 1 ? (c.up.set(0, 0, u[S]), c.lookAt(0, l[S], 0)) : (c.up.set(0, u[S], 0), c.lookAt(0, 0, l[S])), V_(
        i,
        D * rr,
        S > 2 ? rr : 0,
        rr,
        rr
      ), f.setRenderTarget(i), f.render(e, c);
    }
    f.toneMapping = h, f.outputEncoding = m, f.setClearColor(p, _);
  },
  _textureToCubeUV: function(e, n) {
    const t = this._renderer;
    e.isCubeTexture ? this._cubemapShader == null && (this._cubemapShader = Sx()) : this._equirectShader == null && (this._equirectShader = Ex());
    const i = e.isCubeTexture ? this._cubemapShader : this._equirectShader, r = new Ln(_m[0], i), a = i.uniforms;
    a.envMap.value = e, e.isCubeTexture || a.texelSize.value.set(1 / e.image.width, 1 / e.image.height), a.inputEncoding.value = cr[e.encoding], a.outputEncoding.value = cr[n.texture.encoding], V_(n, 0, 0, 3 * rr, 2 * rr), t.setRenderTarget(n), t.render(r, Iv);
  },
  _applyPMREM: function(e) {
    const n = this._renderer, t = n.autoClear;
    n.autoClear = !1;
    for (let i = 1; i < xb; i++) {
      const r = Math.sqrt(G_[i] * G_[i] - G_[i - 1] * G_[i - 1]), a = bx[(i - 1) % bx.length];
      this._blur(e, i - 1, i, r, a);
    }
    n.autoClear = t;
  },
  /**
   * This is a two-pass Gaussian blur for a cubemap. Normally this is done
   * vertically and horizontally, but this breaks down on a cube. Here we apply
   * the blur latitudinally (around the poles), and then longitudinally (towards
   * the poles) to approximate the orthogonally-separable blur. It is least
   * accurate at the poles, but still does a decent job.
   */
  _blur: function(e, n, t, i, r) {
    const a = this._pingPongRenderTarget;
    this._halfBlur(
      e,
      a,
      n,
      t,
      i,
      "latitudinal",
      r
    ), this._halfBlur(
      a,
      e,
      t,
      t,
      i,
      "longitudinal",
      r
    );
  },
  _halfBlur: function(e, n, t, i, r, a, c) {
    const u = this._renderer, l = this._blurMaterial;
    a !== "latitudinal" && a !== "longitudinal" && console.error(
      "blur direction must be either latitudinal or longitudinal!"
    );
    const f = 3, m = new Ln(_m[i], l), h = l.uniforms, p = xx[t] - 1, _ = isFinite(r) ? Math.PI / (2 * p) : 2 * Math.PI / (2 * Yc - 1), v = r / _, S = isFinite(r) ? 1 + Math.floor(f * v) : Yc;
    S > Yc && console.warn(`sigmaRadians, ${r}, is too large and will clip, as it requested ${S} samples when the maximum is set to ${Yc}`);
    const D = [];
    let w = 0;
    for (let A = 0; A < Yc; ++A) {
      const L = A / v, I = Math.exp(-L * L / 2);
      D.push(I), A == 0 ? w += I : A < S && (w += 2 * I);
    }
    for (let A = 0; A < D.length; A++)
      D[A] = D[A] / w;
    h.envMap.value = e.texture, h.samples.value = S, h.weights.value = D, h.latitudinal.value = a === "latitudinal", c && (h.poleAxis.value = c), h.dTheta.value = _, h.mipInt.value = fo - t, h.inputEncoding.value = cr[e.texture.encoding], h.outputEncoding.value = cr[e.texture.encoding];
    const T = xx[i], F = 3 * Math.max(0, rr - 2 * T), E = (i === 0 ? 0 : 2 * rr) + 2 * T * (i > fo - ou ? i - fo + ou : 0);
    V_(n, F, E, 3 * T, 2 * T), u.setRenderTarget(n), u.render(m, Iv);
  }
};
function MP(e) {
  return e === void 0 || e.type !== dg ? !1 : e.encoding === Ki || e.encoding === $y || e.encoding === F0;
}
function TP() {
  const e = [], n = [], t = [];
  let i = fo;
  for (let r = 0; r < xb; r++) {
    const a = Math.pow(2, i);
    n.push(a);
    let c = 1 / a;
    r > fo - ou ? c = wb[r - fo + ou - 1] : r == 0 && (c = 0), t.push(c);
    const u = 1 / (a - 1), l = -u / 2, f = 1 + u / 2, m = [l, l, f, l, f, f, l, l, f, f, l, f], h = 6, p = 6, _ = 3, v = 2, S = 1, D = new Float32Array(_ * p * h), w = new Float32Array(v * p * h), T = new Float32Array(S * p * h);
    for (let E = 0; E < h; E++) {
      const A = E % 3 * 2 / 3 - 1, L = E > 2 ? 0 : -1, I = [
        A,
        L,
        0,
        A + 2 / 3,
        L,
        0,
        A + 2 / 3,
        L + 1,
        0,
        A,
        L,
        0,
        A + 2 / 3,
        L + 1,
        0,
        A,
        L + 1,
        0
      ];
      D.set(I, _ * p * E), w.set(m, v * p * E);
      const R = [E, E, E, E, E, E];
      T.set(R, S * p * E);
    }
    const F = new Gt();
    F.setAttribute("position", new Jt(D, _)), F.setAttribute("uv", new Jt(w, v)), F.setAttribute("faceIndex", new Jt(T, S)), e.push(F), i > ou && i--;
  }
  return { _lodPlanes: e, _sizeLods: n, _sigmas: t };
}
function Tx(e) {
  const n = new xs(3 * rr, 3 * rr, e);
  return n.texture.mapping = ug, n.texture.name = "PMREM.cubeUv", n.scissorTest = !0, n;
}
function V_(e, n, t, i, r) {
  e.viewport.set(n, t, i, r), e.scissor.set(n, t, i, r);
}
function EP(e) {
  const n = new Float32Array(e), t = new ve(0, 1, 0);
  return new yo({
    name: "SphericalGaussianBlur",
    defines: { n: e },
    uniforms: {
      envMap: { value: null },
      samples: { value: 1 },
      weights: { value: n },
      latitudinal: { value: !1 },
      dTheta: { value: 0 },
      mipInt: { value: 0 },
      poleAxis: { value: t },
      inputEncoding: { value: cr[Ki] },
      outputEncoding: { value: cr[Ki] }
    },
    vertexShader: V0(),
    fragmentShader: (
      /* glsl */
      `

			precision mediump float;
			precision mediump int;

			varying vec3 vOutputDirection;

			uniform sampler2D envMap;
			uniform int samples;
			uniform float weights[ n ];
			uniform bool latitudinal;
			uniform float dTheta;
			uniform float mipInt;
			uniform vec3 poleAxis;

			${j0()}

			#define ENVMAP_TYPE_CUBE_UV
			#include <cube_uv_reflection_fragment>

			vec3 getSample( float theta, vec3 axis ) {

				float cosTheta = cos( theta );
				// Rodrigues' axis-angle rotation
				vec3 sampleDirection = vOutputDirection * cosTheta
					+ cross( axis, vOutputDirection ) * sin( theta )
					+ axis * dot( axis, vOutputDirection ) * ( 1.0 - cosTheta );

				return bilinearCubeUV( envMap, sampleDirection, mipInt );

			}

			void main() {

				vec3 axis = latitudinal ? poleAxis : cross( poleAxis, vOutputDirection );

				if ( all( equal( axis, vec3( 0.0 ) ) ) ) {

					axis = vec3( vOutputDirection.z, 0.0, - vOutputDirection.x );

				}

				axis = normalize( axis );

				gl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );
				gl_FragColor.rgb += weights[ 0 ] * getSample( 0.0, axis );

				for ( int i = 1; i < n; i++ ) {

					if ( i >= samples ) {

						break;

					}

					float theta = dTheta * float( i );
					gl_FragColor.rgb += weights[ i ] * getSample( -1.0 * theta, axis );
					gl_FragColor.rgb += weights[ i ] * getSample( theta, axis );

				}

				gl_FragColor = linearToOutputTexel( gl_FragColor );

			}
		`
    ),
    blending: co,
    depthTest: !1,
    depthWrite: !1
  });
}
function Ex() {
  const e = new vt(1, 1);
  return new yo({
    name: "EquirectangularToCubeUV",
    uniforms: {
      envMap: { value: null },
      texelSize: { value: e },
      inputEncoding: { value: cr[Ki] },
      outputEncoding: { value: cr[Ki] }
    },
    vertexShader: V0(),
    fragmentShader: (
      /* glsl */
      `

			precision mediump float;
			precision mediump int;

			varying vec3 vOutputDirection;

			uniform sampler2D envMap;
			uniform vec2 texelSize;

			${j0()}

			#include <common>

			void main() {

				gl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );

				vec3 outputDirection = normalize( vOutputDirection );
				vec2 uv = equirectUv( outputDirection );

				vec2 f = fract( uv / texelSize - 0.5 );
				uv -= f * texelSize;
				vec3 tl = envMapTexelToLinear( texture2D ( envMap, uv ) ).rgb;
				uv.x += texelSize.x;
				vec3 tr = envMapTexelToLinear( texture2D ( envMap, uv ) ).rgb;
				uv.y += texelSize.y;
				vec3 br = envMapTexelToLinear( texture2D ( envMap, uv ) ).rgb;
				uv.x -= texelSize.x;
				vec3 bl = envMapTexelToLinear( texture2D ( envMap, uv ) ).rgb;

				vec3 tm = mix( tl, tr, f.x );
				vec3 bm = mix( bl, br, f.x );
				gl_FragColor.rgb = mix( tm, bm, f.y );

				gl_FragColor = linearToOutputTexel( gl_FragColor );

			}
		`
    ),
    blending: co,
    depthTest: !1,
    depthWrite: !1
  });
}
function Sx() {
  return new yo({
    name: "CubemapToCubeUV",
    uniforms: {
      envMap: { value: null },
      inputEncoding: { value: cr[Ki] },
      outputEncoding: { value: cr[Ki] }
    },
    vertexShader: V0(),
    fragmentShader: (
      /* glsl */
      `

			precision mediump float;
			precision mediump int;

			varying vec3 vOutputDirection;

			uniform samplerCube envMap;

			${j0()}

			void main() {

				gl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );
				gl_FragColor.rgb = envMapTexelToLinear( textureCube( envMap, vec3( - vOutputDirection.x, vOutputDirection.yz ) ) ).rgb;
				gl_FragColor = linearToOutputTexel( gl_FragColor );

			}
		`
    ),
    blending: co,
    depthTest: !1,
    depthWrite: !1
  });
}
function V0() {
  return (
    /* glsl */
    `

		precision mediump float;
		precision mediump int;

		attribute vec3 position;
		attribute vec2 uv;
		attribute float faceIndex;

		varying vec3 vOutputDirection;

		// RH coordinate system; PMREM face-indexing convention
		vec3 getDirection( vec2 uv, float face ) {

			uv = 2.0 * uv - 1.0;

			vec3 direction = vec3( uv, 1.0 );

			if ( face == 0.0 ) {

				direction = direction.zyx; // ( 1, v, u ) pos x

			} else if ( face == 1.0 ) {

				direction = direction.xzy;
				direction.xz *= -1.0; // ( -u, 1, -v ) pos y

			} else if ( face == 2.0 ) {

				direction.x *= -1.0; // ( -u, v, 1 ) pos z

			} else if ( face == 3.0 ) {

				direction = direction.zyx;
				direction.xz *= -1.0; // ( -1, v, -u ) neg x

			} else if ( face == 4.0 ) {

				direction = direction.xzy;
				direction.xy *= -1.0; // ( -u, -1, v ) neg y

			} else if ( face == 5.0 ) {

				direction.z *= -1.0; // ( u, v, -1 ) neg z

			}

			return direction;

		}

		void main() {

			vOutputDirection = getDirection( uv, faceIndex );
			gl_Position = vec4( position, 1.0 );

		}
	`
  );
}
function j0() {
  return (
    /* glsl */
    `

		uniform int inputEncoding;
		uniform int outputEncoding;

		#include <encodings_pars_fragment>

		vec4 inputTexelToLinear( vec4 value ) {

			if ( inputEncoding == 0 ) {

				return value;

			} else if ( inputEncoding == 1 ) {

				return sRGBToLinear( value );

			} else if ( inputEncoding == 2 ) {

				return RGBEToLinear( value );

			} else if ( inputEncoding == 3 ) {

				return RGBMToLinear( value, 7.0 );

			} else if ( inputEncoding == 4 ) {

				return RGBMToLinear( value, 16.0 );

			} else if ( inputEncoding == 5 ) {

				return RGBDToLinear( value, 256.0 );

			} else {

				return GammaToLinear( value, 2.2 );

			}

		}

		vec4 linearToOutputTexel( vec4 value ) {

			if ( outputEncoding == 0 ) {

				return value;

			} else if ( outputEncoding == 1 ) {

				return LinearTosRGB( value );

			} else if ( outputEncoding == 2 ) {

				return LinearToRGBE( value );

			} else if ( outputEncoding == 3 ) {

				return LinearToRGBM( value, 7.0 );

			} else if ( outputEncoding == 4 ) {

				return LinearToRGBM( value, 16.0 );

			} else if ( outputEncoding == 5 ) {

				return LinearToRGBD( value, 256.0 );

			} else {

				return LinearToGamma( value, 2.2 );

			}

		}

		vec4 envMapTexelToLinear( vec4 color ) {

			return inputTexelToLinear( color );

		}
	`
  );
}
Qt.create = function(e, n) {
  return console.log("THREE.Curve.create() has been deprecated"), e.prototype = Object.create(Qt.prototype), e.prototype.constructor = e, e.prototype.getPoint = n, e;
};
Object.assign(lo.prototype, {
  createPointsGeometry: function(e) {
    console.warn("THREE.CurvePath: .createPointsGeometry() has been removed. Use new THREE.Geometry().setFromPoints( points ) instead.");
    const n = this.getPoints(e);
    return this.createGeometry(n);
  },
  createSpacedPointsGeometry: function(e) {
    console.warn("THREE.CurvePath: .createSpacedPointsGeometry() has been removed. Use new THREE.Geometry().setFromPoints( points ) instead.");
    const n = this.getSpacedPoints(e);
    return this.createGeometry(n);
  },
  createGeometry: function(e) {
    console.warn("THREE.CurvePath: .createGeometry() has been removed. Use new THREE.Geometry().setFromPoints( points ) instead.");
    const n = new an();
    for (let t = 0, i = e.length; t < i; t++) {
      const r = e[t];
      n.vertices.push(new ve(r.x, r.y, r.z || 0));
    }
    return n;
  }
});
Object.assign(lr.prototype, {
  fromPoints: function(e) {
    return console.warn("THREE.Path: .fromPoints() has been renamed to .setFromPoints()."), this.setFromPoints(e);
  }
});
Object.create(cs.prototype);
Object.create(cs.prototype);
function bb(e) {
  console.warn("THREE.Spline has been removed. Use THREE.CatmullRomCurve3 instead."), cs.call(this, e), this.type = "catmullrom";
}
bb.prototype = Object.create(cs.prototype);
Object.assign(bb.prototype, {
  initFromArray: function() {
    console.error("THREE.Spline: .initFromArray() has been removed.");
  },
  getControlPointsArray: function() {
    console.error("THREE.Spline: .getControlPointsArray() has been removed.");
  },
  reparametrizeByArcLength: function() {
    console.error("THREE.Spline: .reparametrizeByArcLength() has been removed.");
  }
});
Iy.prototype.setColors = function() {
  console.error("THREE.GridHelper: setColors() has been deprecated, pass them in the constructor instead.");
};
Tu.prototype.update = function() {
  console.error("THREE.SkeletonHelper: update() no longer needs to be called.");
};
Object.assign(Tn.prototype, {
  extractUrlBase: function(e) {
    return console.warn("THREE.Loader: .extractUrlBase() has been deprecated. Use THREE.LoaderUtils.extractUrlBase() instead."), lb.extractUrlBase(e);
  }
});
Tn.Handlers = {
  add: function() {
    console.error("THREE.Loader: Handlers.add() has been removed. Use LoadingManager.addHandler() instead.");
  },
  get: function() {
    console.error("THREE.Loader: Handlers.get() has been removed. Use LoadingManager.getHandler() instead.");
  }
};
Object.assign(v0.prototype, {
  setTexturePath: function(e) {
    return console.warn("THREE.ObjectLoader: .setTexturePath() has been renamed to .setResourcePath()."), this.setResourcePath(e);
  }
});
Object.assign(_b.prototype, {
  center: function(e) {
    return console.warn("THREE.Box2: .center() has been renamed to .getCenter()."), this.getCenter(e);
  },
  empty: function() {
    return console.warn("THREE.Box2: .empty() has been renamed to .isEmpty()."), this.isEmpty();
  },
  isIntersectionBox: function(e) {
    return console.warn("THREE.Box2: .isIntersectionBox() has been renamed to .intersectsBox()."), this.intersectsBox(e);
  },
  size: function(e) {
    return console.warn("THREE.Box2: .size() has been renamed to .getSize()."), this.getSize(e);
  }
});
Object.assign(mr.prototype, {
  center: function(e) {
    return console.warn("THREE.Box3: .center() has been renamed to .getCenter()."), this.getCenter(e);
  },
  empty: function() {
    return console.warn("THREE.Box3: .empty() has been renamed to .isEmpty()."), this.isEmpty();
  },
  isIntersectionBox: function(e) {
    return console.warn("THREE.Box3: .isIntersectionBox() has been renamed to .intersectsBox()."), this.intersectsBox(e);
  },
  isIntersectionSphere: function(e) {
    return console.warn("THREE.Box3: .isIntersectionSphere() has been renamed to .intersectsSphere()."), this.intersectsSphere(e);
  },
  size: function(e) {
    return console.warn("THREE.Box3: .size() has been renamed to .getSize()."), this.getSize(e);
  }
});
Object.assign(Rr.prototype, {
  empty: function() {
    return console.warn("THREE.Sphere: .empty() has been renamed to .isEmpty()."), this.isEmpty();
  }
});
hg.prototype.setFromMatrix = function(e) {
  return console.warn("THREE.Frustum: .setFromMatrix() has been renamed to .setFromProjectionMatrix()."), this.setFromProjectionMatrix(e);
};
yb.prototype.center = function(e) {
  return console.warn("THREE.Line3: .center() has been renamed to .getCenter()."), this.getCenter(e);
};
Object.assign(un, {
  random16: function() {
    return console.warn("THREE.Math: .random16() has been deprecated. Use Math.random() instead."), Math.random();
  },
  nearestPowerOfTwo: function(e) {
    return console.warn("THREE.Math: .nearestPowerOfTwo() has been renamed to .floorPowerOfTwo()."), un.floorPowerOfTwo(e);
  },
  nextPowerOfTwo: function(e) {
    return console.warn("THREE.Math: .nextPowerOfTwo() has been renamed to .ceilPowerOfTwo()."), un.ceilPowerOfTwo(e);
  }
});
Object.assign(Bi.prototype, {
  flattenToArrayOffset: function(e, n) {
    return console.warn("THREE.Matrix3: .flattenToArrayOffset() has been deprecated. Use .toArray() instead."), this.toArray(e, n);
  },
  multiplyVector3: function(e) {
    return console.warn("THREE.Matrix3: .multiplyVector3() has been removed. Use vector.applyMatrix3( matrix ) instead."), e.applyMatrix3(this);
  },
  multiplyVector3Array: function() {
    console.error("THREE.Matrix3: .multiplyVector3Array() has been removed.");
  },
  applyToBufferAttribute: function(e) {
    return console.warn("THREE.Matrix3: .applyToBufferAttribute() has been removed. Use attribute.applyMatrix3( matrix ) instead."), e.applyMatrix3(this);
  },
  applyToVector3Array: function() {
    console.error("THREE.Matrix3: .applyToVector3Array() has been removed.");
  }
});
Object.assign(dn.prototype, {
  extractPosition: function(e) {
    return console.warn("THREE.Matrix4: .extractPosition() has been renamed to .copyPosition()."), this.copyPosition(e);
  },
  flattenToArrayOffset: function(e, n) {
    return console.warn("THREE.Matrix4: .flattenToArrayOffset() has been deprecated. Use .toArray() instead."), this.toArray(e, n);
  },
  getPosition: function() {
    return console.warn("THREE.Matrix4: .getPosition() has been removed. Use Vector3.setFromMatrixPosition( matrix ) instead."), new ve().setFromMatrixColumn(this, 3);
  },
  setRotationFromQuaternion: function(e) {
    return console.warn("THREE.Matrix4: .setRotationFromQuaternion() has been renamed to .makeRotationFromQuaternion()."), this.makeRotationFromQuaternion(e);
  },
  multiplyToArray: function() {
    console.warn("THREE.Matrix4: .multiplyToArray() has been removed.");
  },
  multiplyVector3: function(e) {
    return console.warn("THREE.Matrix4: .multiplyVector3() has been removed. Use vector.applyMatrix4( matrix ) instead."), e.applyMatrix4(this);
  },
  multiplyVector4: function(e) {
    return console.warn("THREE.Matrix4: .multiplyVector4() has been removed. Use vector.applyMatrix4( matrix ) instead."), e.applyMatrix4(this);
  },
  multiplyVector3Array: function() {
    console.error("THREE.Matrix4: .multiplyVector3Array() has been removed.");
  },
  rotateAxis: function(e) {
    console.warn("THREE.Matrix4: .rotateAxis() has been removed. Use Vector3.transformDirection( matrix ) instead."), e.transformDirection(this);
  },
  crossVector: function(e) {
    return console.warn("THREE.Matrix4: .crossVector() has been removed. Use vector.applyMatrix4( matrix ) instead."), e.applyMatrix4(this);
  },
  translate: function() {
    console.error("THREE.Matrix4: .translate() has been removed.");
  },
  rotateX: function() {
    console.error("THREE.Matrix4: .rotateX() has been removed.");
  },
  rotateY: function() {
    console.error("THREE.Matrix4: .rotateY() has been removed.");
  },
  rotateZ: function() {
    console.error("THREE.Matrix4: .rotateZ() has been removed.");
  },
  rotateByAxis: function() {
    console.error("THREE.Matrix4: .rotateByAxis() has been removed.");
  },
  applyToBufferAttribute: function(e) {
    return console.warn("THREE.Matrix4: .applyToBufferAttribute() has been removed. Use attribute.applyMatrix4( matrix ) instead."), e.applyMatrix4(this);
  },
  applyToVector3Array: function() {
    console.error("THREE.Matrix4: .applyToVector3Array() has been removed.");
  },
  makeFrustum: function(e, n, t, i, r, a) {
    return console.warn("THREE.Matrix4: .makeFrustum() has been removed. Use .makePerspective( left, right, top, bottom, near, far ) instead."), this.makePerspective(e, n, i, t, r, a);
  }
});
or.prototype.isIntersectionLine = function(e) {
  return console.warn("THREE.Plane: .isIntersectionLine() has been renamed to .intersectsLine()."), this.intersectsLine(e);
};
yi.prototype.multiplyVector3 = function(e) {
  return console.warn("THREE.Quaternion: .multiplyVector3() has been removed. Use is now vector.applyQuaternion( quaternion ) instead."), e.applyQuaternion(this);
};
Object.assign(Au.prototype, {
  isIntersectionBox: function(e) {
    return console.warn("THREE.Ray: .isIntersectionBox() has been renamed to .intersectsBox()."), this.intersectsBox(e);
  },
  isIntersectionPlane: function(e) {
    return console.warn("THREE.Ray: .isIntersectionPlane() has been renamed to .intersectsPlane()."), this.intersectsPlane(e);
  },
  isIntersectionSphere: function(e) {
    return console.warn("THREE.Ray: .isIntersectionSphere() has been renamed to .intersectsSphere()."), this.intersectsSphere(e);
  }
});
Object.assign(Ei.prototype, {
  area: function() {
    return console.warn("THREE.Triangle: .area() has been renamed to .getArea()."), this.getArea();
  },
  barycoordFromPoint: function(e, n) {
    return console.warn("THREE.Triangle: .barycoordFromPoint() has been renamed to .getBarycoord()."), this.getBarycoord(e, n);
  },
  midpoint: function(e) {
    return console.warn("THREE.Triangle: .midpoint() has been renamed to .getMidpoint()."), this.getMidpoint(e);
  },
  normal: function(e) {
    return console.warn("THREE.Triangle: .normal() has been renamed to .getNormal()."), this.getNormal(e);
  },
  plane: function(e) {
    return console.warn("THREE.Triangle: .plane() has been renamed to .getPlane()."), this.getPlane(e);
  }
});
Object.assign(Ei, {
  barycoordFromPoint: function(e, n, t, i, r) {
    return console.warn("THREE.Triangle: .barycoordFromPoint() has been renamed to .getBarycoord()."), Ei.getBarycoord(e, n, t, i, r);
  },
  normal: function(e, n, t, i) {
    return console.warn("THREE.Triangle: .normal() has been renamed to .getNormal()."), Ei.getNormal(e, n, t, i);
  }
});
Object.assign(ma.prototype, {
  extractAllPoints: function(e) {
    return console.warn("THREE.Shape: .extractAllPoints() has been removed. Use .extractPoints() instead."), this.extractPoints(e);
  },
  extrude: function(e) {
    return console.warn("THREE.Shape: .extrude() has been removed. Use ExtrudeGeometry() instead."), new fu(this, e);
  },
  makeGeometry: function(e) {
    return console.warn("THREE.Shape: .makeGeometry() has been removed. Use ShapeGeometry() instead."), new mu(this, e);
  }
});
Object.assign(vt.prototype, {
  fromAttribute: function(e, n, t) {
    return console.warn("THREE.Vector2: .fromAttribute() has been renamed to .fromBufferAttribute()."), this.fromBufferAttribute(e, n, t);
  },
  distanceToManhattan: function(e) {
    return console.warn("THREE.Vector2: .distanceToManhattan() has been renamed to .manhattanDistanceTo()."), this.manhattanDistanceTo(e);
  },
  lengthManhattan: function() {
    return console.warn("THREE.Vector2: .lengthManhattan() has been renamed to .manhattanLength()."), this.manhattanLength();
  }
});
Object.assign(ve.prototype, {
  setEulerFromRotationMatrix: function() {
    console.error("THREE.Vector3: .setEulerFromRotationMatrix() has been removed. Use Euler.setFromRotationMatrix() instead.");
  },
  setEulerFromQuaternion: function() {
    console.error("THREE.Vector3: .setEulerFromQuaternion() has been removed. Use Euler.setFromQuaternion() instead.");
  },
  getPositionFromMatrix: function(e) {
    return console.warn("THREE.Vector3: .getPositionFromMatrix() has been renamed to .setFromMatrixPosition()."), this.setFromMatrixPosition(e);
  },
  getScaleFromMatrix: function(e) {
    return console.warn("THREE.Vector3: .getScaleFromMatrix() has been renamed to .setFromMatrixScale()."), this.setFromMatrixScale(e);
  },
  getColumnFromMatrix: function(e, n) {
    return console.warn("THREE.Vector3: .getColumnFromMatrix() has been renamed to .setFromMatrixColumn()."), this.setFromMatrixColumn(n, e);
  },
  applyProjection: function(e) {
    return console.warn("THREE.Vector3: .applyProjection() has been removed. Use .applyMatrix4( m ) instead."), this.applyMatrix4(e);
  },
  fromAttribute: function(e, n, t) {
    return console.warn("THREE.Vector3: .fromAttribute() has been renamed to .fromBufferAttribute()."), this.fromBufferAttribute(e, n, t);
  },
  distanceToManhattan: function(e) {
    return console.warn("THREE.Vector3: .distanceToManhattan() has been renamed to .manhattanDistanceTo()."), this.manhattanDistanceTo(e);
  },
  lengthManhattan: function() {
    return console.warn("THREE.Vector3: .lengthManhattan() has been renamed to .manhattanLength()."), this.manhattanLength();
  }
});
Object.assign(In.prototype, {
  fromAttribute: function(e, n, t) {
    return console.warn("THREE.Vector4: .fromAttribute() has been renamed to .fromBufferAttribute()."), this.fromBufferAttribute(e, n, t);
  },
  lengthManhattan: function() {
    return console.warn("THREE.Vector4: .lengthManhattan() has been renamed to .manhattanLength()."), this.manhattanLength();
  }
});
Object.assign(an.prototype, {
  computeTangents: function() {
    console.error("THREE.Geometry: .computeTangents() has been removed.");
  },
  computeLineDistances: function() {
    console.error("THREE.Geometry: .computeLineDistances() has been removed. Use THREE.Line.computeLineDistances() instead.");
  },
  applyMatrix: function(e) {
    return console.warn("THREE.Geometry: .applyMatrix() has been renamed to .applyMatrix4()."), this.applyMatrix4(e);
  }
});
Object.assign(Ft.prototype, {
  getChildByName: function(e) {
    return console.warn("THREE.Object3D: .getChildByName() has been renamed to .getObjectByName()."), this.getObjectByName(e);
  },
  renderDepth: function() {
    console.warn("THREE.Object3D: .renderDepth has been removed. Use .renderOrder, instead.");
  },
  translate: function(e, n) {
    return console.warn("THREE.Object3D: .translate() has been removed. Use .translateOnAxis( axis, distance ) instead."), this.translateOnAxis(n, e);
  },
  getWorldRotation: function() {
    console.error("THREE.Object3D: .getWorldRotation() has been removed. Use THREE.Object3D.getWorldQuaternion( target ) instead.");
  },
  applyMatrix: function(e) {
    return console.warn("THREE.Object3D: .applyMatrix() has been renamed to .applyMatrix4()."), this.applyMatrix4(e);
  }
});
Object.defineProperties(Ft.prototype, {
  eulerOrder: {
    get: function() {
      return console.warn("THREE.Object3D: .eulerOrder is now .rotation.order."), this.rotation.order;
    },
    set: function(e) {
      console.warn("THREE.Object3D: .eulerOrder is now .rotation.order."), this.rotation.order = e;
    }
  },
  useQuaternion: {
    get: function() {
      console.warn("THREE.Object3D: .useQuaternion has been removed. The library now uses quaternions by default.");
    },
    set: function() {
      console.warn("THREE.Object3D: .useQuaternion has been removed. The library now uses quaternions by default.");
    }
  }
});
Object.assign(Ln.prototype, {
  setDrawMode: function() {
    console.error("THREE.Mesh: .setDrawMode() has been removed. The renderer now always assumes THREE.TrianglesDrawMode. Transform your geometry via BufferGeometryUtils.toTrianglesDrawMode() if necessary.");
  }
});
Object.defineProperties(Ln.prototype, {
  drawMode: {
    get: function() {
      return console.error("THREE.Mesh: .drawMode has been removed. The renderer now always assumes THREE.TrianglesDrawMode."), u1;
    },
    set: function() {
      console.error("THREE.Mesh: .drawMode has been removed. The renderer now always assumes THREE.TrianglesDrawMode. Transform your geometry via BufferGeometryUtils.toTrianglesDrawMode() if necessary.");
    }
  }
});
Object.defineProperties(iy.prototype, {
  objects: {
    get: function() {
      return console.warn("THREE.LOD: .objects has been renamed to .levels."), this.levels;
    }
  }
});
Object.defineProperty(Xv.prototype, "useVertexTexture", {
  get: function() {
    console.warn("THREE.Skeleton: useVertexTexture has been removed.");
  },
  set: function() {
    console.warn("THREE.Skeleton: useVertexTexture has been removed.");
  }
});
Kv.prototype.initBones = function() {
  console.error("THREE.SkinnedMesh: initBones() has been removed.");
};
Object.defineProperty(Qt.prototype, "__arcLengthDivisions", {
  get: function() {
    return console.warn("THREE.Curve: .__arcLengthDivisions is now .arcLengthDivisions."), this.arcLengthDivisions;
  },
  set: function(e) {
    console.warn("THREE.Curve: .__arcLengthDivisions is now .arcLengthDivisions."), this.arcLengthDivisions = e;
  }
});
oi.prototype.setLens = function(e, n) {
  console.warn("THREE.PerspectiveCamera.setLens is deprecated. Use .setFocalLength and .filmGauge for a photographic setup."), n !== void 0 && (this.filmGauge = n), this.setFocalLength(e);
};
Object.defineProperties(Nn.prototype, {
  onlyShadow: {
    set: function() {
      console.warn("THREE.Light: .onlyShadow has been removed.");
    }
  },
  shadowCameraFov: {
    set: function(e) {
      console.warn("THREE.Light: .shadowCameraFov is now .shadow.camera.fov."), this.shadow.camera.fov = e;
    }
  },
  shadowCameraLeft: {
    set: function(e) {
      console.warn("THREE.Light: .shadowCameraLeft is now .shadow.camera.left."), this.shadow.camera.left = e;
    }
  },
  shadowCameraRight: {
    set: function(e) {
      console.warn("THREE.Light: .shadowCameraRight is now .shadow.camera.right."), this.shadow.camera.right = e;
    }
  },
  shadowCameraTop: {
    set: function(e) {
      console.warn("THREE.Light: .shadowCameraTop is now .shadow.camera.top."), this.shadow.camera.top = e;
    }
  },
  shadowCameraBottom: {
    set: function(e) {
      console.warn("THREE.Light: .shadowCameraBottom is now .shadow.camera.bottom."), this.shadow.camera.bottom = e;
    }
  },
  shadowCameraNear: {
    set: function(e) {
      console.warn("THREE.Light: .shadowCameraNear is now .shadow.camera.near."), this.shadow.camera.near = e;
    }
  },
  shadowCameraFar: {
    set: function(e) {
      console.warn("THREE.Light: .shadowCameraFar is now .shadow.camera.far."), this.shadow.camera.far = e;
    }
  },
  shadowCameraVisible: {
    set: function() {
      console.warn("THREE.Light: .shadowCameraVisible has been removed. Use new THREE.CameraHelper( light.shadow.camera ) instead.");
    }
  },
  shadowBias: {
    set: function(e) {
      console.warn("THREE.Light: .shadowBias is now .shadow.bias."), this.shadow.bias = e;
    }
  },
  shadowDarkness: {
    set: function() {
      console.warn("THREE.Light: .shadowDarkness has been removed.");
    }
  },
  shadowMapWidth: {
    set: function(e) {
      console.warn("THREE.Light: .shadowMapWidth is now .shadow.mapSize.width."), this.shadow.mapSize.width = e;
    }
  },
  shadowMapHeight: {
    set: function(e) {
      console.warn("THREE.Light: .shadowMapHeight is now .shadow.mapSize.height."), this.shadow.mapSize.height = e;
    }
  }
});
Object.defineProperties(Jt.prototype, {
  length: {
    get: function() {
      return console.warn("THREE.BufferAttribute: .length has been deprecated. Use .count instead."), this.array.length;
    }
  },
  dynamic: {
    get: function() {
      return console.warn("THREE.BufferAttribute: .dynamic has been deprecated. Use .usage instead."), this.usage === Am;
    },
    set: function() {
      console.warn("THREE.BufferAttribute: .dynamic has been deprecated. Use .usage instead."), this.setUsage(Am);
    }
  }
});
Object.assign(Jt.prototype, {
  setDynamic: function(e) {
    return console.warn("THREE.BufferAttribute: .setDynamic() has been deprecated. Use .setUsage() instead."), this.setUsage(e === !0 ? Am : Ny), this;
  },
  copyIndicesArray: function() {
    console.error("THREE.BufferAttribute: .copyIndicesArray() has been removed.");
  },
  setArray: function() {
    console.error("THREE.BufferAttribute: .setArray has been removed. Use BufferGeometry .setAttribute to replace/resize attribute buffers");
  }
});
Object.assign(Gt.prototype, {
  addIndex: function(e) {
    console.warn("THREE.BufferGeometry: .addIndex() has been renamed to .setIndex()."), this.setIndex(e);
  },
  addAttribute: function(e, n) {
    return console.warn("THREE.BufferGeometry: .addAttribute() has been renamed to .setAttribute()."), !(n && n.isBufferAttribute) && !(n && n.isInterleavedBufferAttribute) ? (console.warn("THREE.BufferGeometry: .addAttribute() now expects ( name, attribute )."), this.setAttribute(e, new Jt(arguments[1], arguments[2]))) : e === "index" ? (console.warn("THREE.BufferGeometry.addAttribute: Use .setIndex() for index attribute."), this.setIndex(n), this) : this.setAttribute(e, n);
  },
  addDrawCall: function(e, n, t) {
    t !== void 0 && console.warn("THREE.BufferGeometry: .addDrawCall() no longer supports indexOffset."), console.warn("THREE.BufferGeometry: .addDrawCall() is now .addGroup()."), this.addGroup(e, n);
  },
  clearDrawCalls: function() {
    console.warn("THREE.BufferGeometry: .clearDrawCalls() is now .clearGroups()."), this.clearGroups();
  },
  computeTangents: function() {
    console.warn("THREE.BufferGeometry: .computeTangents() has been removed.");
  },
  computeOffsets: function() {
    console.warn("THREE.BufferGeometry: .computeOffsets() has been removed.");
  },
  removeAttribute: function(e) {
    return console.warn("THREE.BufferGeometry: .removeAttribute() has been renamed to .deleteAttribute()."), this.deleteAttribute(e);
  },
  applyMatrix: function(e) {
    return console.warn("THREE.BufferGeometry: .applyMatrix() has been renamed to .applyMatrix4()."), this.applyMatrix4(e);
  }
});
Object.defineProperties(Gt.prototype, {
  drawcalls: {
    get: function() {
      return console.error("THREE.BufferGeometry: .drawcalls has been renamed to .groups."), this.groups;
    }
  },
  offsets: {
    get: function() {
      return console.warn("THREE.BufferGeometry: .offsets has been renamed to .groups."), this.groups;
    }
  }
});
Object.defineProperties(Ay.prototype, {
  maxInstancedCount: {
    get: function() {
      return console.warn("THREE.InstancedBufferGeometry: .maxInstancedCount has been renamed to .instanceCount."), this.instanceCount;
    },
    set: function(e) {
      console.warn("THREE.InstancedBufferGeometry: .maxInstancedCount has been renamed to .instanceCount."), this.instanceCount = e;
    }
  }
});
Object.defineProperties(G0.prototype, {
  linePrecision: {
    get: function() {
      return console.warn("THREE.Raycaster: .linePrecision has been deprecated. Use .params.Line.threshold instead."), this.params.Line.threshold;
    },
    set: function(e) {
      console.warn("THREE.Raycaster: .linePrecision has been deprecated. Use .params.Line.threshold instead."), this.params.Line.threshold = e;
    }
  }
});
Object.defineProperties(vs.prototype, {
  dynamic: {
    get: function() {
      return console.warn("THREE.InterleavedBuffer: .length has been deprecated. Use .usage instead."), this.usage === Am;
    },
    set: function(e) {
      console.warn("THREE.InterleavedBuffer: .length has been deprecated. Use .usage instead."), this.setUsage(e);
    }
  }
});
Object.assign(vs.prototype, {
  setDynamic: function(e) {
    return console.warn("THREE.InterleavedBuffer: .setDynamic() has been deprecated. Use .setUsage() instead."), this.setUsage(e === !0 ? Am : Ny), this;
  },
  setArray: function() {
    console.error("THREE.InterleavedBuffer: .setArray has been removed. Use BufferGeometry .setAttribute to replace/resize attribute buffers");
  }
});
Object.assign(Lr.prototype, {
  getArrays: function() {
    console.error("THREE.ExtrudeBufferGeometry: .getArrays() has been removed.");
  },
  addShapeList: function() {
    console.error("THREE.ExtrudeBufferGeometry: .addShapeList() has been removed.");
  },
  addShape: function() {
    console.error("THREE.ExtrudeBufferGeometry: .addShape() has been removed.");
  }
});
Object.defineProperties(x0.prototype, {
  dynamic: {
    set: function() {
      console.warn("THREE.Uniform: .dynamic has been removed. Use object.onBeforeRender() instead.");
    }
  },
  onUpdate: {
    value: function() {
      return console.warn("THREE.Uniform: .onUpdate() has been removed. Use object.onBeforeRender() instead."), this;
    }
  }
});
Object.defineProperties(rn.prototype, {
  wrapAround: {
    get: function() {
      console.warn("THREE.Material: .wrapAround has been removed.");
    },
    set: function() {
      console.warn("THREE.Material: .wrapAround has been removed.");
    }
  },
  overdraw: {
    get: function() {
      console.warn("THREE.Material: .overdraw has been removed.");
    },
    set: function() {
      console.warn("THREE.Material: .overdraw has been removed.");
    }
  },
  wrapRGB: {
    get: function() {
      return console.warn("THREE.Material: .wrapRGB has been removed."), new Wt();
    }
  },
  shading: {
    get: function() {
      console.error("THREE." + this.type + ": .shading has been removed. Use the boolean .flatShading instead.");
    },
    set: function(e) {
      console.warn("THREE." + this.type + ": .shading has been removed. Use the boolean .flatShading instead."), this.flatShading = e === Dx;
    }
  },
  stencilMask: {
    get: function() {
      return console.warn("THREE." + this.type + ": .stencilMask has been removed. Use .stencilFuncMask instead."), this.stencilFuncMask;
    },
    set: function(e) {
      console.warn("THREE." + this.type + ": .stencilMask has been removed. Use .stencilFuncMask instead."), this.stencilFuncMask = e;
    }
  }
});
Object.defineProperties(ba.prototype, {
  metal: {
    get: function() {
      return console.warn("THREE.MeshPhongMaterial: .metal has been removed. Use THREE.MeshStandardMaterial instead."), !1;
    },
    set: function() {
      console.warn("THREE.MeshPhongMaterial: .metal has been removed. Use THREE.MeshStandardMaterial instead");
    }
  }
});
Object.defineProperties(xa.prototype, {
  transparency: {
    get: function() {
      return console.warn("THREE.MeshPhysicalMaterial: .transparency has been renamed to .transmission."), this.transmission;
    },
    set: function(e) {
      console.warn("THREE.MeshPhysicalMaterial: .transparency has been renamed to .transmission."), this.transmission = e;
    }
  }
});
Object.defineProperties(Xi.prototype, {
  derivatives: {
    get: function() {
      return console.warn("THREE.ShaderMaterial: .derivatives has been moved to .extensions.derivatives."), this.extensions.derivatives;
    },
    set: function(e) {
      console.warn("THREE. ShaderMaterial: .derivatives has been moved to .extensions.derivatives."), this.extensions.derivatives = e;
    }
  }
});
Object.assign(fg.prototype, {
  clearTarget: function(e, n, t, i) {
    console.warn("THREE.WebGLRenderer: .clearTarget() has been deprecated. Use .setRenderTarget() and .clear() instead."), this.setRenderTarget(e), this.clear(n, t, i);
  },
  animate: function(e) {
    console.warn("THREE.WebGLRenderer: .animate() is now .setAnimationLoop()."), this.setAnimationLoop(e);
  },
  getCurrentRenderTarget: function() {
    return console.warn("THREE.WebGLRenderer: .getCurrentRenderTarget() is now .getRenderTarget()."), this.getRenderTarget();
  },
  getMaxAnisotropy: function() {
    return console.warn("THREE.WebGLRenderer: .getMaxAnisotropy() is now .capabilities.getMaxAnisotropy()."), this.capabilities.getMaxAnisotropy();
  },
  getPrecision: function() {
    return console.warn("THREE.WebGLRenderer: .getPrecision() is now .capabilities.precision."), this.capabilities.precision;
  },
  resetGLState: function() {
    return console.warn("THREE.WebGLRenderer: .resetGLState() is now .state.reset()."), this.state.reset();
  },
  supportsFloatTextures: function() {
    return console.warn("THREE.WebGLRenderer: .supportsFloatTextures() is now .extensions.get( 'OES_texture_float' )."), this.extensions.get("OES_texture_float");
  },
  supportsHalfFloatTextures: function() {
    return console.warn("THREE.WebGLRenderer: .supportsHalfFloatTextures() is now .extensions.get( 'OES_texture_half_float' )."), this.extensions.get("OES_texture_half_float");
  },
  supportsStandardDerivatives: function() {
    return console.warn("THREE.WebGLRenderer: .supportsStandardDerivatives() is now .extensions.get( 'OES_standard_derivatives' )."), this.extensions.get("OES_standard_derivatives");
  },
  supportsCompressedTextureS3TC: function() {
    return console.warn("THREE.WebGLRenderer: .supportsCompressedTextureS3TC() is now .extensions.get( 'WEBGL_compressed_texture_s3tc' )."), this.extensions.get("WEBGL_compressed_texture_s3tc");
  },
  supportsCompressedTexturePVRTC: function() {
    return console.warn("THREE.WebGLRenderer: .supportsCompressedTexturePVRTC() is now .extensions.get( 'WEBGL_compressed_texture_pvrtc' )."), this.extensions.get("WEBGL_compressed_texture_pvrtc");
  },
  supportsBlendMinMax: function() {
    return console.warn("THREE.WebGLRenderer: .supportsBlendMinMax() is now .extensions.get( 'EXT_blend_minmax' )."), this.extensions.get("EXT_blend_minmax");
  },
  supportsVertexTextures: function() {
    return console.warn("THREE.WebGLRenderer: .supportsVertexTextures() is now .capabilities.vertexTextures."), this.capabilities.vertexTextures;
  },
  supportsInstancedArrays: function() {
    return console.warn("THREE.WebGLRenderer: .supportsInstancedArrays() is now .extensions.get( 'ANGLE_instanced_arrays' )."), this.extensions.get("ANGLE_instanced_arrays");
  },
  enableScissorTest: function(e) {
    console.warn("THREE.WebGLRenderer: .enableScissorTest() is now .setScissorTest()."), this.setScissorTest(e);
  },
  initMaterial: function() {
    console.warn("THREE.WebGLRenderer: .initMaterial() has been removed.");
  },
  addPrePlugin: function() {
    console.warn("THREE.WebGLRenderer: .addPrePlugin() has been removed.");
  },
  addPostPlugin: function() {
    console.warn("THREE.WebGLRenderer: .addPostPlugin() has been removed.");
  },
  updateShadowMap: function() {
    console.warn("THREE.WebGLRenderer: .updateShadowMap() has been removed.");
  },
  setFaceCulling: function() {
    console.warn("THREE.WebGLRenderer: .setFaceCulling() has been removed.");
  },
  allocTextureUnit: function() {
    console.warn("THREE.WebGLRenderer: .allocTextureUnit() has been removed.");
  },
  setTexture: function() {
    console.warn("THREE.WebGLRenderer: .setTexture() has been removed.");
  },
  setTexture2D: function() {
    console.warn("THREE.WebGLRenderer: .setTexture2D() has been removed.");
  },
  setTextureCube: function() {
    console.warn("THREE.WebGLRenderer: .setTextureCube() has been removed.");
  },
  getActiveMipMapLevel: function() {
    return console.warn("THREE.WebGLRenderer: .getActiveMipMapLevel() is now .getActiveMipmapLevel()."), this.getActiveMipmapLevel();
  }
});
Object.defineProperties(fg.prototype, {
  shadowMapEnabled: {
    get: function() {
      return this.shadowMap.enabled;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderer: .shadowMapEnabled is now .shadowMap.enabled."), this.shadowMap.enabled = e;
    }
  },
  shadowMapType: {
    get: function() {
      return this.shadowMap.type;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderer: .shadowMapType is now .shadowMap.type."), this.shadowMap.type = e;
    }
  },
  shadowMapCullFace: {
    get: function() {
      console.warn("THREE.WebGLRenderer: .shadowMapCullFace has been removed. Set Material.shadowSide instead.");
    },
    set: function() {
      console.warn("THREE.WebGLRenderer: .shadowMapCullFace has been removed. Set Material.shadowSide instead.");
    }
  },
  context: {
    get: function() {
      return console.warn("THREE.WebGLRenderer: .context has been removed. Use .getContext() instead."), this.getContext();
    }
  },
  vr: {
    get: function() {
      return console.warn("THREE.WebGLRenderer: .vr has been renamed to .xr"), this.xr;
    }
  },
  gammaInput: {
    get: function() {
      return console.warn("THREE.WebGLRenderer: .gammaInput has been removed. Set the encoding for textures via Texture.encoding instead."), !1;
    },
    set: function() {
      console.warn("THREE.WebGLRenderer: .gammaInput has been removed. Set the encoding for textures via Texture.encoding instead.");
    }
  },
  gammaOutput: {
    get: function() {
      return console.warn("THREE.WebGLRenderer: .gammaOutput has been removed. Set WebGLRenderer.outputEncoding instead."), !1;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderer: .gammaOutput has been removed. Set WebGLRenderer.outputEncoding instead."), this.outputEncoding = e === !0 ? $y : Ki;
    }
  },
  toneMappingWhitePoint: {
    get: function() {
      return console.warn("THREE.WebGLRenderer: .toneMappingWhitePoint has been removed."), 1;
    },
    set: function() {
      console.warn("THREE.WebGLRenderer: .toneMappingWhitePoint has been removed.");
    }
  }
});
Object.defineProperties(Zx.prototype, {
  cullFace: {
    get: function() {
      console.warn("THREE.WebGLRenderer: .shadowMap.cullFace has been removed. Set Material.shadowSide instead.");
    },
    set: function() {
      console.warn("THREE.WebGLRenderer: .shadowMap.cullFace has been removed. Set Material.shadowSide instead.");
    }
  },
  renderReverseSided: {
    get: function() {
      console.warn("THREE.WebGLRenderer: .shadowMap.renderReverseSided has been removed. Set Material.shadowSide instead.");
    },
    set: function() {
      console.warn("THREE.WebGLRenderer: .shadowMap.renderReverseSided has been removed. Set Material.shadowSide instead.");
    }
  },
  renderSingleSided: {
    get: function() {
      console.warn("THREE.WebGLRenderer: .shadowMap.renderSingleSided has been removed. Set Material.shadowSide instead.");
    },
    set: function() {
      console.warn("THREE.WebGLRenderer: .shadowMap.renderSingleSided has been removed. Set Material.shadowSide instead.");
    }
  }
});
Object.defineProperties(xs.prototype, {
  wrapS: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .wrapS is now .texture.wrapS."), this.texture.wrapS;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .wrapS is now .texture.wrapS."), this.texture.wrapS = e;
    }
  },
  wrapT: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .wrapT is now .texture.wrapT."), this.texture.wrapT;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .wrapT is now .texture.wrapT."), this.texture.wrapT = e;
    }
  },
  magFilter: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .magFilter is now .texture.magFilter."), this.texture.magFilter;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .magFilter is now .texture.magFilter."), this.texture.magFilter = e;
    }
  },
  minFilter: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .minFilter is now .texture.minFilter."), this.texture.minFilter;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .minFilter is now .texture.minFilter."), this.texture.minFilter = e;
    }
  },
  anisotropy: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .anisotropy is now .texture.anisotropy."), this.texture.anisotropy;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .anisotropy is now .texture.anisotropy."), this.texture.anisotropy = e;
    }
  },
  offset: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .offset is now .texture.offset."), this.texture.offset;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .offset is now .texture.offset."), this.texture.offset = e;
    }
  },
  repeat: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .repeat is now .texture.repeat."), this.texture.repeat;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .repeat is now .texture.repeat."), this.texture.repeat = e;
    }
  },
  format: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .format is now .texture.format."), this.texture.format;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .format is now .texture.format."), this.texture.format = e;
    }
  },
  type: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .type is now .texture.type."), this.texture.type;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .type is now .texture.type."), this.texture.type = e;
    }
  },
  generateMipmaps: {
    get: function() {
      return console.warn("THREE.WebGLRenderTarget: .generateMipmaps is now .texture.generateMipmaps."), this.texture.generateMipmaps;
    },
    set: function(e) {
      console.warn("THREE.WebGLRenderTarget: .generateMipmaps is now .texture.generateMipmaps."), this.texture.generateMipmaps = e;
    }
  }
});
Object.defineProperties(ig.prototype, {
  load: {
    value: function(e) {
      console.warn("THREE.Audio: .load has been deprecated. Use THREE.AudioLoader instead.");
      const n = this;
      return new w0().load(e, function(i) {
        n.setBuffer(i);
      }), this;
    }
  },
  startTime: {
    set: function() {
      console.warn("THREE.Audio: .startTime is now .play( delay ).");
    }
  }
});
fb.prototype.getData = function() {
  return console.warn("THREE.AudioAnalyser: .getData() is now .getFrequencyData()."), this.getFrequencyData();
};
Dm.prototype.updateCubeMap = function(e, n) {
  return console.warn("THREE.CubeCamera: .updateCubeMap() is now .update()."), this.update(e, n);
};
ga.crossOrigin = void 0;
ga.loadTexture = function(e, n, t, i) {
  console.warn("THREE.ImageUtils.loadTexture has been deprecated. Use THREE.TextureLoader() instead.");
  const r = new Ey();
  r.setCrossOrigin(this.crossOrigin);
  const a = r.load(e, t, void 0, i);
  return n && (a.mapping = n), a;
};
ga.loadTextureCube = function(e, n, t, i) {
  console.warn("THREE.ImageUtils.loadTextureCube has been deprecated. Use THREE.CubeTextureLoader() instead.");
  const r = new a0();
  r.setCrossOrigin(this.crossOrigin);
  const a = r.load(e, t, void 0, i);
  return n && (a.mapping = n), a;
};
ga.loadCompressedTexture = function() {
  console.error("THREE.ImageUtils.loadCompressedTexture has been removed. Use THREE.DDSLoader instead.");
};
ga.loadCompressedTextureCube = function() {
  console.error("THREE.ImageUtils.loadCompressedTextureCube has been removed. Use THREE.DDSLoader instead.");
};
typeof __THREE_DEVTOOLS__ < "u" && __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent("register", { detail: {
  revision: $b
} }));
const Pr = function() {
  const [e, n] = arguments;
  /\/1\/601-tinified/.test(n) && console.log(...arguments);
}, Ai = {};
class SP extends Tn {
  constructor(n) {
    super(n);
  }
  load(n, t, i, r, a) {
    Pr("load", n), n === void 0 && (n = ""), this.path !== void 0 && (n = this.path + n), n = this.manager.resolveURL(n);
    const c = ur.get(n);
    if (c !== void 0)
      return Pr("cached", n), this.manager.itemStart(n), setTimeout(() => {
        t && t(c), this.manager.itemEnd(n);
      }, 0), c;
    if (Ai[n] !== void 0) {
      Ai[n].push({
        onLoad: t,
        onProgress: i,
        onError: r
      }), Pr("return", n, Ai[n]);
      return;
    }
    Ai[n] = [], Ai[n].push({
      onLoad: t,
      onProgress: i,
      onError: r
    }), Pr("push", n, Ai[n]);
    const u = new Request(n, {
      headers: new Headers(this.requestHeader),
      credentials: this.withCredentials ? "include" : "same-origin"
      // An abort controller could be added within a future PR
    }), l = this.mimeType, f = this.responseType;
    Pr("started fetch", n), fetch(u, a).then((m) => {
      if (m.status === 200 || m.status === 0) {
        if (m.status === 0 && console.warn("THREE.FileLoader: HTTP Status 0 received."), typeof ReadableStream > "u" || m.body === void 0 || m.body.getReader === void 0)
          return m;
        const h = Ai[n], p = m.body.getReader(), _ = m.headers.get("Content-Length"), v = _ ? parseInt(_) : 0, S = v !== 0;
        let D = 0;
        const w = new ReadableStream({
          start(T) {
            F();
            function F() {
              p.read().then(({ done: E, value: A }) => {
                if (E)
                  T.close();
                else {
                  D += A.byteLength;
                  const L = new ProgressEvent("progress", {
                    lengthComputable: S,
                    loaded: D,
                    total: v
                  });
                  for (let I = 0, R = h.length; I < R; I++) {
                    const N = h[I];
                    N.onProgress && N.onProgress(L);
                  }
                  T.enqueue(A), F();
                }
              }).catch((E) => {
                delete Ai[n];
              });
            }
          }
        });
        return new Response(w);
      } else
        throw Error(
          `fetch for "${m.url}" responded with ${m.status}: ${m.statusText}`
        );
    }).then((m) => {
      switch (f) {
        case "arraybuffer":
          return m.arrayBuffer();
        case "blob":
          return m.blob();
        case "document":
          return m.text().then((h) => new DOMParser().parseFromString(h, l));
        case "json":
          return m.json();
        default:
          if (l === void 0)
            return m.text();
          {
            const p = /charset="?([^;"\s]*)"?/i.exec(l), _ = p && p[1] ? p[1].toLowerCase() : void 0, v = new TextDecoder(_);
            return m.arrayBuffer().then((S) => v.decode(S));
          }
      }
    }).then((m) => {
      ur.add(n, m);
      const h = Ai[n];
      Pr("then delete", n, Ai[n]), delete Ai[n];
      for (let p = 0, _ = h.length; p < _; p++) {
        const v = h[p];
        v.onLoad && v.onLoad(m);
      }
    }).catch((m) => {
      const h = Ai[n];
      if (Pr("err delete", n, Ai[n]), delete Ai[n], h === void 0)
        throw this.manager.itemError(n), m;
      for (let p = 0, _ = h.length; p < _; p++) {
        const v = h[p];
        v.onError && v.onError(m);
      }
      this.manager.itemError(n);
    }).finally(() => {
      Pr("finally delete", n, Ai[n]), delete Ai[n], this.manager.itemEnd(n);
    }), this.manager.itemStart(n);
  }
  setResponseType(n) {
    return this.responseType = n, this;
  }
  setMimeType(n) {
    return this.mimeType = n, this;
  }
}
const PP = function(e) {
  const n = ur, { signal: t } = e;
  n.enabled = !0;
  const i = new Ey(), r = new SP();
  r.setResponseType("blob");
  function a(c, u, l, f, m = 1) {
    r.load(
      c,
      h,
      l,
      (v) => {
        console.error("loader err", v), f();
      },
      { signal: t }
    );
    function h(v) {
      if (Pr("cache image called", c, v), v.tagName != "IMG") {
        const S = URL.createObjectURL(v), D = document.createElementNS(
          "http://www.w3.org/1999/xhtml",
          "img"
        );
        D.onload = () => {
          n.add(c, D), URL.revokeObjectURL(S), document.body.removeChild(D), m == 1 ? p() : _(D);
        }, D.src = S, D.style.visibility = "hidden", document.body.appendChild(D);
      } else
        m == 1 ? p() : _(v);
    }
    function p() {
      i.load(c, u, () => {
      }, f);
    }
    function _(v) {
      const S = document.createElement("canvas"), D = S.getContext("2d");
      S.width = v.width, S.height = v.height, D.filter = `brightness(${m})`, D.drawImage(v, 0, 0, v.width, v.height);
      const w = new Bm(S);
      u(w), S.remove();
    }
  }
  return Object.assign({}, i, { load: a });
}, E0 = function() {
  this.logging = {
    enabled: !1,
    debug: !1
  };
  let e = this;
  this.callbacks = {
    onProgress: function(n) {
      e._onProgress(n);
    },
    onAssetAvailable: function(n) {
      e._onAssetAvailable(n);
    },
    onError: function(n) {
      e._onError(n);
    },
    onLoad: function(n, t) {
      e._onLoad(n, t);
    }
  }, this.contentRef = null, this.legacyMode = !1, this.materials = {}, this.materialPerSmoothingGroup = !1, this.useOAsMesh = !1, this.useIndices = !1, this.disregardNormals = !1, this.vertices = [], this.colors = [], this.normals = [], this.uvs = [], this.rawMesh = {
    objectName: "",
    groupName: "",
    activeMtlName: "",
    mtllibName: "",
    // reset with new mesh
    faceType: -1,
    subGroups: [],
    subGroupInUse: null,
    smoothingGroup: {
      splitMaterials: !1,
      normalized: -1,
      real: -1
    },
    counts: {
      doubleIndicesCount: 0,
      faceCount: 0,
      mtlCount: 0,
      smoothingGroupCount: 0
    }
  }, this.inputObjectCount = 1, this.outputObjectCount = 1, this.globalCounts = {
    vertices: 0,
    faces: 0,
    doubleIndicesCount: 0,
    lineByte: 0,
    currentByte: 0,
    totalBytes: 0
  };
};
E0.prototype = {
  constructor: E0,
  _resetRawMesh: function() {
    this.rawMesh.subGroups = [], this.rawMesh.subGroupInUse = null, this.rawMesh.smoothingGroup.normalized = -1, this.rawMesh.smoothingGroup.real = -1, this._pushSmoothingGroup(1), this.rawMesh.counts.doubleIndicesCount = 0, this.rawMesh.counts.faceCount = 0, this.rawMesh.counts.mtlCount = 0, this.rawMesh.counts.smoothingGroupCount = 0;
  },
  /**
   * Tells whether a material shall be created per smoothing group.
   *
   * @param {boolean} materialPerSmoothingGroup=false
   * @return {OBJLoader2Parser}
   */
  setMaterialPerSmoothingGroup: function(e) {
    return this.materialPerSmoothingGroup = e === !0, this;
  },
  /**
   * Usually 'o' is meta-information and does not result in creation of new meshes, but mesh creation on occurrence of "o" can be enforced.
   *
   * @param {boolean} useOAsMesh=false
   * @return {OBJLoader2Parser}
   */
  setUseOAsMesh: function(e) {
    return this.useOAsMesh = e === !0, this;
  },
  /**
   * Instructs loaders to create indexed {@link BufferGeometry}.
   *
   * @param {boolean} useIndices=false
   * @return {OBJLoader2Parser}
   */
  setUseIndices: function(e) {
    return this.useIndices = e === !0, this;
  },
  /**
   * Tells whether normals should be completely disregarded and regenerated.
   *
   * @param {boolean} disregardNormals=false
   * @return {OBJLoader2Parser}
   */
  setDisregardNormals: function(e) {
    return this.disregardNormals = e === !0, this;
  },
  /**
   * Clears materials object and sets the new ones.
   *
   * @param {Object} materials Object with named materials
   */
  setMaterials: function(e) {
    this.materials = Object.assign({}, e);
  },
  /**
   * Register a function that is called once an asset (mesh/material) becomes available.
   *
   * @param onAssetAvailable
   * @return {OBJLoader2Parser}
   */
  setCallbackOnAssetAvailable: function(e) {
    return e != null && e instanceof Function && (this.callbacks.onAssetAvailable = e), this;
  },
  /**
   * Register a function that is used to report overall processing progress.
   *
   * @param {Function} onProgress
   * @return {OBJLoader2Parser}
   */
  setCallbackOnProgress: function(e) {
    return e != null && e instanceof Function && (this.callbacks.onProgress = e), this;
  },
  /**
   * Register an error handler function that is called if errors occur. It can decide to just log or to throw an exception.
   *
   * @param {Function} onError
   * @return {OBJLoader2Parser}
   */
  setCallbackOnError: function(e) {
    return e != null && e instanceof Function && (this.callbacks.onError = e), this;
  },
  /**
   * Register a function that is called when parsing was completed.
   *
   * @param {Function} onLoad
   * @return {OBJLoader2Parser}
   */
  setCallbackOnLoad: function(e) {
    return e != null && e instanceof Function && (this.callbacks.onLoad = e), this;
  },
  /**
   * Announce parse progress feedback which is logged to the console.
   * @private
   *
   * @param {string} text Textual description of the event
   */
  _onProgress: function(e) {
    let n = e || "";
    this.logging.enabled && this.logging.debug && console.log(n);
  },
  /**
   * Announce error feedback which is logged as error message.
   * @private
   *
   * @param {String} errorMessage The event containing the error
   */
  _onError: function(e) {
    this.logging.enabled && this.logging.debug && console.error(e);
  },
  _onAssetAvailable: function(e) {
    let n = "OBJLoader2Parser does not provide implementation for onAssetAvailable. Aborting...";
    throw this.callbacks.onError(n), n;
  },
  _onLoad: function(e, n) {
    console.log("You reached parser default onLoad callback: " + n);
  },
  /**
   * Enable or disable logging in general (except warn and error), plus enable or disable debug logging.
   *
   * @param {boolean} enabled True or false.
   * @param {boolean} debug True or false.
   *
   * @return {OBJLoader2Parser}
   */
  setLogging: function(e, n) {
    return this.logging.enabled = e === !0, this.logging.debug = n === !0, this;
  },
  _configure: function() {
    if (this._pushSmoothingGroup(1), this.logging.enabled) {
      let e = Object.keys(this.materials), t = "OBJLoader.Parser configuration:" + (e.length > 0 ? `
	materialNames:
		- ` + e.join(`
		- `) : `
	materialNames: None`) + `
	materialPerSmoothingGroup: ` + this.materialPerSmoothingGroup + `
	useOAsMesh: ` + this.useOAsMesh + `
	useIndices: ` + this.useIndices + `
	disregardNormals: ` + this.disregardNormals;
      t += `
	callbacks.onProgress: ` + this.callbacks.onProgress.name, t += `
	callbacks.onAssetAvailable: ` + this.callbacks.onAssetAvailable.name, t += `
	callbacks.onError: ` + this.callbacks.onError.name, console.info(t);
    }
  },
  /**
   * Parse the provided arraybuffer
   *
   * @param {Uint8Array} arrayBuffer OBJ data as Uint8Array
   */
  execute: function(e) {
    this.logging.enabled && console.time("OBJLoader2Parser.execute"), this._configure();
    let n = new Uint8Array(e);
    this.contentRef = n;
    let t = n.byteLength;
    this.globalCounts.totalBytes = t;
    let i = new Array(128), r = 0, a = 0, c = "", u = 0;
    for (let l, f = 0; f < t; f++)
      switch (l = n[f], l) {
        case 32:
          c.length > 0 && (i[r++] = c), c = "";
          break;
        case 47:
          c.length > 0 && (i[r++] = c), a++, c = "";
          break;
        case 10:
          this._processLine(i, r, a, c, f), c = "", r = 0, a = 0;
          break;
        case 13:
          break;
        default:
          c += String.fromCharCode(l);
          break;
      }
    this._processLine(i, r, a, c, u), this._finalizeParsing(), this.logging.enabled && console.timeEnd("OBJLoader2Parser.execute");
  },
  /**
   * Parse the provided text
   *
   * @param {string} text OBJ data as string
   */
  executeLegacy: function(e) {
    this.logging.enabled && console.time("OBJLoader2Parser.executeLegacy"), this._configure(), this.legacyMode = !0, this.contentRef = e;
    let n = e.length;
    this.globalCounts.totalBytes = n;
    let t = new Array(128), i = 0, r = 0, a = "", c = 0;
    for (let u; c < n; c++)
      switch (u = e[c], u) {
        case " ":
          a.length > 0 && (t[i++] = a), a = "";
          break;
        case "/":
          a.length > 0 && (t[i++] = a), r++, a = "";
          break;
        case `
`:
          this._processLine(t, i, r, a, c), a = "", i = 0, r = 0;
          break;
        case "\r":
          break;
        default:
          a += u;
      }
    this._processLine(t, i, a, r), this._finalizeParsing(), this.logging.enabled && console.timeEnd("OBJLoader2Parser.executeLegacy");
  },
  _processLine: function(e, n, t, i, r) {
    if (this.globalCounts.lineByte = this.globalCounts.currentByte, this.globalCounts.currentByte = r, n < 1)
      return;
    i.length > 0 && (e[n++] = i);
    let a = function(m, h, p, _) {
      let v = "";
      if (_ > p) {
        let S;
        if (h)
          for (S = p; S < _; S++)
            v += m[S];
        else
          for (S = p; S < _; S++)
            v += String.fromCharCode(m[S]);
        v = v.trim();
      }
      return v;
    }, c, u, l, f;
    switch (f = e[0], f) {
      case "v":
        this.vertices.push(parseFloat(e[1])), this.vertices.push(parseFloat(e[2])), this.vertices.push(parseFloat(e[3])), n > 4 && (this.colors.push(parseFloat(e[4])), this.colors.push(parseFloat(e[5])), this.colors.push(parseFloat(e[6])));
        break;
      case "vt":
        this.uvs.push(parseFloat(e[1])), this.uvs.push(parseFloat(e[2]));
        break;
      case "vn":
        this.normals.push(parseFloat(e[1])), this.normals.push(parseFloat(e[2])), this.normals.push(parseFloat(e[3]));
        break;
      case "f":
        if (c = n - 1, t === 0)
          for (this._checkFaceType(0), l = 2, u = c; l < u; l++)
            this._buildFace(e[1]), this._buildFace(e[l]), this._buildFace(e[l + 1]);
        else if (c === t * 2)
          for (this._checkFaceType(1), l = 3, u = c - 2; l < u; l += 2)
            this._buildFace(e[1], e[2]), this._buildFace(e[l], e[l + 1]), this._buildFace(e[l + 2], e[l + 3]);
        else if (c * 2 === t * 3)
          for (this._checkFaceType(2), l = 4, u = c - 3; l < u; l += 3)
            this._buildFace(e[1], e[2], e[3]), this._buildFace(e[l], e[l + 1], e[l + 2]), this._buildFace(e[l + 3], e[l + 4], e[l + 5]);
        else
          for (this._checkFaceType(3), l = 3, u = c - 2; l < u; l += 2)
            this._buildFace(e[1], void 0, e[2]), this._buildFace(e[l], void 0, e[l + 1]), this._buildFace(e[l + 2], void 0, e[l + 3]);
        break;
      case "l":
      case "p":
        if (c = n - 1, c === t * 2)
          for (this._checkFaceType(4), l = 1, u = c + 1; l < u; l += 2)
            this._buildFace(e[l], e[l + 1]);
        else
          for (this._checkFaceType(f === "l" ? 5 : 6), l = 1, u = c + 1; l < u; l++)
            this._buildFace(e[l]);
        break;
      case "s":
        this._pushSmoothingGroup(e[1]);
        break;
      case "g":
        this._processCompletedMesh(), this.rawMesh.groupName = a(this.contentRef, this.legacyMode, this.globalCounts.lineByte + 2, this.globalCounts.currentByte);
        break;
      case "o":
        this.useOAsMesh && this._processCompletedMesh(), this.rawMesh.objectName = a(this.contentRef, this.legacyMode, this.globalCounts.lineByte + 2, this.globalCounts.currentByte);
        break;
      case "mtllib":
        this.rawMesh.mtllibName = a(this.contentRef, this.legacyMode, this.globalCounts.lineByte + 7, this.globalCounts.currentByte);
        break;
      case "usemtl":
        let m = a(this.contentRef, this.legacyMode, this.globalCounts.lineByte + 7, this.globalCounts.currentByte);
        m !== "" && this.rawMesh.activeMtlName !== m && (this.rawMesh.activeMtlName = m, this.rawMesh.counts.mtlCount++, this._checkSubGroup());
        break;
    }
  },
  _pushSmoothingGroup: function(e) {
    let n = parseInt(e);
    isNaN(n) && (n = e === "off" ? 0 : 1);
    let t = this.rawMesh.smoothingGroup.normalized;
    this.rawMesh.smoothingGroup.normalized = this.rawMesh.smoothingGroup.splitMaterials ? n : n === 0 ? 0 : 1, this.rawMesh.smoothingGroup.real = n, t !== n && (this.rawMesh.counts.smoothingGroupCount++, this._checkSubGroup());
  },
  /**
   * Expanded faceTypes include all four face types, both line types and the point type
   * faceType = 0: "f vertex ..."
   * faceType = 1: "f vertex/uv ..."
   * faceType = 2: "f vertex/uv/normal ..."
   * faceType = 3: "f vertex//normal ..."
   * faceType = 4: "l vertex/uv ..." or "l vertex ..."
   * faceType = 5: "l vertex ..."
   * faceType = 6: "p vertex ..."
   */
  _checkFaceType: function(e) {
    this.rawMesh.faceType !== e && (this._processCompletedMesh(), this.rawMesh.faceType = e, this._checkSubGroup());
  },
  _checkSubGroup: function() {
    let e = this.rawMesh.activeMtlName + "|" + this.rawMesh.smoothingGroup.normalized;
    this.rawMesh.subGroupInUse = this.rawMesh.subGroups[e], (this.rawMesh.subGroupInUse === void 0 || this.rawMesh.subGroupInUse === null) && (this.rawMesh.subGroupInUse = {
      index: e,
      objectName: this.rawMesh.objectName,
      groupName: this.rawMesh.groupName,
      materialName: this.rawMesh.activeMtlName,
      smoothingGroup: this.rawMesh.smoothingGroup.normalized,
      vertices: [],
      indexMappingsCount: 0,
      indexMappings: [],
      indices: [],
      colors: [],
      uvs: [],
      normals: []
    }, this.rawMesh.subGroups[e] = this.rawMesh.subGroupInUse);
  },
  _buildFace: function(e, n, t) {
    let i = this.rawMesh.subGroupInUse, r = this, a = function() {
      let c = parseInt(e), u = 3 * (c > 0 ? c - 1 : c + r.vertices.length / 3), l = r.colors.length > 0 ? u : null, f = i.vertices;
      if (f.push(r.vertices[u++]), f.push(r.vertices[u++]), f.push(r.vertices[u]), l !== null) {
        let m = i.colors;
        m.push(r.colors[l++]), m.push(r.colors[l++]), m.push(r.colors[l]);
      }
      if (n) {
        let m = parseInt(n), h = 2 * (m > 0 ? m - 1 : m + r.uvs.length / 2), p = i.uvs;
        p.push(r.uvs[h++]), p.push(r.uvs[h]);
      }
      if (t && !r.disregardNormals) {
        let m = parseInt(t), h = 3 * (m > 0 ? m - 1 : m + r.normals.length / 3), p = i.normals;
        p.push(r.normals[h++]), p.push(r.normals[h++]), p.push(r.normals[h]);
      }
    };
    if (this.useIndices) {
      this.disregardNormals && (t = void 0);
      let c = e + (n ? "_" + n : "_n") + (t ? "_" + t : "_n"), u = i.indexMappings[c];
      u == null ? (u = this.rawMesh.subGroupInUse.vertices.length / 3, a(), i.indexMappings[c] = u, i.indexMappingsCount++) : this.rawMesh.counts.doubleIndicesCount++, i.indices.push(u);
    } else
      a();
    this.rawMesh.counts.faceCount++;
  },
  _createRawMeshReport: function(e) {
    return "Input Object number: " + e + `
	Object name: ` + this.rawMesh.objectName + `
	Group name: ` + this.rawMesh.groupName + `
	Mtllib name: ` + this.rawMesh.mtllibName + `
	Vertex count: ` + this.vertices.length / 3 + `
	Normal count: ` + this.normals.length / 3 + `
	UV count: ` + this.uvs.length / 2 + `
	SmoothingGroup count: ` + this.rawMesh.counts.smoothingGroupCount + `
	Material count: ` + this.rawMesh.counts.mtlCount + `
	Real MeshOutputGroup count: ` + this.rawMesh.subGroups.length;
  },
  /**
   * Clear any empty subGroup and calculate absolute vertex, normal and uv counts
   */
  _finalizeRawMesh: function() {
    let e = [], n, t = 0, i = 0, r = 0, a = 0, c = 0, u = 0, l;
    for (let m in this.rawMesh.subGroups)
      if (n = this.rawMesh.subGroups[m], n.vertices.length > 0) {
        if (l = n.indices, l.length > 0 && i > 0)
          for (let h = 0; h < l.length; h++)
            l[h] = l[h] + i;
        e.push(n), t += n.vertices.length, i += n.indexMappingsCount, r += n.indices.length, a += n.colors.length, u += n.uvs.length, c += n.normals.length;
      }
    let f = null;
    return e.length > 0 && (f = {
      name: this.rawMesh.groupName !== "" ? this.rawMesh.groupName : this.rawMesh.objectName,
      subGroups: e,
      absoluteVertexCount: t,
      absoluteIndexCount: r,
      absoluteColorCount: a,
      absoluteNormalCount: c,
      absoluteUvCount: u,
      faceCount: this.rawMesh.counts.faceCount,
      doubleIndicesCount: this.rawMesh.counts.doubleIndicesCount
    }), f;
  },
  _processCompletedMesh: function() {
    let e = this._finalizeRawMesh(), n = e !== null;
    if (n) {
      this.colors.length > 0 && this.colors.length !== this.vertices.length && this.callbacks.onError("Vertex Colors were detected, but vertex count and color count do not match!"), this.logging.enabled && this.logging.debug && console.debug(this._createRawMeshReport(this.inputObjectCount)), this.inputObjectCount++, this._buildMesh(e);
      let t = this.globalCounts.currentByte / this.globalCounts.totalBytes;
      this._onProgress("Completed [o: " + this.rawMesh.objectName + " g:" + this.rawMesh.groupName + "] Total progress: " + (t * 100).toFixed(2) + "%"), this._resetRawMesh();
    }
    return n;
  },
  /**
   * SubGroups are transformed to too intermediate format that is forwarded to the MeshReceiver.
   * It is ensured that SubGroups only contain objects with vertices (no need to check).
   *
   * @param result
   */
  _buildMesh: function(e) {
    let n = e.subGroups, t = new Float32Array(e.absoluteVertexCount);
    this.globalCounts.vertices += e.absoluteVertexCount / 3, this.globalCounts.faces += e.faceCount, this.globalCounts.doubleIndicesCount += e.doubleIndicesCount;
    let i = e.absoluteIndexCount > 0 ? new Uint32Array(e.absoluteIndexCount) : null, r = e.absoluteColorCount > 0 ? new Float32Array(e.absoluteColorCount) : null, a = e.absoluteNormalCount > 0 ? new Float32Array(e.absoluteNormalCount) : null, c = e.absoluteUvCount > 0 ? new Float32Array(e.absoluteUvCount) : null, u = r !== null, l, f = [], m = n.length > 1, h = 0, p = [], _, v, S = [], D = 0, w = 0, T = 0, F = 0, E = 0, A = 0, L = 0, I, R, N, q;
    for (let ne in n)
      if (n.hasOwnProperty(ne)) {
        if (l = n[ne], q = l.materialName, this.rawMesh.faceType < 4 ? N = q + (u ? "_vertexColor" : "") + (l.smoothingGroup === 0 ? "_flat" : "") : N = this.rawMesh.faceType === 6 ? "defaultPointMaterial" : "defaultLineMaterial", I = this.materials[q], R = this.materials[N], I == null && R == null && (N = u ? "defaultVertexColorMaterial" : "defaultMaterial", R = this.materials[N], this.logging.enabled && console.info('object_group "' + l.objectName + "_" + l.groupName + '" was defined with unresolvable material "' + q + '"! Assigning "' + N + '".')), R == null) {
          let Q = {
            materialNameOrg: q,
            materialName: N,
            materialProperties: {
              vertexColors: u ? 2 : 0,
              flatShading: l.smoothingGroup === 0
            }
          }, W = {
            cmd: "assetAvailable",
            type: "material",
            materials: {
              materialCloneInstructions: Q
            }
          };
          this.callbacks.onAssetAvailable(W);
          let te = this.materials[N];
          te == null && (this.materials[N] = Q);
        }
        if (m ? (_ = p[N], _ || (_ = h, p[N] = h, f.push(N), h++), L = this.useIndices ? l.indices.length : l.vertices.length / 3, v = {
          start: A,
          count: L,
          index: _
        }, S.push(v), A += L) : f.push(N), t.set(l.vertices, D), D += l.vertices.length, i && (i.set(l.indices, w), w += l.indices.length), r && (r.set(l.colors, T), T += l.colors.length), a && (a.set(l.normals, F), F += l.normals.length), c && (c.set(l.uvs, E), E += l.uvs.length), this.logging.enabled && this.logging.debug) {
          let Q = "";
          _ && (Q = `
		materialIndex: ` + _);
          let W = "	Output Object no.: " + this.outputObjectCount + `
		groupName: ` + l.groupName + `
		Index: ` + l.index + `
		faceType: ` + this.rawMesh.faceType + `
		materialName: ` + l.materialName + `
		smoothingGroup: ` + l.smoothingGroup + Q + `
		objectName: ` + l.objectName + `
		#vertices: ` + l.vertices.length / 3 + `
		#indices: ` + l.indices.length + `
		#colors: ` + l.colors.length / 3 + `
		#uvs: ` + l.uvs.length / 2 + `
		#normals: ` + l.normals.length / 3;
          console.debug(W);
        }
      }
    this.outputObjectCount++, this.callbacks.onAssetAvailable(
      {
        cmd: "assetAvailable",
        type: "mesh",
        progress: {
          numericalValue: this.globalCounts.currentByte / this.globalCounts.totalBytes
        },
        params: {
          meshName: e.name
        },
        materials: {
          multiMaterial: m,
          materialNames: f,
          materialGroups: S
        },
        buffers: {
          vertices: t,
          indices: i,
          colors: r,
          normals: a,
          uvs: c
        },
        // 0: mesh, 1: line, 2: point
        geometryType: this.rawMesh.faceType < 4 ? 0 : this.rawMesh.faceType === 6 ? 2 : 1
      },
      [t.buffer],
      i !== null ? [i.buffer] : null,
      r !== null ? [r.buffer] : null,
      a !== null ? [a.buffer] : null,
      c !== null ? [c.buffer] : null
    );
  },
  _finalizeParsing: function() {
    if (this.logging.enabled && console.info("Global output object count: " + this.outputObjectCount), this._processCompletedMesh() && this.logging.enabled) {
      let e = `Overall counts: 
	Vertices: ` + this.globalCounts.vertices + `
	Faces: ` + this.globalCounts.faces + `
	Multiple definitions: ` + this.globalCounts.doubleIndicesCount;
      console.info(e);
    }
  }
};
const S0 = function(e) {
  this.logging = {
    enabled: !1,
    debug: !1
  }, this.callbacks = {
    onProgress: null,
    onMeshAlter: null
  }, this.materialHandler = e;
};
S0.prototype = {
  constructor: S0,
  /**
   * Enable or disable logging in general (except warn and error), plus enable or disable debug logging.
   *
   * @param {boolean} enabled True or false.
   * @param {boolean} debug True or false.
   */
  setLogging: function(e, n) {
    this.logging.enabled = e === !0, this.logging.debug = n === !0;
  },
  /**
   *
   * @param {Function} onProgress
   * @param {Function} onMeshAlter
   * @private
   */
  _setCallbacks: function(e, n) {
    e != null && e instanceof Function && (this.callbacks.onProgress = e), n != null && n instanceof Function && (this.callbacks.onMeshAlter = n);
  },
  /**
   * Builds one or multiple meshes from the data described in the payload (buffers, params, material info).
   *
   * @param {Object} meshPayload Raw mesh description (buffers, params, materials) used to build one to many meshes.
   * @returns {Mesh[]} mesh Array of {@link Mesh}
   */
  buildMeshes: function(e) {
    let n = e.params.meshName, t = e.buffers, i = new Gt();
    t.vertices !== void 0 && t.vertices !== null && i.setAttribute("position", new Jt(new Float32Array(t.vertices), 3)), t.indices !== void 0 && t.indices !== null && i.setIndex(new Jt(new Uint32Array(t.indices), 1)), t.colors !== void 0 && t.colors !== null && i.setAttribute("color", new Jt(new Float32Array(t.colors), 3)), t.normals !== void 0 && t.normals !== null ? i.setAttribute("normal", new Jt(new Float32Array(t.normals), 3)) : i.computeVertexNormals(), t.uvs !== void 0 && t.uvs !== null && i.setAttribute("uv", new Jt(new Float32Array(t.uvs), 2)), t.skinIndex !== void 0 && t.skinIndex !== null && i.setAttribute("skinIndex", new Jt(new Uint16Array(t.skinIndex), 4)), t.skinWeight !== void 0 && t.skinWeight !== null && i.setAttribute("skinWeight", new Jt(new Float32Array(t.skinWeight), 4));
    let r, a, c, u = e.materials.materialNames, l = e.materials.multiMaterial, f = [];
    for (c in u)
      a = u[c], r = this.materialHandler.getMaterial(a), l && f.push(r);
    if (l) {
      r = f;
      let D = e.materials.materialGroups, w;
      for (c in D)
        w = D[c], i.addGroup(w.start, w.count, w.index);
    }
    let m = [], h, p, _ = !0, v = e.geometryType === null ? 0 : e.geometryType;
    if (this.callbacks.onMeshAlter && (p = this.callbacks.onMeshAlter(
      {
        detail: {
          meshName: n,
          bufferGeometry: i,
          material: r,
          geometryType: v
        }
      }
    )), p) {
      if (p.isDisregardMesh())
        _ = !1;
      else if (p.providesAlteredMeshes()) {
        for (let D in p.meshes)
          m.push(p.meshes[D]);
        _ = !1;
      }
    }
    _ && (e.computeBoundingSphere && i.computeBoundingSphere(), v === 0 ? h = new Ln(i, r) : v === 1 ? h = new ai(i, r) : h = new sy(i, r), h.name = n, m.push(h));
    let S = e.params.meshName;
    if (m.length > 0) {
      let D = [];
      for (let w in m)
        h = m[w], D[w] = h.name;
      S += ": Adding mesh(es) (" + D.length + ": " + D + ") from input mesh: " + n, S += " (" + (e.progress.numericalValue * 100).toFixed(2) + "%)";
    } else
      S += ": Not adding mesh: " + n, S += " (" + (e.progress.numericalValue * 100).toFixed(2) + "%)";
    return this.callbacks.onProgress && this.callbacks.onProgress("progress", S, e.progress.numericalValue), m;
  }
};
const Px = function(e, n) {
  this.disregardMesh = e === !0, this.alteredMesh = n === !0, this.meshes = [];
};
Px.prototype = {
  constructor: Px,
  /**
   * Add a mesh created within callback.
   *
   * @param {Mesh} mesh
   */
  addMesh: function(e) {
    this.meshes.push(e), this.alteredMesh = !0;
  },
  /**
   * Answers if mesh shall be disregarded completely.
   *
   * @returns {boolean}
   */
  isDisregardMesh: function() {
    return this.disregardMesh;
  },
  /**
   * Answers if new mesh(es) were created.
   *
   * @returns {boolean}
   */
  providesAlteredMeshes: function() {
    return this.alteredMesh;
  }
};
const P0 = function() {
  this.logging = {
    enabled: !1,
    debug: !1
  }, this.callbacks = {
    onLoadMaterials: null
  }, this.materials = {};
};
P0.prototype = {
  constructor: P0,
  /**
   * Enable or disable logging in general (except warn and error), plus enable or disable debug logging.
   *
   * @param {boolean} enabled True or false.
   * @param {boolean} debug True or false.
   */
  setLogging: function(e, n) {
    this.logging.enabled = e === !0, this.logging.debug = n === !0;
  },
  _setCallbacks: function(e) {
    e != null && e instanceof Function && (this.callbacks.onLoadMaterials = e);
  },
  /**
   * Creates default materials and adds them to the materials object.
   *
   * @param overrideExisting boolean Override existing material
   */
  createDefaultMaterials: function(e) {
    let n = new Vs({ color: 14479871 });
    n.name = "defaultMaterial";
    let t = new Vs({ color: 14479871 });
    t.name = "defaultVertexColorMaterial", t.vertexColors = !0;
    let i = new Zn();
    i.name = "defaultLineMaterial";
    let r = new mo({ size: 0.1 });
    r.name = "defaultPointMaterial";
    let a = {};
    a[n.name] = n, a[t.name] = t, a[i.name] = i, a[r.name] = r, this.addMaterials(a, e);
  },
  /**
   * Updates the materials with contained material objects (sync) or from alteration instructions (async).
   *
   * @param {Object} materialPayload Material update instructions
   * @returns {Object} Map of {@link Material}
   */
  addPayloadMaterials: function(e) {
    let n, t, i = e.materials.materialCloneInstructions, r = {};
    if (i != null) {
      let c = i.materialNameOrg;
      c = c ?? "";
      let u = this.materials[c];
      u ? (n = u.clone(), t = i.materialName, n.name = t, Object.assign(n, i.materialProperties), this.materials[t] = n, r[t] = n) : this.logging.enabled && console.info('Requested material "' + c + '" is not available!');
    }
    let a = e.materials.serializedMaterials;
    if (a != null && Object.keys(a).length > 0) {
      let c = new Py(), u;
      for (t in a)
        u = a[t], u != null && (n = c.parse(u), this.logging.enabled && console.info('De-serialized material with name "' + t + '" will be added.'), this.materials[t] = n, r[t] = n);
    }
    return a = e.materials.runtimeMaterials, r = this.addMaterials(a, !0, r), r;
  },
  /**
   * Set materials loaded by any supplier of an Array of {@link Material}.
   *
   * @param materials Object with named {@link Material}
   * @param overrideExisting boolean Override existing material
   * @param newMaterials [Object] with named {@link Material}
   */
  addMaterials: function(e, n, t) {
    if (t == null && (t = {}), e != null && Object.keys(e).length > 0) {
      let i, r, a;
      for (let c in e)
        i = e[c], a = n === !0, a || (r = this.materials[c], a = r == null), a && (this.materials[c] = i, t[c] = i), this.logging.enabled && this.logging.debug && console.info('Material with name "' + c + '" was added.');
    }
    return this.callbacks.onLoadMaterials && this.callbacks.onLoadMaterials(t), t;
  },
  /**
   * Returns the mapping object of material name and corresponding material.
   *
   * @returns {Object} Map of {@link Material}
   */
  getMaterials: function() {
    return this.materials;
  },
  /**
   *
   * @param {String} materialName
   * @returns {Material}
   */
  getMaterial: function(e) {
    return this.materials[e];
  },
  /**
   * Returns the mapping object of material name and corresponding jsonified material.
   *
   * @returns {Object} Map of Materials in JSON representation
   */
  getMaterialsJSON: function() {
    let e = {}, n;
    for (let t in this.materials)
      n = this.materials[t], e[t] = n.toJSON();
    return e;
  },
  /**
   * Removes all materials
   */
  clearMaterials: function() {
    this.materials = {};
  }
};
const lg = function(e) {
  Tn.call(this, e), this.parser = new E0(), this.modelName = "", this.instanceNo = 0, this.baseObject3d = new Ft(), this.materialHandler = new P0(), this.meshReceiver = new S0(this.materialHandler);
  let n = this, t = function(i) {
    n._onAssetAvailable(i);
  };
  this.parser.setCallbackOnAssetAvailable(t);
};
lg.OBJLOADER2_VERSION = "3.2.0";
console.info("Using OBJLoader2 version: " + lg.OBJLOADER2_VERSION);
lg.prototype = Object.assign(Object.create(Tn.prototype), {
  constructor: lg,
  /**
   * See {@link OBJLoader2Parser.setLogging}
   * @return {OBJLoader2}
   */
  setLogging: function(e, n) {
    return this.parser.setLogging(e, n), this;
  },
  /**
   * See {@link OBJLoader2Parser.setMaterialPerSmoothingGroup}
   * @return {OBJLoader2}
   */
  setMaterialPerSmoothingGroup: function(e) {
    return this.parser.setMaterialPerSmoothingGroup(e), this;
  },
  /**
   * See {@link OBJLoader2Parser.setUseOAsMesh}
   * @return {OBJLoader2}
   */
  setUseOAsMesh: function(e) {
    return this.parser.setUseOAsMesh(e), this;
  },
  /**
   * See {@link OBJLoader2Parser.setUseIndices}
   * @return {OBJLoader2}
   */
  setUseIndices: function(e) {
    return this.parser.setUseIndices(e), this;
  },
  /**
   * See {@link OBJLoader2Parser.setDisregardNormals}
   * @return {OBJLoader2}
   */
  setDisregardNormals: function(e) {
    return this.parser.setDisregardNormals(e), this;
  },
  /**
   * Set the name of the model.
   *
   * @param {string} modelName
   * @return {OBJLoader2}
   */
  setModelName: function(e) {
    return this.modelName = e || this.modelName, this;
  },
  /**
   * Set the node where the loaded objects will be attached directly.
   *
   * @param {Object3D} baseObject3d Object already attached to scenegraph where new meshes will be attached to
   * @return {OBJLoader2}
   */
  setBaseObject3d: function(e) {
    return this.baseObject3d = e ?? this.baseObject3d, this;
  },
  /**
   * Add materials as associated array.
   *
   * @param {Object} materials Object with named {@link Material}
   * @param overrideExisting boolean Override existing material
   * @return {OBJLoader2}
   */
  addMaterials: function(e, n) {
    return this.materialHandler.addMaterials(e, n), this;
  },
  /**
   * See {@link OBJLoader2Parser.setCallbackOnAssetAvailable}
   * @return {OBJLoader2}
   */
  setCallbackOnAssetAvailable: function(e) {
    return this.parser.setCallbackOnAssetAvailable(e), this;
  },
  /**
   * See {@link OBJLoader2Parser.setCallbackOnProgress}
   * @return {OBJLoader2}
   */
  setCallbackOnProgress: function(e) {
    return this.parser.setCallbackOnProgress(e), this;
  },
  /**
   * See {@link OBJLoader2Parser.setCallbackOnError}
   * @return {OBJLoader2}
   */
  setCallbackOnError: function(e) {
    return this.parser.setCallbackOnError(e), this;
  },
  /**
   * See {@link OBJLoader2Parser.setCallbackOnLoad}
   * @return {OBJLoader2}
   */
  setCallbackOnLoad: function(e) {
    return this.parser.setCallbackOnLoad(e), this;
  },
  /**
   * Register a function that is called once a single mesh is available and it could be altered by the supplied function.
   *
   * @param {Function} [onMeshAlter]
   * @return {OBJLoader2}
   */
  setCallbackOnMeshAlter: function(e) {
    return this.meshReceiver._setCallbacks(this.parser.callbacks.onProgress, e), this;
  },
  /**
   * Register a function that is called once all materials have been loaded and they could be altered by the supplied function.
   *
   * @param {Function} [onLoadMaterials]
   * @return {OBJLoader2}
   */
  setCallbackOnLoadMaterials: function(e) {
    return this.materialHandler._setCallbacks(e), this;
  },
  /**
   * Use this convenient method to load a file at the given URL. By default the fileLoader uses an ArrayBuffer.
   *
   * @param {string}  url A string containing the path/URL of the file to be loaded.
   * @param {function} onLoad A function to be called after loading is successfully completed. The function receives loaded Object3D as an argument.
   * @param {function} [onFileLoadProgress] A function to be called while the loading is in progress. The argument will be the XMLHttpRequest instance, which contains total and Integer bytes.
   * @param {function} [onError] A function to be called if an error occurs during loading. The function receives the error as an argument.
   * @param {function} [onMeshAlter] Called after every single mesh is made available by the parser
   */
  load: function(e, n, t, i, r) {
    let a = this;
    if (n == null || !(n instanceof Function)) {
      let h = "onLoad is not a function! Aborting...";
      throw a.parser.callbacks.onError(h), h;
    } else
      this.parser.setCallbackOnLoad(n);
    (i == null || !(i instanceof Function)) && (i = function(h) {
      let p = h;
      h.currentTarget && h.currentTarget.statusText !== null && (p = `Error occurred while downloading!
url: ` + h.currentTarget.responseURL + `
status: ` + h.currentTarget.statusText), a.parser.callbacks.onError(p);
    }), e || i("An invalid url was provided. Unable to continue!");
    let c = new URL(e, window.location.href).href, u = c, l = c.split("/");
    if (l.length > 2 && (u = l[l.length - 1], this.path = l.slice(0, l.length - 1).join("/") + "/"), t == null || !(t instanceof Function)) {
      let h = 0, p = 0;
      t = function(_) {
        if (_.lengthComputable && (p = _.loaded / _.total, p > h)) {
          h = p;
          let v = 'Download of "' + e + '": ' + (p * 100).toFixed(2) + "%";
          a.parser.callbacks.onProgress("progressLoad", v, p);
        }
      };
    }
    this.setCallbackOnMeshAlter(r);
    let f = function(h) {
      a.parser.callbacks.onLoad(a.parse(h), "OBJLoader2#load: Parsing completed");
    }, m = new js(this.manager);
    m.setPath(this.path || this.resourcePath), m.setResponseType("arraybuffer"), m.load(u, f, t, i);
  },
  /**
   * Parses OBJ data synchronously from arraybuffer or string and returns the {@link Object3D}.
   *
   * @param {arraybuffer|string} content OBJ data as Uint8Array or String
   * @return {Object3D}
   */
  parse: function(e) {
    if (e == null)
      throw "Provided content is not a valid ArrayBuffer or String. Unable to continue parsing";
    return this.parser.logging.enabled && console.time("OBJLoader parse: " + this.modelName), this.materialHandler.createDefaultMaterials(!1), this.parser.setMaterials(this.materialHandler.getMaterials()), e instanceof ArrayBuffer || e instanceof Uint8Array ? (this.parser.logging.enabled && console.info("Parsing arrayBuffer..."), this.parser.execute(e)) : typeof e == "string" || e instanceof String ? (this.parser.logging.enabled && console.info("Parsing text..."), this.parser.executeLegacy(e)) : this.parser.callbacks.onError("Provided content was neither of type String nor Uint8Array! Aborting..."), this.parser.logging.enabled && console.timeEnd("OBJLoader parse: " + this.modelName), this.baseObject3d;
  },
  _onAssetAvailable: function(e) {
    if (e.cmd === "assetAvailable")
      if (e.type === "mesh") {
        let n = this.meshReceiver.buildMeshes(e);
        for (let t of n)
          this.baseObject3d.add(t);
      } else
        e.type === "material" && this.materialHandler.addPayloadMaterials(e);
  }
});
const AP = function() {
  let e = {};
  const n = function(t) {
    delete e[t];
  };
  this.add = function(t) {
    const i = performance.now() + "";
    return e[i] = t, t.then(() => n(i)), t;
  }, this.done = function(t) {
    Promise.all(Object.values(e)).then(() => {
      t();
    });
  };
}, Ar = (e, n = {}, t = "") => {
  const i = document.createElement(e);
  for (let r in n)
    i.setAttribute(r, n[r]);
  return i.innerHTML = t, i;
}, CP = (e, n) => (document.getElementById(e) || document.getElementsByTagName("head")[0].prepend(Ar("STYLE", { type: "text/css" }, n)), !0), Ci = function(e) {
  let n = e, t = [];
  return function(r, a = {}) {
    return arguments.length > 0 ? typeof r == "function" ? (a.prepend ? t.unshift(r) : t.push(r), a.dontCallOnRegistration || r(n), () => {
      const c = t.indexOf(r);
      c !== -1 && t.splice(c, 1);
    }) : (n !== r && JSON.stringify(n) !== JSON.stringify(r) && (n = r, t.forEach((c) => c(n))), n) : n;
  };
}, IP = function(e, n = {}) {
  CP("geocam-viewer", `
    .geocam-viewer {
      position: relative;
      z-index: 1;
    }

    .geocam-viewer-hidden {
      display: none;
    }

    .geocam-viewer-control {
      pointer-events: auto;
    }

    .geocam-viewer-control-button {
      background-color: rgba(255,255,255,0.5);
      border-radius: 4px;
      border: 1px solid #666;
      color: rgba(0,0,0,0);
      width: 32px;
      height: 32px;
      display: block;
      background-size: cover;
      background-position: center;
      cursor: pointer;
    }

    .geocam-viewer-controls {
        position: absolute;
        pointer-events: none;
        display: flex;
        left: 16px;
        top: 16px;
        right: 16px;
        bottom: 16px;
        --gap: 16px;
    }

    .geocam-viewer-controls-left, .geocam-viewer-controls-right {
      display: flex;
      flex-justify: space-between;
      flex-direction: column;
    }

    .geocam-viewer-controls-left-top, .geocam-viewer-controls-right-top {
      display: flex;
        flex-direction: column;
        align-items: flex-start;
        gap: var(--gap);
        row-gap: 8px;
    }

    .geocam-viewer-controls-left-bottom,   .geocam-viewer-controls-right-bottom {
      display: flex;
        flex-direction: column;
        align-items: flex-end;
        gap: var(--gap);
        row-gap: 8px;
    }

    .geocam-viewer-controls-center {
      flex: 1;
      display: flex;
      flex-direction: column;
    }

    .geocam-viewer-controls-top,  .geocam-viewer-controls-bottom {
      display: flex;
      justify-content: center;
      gap: var(--gap);
    } 

    .geocam-viewer-controls-mid {
      flex: 1;
    }
  `);
  const i = 0.5, r = {
    aspect: 2,
    // standard defaults if not overridden by rigConfig
    near: 0.1,
    fov: 35,
    far: 100,
    scale: 1,
    xOffset: 0,
    yOffset: 0,
    rotationOffsets: [0, 0, 0],
    hemispheres: [
      () => K(0),
      () => K(1),
      () => K(2)
    ]
  }, a = n.plugins, c = new AP(), u = {
    shot: Ci(),
    capture: Ci(),
    fov: Ci(),
    yaw: Ci(0),
    rotation: Ci([]),
    brightness: Ci([]),
    facing: Ci(0),
    horizon: Ci(0),
    urls: Ci([]),
    visible: Ci(!1),
    hemispheres: Ci([])
  }, l = [Ci(1), Ci(1), Ci(1)], f = Ci(window.performance.now());
  let m = !1, h, p, _, v, S = 0, D = 0, w = 0, T = 0, F = [null, null, null], E = null, A = !1, L, I, R = [], N, q, ne, Q = JSON.stringify([]), W = JSON.stringify([]);
  const te = function(de) {
    return (270 - de) * (Math.PI / 180);
  }, K = function(de) {
    const qe = new Km(
      12,
      32,
      32,
      0,
      2 * Math.PI,
      Math.PI / 3 * de,
      Math.PI / 3
    ), tt = new Ms({}), He = new Ln(qe, tt);
    return He.material.side = hi, He;
  }, pe = function() {
    v.style.top = S + "px", v.style.left = D + "px", v.style.width = w + "px", v.style.height = T + "px";
  }, be = function(de, qe = !1) {
    const tt = de.domElement, He = v.parentNode.clientWidth, je = v.parentNode.clientHeight, lt = qe || Math.abs(tt.clientWidth - He) > 1 || Math.abs(tt.clientHeight - je) > 1;
    if (lt) {
      console.log("Resizing canvas:", { displayWidth: He, displayHeight: je }), v.style.width = He + "px", v.style.height = je + "px", de.setSize(He, je, !0);
      const Mt = de.domElement;
      p.aspect = Mt.clientWidth / Mt.clientHeight, A = !0, console.log("Canvas after resize:", {
        clientWidth: Mt.clientWidth,
        clientHeight: Mt.clientHeight,
        width: Mt.width,
        height: Mt.height
      });
    }
    return lt;
  }, Ee = (de) => {
    if (!Ye)
      return;
    be(H);
    const qe = u.horizon(), tt = u.facing();
    u.facing((360 + tt) % 360), u.horizon(Math.max(-85, Math.min(85, qe)));
    const He = (90 - qe) * (Math.PI / 180), je = tt * (Math.PI / 180), lt = 10;
    {
      const Mt = lt * Math.sin(He) * Math.sin(je), Rt = -lt * Math.cos(He), Kt = lt * Math.sin(He) * Math.cos(je);
      p.up.set(0, 0, 1), p.lookAt(Mt, Kt, Rt);
    }
    A && (p.updateProjectionMatrix(), A = !1), H.render(Y, p), L = requestAnimationFrame((Mt) => Ee());
  }, Ge = function(de) {
    return new Promise((qe, tt) => {
      typeof de == "function" ? qe(de()) : new lg().load(de, (je) => {
        je.traverse(function(lt) {
          lt instanceof Ln && (lt.material.side = 2, lt.material.flatShading = !0, lt.material.transparent = !0, lt.rotation.set(0, 0, 0), qe(lt));
        });
      });
    });
  }, _e = function(de) {
    return console.log("loadMeshes"), c.add(
      new Promise((qe, tt) => {
        let He = F.length;
        de.forEach((je, lt) => {
          Ge(je).then((Mt) => {
            F[lt] = Mt, He -= 1, He <= 0 && qe();
          });
        });
      })
    );
  }, De = function() {
    F.forEach((de, qe) => de ? E.remove(de) : null), Y.remove(E), H.renderLists.dispose(), F = [null, null, null], E = null;
  }, he = function() {
    N && (N(), N = null);
  }, Z = function() {
    ne && (ne(), ne = null);
  }, me = function(de, ...qe) {
    return Object.assign(de, ...qe);
  }, we = async function(de) {
    let qe;
    de && de.length > 0 && Q !== (qe = JSON.stringify(de)) && (Q = qe, he(), E && De(), await _e(de), E = new ao(), F.forEach((tt, He) => {
      E.add(tt), tt.name = `${He}`;
    }), Y.add(E), N = u.urls((tt) => {
      const He = JSON.stringify(tt);
      He !== W && tt.length > 0 && (W = He, U(tt, u.brightness()));
    }));
  }, xe = async function(de = {}) {
    Z(), De(), _ = me(r, de);
    const qe = u.fov() || _.fov;
    return u.fov(qe), p = new oi(
      qe,
      _.aspect,
      _.near,
      _.far
    ), ne = u.hemispheres(we), be(H, !0), this;
  }, et = function() {
    F.forEach((de, qe) => {
      de && de.material && (de.material.opacity = i);
    }), l.forEach((de) => de(0));
  }, Ve = function(de, qe, tt, He, je, lt) {
    de.material.opacity = i;
    const Mt = parseInt(de.name);
    l[Mt](0), new PP(I).load(
      qe,
      (Rt) => {
        window.tex = Rt, de.material.map = Rt, window.mat = de.material, de.material.opacity = 1, Rt.repeat.set(_.scale, _.scale), Rt.offset.set(_.yOffset, _.xOffset), Rt.rotation = _.rotationOffsets[Mt], de.material.needsUpdate = !0, l[Mt](1), tt && tt(de, qe);
      },
      (Rt) => {
        const Kt = Rt.loaded / Rt.total;
        He && He(de, qe, Kt);
      },
      (Rt) => {
        je ? je(de, qe, Rt) : console.error("error loading image", Rt, Mt, qe);
      },
      lt
    );
  }, nt = function(de, qe, tt, He, je) {
    const lt = function(Rt, Kt, vn, wn) {
      const ln = parseInt(Rt.name);
      let Gn = Kt.length - vn;
      const li = Kt[vn];
      Ve(
        Rt,
        li,
        () => {
          l[ln]((vn + 1) / Kt.length), He && Gn == Kt.length && He(Rt, li), tt && Gn <= 1 && tt(Rt, li), vn += 1, vn < Kt.length && lt(Rt, Kt, vn);
        },
        ($i, An, bn) => {
          l[ln]((vn + bn) / Kt.length);
        },
        null,
        1
      );
    }, Mt = parseInt(de.name);
    if (Array.isArray(qe))
      lt(de, qe, 0);
    else {
      const Rt = qe;
      Ve(
        de,
        Rt,
        () => {
          l[Mt](1), He && He(de, Rt), tt && tt(de, qe);
        },
        (Kt, vn, wn) => {
          l[Mt](wn);
        },
        null,
        // nothing to do on error
        je
        // assume a single brightness value too.
      );
    }
  }, Be = function(de) {
    a.push(de), m && de.init.apply(de, [this]);
  }, ae = function() {
    const de = u.rotation();
    var qe = new dn();
    de.length == 9 ? qe.set(
      de[0],
      de[1],
      de[2],
      0,
      de[3],
      de[4],
      de[5],
      0,
      de[6],
      de[7],
      de[8],
      0,
      0,
      0,
      0,
      1
    ) : qe.makeRotationY(te(u.yaw() - 90));
    {
      var tt = new dn();
      tt.makeRotationX(Math.PI / 2), qe.premultiply(tt);
    }
    E.setRotationFromMatrix(qe);
  }, U = async function(de, qe = [1, 1, 1]) {
    I && I.abort(), I = new AbortController();
    let tt = F.length;
    F.length, ae(), F.forEach((He, je) => {
      const lt = de[je];
      nt(
        He,
        lt,
        (Mt, Rt) => {
          if (tt -= 1, tt <= 0)
            return !0;
        },
        (Mt, Rt) => {
        },
        qe[je]
      );
    }), Ee();
  }, Se = function(de, qe, tt, He, je) {
    const lt = je ? JSON.parse(je) : [1, 1, 1];
    tt && tt.length > 0 && u.hemispheres(tt);
    const Mt = typeof He == "string" ? JSON.parse(He) : He;
    u.rotation(Mt || []), u.brightness(lt), u.yaw(parseFloat(qe || 0)), u.urls(de), u.visible(!0), be(H, !0);
  }, ze = function(de) {
    const qe = u.urls();
    qe && qe.length >= F.length && (de && u.brightness(JSON.parse(de)), U(qe, u.brightness())), be(H, !0);
  }, Oe = function() {
    u.visible(!1), u.shot(null);
  };
  let Ye = !1, H = new fg({ preserveDrawingBuffer: !0 });
  H.setPixelRatio(Math.min(window.devicePixelRatio || 1, 2));
  let Y = new Cm(), $e = new Sy(16777215, 1);
  Y.add($e);
  const Ie = e.getBoundingClientRect();
  v = Ar("DIV", { class: "geocam-viewer" }), h = Ar("DIV", { class: "geocam-viewer-controls" }), h.append(
    Ar(
      "DIV",
      { class: "geocam-viewer-controls-left" },
      '<div class="geocam-viewer-controls-left-top"></div><div class="geocam-viewer-controls-left-bottom"></div>'
    )
  );
  const fe = Ar(
    "DIV",
    { class: "geocam-viewer-controls-center" },
    '<div class="geocam-viewer-controls-top"></div><div class="geocam-viewer-controls-mid"></div><div class="geocam-viewer-controls-bottom"></div>'
  );
  fe.append(Ar("DIV")), fe.append(Ar("DIV")), fe.append(Ar("DIV")), h.append(fe), h.append(
    Ar(
      "DIV",
      { class: "geocam-viewer-controls-right" },
      '<div class="geocam-viewer-controls-right-top"></div><div class="geocam-viewer-controls-right-bottom"></div>'
    )
  ), v.appendChild(h), w = Ie.width, T = Ie.height, pe(), v.appendChild(H.domElement), q = u.visible((de) => {
    de ? v.classList.remove("geocam-viewer-hidden") : v.classList.add("geocam-viewer-hidden"), Ye = de;
  }), e.appendChild(v), R.push(
    u.fov((de) => {
      p && de !== null && (p.fov = de, A = !0);
    })
  );
  const Qe = function() {
    if (L && (cancelAnimationFrame(L), L = null), Ye = !1, I && (I.abort(), I = null), R.forEach((de) => de()), R = [], q && (q(), q = null), he(), Z(), a.forEach((de) => {
      "destroy" in de && de.destroy.apply(de);
    }), F && (F.forEach((de) => {
      de && (de.geometry && de.geometry.dispose(), de.material && (de.material.map && de.material.map.dispose(), de.material.dispose()), E && E.remove(de));
    }), F = [null, null, null]), E && (Y.remove(E), E = null), $e && (Y.remove($e), $e = null), Y) {
      for (Y.traverse((de) => {
        de.geometry && de.geometry.dispose(), de.material && (Array.isArray(de.material) ? de.material.forEach((qe) => {
          qe.map && qe.map.dispose(), qe.dispose();
        }) : (de.material.map && de.material.map.dispose(), de.material.dispose()));
      }); Y.children.length > 0; )
        Y.remove(Y.children[0]);
      Y = null;
    }
    if (H) {
      H.renderLists.dispose(), H.dispose();
      const de = H.getContext();
      if (de && de.getExtension) {
        const qe = de.getExtension("WEBGL_lose_context");
        qe && qe.loseContext();
      }
      H.domElement && v && v.removeChild(H.domElement), H = null;
    }
    ur.clear(), v && e && (e.removeChild(v), v = null), p = null, h = null, _ = null, Object.keys(u).forEach((de) => {
      if (u[de] && typeof u[de] == "function")
        try {
          u[de](null);
        } catch {
        }
    });
  }, Ne = function(de, qe = null) {
    return u[de] || this[de] ? (console.info(
      "geocam viewer attempt to add store that already exists",
      de
    ), u[de]() === null && qe !== null && u[de](qe)) : (u[de] = Ci(qe), this[de] = u[de], f(window.performance.now())), u[de];
  }, ut = function(de, qe, tt = {}) {
    const He = document.getElementsByClassName(
      `geocam-viewer-controls-${qe}`
    )[0];
    He ? (de.classList.add("geocam-viewer-control"), tt.after ? tt.after.parentNode.insertBefore(de, tt.after.nextSibling) : tt.prepend ? He.prepend(de) : He.appendChild(de)) : console.error(
      "geocam viewer unable to add control no matching location",
      de,
      qe
    );
  };
  this.setup = xe, this.show = Se, this.reload = ze, this.hide = Oe, this.resetProgress = et, this.plugin = Be, this.destroy = Qe, Object.defineProperty(this, "camera", {
    get: function() {
      return p;
    },
    enumerable: !0,
    configurable: !0
  }), Object.defineProperty(this, "meshGroup", {
    get: function() {
      return E;
    },
    enumerable: !0,
    configurable: !0
  }), this.renderer = H, this.element = e, this.wrapper = v, this.done = c.done, this.progress = l, this.newstoreadded = f, this.stores = u;
  for (let de in u)
    this[de] = u[de];
  this.store = Ne, this.addControl = ut, a.forEach((de) => {
    "init" in de && de.init.apply(de, [this]);
  }), xe(n.config), Ee(), m = !0;
}, H_ = /* @__PURE__ */ new Map(), fa = [], LP = (e, n, t) => {
  if (n && typeof n.init == "function" && typeof n.createInferenceSessionHandler == "function") {
    const i = H_.get(e);
    if (i === void 0)
      H_.set(e, { backend: n, priority: t });
    else {
      if (i.priority > t)
        return;
      if (i.priority === t && i.backend !== n)
        throw new Error(`cannot register backend "${e}" using priority ${t}`);
    }
    if (t >= 0) {
      const r = fa.indexOf(e);
      r !== -1 && fa.splice(r, 1);
      for (let a = 0; a < fa.length; a++)
        if (H_.get(fa[a]).priority <= t) {
          fa.splice(a, 0, e);
          return;
        }
      fa.push(e);
    }
    return;
  }
  throw new TypeError("not a valid backend");
}, DP = async (e) => {
  const n = H_.get(e);
  if (!n)
    return "backend not found.";
  if (n.initialized)
    return n.backend;
  if (n.aborted)
    return n.error;
  {
    const t = !!n.initPromise;
    try {
      return t || (n.initPromise = n.backend.init(e)), await n.initPromise, n.initialized = !0, n.backend;
    } catch (i) {
      return t || (n.error = `${i}`, n.aborted = !0), n.error;
    } finally {
      delete n.initPromise;
    }
  }
}, kP = async (e) => {
  const n = e.executionProviders || [], t = n.map((l) => typeof l == "string" ? l : l.name), i = t.length === 0 ? fa : t;
  let r;
  const a = [], c = /* @__PURE__ */ new Set();
  for (const l of i) {
    const f = await DP(l);
    typeof f == "string" ? a.push({ name: l, err: f }) : (r || (r = f), r === f && c.add(l));
  }
  if (!r)
    throw new Error(`no available backend found. ERR: ${a.map((l) => `[${l.name}] ${l.err}`).join(", ")}`);
  for (const { name: l, err: f } of a)
    t.includes(l) && console.warn(`removing requested execution provider "${l}" from session options because it is not available: ${f}`);
  const u = n.filter((l) => c.has(typeof l == "string" ? l : l.name));
  return [
    r,
    new Proxy(e, {
      get: (l, f) => f === "executionProviders" ? u : Reflect.get(l, f)
    })
  ];
}, OP = "1.21.0";
let Ax = "warning";
const Gs = {
  wasm: {},
  webgl: {},
  webgpu: {},
  versions: { common: OP },
  set logLevel(e) {
    if (e !== void 0) {
      if (typeof e != "string" || ["verbose", "info", "warning", "error", "fatal"].indexOf(e) === -1)
        throw new Error(`Unsupported logging level: ${e}`);
      Ax = e;
    }
  },
  get logLevel() {
    return Ax;
  }
};
Object.defineProperty(Gs, "logLevel", { enumerable: !0 });
const FP = Gs, RP = (e, n) => {
  const t = typeof document < "u" ? document.createElement("canvas") : new OffscreenCanvas(1, 1);
  t.width = e.dims[3], t.height = e.dims[2];
  const i = t.getContext("2d");
  if (i != null) {
    let r, a;
    (n == null ? void 0 : n.tensorLayout) !== void 0 && n.tensorLayout === "NHWC" ? (r = e.dims[2], a = e.dims[3]) : (r = e.dims[3], a = e.dims[2]);
    const c = (n == null ? void 0 : n.format) !== void 0 ? n.format : "RGB", u = n == null ? void 0 : n.norm;
    let l, f;
    u === void 0 || u.mean === void 0 ? l = [255, 255, 255, 255] : typeof u.mean == "number" ? l = [u.mean, u.mean, u.mean, u.mean] : (l = [u.mean[0], u.mean[1], u.mean[2], 0], u.mean[3] !== void 0 && (l[3] = u.mean[3])), u === void 0 || u.bias === void 0 ? f = [0, 0, 0, 0] : typeof u.bias == "number" ? f = [u.bias, u.bias, u.bias, u.bias] : (f = [u.bias[0], u.bias[1], u.bias[2], 0], u.bias[3] !== void 0 && (f[3] = u.bias[3]));
    const m = a * r;
    let h = 0, p = m, _ = m * 2, v = -1;
    c === "RGBA" ? (h = 0, p = m, _ = m * 2, v = m * 3) : c === "RGB" ? (h = 0, p = m, _ = m * 2) : c === "RBG" && (h = 0, _ = m, p = m * 2);
    for (let S = 0; S < a; S++)
      for (let D = 0; D < r; D++) {
        const w = (e.data[h++] - f[0]) * l[0], T = (e.data[p++] - f[1]) * l[1], F = (e.data[_++] - f[2]) * l[2], E = v === -1 ? 255 : (e.data[v++] - f[3]) * l[3];
        i.fillStyle = "rgba(" + w + "," + T + "," + F + "," + E + ")", i.fillRect(D, S, 1, 1);
      }
    if ("toDataURL" in t)
      return t.toDataURL();
    throw new Error("toDataURL is not supported");
  } else
    throw new Error("Can not access image data");
}, BP = (e, n) => {
  const t = typeof document < "u" ? document.createElement("canvas").getContext("2d") : new OffscreenCanvas(1, 1).getContext("2d");
  let i;
  if (t != null) {
    let r, a, c;
    (n == null ? void 0 : n.tensorLayout) !== void 0 && n.tensorLayout === "NHWC" ? (r = e.dims[2], a = e.dims[1], c = e.dims[3]) : (r = e.dims[3], a = e.dims[2], c = e.dims[1]);
    const u = n !== void 0 && n.format !== void 0 ? n.format : "RGB", l = n == null ? void 0 : n.norm;
    let f, m;
    l === void 0 || l.mean === void 0 ? f = [255, 255, 255, 255] : typeof l.mean == "number" ? f = [l.mean, l.mean, l.mean, l.mean] : (f = [l.mean[0], l.mean[1], l.mean[2], 255], l.mean[3] !== void 0 && (f[3] = l.mean[3])), l === void 0 || l.bias === void 0 ? m = [0, 0, 0, 0] : typeof l.bias == "number" ? m = [l.bias, l.bias, l.bias, l.bias] : (m = [l.bias[0], l.bias[1], l.bias[2], 0], l.bias[3] !== void 0 && (m[3] = l.bias[3]));
    const h = a * r;
    if (n !== void 0 && (n.format !== void 0 && c === 4 && n.format !== "RGBA" || c === 3 && n.format !== "RGB" && n.format !== "BGR"))
      throw new Error("Tensor format doesn't match input tensor dims");
    const p = 4;
    let _ = 0, v = 1, S = 2, D = 3, w = 0, T = h, F = h * 2, E = -1;
    u === "RGBA" ? (w = 0, T = h, F = h * 2, E = h * 3) : u === "RGB" ? (w = 0, T = h, F = h * 2) : u === "RBG" && (w = 0, F = h, T = h * 2), i = t.createImageData(r, a);
    for (let A = 0; A < a * r; _ += p, v += p, S += p, D += p, A++)
      i.data[_] = (e.data[w++] - m[0]) * f[0], i.data[v] = (e.data[T++] - m[1]) * f[1], i.data[S] = (e.data[F++] - m[2]) * f[2], i.data[D] = E === -1 ? 255 : (e.data[E++] - m[3]) * f[3];
  } else
    throw new Error("Can not access image data");
  return i;
}, Dv = (e, n) => {
  if (e === void 0)
    throw new Error("Image buffer must be defined");
  if (n.height === void 0 || n.width === void 0)
    throw new Error("Image height and width must be defined");
  if (n.tensorLayout === "NHWC")
    throw new Error("NHWC Tensor layout is not supported yet");
  const { height: t, width: i } = n, r = n.norm ?? { mean: 255, bias: 0 };
  let a, c;
  typeof r.mean == "number" ? a = [r.mean, r.mean, r.mean, r.mean] : a = [r.mean[0], r.mean[1], r.mean[2], r.mean[3] ?? 255], typeof r.bias == "number" ? c = [r.bias, r.bias, r.bias, r.bias] : c = [r.bias[0], r.bias[1], r.bias[2], r.bias[3] ?? 0];
  const u = n.format !== void 0 ? n.format : "RGBA", l = n.tensorFormat !== void 0 && n.tensorFormat !== void 0 ? n.tensorFormat : "RGB", f = t * i, m = l === "RGBA" ? new Float32Array(f * 4) : new Float32Array(f * 3);
  let h = 4, p = 0, _ = 1, v = 2, S = 3, D = 0, w = f, T = f * 2, F = -1;
  u === "RGB" && (h = 3, p = 0, _ = 1, v = 2, S = -1), l === "RGBA" ? F = f * 3 : l === "RBG" ? (D = 0, T = f, w = f * 2) : l === "BGR" && (T = 0, w = f, D = f * 2);
  for (let A = 0; A < f; A++, p += h, v += h, _ += h, S += h)
    m[D++] = (e[p] + c[0]) / a[0], m[w++] = (e[_] + c[1]) / a[1], m[T++] = (e[v] + c[2]) / a[2], F !== -1 && S !== -1 && (m[F++] = (e[S] + c[3]) / a[3]);
  return l === "RGBA" ? new ys("float32", m, [1, 4, t, i]) : new ys("float32", m, [1, 3, t, i]);
}, zP = async (e, n) => {
  const t = typeof HTMLImageElement < "u" && e instanceof HTMLImageElement, i = typeof ImageData < "u" && e instanceof ImageData, r = typeof ImageBitmap < "u" && e instanceof ImageBitmap, a = typeof e == "string";
  let c, u = n ?? {};
  const l = () => {
    if (typeof document < "u")
      return document.createElement("canvas");
    if (typeof OffscreenCanvas < "u")
      return new OffscreenCanvas(1, 1);
    throw new Error("Canvas is not supported");
  }, f = (m) => typeof HTMLCanvasElement < "u" && m instanceof HTMLCanvasElement || m instanceof OffscreenCanvas ? m.getContext("2d") : null;
  if (t) {
    const m = l();
    m.width = e.width, m.height = e.height;
    const h = f(m);
    if (h != null) {
      let p = e.height, _ = e.width;
      if (n !== void 0 && n.resizedHeight !== void 0 && n.resizedWidth !== void 0 && (p = n.resizedHeight, _ = n.resizedWidth), n !== void 0) {
        if (u = n, n.tensorFormat !== void 0)
          throw new Error("Image input config format must be RGBA for HTMLImageElement");
        u.tensorFormat = "RGBA", u.height = p, u.width = _;
      } else
        u.tensorFormat = "RGBA", u.height = p, u.width = _;
      h.drawImage(e, 0, 0), c = h.getImageData(0, 0, _, p).data;
    } else
      throw new Error("Can not access image data");
  } else if (i) {
    let m, h;
    if (n !== void 0 && n.resizedWidth !== void 0 && n.resizedHeight !== void 0 ? (m = n.resizedHeight, h = n.resizedWidth) : (m = e.height, h = e.width), n !== void 0 && (u = n), u.format = "RGBA", u.height = m, u.width = h, n !== void 0) {
      const p = l();
      p.width = h, p.height = m;
      const _ = f(p);
      if (_ != null)
        _.putImageData(e, 0, 0), c = _.getImageData(0, 0, h, m).data;
      else
        throw new Error("Can not access image data");
    } else
      c = e.data;
  } else if (r) {
    if (n === void 0)
      throw new Error("Please provide image config with format for Imagebitmap");
    const m = l();
    m.width = e.width, m.height = e.height;
    const h = f(m);
    if (h != null) {
      const p = e.height, _ = e.width;
      return h.drawImage(e, 0, 0, _, p), c = h.getImageData(0, 0, _, p).data, u.height = p, u.width = _, Dv(c, u);
    } else
      throw new Error("Can not access image data");
  } else {
    if (a)
      return new Promise((m, h) => {
        const p = l(), _ = f(p);
        if (!e || !_)
          return h();
        const v = new Image();
        v.crossOrigin = "Anonymous", v.src = e, v.onload = () => {
          p.width = v.width, p.height = v.height, _.drawImage(v, 0, 0, p.width, p.height);
          const S = _.getImageData(0, 0, p.width, p.height);
          u.height = p.height, u.width = p.width, m(Dv(S.data, u));
        };
      });
    throw new Error("Input data provided is not supported - aborted tensor creation");
  }
  if (c !== void 0)
    return Dv(c, u);
  throw new Error("Input data provided is not supported - aborted tensor creation");
}, $P = (e, n) => {
  const { width: t, height: i, download: r, dispose: a } = n, c = [1, i, t, 4];
  return new ys({ location: "texture", type: "float32", texture: e, dims: c, download: r, dispose: a });
}, NP = (e, n) => {
  const { dataType: t, dims: i, download: r, dispose: a } = n;
  return new ys({ location: "gpu-buffer", type: t ?? "float32", gpuBuffer: e, dims: i, download: r, dispose: a });
}, UP = (e, n) => {
  const { dataType: t, dims: i, download: r, dispose: a } = n;
  return new ys({ location: "ml-tensor", type: t ?? "float32", mlTensor: e, dims: i, download: r, dispose: a });
}, GP = (e, n, t) => new ys({ location: "cpu-pinned", type: e, data: n, dims: t ?? [n.length] }), iu = /* @__PURE__ */ new Map([
  ["float32", Float32Array],
  ["uint8", Uint8Array],
  ["int8", Int8Array],
  ["uint16", Uint16Array],
  ["int16", Int16Array],
  ["int32", Int32Array],
  ["bool", Uint8Array],
  ["float64", Float64Array],
  ["uint32", Uint32Array],
  ["int4", Uint8Array],
  ["uint4", Uint8Array]
]), q_ = /* @__PURE__ */ new Map([
  [Float32Array, "float32"],
  [Uint8Array, "uint8"],
  [Int8Array, "int8"],
  [Uint16Array, "uint16"],
  [Int16Array, "int16"],
  [Int32Array, "int32"],
  [Float64Array, "float64"],
  [Uint32Array, "uint32"]
]);
let Cx = !1;
const VP = () => {
  if (!Cx) {
    Cx = !0;
    const e = typeof BigInt64Array < "u" && BigInt64Array.from, n = typeof BigUint64Array < "u" && BigUint64Array.from, t = globalThis.Float16Array, i = typeof t < "u" && t.from;
    e && (iu.set("int64", BigInt64Array), q_.set(BigInt64Array, "int64")), n && (iu.set("uint64", BigUint64Array), q_.set(BigUint64Array, "uint64")), i ? (iu.set("float16", t), q_.set(t, "float16")) : iu.set("float16", Uint16Array);
  }
}, jP = (e) => {
  let n = 1;
  for (let t = 0; t < e.length; t++) {
    const i = e[t];
    if (typeof i != "number" || !Number.isSafeInteger(i))
      throw new TypeError(`dims[${t}] must be an integer, got: ${i}`);
    if (i < 0)
      throw new RangeError(`dims[${t}] must be a non-negative integer, got: ${i}`);
    n *= i;
  }
  return n;
}, WP = (e, n) => {
  switch (e.location) {
    case "cpu":
      return new ys(e.type, e.data, n);
    case "cpu-pinned":
      return new ys({
        location: "cpu-pinned",
        data: e.data,
        type: e.type,
        dims: n
      });
    case "texture":
      return new ys({
        location: "texture",
        texture: e.texture,
        type: e.type,
        dims: n
      });
    case "gpu-buffer":
      return new ys({
        location: "gpu-buffer",
        gpuBuffer: e.gpuBuffer,
        type: e.type,
        dims: n
      });
    case "ml-tensor":
      return new ys({
        location: "ml-tensor",
        mlTensor: e.mlTensor,
        type: e.type,
        dims: n
      });
    default:
      throw new Error(`tensorReshape: tensor location ${e.location} is not supported`);
  }
};
let ys = class {
  /**
   * implementation.
   */
  constructor(n, t, i) {
    VP();
    let r, a;
    if (typeof n == "object" && "location" in n)
      switch (this.dataLocation = n.location, r = n.type, a = n.dims, n.location) {
        case "cpu-pinned": {
          const u = iu.get(r);
          if (!u)
            throw new TypeError(`unsupported type "${r}" to create tensor from pinned buffer`);
          if (!(n.data instanceof u))
            throw new TypeError(`buffer should be of type ${u.name}`);
          this.cpuData = n.data;
          break;
        }
        case "texture": {
          if (r !== "float32")
            throw new TypeError(`unsupported type "${r}" to create tensor from texture`);
          this.gpuTextureData = n.texture, this.downloader = n.download, this.disposer = n.dispose;
          break;
        }
        case "gpu-buffer": {
          if (r !== "float32" && r !== "float16" && r !== "int32" && r !== "int64" && r !== "uint32" && r !== "uint8" && r !== "bool" && r !== "uint4" && r !== "int4")
            throw new TypeError(`unsupported type "${r}" to create tensor from gpu buffer`);
          this.gpuBufferData = n.gpuBuffer, this.downloader = n.download, this.disposer = n.dispose;
          break;
        }
        case "ml-tensor": {
          if (r !== "float32" && r !== "float16" && r !== "int32" && r !== "int64" && r !== "uint32" && r !== "uint64" && r !== "int8" && r !== "uint8" && r !== "bool" && r !== "uint4" && r !== "int4")
            throw new TypeError(`unsupported type "${r}" to create tensor from MLTensor`);
          this.mlTensorData = n.mlTensor, this.downloader = n.download, this.disposer = n.dispose;
          break;
        }
        default:
          throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);
      }
    else {
      let u, l;
      if (typeof n == "string")
        if (r = n, l = i, n === "string") {
          if (!Array.isArray(t))
            throw new TypeError("A string tensor's data must be a string array.");
          u = t;
        } else {
          const f = iu.get(n);
          if (f === void 0)
            throw new TypeError(`Unsupported tensor type: ${n}.`);
          if (Array.isArray(t)) {
            if (n === "float16" && f === Uint16Array || n === "uint4" || n === "int4")
              throw new TypeError(`Creating a ${n} tensor from number array is not supported. Please use ${f.name} as data.`);
            n === "uint64" || n === "int64" ? u = f.from(t, BigInt) : u = f.from(t);
          } else if (t instanceof f)
            u = t;
          else if (t instanceof Uint8ClampedArray)
            if (n === "uint8")
              u = Uint8Array.from(t);
            else
              throw new TypeError("A Uint8ClampedArray tensor's data must be type of uint8");
          else if (n === "float16" && t instanceof Uint16Array && f !== Uint16Array)
            u = new globalThis.Float16Array(t.buffer, t.byteOffset, t.length);
          else
            throw new TypeError(`A ${r} tensor's data must be type of ${f}`);
        }
      else if (l = t, Array.isArray(n)) {
        if (n.length === 0)
          throw new TypeError("Tensor type cannot be inferred from an empty array.");
        const f = typeof n[0];
        if (f === "string")
          r = "string", u = n;
        else if (f === "boolean")
          r = "bool", u = Uint8Array.from(n);
        else
          throw new TypeError(`Invalid element type of data array: ${f}.`);
      } else if (n instanceof Uint8ClampedArray)
        r = "uint8", u = Uint8Array.from(n);
      else {
        const f = q_.get(n.constructor);
        if (f === void 0)
          throw new TypeError(`Unsupported type for tensor data: ${n.constructor}.`);
        r = f, u = n;
      }
      if (l === void 0)
        l = [u.length];
      else if (!Array.isArray(l))
        throw new TypeError("A tensor's dims must be a number array");
      a = l, this.cpuData = u, this.dataLocation = "cpu";
    }
    const c = jP(a);
    if (this.cpuData && c !== this.cpuData.length && !((r === "uint4" || r === "int4") && Math.ceil(c / 2) === this.cpuData.length))
      throw new Error(`Tensor's size(${c}) does not match data length(${this.cpuData.length}).`);
    this.type = r, this.dims = a, this.size = c;
  }
  // #endregion
  // #region factory
  static async fromImage(n, t) {
    return zP(n, t);
  }
  static fromTexture(n, t) {
    return $P(n, t);
  }
  static fromGpuBuffer(n, t) {
    return NP(n, t);
  }
  static fromMLTensor(n, t) {
    return UP(n, t);
  }
  static fromPinnedBuffer(n, t, i) {
    return GP(n, t, i);
  }
  // #endregion
  // #region conversions
  toDataURL(n) {
    return RP(this, n);
  }
  toImageData(n) {
    return BP(this, n);
  }
  // #endregion
  // #region properties
  get data() {
    if (this.ensureValid(), !this.cpuData)
      throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");
    return this.cpuData;
  }
  get location() {
    return this.dataLocation;
  }
  get texture() {
    if (this.ensureValid(), !this.gpuTextureData)
      throw new Error("The data is not stored as a WebGL texture.");
    return this.gpuTextureData;
  }
  get gpuBuffer() {
    if (this.ensureValid(), !this.gpuBufferData)
      throw new Error("The data is not stored as a WebGPU buffer.");
    return this.gpuBufferData;
  }
  get mlTensor() {
    if (this.ensureValid(), !this.mlTensorData)
      throw new Error("The data is not stored as a WebNN MLTensor.");
    return this.mlTensorData;
  }
  // #endregion
  // #region methods
  async getData(n) {
    switch (this.ensureValid(), this.dataLocation) {
      case "cpu":
      case "cpu-pinned":
        return this.data;
      case "texture":
      case "gpu-buffer":
      case "ml-tensor": {
        if (!this.downloader)
          throw new Error("The current tensor is not created with a specified data downloader.");
        if (this.isDownloading)
          throw new Error("The current tensor is being downloaded.");
        try {
          this.isDownloading = !0;
          const t = await this.downloader();
          return this.downloader = void 0, this.dataLocation = "cpu", this.cpuData = t, n && this.disposer && (this.disposer(), this.disposer = void 0), t;
        } finally {
          this.isDownloading = !1;
        }
      }
      default:
        throw new Error(`cannot get data from location: ${this.dataLocation}`);
    }
  }
  dispose() {
    if (this.isDownloading)
      throw new Error("The current tensor is being downloaded.");
    this.disposer && (this.disposer(), this.disposer = void 0), this.cpuData = void 0, this.gpuTextureData = void 0, this.gpuBufferData = void 0, this.mlTensorData = void 0, this.downloader = void 0, this.isDownloading = void 0, this.dataLocation = "none";
  }
  // #endregion
  // #region tensor utilities
  ensureValid() {
    if (this.dataLocation === "none")
      throw new Error("The tensor is disposed.");
  }
  reshape(n) {
    if (this.ensureValid(), this.downloader || this.disposer)
      throw new Error("Cannot reshape a tensor that owns GPU resource.");
    return WP(this, n);
  }
};
const Jc = ys, Mb = (e, n) => {
  (typeof Gs.trace > "u" ? !Gs.wasm.trace : !Gs.trace) || console.timeStamp(`${e}::ORT::${n}`);
}, Tb = (e, n) => {
  var r;
  const t = ((r = new Error().stack) == null ? void 0 : r.split(/\r\n|\r|\n/g)) || [];
  let i = !1;
  for (let a = 0; a < t.length; a++) {
    if (i && !t[a].includes("TRACE_FUNC")) {
      let c = `FUNC_${e}::${t[a].trim().split(" ")[1]}`;
      n && (c += `::${n}`), Mb("CPU", c);
      return;
    }
    t[a].includes("TRACE_FUNC") && (i = !0);
  }
}, A0 = (e) => {
  (typeof Gs.trace > "u" ? !Gs.wasm.trace : !Gs.trace) || Tb("BEGIN", e);
}, C0 = (e) => {
  (typeof Gs.trace > "u" ? !Gs.wasm.trace : !Gs.trace) || Tb("END", e);
};
let HP = class Eb {
  constructor(n) {
    this.handler = n;
  }
  async run(n, t, i) {
    A0();
    const r = {};
    let a = {};
    if (typeof n != "object" || n === null || n instanceof Jc || Array.isArray(n))
      throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");
    let c = !0;
    if (typeof t == "object") {
      if (t === null)
        throw new TypeError("Unexpected argument[1]: cannot be null.");
      if (t instanceof Jc)
        throw new TypeError("'fetches' cannot be a Tensor");
      if (Array.isArray(t)) {
        if (t.length === 0)
          throw new TypeError("'fetches' cannot be an empty array.");
        c = !1;
        for (const f of t) {
          if (typeof f != "string")
            throw new TypeError("'fetches' must be a string array or an object.");
          if (this.outputNames.indexOf(f) === -1)
            throw new RangeError(`'fetches' contains invalid output name: ${f}.`);
          r[f] = null;
        }
        if (typeof i == "object" && i !== null)
          a = i;
        else if (typeof i < "u")
          throw new TypeError("'options' must be an object.");
      } else {
        let f = !1;
        const m = Object.getOwnPropertyNames(t);
        for (const h of this.outputNames)
          if (m.indexOf(h) !== -1) {
            const p = t[h];
            (p === null || p instanceof Jc) && (f = !0, c = !1, r[h] = p);
          }
        if (f) {
          if (typeof i == "object" && i !== null)
            a = i;
          else if (typeof i < "u")
            throw new TypeError("'options' must be an object.");
        } else
          a = t;
      }
    } else if (typeof t < "u")
      throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");
    for (const f of this.inputNames)
      if (typeof n[f] > "u")
        throw new Error(`input '${f}' is missing in 'feeds'.`);
    if (c)
      for (const f of this.outputNames)
        r[f] = null;
    const u = await this.handler.run(n, r, a), l = {};
    for (const f in u)
      if (Object.hasOwnProperty.call(u, f)) {
        const m = u[f];
        m instanceof Jc ? l[f] = m : l[f] = new Jc(m.type, m.data, m.dims);
      }
    return C0(), l;
  }
  async release() {
    return this.handler.dispose();
  }
  static async create(n, t, i, r) {
    A0();
    let a, c = {};
    if (typeof n == "string") {
      if (a = n, typeof t == "object" && t !== null)
        c = t;
      else if (typeof t < "u")
        throw new TypeError("'options' must be an object.");
    } else if (n instanceof Uint8Array) {
      if (a = n, typeof t == "object" && t !== null)
        c = t;
      else if (typeof t < "u")
        throw new TypeError("'options' must be an object.");
    } else if (n instanceof ArrayBuffer || typeof SharedArrayBuffer < "u" && n instanceof SharedArrayBuffer) {
      const m = n;
      let h = 0, p = n.byteLength;
      if (typeof t == "object" && t !== null)
        c = t;
      else if (typeof t == "number") {
        if (h = t, !Number.isSafeInteger(h))
          throw new RangeError("'byteOffset' must be an integer.");
        if (h < 0 || h >= m.byteLength)
          throw new RangeError(`'byteOffset' is out of range [0, ${m.byteLength}).`);
        if (p = n.byteLength - h, typeof i == "number") {
          if (p = i, !Number.isSafeInteger(p))
            throw new RangeError("'byteLength' must be an integer.");
          if (p <= 0 || h + p > m.byteLength)
            throw new RangeError(`'byteLength' is out of range (0, ${m.byteLength - h}].`);
          if (typeof r == "object" && r !== null)
            c = r;
          else if (typeof r < "u")
            throw new TypeError("'options' must be an object.");
        } else if (typeof i < "u")
          throw new TypeError("'byteLength' must be a number.");
      } else if (typeof t < "u")
        throw new TypeError("'options' must be an object.");
      a = new Uint8Array(m, h, p);
    } else
      throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");
    const [u, l] = await kP(c), f = await u.createInferenceSessionHandler(a, l);
    return C0(), new Eb(f);
  }
  startProfiling() {
    this.handler.startProfiling();
  }
  endProfiling() {
    this.handler.endProfiling();
  }
  get inputNames() {
    return this.handler.inputNames;
  }
  get outputNames() {
    return this.handler.outputNames;
  }
};
const qP = HP, KP = /* @__PURE__ */ Object.freeze(/* @__PURE__ */ Object.defineProperty({
  __proto__: null,
  InferenceSession: qP,
  TRACE: Mb,
  TRACE_FUNC_BEGIN: A0,
  TRACE_FUNC_END: C0,
  Tensor: Jc,
  env: FP,
  registerBackend: LP
}, Symbol.toStringTag, { value: "Module" }));
function XP(e) {
  return e && e.__esModule && Object.prototype.hasOwnProperty.call(e, "default") ? e.default : e;
}
function Kc(e) {
  throw new Error('Could not dynamically require "' + e + '". Please configure the dynamicRequireTargets or/and ignoreDynamicRequires option of @rollup/plugin-commonjs appropriately for this require call to work.');
}
var Sb = { exports: {} };
/*!
 * ONNX Runtime Web v1.22.0-dev.20250409-89f8206ba4
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License.
 */
(function(e, n) {
  var t = (() => {
    var i = Object.defineProperty, r = Object.getOwnPropertyDescriptor, a = Object.getOwnPropertyNames, c = Object.prototype.hasOwnProperty, u = ((s) => typeof Kc < "u" ? Kc : typeof Proxy < "u" ? new Proxy(s, { get: (o, d) => (typeof Kc < "u" ? Kc : o)[d] }) : s)(function(s) {
      if (typeof Kc < "u")
        return Kc.apply(this, arguments);
      throw Error('Dynamic require of "' + s + '" is not supported');
    }), l = (s, o) => () => (s && (o = s(s = 0)), o), f = (s, o) => {
      for (var d in o)
        i(s, d, { get: o[d], enumerable: !0 });
    }, m = (s, o, d, g) => {
      if (o && typeof o == "object" || typeof o == "function")
        for (let y of a(o))
          !c.call(s, y) && y !== d && i(s, y, { get: () => o[y], enumerable: !(g = r(o, y)) || g.enumerable });
      return s;
    }, h = (s) => m(i({}, "__esModule", { value: !0 }), s), p, _, v, S, D, w = l(() => {
      p = /* @__PURE__ */ new Map(), _ = [], v = (s, o, d) => {
        if (o && typeof o.init == "function" && typeof o.createInferenceSessionHandler == "function") {
          let g = p.get(s);
          if (g === void 0)
            p.set(s, { backend: o, priority: d });
          else {
            if (g.priority > d)
              return;
            if (g.priority === d && g.backend !== o)
              throw new Error(`cannot register backend "${s}" using priority ${d}`);
          }
          if (d >= 0) {
            let y = _.indexOf(s);
            y !== -1 && _.splice(y, 1);
            for (let x = 0; x < _.length; x++)
              if (p.get(_[x]).priority <= d) {
                _.splice(x, 0, s);
                return;
              }
            _.push(s);
          }
          return;
        }
        throw new TypeError("not a valid backend");
      }, S = async (s) => {
        let o = p.get(s);
        if (!o)
          return "backend not found.";
        if (o.initialized)
          return o.backend;
        if (o.aborted)
          return o.error;
        {
          let d = !!o.initPromise;
          try {
            return d || (o.initPromise = o.backend.init(s)), await o.initPromise, o.initialized = !0, o.backend;
          } catch (g) {
            return d || (o.error = `${g}`, o.aborted = !0), o.error;
          } finally {
            delete o.initPromise;
          }
        }
      }, D = async (s) => {
        let o = s.executionProviders || [], d = o.map((k) => typeof k == "string" ? k : k.name), g = d.length === 0 ? _ : d, y, x = [], b = /* @__PURE__ */ new Set();
        for (let k of g) {
          let O = await S(k);
          typeof O == "string" ? x.push({ name: k, err: O }) : (y || (y = O), y === O && b.add(k));
        }
        if (!y)
          throw new Error(`no available backend found. ERR: ${x.map((k) => `[${k.name}] ${k.err}`).join(", ")}`);
        for (let { name: k, err: O } of x)
          d.includes(k) && console.warn(`removing requested execution provider "${k}" from session options because it is not available: ${O}`);
        let P = o.filter((k) => b.has(typeof k == "string" ? k : k.name));
        return [y, new Proxy(s, { get: (k, O) => O === "executionProviders" ? P : Reflect.get(k, O) })];
      };
    }), T = l(() => {
      w();
    }), F, E = l(() => {
      F = "1.22.0-dev.20250409-89f8206ba4";
    }), A, L, I = l(() => {
      E(), A = "warning", L = { wasm: {}, webgl: {}, webgpu: {}, versions: { common: F }, set logLevel(s) {
        if (s !== void 0) {
          if (typeof s != "string" || ["verbose", "info", "warning", "error", "fatal"].indexOf(s) === -1)
            throw new Error(`Unsupported logging level: ${s}`);
          A = s;
        }
      }, get logLevel() {
        return A;
      } }, Object.defineProperty(L, "logLevel", { enumerable: !0 });
    }), R, N = l(() => {
      I(), R = L;
    }), q, ne, Q = l(() => {
      q = (s, o) => {
        let d = typeof document < "u" ? document.createElement("canvas") : new OffscreenCanvas(1, 1);
        d.width = s.dims[3], d.height = s.dims[2];
        let g = d.getContext("2d");
        if (g != null) {
          let y, x;
          (o == null ? void 0 : o.tensorLayout) !== void 0 && o.tensorLayout === "NHWC" ? (y = s.dims[2], x = s.dims[3]) : (y = s.dims[3], x = s.dims[2]);
          let b = (o == null ? void 0 : o.format) !== void 0 ? o.format : "RGB", P = o == null ? void 0 : o.norm, k, O;
          P === void 0 || P.mean === void 0 ? k = [255, 255, 255, 255] : typeof P.mean == "number" ? k = [P.mean, P.mean, P.mean, P.mean] : (k = [P.mean[0], P.mean[1], P.mean[2], 0], P.mean[3] !== void 0 && (k[3] = P.mean[3])), P === void 0 || P.bias === void 0 ? O = [0, 0, 0, 0] : typeof P.bias == "number" ? O = [P.bias, P.bias, P.bias, P.bias] : (O = [P.bias[0], P.bias[1], P.bias[2], 0], P.bias[3] !== void 0 && (O[3] = P.bias[3]));
          let $ = x * y, V = 0, G = $, ee = $ * 2, X = -1;
          b === "RGBA" ? (V = 0, G = $, ee = $ * 2, X = $ * 3) : b === "RGB" ? (V = 0, G = $, ee = $ * 2) : b === "RBG" && (V = 0, ee = $, G = $ * 2);
          for (let re = 0; re < x; re++)
            for (let Te = 0; Te < y; Te++) {
              let ue = (s.data[V++] - O[0]) * k[0], ce = (s.data[G++] - O[1]) * k[1], ke = (s.data[ee++] - O[2]) * k[2], Le = X === -1 ? 255 : (s.data[X++] - O[3]) * k[3];
              g.fillStyle = "rgba(" + ue + "," + ce + "," + ke + "," + Le + ")", g.fillRect(Te, re, 1, 1);
            }
          if ("toDataURL" in d)
            return d.toDataURL();
          throw new Error("toDataURL is not supported");
        } else
          throw new Error("Can not access image data");
      }, ne = (s, o) => {
        let d = typeof document < "u" ? document.createElement("canvas").getContext("2d") : new OffscreenCanvas(1, 1).getContext("2d"), g;
        if (d != null) {
          let y, x, b;
          (o == null ? void 0 : o.tensorLayout) !== void 0 && o.tensorLayout === "NHWC" ? (y = s.dims[2], x = s.dims[1], b = s.dims[3]) : (y = s.dims[3], x = s.dims[2], b = s.dims[1]);
          let P = o !== void 0 && o.format !== void 0 ? o.format : "RGB", k = o == null ? void 0 : o.norm, O, $;
          k === void 0 || k.mean === void 0 ? O = [255, 255, 255, 255] : typeof k.mean == "number" ? O = [k.mean, k.mean, k.mean, k.mean] : (O = [k.mean[0], k.mean[1], k.mean[2], 255], k.mean[3] !== void 0 && (O[3] = k.mean[3])), k === void 0 || k.bias === void 0 ? $ = [0, 0, 0, 0] : typeof k.bias == "number" ? $ = [k.bias, k.bias, k.bias, k.bias] : ($ = [k.bias[0], k.bias[1], k.bias[2], 0], k.bias[3] !== void 0 && ($[3] = k.bias[3]));
          let V = x * y;
          if (o !== void 0 && (o.format !== void 0 && b === 4 && o.format !== "RGBA" || b === 3 && o.format !== "RGB" && o.format !== "BGR"))
            throw new Error("Tensor format doesn't match input tensor dims");
          let G = 4, ee = 0, X = 1, re = 2, Te = 3, ue = 0, ce = V, ke = V * 2, Le = -1;
          P === "RGBA" ? (ue = 0, ce = V, ke = V * 2, Le = V * 3) : P === "RGB" ? (ue = 0, ce = V, ke = V * 2) : P === "RBG" && (ue = 0, ke = V, ce = V * 2), g = d.createImageData(y, x);
          for (let M = 0; M < x * y; ee += G, X += G, re += G, Te += G, M++)
            g.data[ee] = (s.data[ue++] - $[0]) * O[0], g.data[X] = (s.data[ce++] - $[1]) * O[1], g.data[re] = (s.data[ke++] - $[2]) * O[2], g.data[Te] = Le === -1 ? 255 : (s.data[Le++] - $[3]) * O[3];
        } else
          throw new Error("Can not access image data");
        return g;
      };
    }), W, te, K, pe, be, Ee, Ge = l(() => {
      nt(), W = (s, o) => {
        if (s === void 0)
          throw new Error("Image buffer must be defined");
        if (o.height === void 0 || o.width === void 0)
          throw new Error("Image height and width must be defined");
        if (o.tensorLayout === "NHWC")
          throw new Error("NHWC Tensor layout is not supported yet");
        let { height: d, width: g } = o, y = o.norm ?? { mean: 255, bias: 0 }, x, b;
        typeof y.mean == "number" ? x = [y.mean, y.mean, y.mean, y.mean] : x = [y.mean[0], y.mean[1], y.mean[2], y.mean[3] ?? 255], typeof y.bias == "number" ? b = [y.bias, y.bias, y.bias, y.bias] : b = [y.bias[0], y.bias[1], y.bias[2], y.bias[3] ?? 0];
        let P = o.format !== void 0 ? o.format : "RGBA", k = o.tensorFormat !== void 0 && o.tensorFormat !== void 0 ? o.tensorFormat : "RGB", O = d * g, $ = k === "RGBA" ? new Float32Array(O * 4) : new Float32Array(O * 3), V = 4, G = 0, ee = 1, X = 2, re = 3, Te = 0, ue = O, ce = O * 2, ke = -1;
        P === "RGB" && (V = 3, G = 0, ee = 1, X = 2, re = -1), k === "RGBA" ? ke = O * 3 : k === "RBG" ? (Te = 0, ce = O, ue = O * 2) : k === "BGR" && (ce = 0, ue = O, Te = O * 2);
        for (let Le = 0; Le < O; Le++, G += V, X += V, ee += V, re += V)
          $[Te++] = (s[G] + b[0]) / x[0], $[ue++] = (s[ee] + b[1]) / x[1], $[ce++] = (s[X] + b[2]) / x[2], ke !== -1 && re !== -1 && ($[ke++] = (s[re] + b[3]) / x[3]);
        return k === "RGBA" ? new Ve("float32", $, [1, 4, d, g]) : new Ve("float32", $, [1, 3, d, g]);
      }, te = async (s, o) => {
        let d = typeof HTMLImageElement < "u" && s instanceof HTMLImageElement, g = typeof ImageData < "u" && s instanceof ImageData, y = typeof ImageBitmap < "u" && s instanceof ImageBitmap, x = typeof s == "string", b, P = o ?? {}, k = () => {
          if (typeof document < "u")
            return document.createElement("canvas");
          if (typeof OffscreenCanvas < "u")
            return new OffscreenCanvas(1, 1);
          throw new Error("Canvas is not supported");
        }, O = ($) => typeof HTMLCanvasElement < "u" && $ instanceof HTMLCanvasElement || $ instanceof OffscreenCanvas ? $.getContext("2d") : null;
        if (d) {
          let $ = k();
          $.width = s.width, $.height = s.height;
          let V = O($);
          if (V != null) {
            let G = s.height, ee = s.width;
            if (o !== void 0 && o.resizedHeight !== void 0 && o.resizedWidth !== void 0 && (G = o.resizedHeight, ee = o.resizedWidth), o !== void 0) {
              if (P = o, o.tensorFormat !== void 0)
                throw new Error("Image input config format must be RGBA for HTMLImageElement");
              P.tensorFormat = "RGBA", P.height = G, P.width = ee;
            } else
              P.tensorFormat = "RGBA", P.height = G, P.width = ee;
            V.drawImage(s, 0, 0), b = V.getImageData(0, 0, ee, G).data;
          } else
            throw new Error("Can not access image data");
        } else if (g) {
          let $, V;
          if (o !== void 0 && o.resizedWidth !== void 0 && o.resizedHeight !== void 0 ? ($ = o.resizedHeight, V = o.resizedWidth) : ($ = s.height, V = s.width), o !== void 0 && (P = o), P.format = "RGBA", P.height = $, P.width = V, o !== void 0) {
            let G = k();
            G.width = V, G.height = $;
            let ee = O(G);
            if (ee != null)
              ee.putImageData(s, 0, 0), b = ee.getImageData(0, 0, V, $).data;
            else
              throw new Error("Can not access image data");
          } else
            b = s.data;
        } else if (y) {
          if (o === void 0)
            throw new Error("Please provide image config with format for Imagebitmap");
          let $ = k();
          $.width = s.width, $.height = s.height;
          let V = O($);
          if (V != null) {
            let G = s.height, ee = s.width;
            return V.drawImage(s, 0, 0, ee, G), b = V.getImageData(0, 0, ee, G).data, P.height = G, P.width = ee, W(b, P);
          } else
            throw new Error("Can not access image data");
        } else {
          if (x)
            return new Promise(($, V) => {
              let G = k(), ee = O(G);
              if (!s || !ee)
                return V();
              let X = new Image();
              X.crossOrigin = "Anonymous", X.src = s, X.onload = () => {
                G.width = X.width, G.height = X.height, ee.drawImage(X, 0, 0, G.width, G.height);
                let re = ee.getImageData(0, 0, G.width, G.height);
                P.height = G.height, P.width = G.width, $(W(re.data, P));
              };
            });
          throw new Error("Input data provided is not supported - aborted tensor creation");
        }
        if (b !== void 0)
          return W(b, P);
        throw new Error("Input data provided is not supported - aborted tensor creation");
      }, K = (s, o) => {
        let { width: d, height: g, download: y, dispose: x } = o, b = [1, g, d, 4];
        return new Ve({ location: "texture", type: "float32", texture: s, dims: b, download: y, dispose: x });
      }, pe = (s, o) => {
        let { dataType: d, dims: g, download: y, dispose: x } = o;
        return new Ve({ location: "gpu-buffer", type: d ?? "float32", gpuBuffer: s, dims: g, download: y, dispose: x });
      }, be = (s, o) => {
        let { dataType: d, dims: g, download: y, dispose: x } = o;
        return new Ve({ location: "ml-tensor", type: d ?? "float32", mlTensor: s, dims: g, download: y, dispose: x });
      }, Ee = (s, o, d) => new Ve({ location: "cpu-pinned", type: s, data: o, dims: d ?? [o.length] });
    }), _e, De, he, Z, me = l(() => {
      _e = /* @__PURE__ */ new Map([["float32", Float32Array], ["uint8", Uint8Array], ["int8", Int8Array], ["uint16", Uint16Array], ["int16", Int16Array], ["int32", Int32Array], ["bool", Uint8Array], ["float64", Float64Array], ["uint32", Uint32Array], ["int4", Uint8Array], ["uint4", Uint8Array]]), De = /* @__PURE__ */ new Map([[Float32Array, "float32"], [Uint8Array, "uint8"], [Int8Array, "int8"], [Uint16Array, "uint16"], [Int16Array, "int16"], [Int32Array, "int32"], [Float64Array, "float64"], [Uint32Array, "uint32"]]), he = !1, Z = () => {
        if (!he) {
          he = !0;
          let s = typeof BigInt64Array < "u" && BigInt64Array.from, o = typeof BigUint64Array < "u" && BigUint64Array.from, d = globalThis.Float16Array, g = typeof d < "u" && d.from;
          s && (_e.set("int64", BigInt64Array), De.set(BigInt64Array, "int64")), o && (_e.set("uint64", BigUint64Array), De.set(BigUint64Array, "uint64")), g ? (_e.set("float16", d), De.set(d, "float16")) : _e.set("float16", Uint16Array);
        }
      };
    }), we, xe, et = l(() => {
      nt(), we = (s) => {
        let o = 1;
        for (let d = 0; d < s.length; d++) {
          let g = s[d];
          if (typeof g != "number" || !Number.isSafeInteger(g))
            throw new TypeError(`dims[${d}] must be an integer, got: ${g}`);
          if (g < 0)
            throw new RangeError(`dims[${d}] must be a non-negative integer, got: ${g}`);
          o *= g;
        }
        return o;
      }, xe = (s, o) => {
        switch (s.location) {
          case "cpu":
            return new Ve(s.type, s.data, o);
          case "cpu-pinned":
            return new Ve({ location: "cpu-pinned", data: s.data, type: s.type, dims: o });
          case "texture":
            return new Ve({ location: "texture", texture: s.texture, type: s.type, dims: o });
          case "gpu-buffer":
            return new Ve({ location: "gpu-buffer", gpuBuffer: s.gpuBuffer, type: s.type, dims: o });
          case "ml-tensor":
            return new Ve({ location: "ml-tensor", mlTensor: s.mlTensor, type: s.type, dims: o });
          default:
            throw new Error(`tensorReshape: tensor location ${s.location} is not supported`);
        }
      };
    }), Ve, nt = l(() => {
      Q(), Ge(), me(), et(), Ve = class {
        constructor(s, o, d) {
          Z();
          let g, y;
          if (typeof s == "object" && "location" in s)
            switch (this.dataLocation = s.location, g = s.type, y = s.dims, s.location) {
              case "cpu-pinned": {
                let b = _e.get(g);
                if (!b)
                  throw new TypeError(`unsupported type "${g}" to create tensor from pinned buffer`);
                if (!(s.data instanceof b))
                  throw new TypeError(`buffer should be of type ${b.name}`);
                this.cpuData = s.data;
                break;
              }
              case "texture": {
                if (g !== "float32")
                  throw new TypeError(`unsupported type "${g}" to create tensor from texture`);
                this.gpuTextureData = s.texture, this.downloader = s.download, this.disposer = s.dispose;
                break;
              }
              case "gpu-buffer": {
                if (g !== "float32" && g !== "float16" && g !== "int32" && g !== "int64" && g !== "uint32" && g !== "uint8" && g !== "bool" && g !== "uint4" && g !== "int4")
                  throw new TypeError(`unsupported type "${g}" to create tensor from gpu buffer`);
                this.gpuBufferData = s.gpuBuffer, this.downloader = s.download, this.disposer = s.dispose;
                break;
              }
              case "ml-tensor": {
                if (g !== "float32" && g !== "float16" && g !== "int32" && g !== "int64" && g !== "uint32" && g !== "uint64" && g !== "int8" && g !== "uint8" && g !== "bool" && g !== "uint4" && g !== "int4")
                  throw new TypeError(`unsupported type "${g}" to create tensor from MLTensor`);
                this.mlTensorData = s.mlTensor, this.downloader = s.download, this.disposer = s.dispose;
                break;
              }
              default:
                throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`);
            }
          else {
            let b, P;
            if (typeof s == "string")
              if (g = s, P = d, s === "string") {
                if (!Array.isArray(o))
                  throw new TypeError("A string tensor's data must be a string array.");
                b = o;
              } else {
                let k = _e.get(s);
                if (k === void 0)
                  throw new TypeError(`Unsupported tensor type: ${s}.`);
                if (Array.isArray(o)) {
                  if (s === "float16" && k === Uint16Array || s === "uint4" || s === "int4")
                    throw new TypeError(`Creating a ${s} tensor from number array is not supported. Please use ${k.name} as data.`);
                  s === "uint64" || s === "int64" ? b = k.from(o, BigInt) : b = k.from(o);
                } else if (o instanceof k)
                  b = o;
                else if (o instanceof Uint8ClampedArray)
                  if (s === "uint8")
                    b = Uint8Array.from(o);
                  else
                    throw new TypeError("A Uint8ClampedArray tensor's data must be type of uint8");
                else if (s === "float16" && o instanceof Uint16Array && k !== Uint16Array)
                  b = new globalThis.Float16Array(o.buffer, o.byteOffset, o.length);
                else
                  throw new TypeError(`A ${g} tensor's data must be type of ${k}`);
              }
            else if (P = o, Array.isArray(s)) {
              if (s.length === 0)
                throw new TypeError("Tensor type cannot be inferred from an empty array.");
              let k = typeof s[0];
              if (k === "string")
                g = "string", b = s;
              else if (k === "boolean")
                g = "bool", b = Uint8Array.from(s);
              else
                throw new TypeError(`Invalid element type of data array: ${k}.`);
            } else if (s instanceof Uint8ClampedArray)
              g = "uint8", b = Uint8Array.from(s);
            else {
              let k = De.get(s.constructor);
              if (k === void 0)
                throw new TypeError(`Unsupported type for tensor data: ${s.constructor}.`);
              g = k, b = s;
            }
            if (P === void 0)
              P = [b.length];
            else if (!Array.isArray(P))
              throw new TypeError("A tensor's dims must be a number array");
            y = P, this.cpuData = b, this.dataLocation = "cpu";
          }
          let x = we(y);
          if (this.cpuData && x !== this.cpuData.length && !((g === "uint4" || g === "int4") && Math.ceil(x / 2) === this.cpuData.length))
            throw new Error(`Tensor's size(${x}) does not match data length(${this.cpuData.length}).`);
          this.type = g, this.dims = y, this.size = x;
        }
        static async fromImage(s, o) {
          return te(s, o);
        }
        static fromTexture(s, o) {
          return K(s, o);
        }
        static fromGpuBuffer(s, o) {
          return pe(s, o);
        }
        static fromMLTensor(s, o) {
          return be(s, o);
        }
        static fromPinnedBuffer(s, o, d) {
          return Ee(s, o, d);
        }
        toDataURL(s) {
          return q(this, s);
        }
        toImageData(s) {
          return ne(this, s);
        }
        get data() {
          if (this.ensureValid(), !this.cpuData)
            throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");
          return this.cpuData;
        }
        get location() {
          return this.dataLocation;
        }
        get texture() {
          if (this.ensureValid(), !this.gpuTextureData)
            throw new Error("The data is not stored as a WebGL texture.");
          return this.gpuTextureData;
        }
        get gpuBuffer() {
          if (this.ensureValid(), !this.gpuBufferData)
            throw new Error("The data is not stored as a WebGPU buffer.");
          return this.gpuBufferData;
        }
        get mlTensor() {
          if (this.ensureValid(), !this.mlTensorData)
            throw new Error("The data is not stored as a WebNN MLTensor.");
          return this.mlTensorData;
        }
        async getData(s) {
          switch (this.ensureValid(), this.dataLocation) {
            case "cpu":
            case "cpu-pinned":
              return this.data;
            case "texture":
            case "gpu-buffer":
            case "ml-tensor": {
              if (!this.downloader)
                throw new Error("The current tensor is not created with a specified data downloader.");
              if (this.isDownloading)
                throw new Error("The current tensor is being downloaded.");
              try {
                this.isDownloading = !0;
                let o = await this.downloader();
                return this.downloader = void 0, this.dataLocation = "cpu", this.cpuData = o, s && this.disposer && (this.disposer(), this.disposer = void 0), o;
              } finally {
                this.isDownloading = !1;
              }
            }
            default:
              throw new Error(`cannot get data from location: ${this.dataLocation}`);
          }
        }
        dispose() {
          if (this.isDownloading)
            throw new Error("The current tensor is being downloaded.");
          this.disposer && (this.disposer(), this.disposer = void 0), this.cpuData = void 0, this.gpuTextureData = void 0, this.gpuBufferData = void 0, this.mlTensorData = void 0, this.downloader = void 0, this.isDownloading = void 0, this.dataLocation = "none";
        }
        ensureValid() {
          if (this.dataLocation === "none")
            throw new Error("The tensor is disposed.");
        }
        reshape(s) {
          if (this.ensureValid(), this.downloader || this.disposer)
            throw new Error("Cannot reshape a tensor that owns GPU resource.");
          return xe(this, s);
        }
      };
    }), Be, ae = l(() => {
      nt(), Be = Ve;
    }), U, Se, ze, Oe, Ye = l(() => {
      I(), U = (s, o) => {
        (typeof L.trace > "u" ? !L.wasm.trace : !L.trace) || console.timeStamp(`${s}::ORT::${o}`);
      }, Se = (s, o) => {
        var y;
        let d = ((y = new Error().stack) == null ? void 0 : y.split(/\r\n|\r|\n/g)) || [], g = !1;
        for (let x = 0; x < d.length; x++) {
          if (g && !d[x].includes("TRACE_FUNC")) {
            let b = `FUNC_${s}::${d[x].trim().split(" ")[1]}`;
            o && (b += `::${o}`), U("CPU", b);
            return;
          }
          d[x].includes("TRACE_FUNC") && (g = !0);
        }
      }, ze = (s) => {
        (typeof L.trace > "u" ? !L.wasm.trace : !L.trace) || Se("BEGIN", s);
      }, Oe = (s) => {
        (typeof L.trace > "u" ? !L.wasm.trace : !L.trace) || Se("END", s);
      };
    }), H, Y = l(() => {
      w(), ae(), Ye(), H = class Pb {
        constructor(o) {
          this.handler = o;
        }
        async run(o, d, g) {
          ze();
          let y = {}, x = {};
          if (typeof o != "object" || o === null || o instanceof Be || Array.isArray(o))
            throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");
          let b = !0;
          if (typeof d == "object") {
            if (d === null)
              throw new TypeError("Unexpected argument[1]: cannot be null.");
            if (d instanceof Be)
              throw new TypeError("'fetches' cannot be a Tensor");
            if (Array.isArray(d)) {
              if (d.length === 0)
                throw new TypeError("'fetches' cannot be an empty array.");
              b = !1;
              for (let O of d) {
                if (typeof O != "string")
                  throw new TypeError("'fetches' must be a string array or an object.");
                if (this.outputNames.indexOf(O) === -1)
                  throw new RangeError(`'fetches' contains invalid output name: ${O}.`);
                y[O] = null;
              }
              if (typeof g == "object" && g !== null)
                x = g;
              else if (typeof g < "u")
                throw new TypeError("'options' must be an object.");
            } else {
              let O = !1, $ = Object.getOwnPropertyNames(d);
              for (let V of this.outputNames)
                if ($.indexOf(V) !== -1) {
                  let G = d[V];
                  (G === null || G instanceof Be) && (O = !0, b = !1, y[V] = G);
                }
              if (O) {
                if (typeof g == "object" && g !== null)
                  x = g;
                else if (typeof g < "u")
                  throw new TypeError("'options' must be an object.");
              } else
                x = d;
            }
          } else if (typeof d < "u")
            throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");
          for (let O of this.inputNames)
            if (typeof o[O] > "u")
              throw new Error(`input '${O}' is missing in 'feeds'.`);
          if (b)
            for (let O of this.outputNames)
              y[O] = null;
          let P = await this.handler.run(o, y, x), k = {};
          for (let O in P)
            if (Object.hasOwnProperty.call(P, O)) {
              let $ = P[O];
              $ instanceof Be ? k[O] = $ : k[O] = new Be($.type, $.data, $.dims);
            }
          return Oe(), k;
        }
        async release() {
          return this.handler.dispose();
        }
        static async create(o, d, g, y) {
          ze();
          let x, b = {};
          if (typeof o == "string") {
            if (x = o, typeof d == "object" && d !== null)
              b = d;
            else if (typeof d < "u")
              throw new TypeError("'options' must be an object.");
          } else if (o instanceof Uint8Array) {
            if (x = o, typeof d == "object" && d !== null)
              b = d;
            else if (typeof d < "u")
              throw new TypeError("'options' must be an object.");
          } else if (o instanceof ArrayBuffer || typeof SharedArrayBuffer < "u" && o instanceof SharedArrayBuffer) {
            let $ = o, V = 0, G = o.byteLength;
            if (typeof d == "object" && d !== null)
              b = d;
            else if (typeof d == "number") {
              if (V = d, !Number.isSafeInteger(V))
                throw new RangeError("'byteOffset' must be an integer.");
              if (V < 0 || V >= $.byteLength)
                throw new RangeError(`'byteOffset' is out of range [0, ${$.byteLength}).`);
              if (G = o.byteLength - V, typeof g == "number") {
                if (G = g, !Number.isSafeInteger(G))
                  throw new RangeError("'byteLength' must be an integer.");
                if (G <= 0 || V + G > $.byteLength)
                  throw new RangeError(`'byteLength' is out of range (0, ${$.byteLength - V}].`);
                if (typeof y == "object" && y !== null)
                  b = y;
                else if (typeof y < "u")
                  throw new TypeError("'options' must be an object.");
              } else if (typeof g < "u")
                throw new TypeError("'byteLength' must be a number.");
            } else if (typeof d < "u")
              throw new TypeError("'options' must be an object.");
            x = new Uint8Array($, V, G);
          } else
            throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");
          let [P, k] = await D(b), O = await P.createInferenceSessionHandler(x, k);
          return Oe(), new Pb(O);
        }
        startProfiling() {
          this.handler.startProfiling();
        }
        endProfiling() {
          this.handler.endProfiling();
        }
        get inputNames() {
          return this.handler.inputNames;
        }
        get outputNames() {
          return this.handler.outputNames;
        }
        get inputMetadata() {
          return this.handler.inputMetadata;
        }
        get outputMetadata() {
          return this.handler.outputMetadata;
        }
      };
    }), $e, Ie = l(() => {
      Y(), $e = H;
    }), fe = l(() => {
    }), Qe = l(() => {
    }), Ne = l(() => {
    }), ut = l(() => {
    }), de = {};
    f(de, { InferenceSession: () => $e, TRACE: () => U, TRACE_FUNC_BEGIN: () => ze, TRACE_FUNC_END: () => Oe, Tensor: () => Be, env: () => R, registerBackend: () => v });
    var qe = l(() => {
      T(), N(), Ie(), ae(), fe(), Qe(), Ye(), Ne(), ut();
    }), tt = l(() => {
    }), He = {};
    f(He, { default: () => Mt });
    var je, lt, Mt, Rt = l(() => {
      var s;
      Kp(), ge(), Me(), je = "ort-wasm-proxy-worker", lt = ((s = globalThis.self) == null ? void 0 : s.name) === je, lt && (self.onmessage = (o) => {
        let { type: d, in: g } = o.data;
        try {
          switch (d) {
            case "init-wasm":
              J(g.wasm).then(() => {
                gc(g).then(() => {
                  postMessage({ type: d });
                }, (y) => {
                  postMessage({ type: d, err: y });
                });
              }, (y) => {
                postMessage({ type: d, err: y });
              });
              break;
            case "init-ep": {
              let { epName: y, env: x } = g;
              _c(x, y).then(() => {
                postMessage({ type: d });
              }, (b) => {
                postMessage({ type: d, err: b });
              });
              break;
            }
            case "copy-from": {
              let { buffer: y } = g, x = Qo(y);
              postMessage({ type: d, out: x });
              break;
            }
            case "create": {
              let { model: y, options: x } = g;
              tr(y, x).then((b) => {
                postMessage({ type: d, out: b });
              }, (b) => {
                postMessage({ type: d, err: b });
              });
              break;
            }
            case "release":
              vc(g), postMessage({ type: d });
              break;
            case "run": {
              let { sessionId: y, inputIndices: x, inputs: b, outputIndices: P, options: k } = g;
              xc(y, x, b, P, new Array(P.length).fill(null), k).then((O) => {
                O.some(($) => $[3] !== "cpu") ? postMessage({ type: d, err: "Proxy does not support non-cpu tensor location." }) : postMessage({ type: d, out: O }, Mc([...b, ...O]));
              }, (O) => {
                postMessage({ type: d, err: O });
              });
              break;
            }
            case "end-profiling":
              bc(g), postMessage({ type: d });
              break;
            default:
          }
        } catch (y) {
          postMessage({ type: d, err: y });
        }
      }), Mt = lt ? null : (o) => new Worker(o ?? wn, { type: "classic", name: je });
    }), Kt, vn, wn, ln, Gn, li, Yi, $i, An, bn, Si, ds, qt, Me = l(() => {
      tt(), Kt = typeof location > "u" ? void 0 : location.origin, vn = () => {
        var s, o;
        return typeof document < "u" ? (s = document.currentScript) == null ? void 0 : s.src : typeof self < "u" ? (o = self.location) == null ? void 0 : o.href : void 0;
      }, wn = vn(), ln = () => {
        if (wn && !wn.startsWith("blob:"))
          return wn.substring(0, wn.lastIndexOf("/") + 1);
      }, Gn = (s, o) => {
        try {
          let d = o ?? wn;
          return (d ? new URL(s, d) : new URL(s)).origin === Kt;
        } catch {
          return !1;
        }
      }, li = (s, o) => {
        let d = o ?? wn;
        try {
          return (d ? new URL(s, d) : new URL(s)).href;
        } catch {
          return;
        }
      }, Yi = (s, o) => `${o ?? "./"}${s}`, $i = async (s) => {
        let o = await (await fetch(s, { credentials: "same-origin" })).blob();
        return URL.createObjectURL(o);
      }, An = async (s) => (await import(
        /*webpackIgnore:true*/
        s
      )).default, bn = (Rt(), h(He)).default, Si = async () => {
        if (!wn)
          throw new Error("Failed to load proxy worker: cannot determine the script source URL.");
        if (Gn(wn))
          return [void 0, bn()];
        let s = await $i(wn);
        return [s, bn(s)];
      }, ds = void 0, qt = async (s, o, d) => {
        if (!s && !o && ds && wn && Gn(wn))
          return [void 0, ds];
        {
          let g = "ort-wasm-simd-threaded.jsep.mjs", y = s ?? li(g, o), x = d && y && !Gn(y, o), b = x ? await $i(y) : y ?? Yi(g, o);
          return [x ? b : void 0, await An(b)];
        }
      };
    }), at, rt, mt, _t, on, B, le, J, se, ge = l(() => {
      Me(), rt = !1, mt = !1, _t = !1, on = () => {
        if (typeof SharedArrayBuffer > "u")
          return !1;
        try {
          return typeof MessageChannel < "u" && new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)), WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16, 2, 0, 26, 11]));
        } catch {
          return !1;
        }
      }, B = () => {
        try {
          return WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 10, 30, 1, 28, 0, 65, 0, 253, 15, 253, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 253, 186, 1, 26, 11]));
        } catch {
          return !1;
        }
      }, le = () => {
        try {
          return WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 123, 3, 2, 1, 0, 10, 19, 1, 17, 0, 65, 1, 253, 15, 65, 2, 253, 15, 65, 3, 253, 15, 253, 147, 2, 11]));
        } catch {
          return !1;
        }
      }, J = async (s) => {
        if (rt)
          return Promise.resolve();
        if (mt)
          throw new Error("multiple calls to 'initializeWebAssembly()' detected.");
        if (_t)
          throw new Error("previous call to 'initializeWebAssembly()' failed.");
        mt = !0;
        let o = s.initTimeout, d = s.numThreads;
        if (s.simd !== !1) {
          if (s.simd === "relaxed") {
            if (!le())
              throw new Error("Relaxed WebAssembly SIMD is not supported in the current environment.");
          } else if (!B())
            throw new Error("WebAssembly SIMD is not supported in the current environment.");
        }
        let g = on();
        d > 1 && !g && (typeof self < "u" && !self.crossOriginIsolated && console.warn("env.wasm.numThreads is set to " + d + ", but this will not work unless you enable crossOriginIsolated mode. See https://web.dev/cross-origin-isolation-guide/ for more info."), console.warn("WebAssembly multi-threading is not supported in the current environment. Falling back to single-threading."), s.numThreads = d = 1);
        let y = s.wasmPaths, x = typeof y == "string" ? y : void 0, b = y == null ? void 0 : y.mjs, P = (b == null ? void 0 : b.href) ?? b, k = y == null ? void 0 : y.wasm, O = (k == null ? void 0 : k.href) ?? k, $ = s.wasmBinary, [V, G] = await qt(P, x, d > 1), ee = !1, X = [];
        if (o > 0 && X.push(new Promise((re) => {
          setTimeout(() => {
            ee = !0, re();
          }, o);
        })), X.push(new Promise((re, Te) => {
          let ue = { numThreads: d };
          if ($)
            ue.wasmBinary = $;
          else if (O || x)
            ue.locateFile = (ce) => O ?? x + ce;
          else if (P && P.indexOf("blob:") !== 0)
            ue.locateFile = (ce) => new URL(ce, P).href;
          else if (V) {
            let ce = ln();
            ce && (ue.locateFile = (ke) => ce + ke);
          }
          G(ue).then((ce) => {
            mt = !1, rt = !0, at = ce, re(), V && URL.revokeObjectURL(V);
          }, (ce) => {
            mt = !1, _t = !0, Te(ce);
          });
        })), await Promise.race(X), ee)
          throw new Error(`WebAssembly backend initializing failed due to timeout: ${o}ms`);
      }, se = () => {
        if (rt && at)
          return at;
        throw new Error("WebAssembly is not initialized yet.");
      };
    }), Fe, Ke, pt, Pt = l(() => {
      ge(), Fe = (s, o) => {
        let d = se(), g = d.lengthBytesUTF8(s) + 1, y = d._malloc(g);
        return d.stringToUTF8(s, y, g), o.push(y), y;
      }, Ke = (s, o, d, g) => {
        if (typeof s == "object" && s !== null) {
          if (d.has(s))
            throw new Error("Circular reference in options");
          d.add(s);
        }
        Object.entries(s).forEach(([y, x]) => {
          let b = o ? o + y : y;
          if (typeof x == "object")
            Ke(x, b + ".", d, g);
          else if (typeof x == "string" || typeof x == "number")
            g(b, x.toString());
          else if (typeof x == "boolean")
            g(b, x ? "1" : "0");
          else
            throw new Error(`Can't handle extra config type: ${typeof x}`);
        });
      }, pt = (s) => {
        let o = se(), d = o.stackSave();
        try {
          let g = o.PTR_SIZE, y = o.stackAlloc(2 * g);
          o._OrtGetLastError(y, y + g);
          let x = Number(o.getValue(y, g === 4 ? "i32" : "i64")), b = o.getValue(y + g, "*"), P = b ? o.UTF8ToString(b) : "";
          throw new Error(`${s} ERROR_CODE: ${x}, ERROR_MESSAGE: ${P}`);
        } finally {
          o.stackRestore(d);
        }
      };
    }), Tt, en = l(() => {
      ge(), Pt(), Tt = (s) => {
        let o = se(), d = 0, g = [], y = s || {};
        try {
          if ((s == null ? void 0 : s.logSeverityLevel) === void 0)
            y.logSeverityLevel = 2;
          else if (typeof s.logSeverityLevel != "number" || !Number.isInteger(s.logSeverityLevel) || s.logSeverityLevel < 0 || s.logSeverityLevel > 4)
            throw new Error(`log serverity level is not valid: ${s.logSeverityLevel}`);
          if ((s == null ? void 0 : s.logVerbosityLevel) === void 0)
            y.logVerbosityLevel = 0;
          else if (typeof s.logVerbosityLevel != "number" || !Number.isInteger(s.logVerbosityLevel))
            throw new Error(`log verbosity level is not valid: ${s.logVerbosityLevel}`);
          (s == null ? void 0 : s.terminate) === void 0 && (y.terminate = !1);
          let x = 0;
          return (s == null ? void 0 : s.tag) !== void 0 && (x = Fe(s.tag, g)), d = o._OrtCreateRunOptions(y.logSeverityLevel, y.logVerbosityLevel, !!y.terminate, x), d === 0 && pt("Can't create run options."), (s == null ? void 0 : s.extra) !== void 0 && Ke(s.extra, "", /* @__PURE__ */ new WeakSet(), (b, P) => {
            let k = Fe(b, g), O = Fe(P, g);
            o._OrtAddRunConfigEntry(d, k, O) !== 0 && pt(`Can't set a run config entry: ${b} - ${P}.`);
          }), [d, g];
        } catch (x) {
          throw d !== 0 && o._OrtReleaseRunOptions(d), g.forEach((b) => o._free(b)), x;
        }
      };
    }), Dt, tn, Vt, nn, Mn, vi, ci = l(() => {
      ge(), Pt(), Dt = (s) => {
        switch (s) {
          case "disabled":
            return 0;
          case "basic":
            return 1;
          case "extended":
            return 2;
          case "all":
            return 99;
          default:
            throw new Error(`unsupported graph optimization level: ${s}`);
        }
      }, tn = (s) => {
        switch (s) {
          case "sequential":
            return 0;
          case "parallel":
            return 1;
          default:
            throw new Error(`unsupported execution mode: ${s}`);
        }
      }, Vt = (s) => {
        s.extra || (s.extra = {}), s.extra.session || (s.extra.session = {});
        let o = s.extra.session;
        o.use_ort_model_bytes_directly || (o.use_ort_model_bytes_directly = "1"), s.executionProviders && s.executionProviders.some((d) => (typeof d == "string" ? d : d.name) === "webgpu") && (s.enableMemPattern = !1);
      }, nn = (s, o, d, g) => {
        let y = Fe(o, g), x = Fe(d, g);
        se()._OrtAddSessionConfigEntry(s, y, x) !== 0 && pt(`Can't set a session config entry: ${o} - ${d}.`);
      }, Mn = async (s, o, d) => {
        for (let g of o) {
          let y = typeof g == "string" ? g : g.name, x = [];
          switch (y) {
            case "webnn":
              if (y = "WEBNN", typeof g != "string") {
                let $ = g == null ? void 0 : g.deviceType;
                $ && nn(s, "deviceType", $, d);
              }
              break;
            case "webgpu":
              if (y = "JS", typeof g != "string") {
                let $ = g;
                if ($ != null && $.preferredLayout) {
                  if ($.preferredLayout !== "NCHW" && $.preferredLayout !== "NHWC")
                    throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${$.preferredLayout}`);
                  nn(s, "preferredLayout", $.preferredLayout, d);
                }
              }
              break;
            case "wasm":
            case "cpu":
              continue;
            default:
              throw new Error(`not supported execution provider: ${y}`);
          }
          let b = Fe(y, d), P = x.length, k = 0, O = 0;
          if (P > 0) {
            k = se()._malloc(P * se().PTR_SIZE), d.push(k), O = se()._malloc(P * se().PTR_SIZE), d.push(O);
            for (let $ = 0; $ < P; $++)
              se().setValue(k + $ * se().PTR_SIZE, x[$][0], "*"), se().setValue(O + $ * se().PTR_SIZE, x[$][1], "*");
          }
          await se()._OrtAppendExecutionProvider(s, b, k, O, P) !== 0 && pt(`Can't append execution provider: ${y}.`);
        }
      }, vi = async (s) => {
        let o = se(), d = 0, g = [], y = s || {};
        Vt(y);
        try {
          let x = Dt(y.graphOptimizationLevel ?? "all"), b = tn(y.executionMode ?? "sequential"), P = typeof y.logId == "string" ? Fe(y.logId, g) : 0, k = y.logSeverityLevel ?? 2;
          if (!Number.isInteger(k) || k < 0 || k > 4)
            throw new Error(`log serverity level is not valid: ${k}`);
          let O = y.logVerbosityLevel ?? 0;
          if (!Number.isInteger(O) || O < 0 || O > 4)
            throw new Error(`log verbosity level is not valid: ${O}`);
          let $ = typeof y.optimizedModelFilePath == "string" ? Fe(y.optimizedModelFilePath, g) : 0;
          if (d = o._OrtCreateSessionOptions(x, !!y.enableCpuMemArena, !!y.enableMemPattern, b, !!y.enableProfiling, 0, P, k, O, $), d === 0 && pt("Can't create session options."), y.executionProviders && await Mn(d, y.executionProviders, g), y.enableGraphCapture !== void 0) {
            if (typeof y.enableGraphCapture != "boolean")
              throw new Error(`enableGraphCapture must be a boolean value: ${y.enableGraphCapture}`);
            nn(d, "enableGraphCapture", y.enableGraphCapture.toString(), g);
          }
          if (y.freeDimensionOverrides)
            for (let [V, G] of Object.entries(y.freeDimensionOverrides)) {
              if (typeof V != "string")
                throw new Error(`free dimension override name must be a string: ${V}`);
              if (typeof G != "number" || !Number.isInteger(G) || G < 0)
                throw new Error(`free dimension override value must be a non-negative integer: ${G}`);
              let ee = Fe(V, g);
              o._OrtAddFreeDimensionOverride(d, ee, G) !== 0 && pt(`Can't set a free dimension override: ${V} - ${G}.`);
            }
          return y.extra !== void 0 && Ke(y.extra, "", /* @__PURE__ */ new WeakSet(), (V, G) => {
            nn(d, V, G, g);
          }), [d, g];
        } catch (x) {
          throw d !== 0 && o._OrtReleaseSessionOptions(d) !== 0 && pt("Can't release session options."), g.forEach((b) => o._free(b)), x;
        }
      };
    }), ki, fi, Pi, wi, hs, fs, Ps, Oi, jt = l(() => {
      ki = (s) => {
        switch (s) {
          case "int8":
            return 3;
          case "uint8":
            return 2;
          case "bool":
            return 9;
          case "int16":
            return 5;
          case "uint16":
            return 4;
          case "int32":
            return 6;
          case "uint32":
            return 12;
          case "float16":
            return 10;
          case "float32":
            return 1;
          case "float64":
            return 11;
          case "string":
            return 8;
          case "int64":
            return 7;
          case "uint64":
            return 13;
          case "int4":
            return 22;
          case "uint4":
            return 21;
          default:
            throw new Error(`unsupported data type: ${s}`);
        }
      }, fi = (s) => {
        switch (s) {
          case 3:
            return "int8";
          case 2:
            return "uint8";
          case 9:
            return "bool";
          case 5:
            return "int16";
          case 4:
            return "uint16";
          case 6:
            return "int32";
          case 12:
            return "uint32";
          case 10:
            return "float16";
          case 1:
            return "float32";
          case 11:
            return "float64";
          case 8:
            return "string";
          case 7:
            return "int64";
          case 13:
            return "uint64";
          case 22:
            return "int4";
          case 21:
            return "uint4";
          default:
            throw new Error(`unsupported data type: ${s}`);
        }
      }, Pi = (s, o) => {
        let d = [-1, 4, 1, 1, 2, 2, 4, 8, -1, 1, 2, 8, 4, 8, -1, -1, -1, -1, -1, -1, -1, 0.5, 0.5][s], g = typeof o == "number" ? o : o.reduce((y, x) => y * x, 1);
        return d > 0 ? Math.ceil(g * d) : void 0;
      }, wi = (s) => {
        switch (s) {
          case "float16":
            return typeof Float16Array < "u" && Float16Array.from ? Float16Array : Uint16Array;
          case "float32":
            return Float32Array;
          case "uint8":
            return Uint8Array;
          case "int8":
            return Int8Array;
          case "uint16":
            return Uint16Array;
          case "int16":
            return Int16Array;
          case "int32":
            return Int32Array;
          case "bool":
            return Uint8Array;
          case "float64":
            return Float64Array;
          case "uint32":
            return Uint32Array;
          case "int64":
            return BigInt64Array;
          case "uint64":
            return BigUint64Array;
          default:
            throw new Error(`unsupported type: ${s}`);
        }
      }, hs = (s) => {
        switch (s) {
          case "verbose":
            return 0;
          case "info":
            return 1;
          case "warning":
            return 2;
          case "error":
            return 3;
          case "fatal":
            return 4;
          default:
            throw new Error(`unsupported logging level: ${s}`);
        }
      }, fs = (s) => s === "float32" || s === "float16" || s === "int32" || s === "int64" || s === "uint32" || s === "uint8" || s === "bool" || s === "uint4" || s === "int4", Ps = (s) => s === "float32" || s === "float16" || s === "int32" || s === "int64" || s === "uint32" || s === "uint64" || s === "int8" || s === "uint8" || s === "bool" || s === "uint4" || s === "int4", Oi = (s) => {
        switch (s) {
          case "none":
            return 0;
          case "cpu":
            return 1;
          case "cpu-pinned":
            return 2;
          case "texture":
            return 3;
          case "gpu-buffer":
            return 4;
          case "ml-tensor":
            return 5;
          default:
            throw new Error(`unsupported data location: ${s}`);
        }
      };
    }), Ni, Ws = l(() => {
      tt(), Ni = async (s) => {
        if (typeof s == "string") {
          let o = await fetch(s);
          if (!o.ok)
            throw new Error(`failed to load external data file: ${s}`);
          let d = o.headers.get("Content-Length"), g = d ? parseInt(d, 10) : 0;
          if (g < 1073741824)
            return new Uint8Array(await o.arrayBuffer());
          {
            if (!o.body)
              throw new Error(`failed to load external data file: ${s}, no response body.`);
            let y = o.body.getReader(), x;
            try {
              x = new ArrayBuffer(g);
            } catch (P) {
              if (P instanceof RangeError) {
                let k = Math.ceil(g / 65536);
                x = new WebAssembly.Memory({ initial: k, maximum: k }).buffer;
              } else
                throw P;
            }
            let b = 0;
            for (; ; ) {
              let { done: P, value: k } = await y.read();
              if (P)
                break;
              let O = k.byteLength;
              new Uint8Array(x, b, O).set(k), b += O;
            }
            return new Uint8Array(x, 0, g);
          }
        } else
          return s instanceof Blob ? new Uint8Array(await s.arrayBuffer()) : s instanceof Uint8Array ? s : new Uint8Array(s);
      };
    }), As, Cs, Is, Ji, pi, bt, ct, Lt = l(() => {
      jt(), As = ["V", "I", "W", "E", "F"], Cs = (s, o) => {
        console.log(`[${As[s]},${(/* @__PURE__ */ new Date()).toISOString()}]${o}`);
      }, pi = (s, o) => {
        Is = s, Ji = o;
      }, bt = (s, o) => {
        let d = hs(s), g = hs(Is);
        d >= g && Cs(d, typeof o == "function" ? o() : o);
      }, ct = (...s) => {
        Ji && bt(...s);
      };
    }), yn, Ui, it, ps, Br, Xe, j, ie = l(() => {
      yn = class {
        static calcMatMulShape(s, o) {
          return s[1] !== o[0] ? void 0 : [s[0], o[1]];
        }
      }, Ui = class {
        static calcShape(s, o, d = !1) {
          let g = s.length, y = o.length;
          if (g === 0)
            return o;
          if (y === 0)
            return s;
          let x = Math.max(s.length, o.length), b = new Array(x);
          if (d) {
            if (g < 2 || y < 2)
              return;
            let P = yn.calcMatMulShape([s[g - 2], s[g - 1]], [o[y - 2], o[y - 1]]);
            if (P === void 0)
              return;
            [b[x - 2], b[x - 1]] = P;
          }
          for (let P = d ? 3 : 1; P <= x; P++) {
            let k = g - P < 0 ? 1 : s[g - P], O = y - P < 0 ? 1 : o[y - P];
            if (k !== O && k > 1 && O > 1)
              return;
            let $ = Math.max(k, O);
            if (k && O)
              b[x - P] = Math.max(k, O);
            else {
              if ($ > 1)
                return;
              b[x - P] = 0;
            }
          }
          return b;
        }
        static isValidBroadcast(s, o) {
          let d = s.length, g = o.length;
          if (d > g)
            return !1;
          for (let y = 1; y <= d; y++)
            if (s[d - y] !== 1 && s[d - y] !== o[g - y])
              return !1;
          return !0;
        }
      }, it = class K_ {
        static size(o) {
          return K_.getSizeFromDimensionRange(o, 0, o.length);
        }
        static convertShape(o, d = 4) {
          let g = o.length;
          if (g === 0)
            return [];
          let y = new Array(g), x = g - 1;
          for (; x >= 0; ) {
            if (o[x] % d === 0) {
              y[x] = o[x] / d;
              break;
            }
            if (d % o[x] !== 0)
              throw new Error("cannot convert shape");
            y[x] = 1, d /= o[x], x--;
          }
          for (x--; x >= 0; x--)
            y[x] = o[x];
          return y;
        }
        static sizeFromDimension(o, d) {
          if (d < 0 || d > o.length)
            throw new Error(`invalid dimension of ${d} for sizeFromDimension as Tensor has ${o.length} dimensions.`);
          return K_.getSizeFromDimensionRange(o, d, o.length);
        }
        static sizeToDimension(o, d) {
          if (d < 0 || d > o.length)
            throw new Error(`invalid dimension of ${d} for sizeToDimension as Tensor has ${o.length} dimensions.`);
          return K_.getSizeFromDimensionRange(o, 0, d);
        }
        static getSizeFromDimensionRange(o, d, g) {
          let y = 1;
          for (let x = d; x < g; x++) {
            if (o[x] < 0)
              throw new Error("cannot get valid size from specified dimension range. Most likely the range contains negative values in them.");
            y *= Number(o[x]);
          }
          return y;
        }
        static computeStrides(o) {
          let d = o.length;
          if (d === 0)
            return [];
          if (d === 1)
            return [1];
          let g = new Array(d);
          g[d - 1] = 1, g[d - 2] = o[d - 1];
          for (let y = d - 3; y >= 0; --y)
            g[y] = g[y + 1] * o[y + 1];
          return g;
        }
        static normalizeAxis(o, d) {
          if (o < -d && o >= d)
            throw new Error("unsupported axis for this operation.");
          return o < 0 ? o + d : o;
        }
        static normalizeAxes(o, d) {
          return o.map((g) => this.normalizeAxis(g, d ?? o.length));
        }
        static sortBasedOnPerm(o, d) {
          return d ? d.map((g) => o[g]) : o.slice().reverse();
        }
        static padShape(o, d) {
          let g = o.length;
          return o.map((y, x) => y + d[x] + d[x + g]);
        }
        static areEqual(o, d) {
          return o.length !== d.length ? !1 : o.every((g, y) => g === d[y]);
        }
      }, ps = class wm {
        static adjustPoolAttributes(o, d, g, y, x, b) {
          if (!o && g.length !== d.length - 2)
            throw new Error("length of specified kernel shapes should be 2 less than length of input dimensions");
          if (o)
            for (let P = 0; P < d.length - 2; P++)
              P >= g.length ? g.push(d[P + 2]) : g[P] = d[P + 2];
          for (let P = 0; P < g.length; P++)
            if (P < y.length) {
              if (y[P] < 0)
                throw new Error("strides should be greater than or equal to 1");
            } else
              y.push(1);
          for (let P = 0; P < g.length; P++)
            if (P < x.length) {
              if (x[P] < 0)
                throw new Error("dilations should be greater than or equal to 1");
            } else
              x.push(1);
          for (let P = 0; P < g.length * 2; P++)
            if (P < b.length) {
              if (b[P] < 0)
                throw new Error("pad should be greater than or equal to 1");
            } else
              b.push(0);
          for (let P = 0; P < g.length; P++) {
            if (g[P] <= 0)
              throw new Error("kernel shapes need to be greater than 0");
            if (b[P] >= g[P] || b[P + g.length] >= g[P])
              throw new Error("pads should be smaller than kernel");
          }
        }
        static adjustPadsBasedOnAutoPad(o, d, g, y, x, b, P) {
          if (P) {
            if (x.length !== 2 * (o.length - 2))
              throw new Error("length of pads should be twice the length of data dimensions");
            if (d.length !== o.length - 2)
              throw new Error("length of strides should be the length of data dimensions");
            if (y.length !== o.length - 2)
              throw new Error("length of kernel shapes should be the length of data dimensions");
            for (let k = 0; k < o.length - 2; k++)
              wm.adjustPadAndReturnShape(o[k + (b ? 1 : 2)], d[k], g[k], y[k], x, k, k + o.length - 2, P);
          }
        }
        static computePoolOutputShape(o, d, g, y, x, b, P) {
          if (d.length <= 0)
            throw new Error("input shape must be of size greater than 0");
          let k = [d[0], d[1]];
          return wm.computeShapeHelper(o, d, k, g, y, x, b, P), k;
        }
        static computeConvOutputShape(o, d, g, y, x, b, P) {
          if (o.length <= 0 || d.length <= 0)
            throw new Error("invalid input tensor dims or invalid filter tensor dims");
          let k = [o[0], d[0]];
          return wm.computeShapeHelper(!1, o, k, g, y, x, b, P), k;
        }
        static computeShapeHelper(o, d, g, y, x, b, P, k) {
          if (o)
            for (let O = 0; O < d.length - 2; O++)
              g.push(1);
          else
            for (let O = 0; O < d.length - 2; O++)
              g.push(wm.adjustPadAndReturnShape(d[O + 2], y[O], x[O], b[O], P, O, O + d.length - 2, k));
        }
        static adjustPadAndReturnShape(o, d, g, y, x, b, P, k) {
          let O = g * (y - 1) + 1;
          if (k && k !== "NOTSET")
            switch (k) {
              case "VALID":
                return x[b] = 0, x[P] = 0, Math.floor((o - O) / d + 1);
              case "SAME_LOWER":
              case "SAME_UPPER":
                if (g !== 1)
                  throw new Error("Dilation not supported for SAME_UPPER or SAME_LOWER");
                {
                  let $ = ((o + d - 1) / d - 1) * d + y - o;
                  return x[b] = Math.floor(k === "SAME_LOWER" ? ($ + 1) / 2 : $ / 2), x[P] = $ - x[b], Math.floor((o + $ - y) / d + 1);
                }
              default:
                throw new Error("Unsupported AutoPad type");
            }
          else
            return Math.floor((o + x[b] + x[P] - O) / d + 1);
        }
      }, Br = class {
        static getShapeOfGemmResult(s, o, d, g, y) {
          if (s.length !== 2 || d.length !== 2)
            throw new Error("shape need to be of size 2");
          let x, b, P;
          o ? (x = s[1], b = s[0]) : (x = s[0], b = s[1]);
          let k = -1;
          if (g ? (P = d[0], k = 1) : (P = d[1], k = 0), d[k] !== b)
            throw new Error("dimension mismatch");
          if (x <= 0 || P <= 0 || b <= 0)
            throw new Error("invalid shape specified");
          if (y && !Ui.isValidBroadcast(y, [x, P]))
            throw new Error("gemm: invalid bias shape for broadcast");
          return [x, P, b];
        }
      }, Xe = -34028234663852886e22, j = 34028234663852886e22;
    }), Ae, Re = l(() => {
      jt(), Ae = (s, o) => new (wi(o))(s);
    }), We, ot, Et, It, At, kt, Xt, fn, _n, Rn, En = l(() => {
      Lt(), We = (s, o = !0) => {
        if (s.byteLength % 8 !== 0)
          throw new Error("Invalid Uint8Array length - must be a multiple of 8 (BigInt).");
        let d = s.byteLength / 8, g = new BigInt64Array(s.buffer, s.byteOffset, d), y = new Int32Array(d);
        for (let x = 0; x < d; x++) {
          let b = g[x];
          if (b > 2147483647n || b < -2147483648n)
            throw new Error(`Overflow occurred when converting BigInt to Int32 at index ${x}: ${b}`);
          y[x] = Number(b);
        }
        return o ? new Uint8Array(y.buffer) : y;
      }, ot = (s, o = !0) => {
        if (s.byteLength % 4 !== 0)
          throw new Error("Invalid Uint8Array length - must be a multiple of 4 (Int32).");
        let d = s.byteLength / 4, g = new Int32Array(s.buffer, s.byteOffset, d), y = BigInt64Array.from(g, BigInt);
        return o ? new Uint8Array(y.buffer) : y;
      }, Et = 1, It = () => Et++, At = /* @__PURE__ */ new Map([["float32", 32], ["float16", 16], ["int32", 32], ["uint32", 32], ["int64", 64], ["uint64", 64], ["int8", 8], ["uint8", 8], ["int4", 4], ["uint4", 4]]), kt = (s, o) => {
        let d = At.get(s);
        if (!d)
          throw new Error("Unsupported data type.");
        return o.length > 0 ? Math.ceil(o.reduce((g, y) => g * y) * d / 8) : 0;
      }, Xt = class {
        constructor(s) {
          this.shouldConvertInt64toInt32 = !1, this.isInt64ToInt32Converted = !1;
          let { sessionId: o, context: d, tensor: g, dataType: y, shape: x, shouldConvertInt64toInt32: b = !1 } = s;
          this.sessionId = o, this.mlContext = d, this.mlTensor = g, this.dataType = y, this.tensorShape = x, this.shouldConvertInt64toInt32 = b;
        }
        get tensor() {
          return this.mlTensor;
        }
        get type() {
          return this.dataType;
        }
        get shape() {
          return this.tensorShape;
        }
        get byteLength() {
          return kt(this.dataType, this.tensorShape);
        }
        destroy() {
          ct("verbose", () => "[WebNN] TensorWrapper.destroy"), this.mlTensor.destroy();
        }
        write(s) {
          this.mlContext.writeTensor(this.mlTensor, s);
        }
        async read(s, o) {
          if (s) {
            let d = await this.mlContext.readTensor(this.mlTensor), g = ot(new Uint8Array(d));
            if (o) {
              (o instanceof ArrayBuffer ? new Uint8Array(o) : new Uint8Array(o.buffer, o.byteOffset, o.byteLength)).set(g);
              return;
            } else
              return g.buffer;
          } else
            return o ? this.mlContext.readTensor(this.mlTensor, o) : this.mlContext.readTensor(this.mlTensor);
        }
        canReuseTensor(s, o, d) {
          return this.mlContext === s && this.dataType === o && this.tensorShape.length === d.length && this.tensorShape.every((g, y) => g === d[y]);
        }
        setIsInt64ToInt32Converted(s) {
          this.isInt64ToInt32Converted = s;
        }
      }, fn = class {
        constructor(s, o) {
          this.tensorManager = s, this.wrapper = o;
        }
        get tensorWrapper() {
          return this.wrapper;
        }
        releaseTensor() {
          this.tensorWrapper && (this.tensorManager.releaseTensor(this.tensorWrapper), this.wrapper = void 0);
        }
        async ensureTensor(s, o, d, g) {
          let y = o, x = this.tensorManager.getMLContext(s), b = y === "int64" && !x.opSupportLimits().input.dataTypes.includes("int64");
          if (b && (y = "int32", ct("verbose", () => "[WebNN] TensorIdTracker.ensureTensor: convert dataType from int64 to int32")), this.wrapper) {
            if (this.wrapper.canReuseTensor(x, y, d))
              return this.wrapper.tensor;
            if (g) {
              if (this.wrapper.byteLength !== kt(y, d))
                throw new Error("Unable to copy data to tensor with different size.");
              this.activeUpload = new Uint8Array(await this.wrapper.read());
            }
            this.tensorManager.releaseTensor(this.wrapper);
          }
          let P = typeof MLTensorUsage > "u" ? void 0 : MLTensorUsage.READ | MLTensorUsage.WRITE;
          return this.wrapper = await this.tensorManager.getCachedTensor(s, y, d, P, !0, !0, b), g && this.activeUpload && (this.wrapper.write(this.activeUpload), this.activeUpload = void 0), this.wrapper.tensor;
        }
        upload(s) {
          let o = s;
          if (this.wrapper)
            if (this.wrapper.shouldConvertInt64toInt32 && (o = We(s, !0), this.wrapper.setIsInt64ToInt32Converted(!0)), o.byteLength === this.wrapper.byteLength) {
              this.wrapper.write(o);
              return;
            } else
              ct("verbose", () => "Data size does not match tensor size. Releasing tensor."), this.releaseTensor();
          this.activeUpload ? this.activeUpload.set(o) : this.activeUpload = new Uint8Array(o);
        }
        async download(s) {
          var o, d, g;
          if (this.activeUpload) {
            let y = (o = this.wrapper) != null && o.isInt64ToInt32Converted ? ot(this.activeUpload) : this.activeUpload;
            if (s) {
              s instanceof ArrayBuffer ? new Uint8Array(s).set(y) : new Uint8Array(s.buffer, s.byteOffset, s.byteLength).set(y);
              return;
            } else
              return y.buffer;
          }
          if (!this.wrapper)
            throw new Error("Tensor has not been created.");
          return s ? this.wrapper.read((d = this.wrapper) == null ? void 0 : d.shouldConvertInt64toInt32, s) : this.wrapper.read((g = this.wrapper) == null ? void 0 : g.shouldConvertInt64toInt32);
        }
      }, _n = class {
        constructor(s) {
          this.backend = s, this.tensorTrackersById = /* @__PURE__ */ new Map(), this.freeTensors = [], this.externalTensors = /* @__PURE__ */ new Set();
        }
        getMLContext(s) {
          let o = this.backend.getMLContext(s);
          if (!o)
            throw new Error("MLContext not found for session.");
          return o;
        }
        reserveTensorId() {
          let s = It();
          return this.tensorTrackersById.set(s, new fn(this)), s;
        }
        releaseTensorId(s) {
          let o = this.tensorTrackersById.get(s);
          o && (this.tensorTrackersById.delete(s), o.tensorWrapper && this.releaseTensor(o.tensorWrapper));
        }
        async ensureTensor(s, o, d, g, y) {
          ct("verbose", () => `[WebNN] TensorManager.ensureTensor {tensorId: ${o}, dataType: ${d}, shape: ${g}, copyOld: ${y}}`);
          let x = this.tensorTrackersById.get(o);
          if (!x)
            throw new Error("Tensor not found.");
          return x.ensureTensor(s, d, g, y);
        }
        upload(s, o) {
          let d = this.tensorTrackersById.get(s);
          if (!d)
            throw new Error("Tensor not found.");
          d.upload(o);
        }
        async download(s, o) {
          ct("verbose", () => `[WebNN] TensorManager.download {tensorId: ${s}, dstBuffer: ${o == null ? void 0 : o.byteLength}}`);
          let d = this.tensorTrackersById.get(s);
          if (!d)
            throw new Error("Tensor not found.");
          return d.download(o);
        }
        releaseTensorsForSession(s) {
          for (let o of this.freeTensors)
            o.sessionId === s && o.destroy();
          this.freeTensors = this.freeTensors.filter((o) => o.sessionId !== s);
        }
        registerTensor(s, o, d, g) {
          let y = this.getMLContext(s), x = It(), b = new Xt({ sessionId: s, context: y, tensor: o, dataType: d, shape: g });
          return this.tensorTrackersById.set(x, new fn(this, b)), this.externalTensors.add(b), x;
        }
        async getCachedTensor(s, o, d, g, y, x, b = !1) {
          let P = this.getMLContext(s);
          for (let [O, $] of this.freeTensors.entries())
            if ($.canReuseTensor(P, o, d)) {
              ct("verbose", () => `[WebNN] Reusing tensor {dataType: ${o}, shape: ${d}}`);
              let V = this.freeTensors.splice(O, 1)[0];
              return V.sessionId = s, V;
            }
          ct("verbose", () => `[WebNN] MLContext.createTensor {dataType: ${o}, shape: ${d}}`);
          let k = await P.createTensor({ dataType: o, shape: d, dimensions: d, usage: g, writable: y, readable: x });
          return new Xt({ sessionId: s, context: P, tensor: k, dataType: o, shape: d, shouldConvertInt64toInt32: b });
        }
        releaseTensor(s) {
          this.externalTensors.has(s) && this.externalTensors.delete(s), this.freeTensors.push(s);
        }
      }, Rn = (...s) => new _n(...s);
    }), Un, ui, xi, ms = l(() => {
      jt(), ge(), Re(), En(), Lt(), Un = /* @__PURE__ */ new Map([[1, "float32"], [10, "float16"], [6, "int32"], [12, "uint32"], [7, "int64"], [13, "uint64"], [22, "int4"], [21, "uint4"], [3, "int8"], [2, "uint8"], [9, "uint8"]]), ui = (s, o) => {
        if (s === o)
          return !0;
        if (s === void 0 || o === void 0)
          return !1;
        let d = Object.keys(s).sort(), g = Object.keys(o).sort();
        return d.length === g.length && d.every((y, x) => y === g[x] && s[y] === o[y]);
      }, xi = class {
        constructor(s) {
          this.tensorManager = Rn(this), this.mlContextBySessionId = /* @__PURE__ */ new Map(), this.sessionIdsByMLContext = /* @__PURE__ */ new Map(), this.mlContextCache = [], this.sessionGraphInputs = /* @__PURE__ */ new Map(), this.temporaryGraphInputs = [], this.temporarySessionTensorIds = /* @__PURE__ */ new Map(), pi(s.logLevel, !!s.debug);
        }
        get currentSessionId() {
          if (this.activeSessionId === void 0)
            throw new Error("No active session");
          return this.activeSessionId;
        }
        onRunStart(s) {
          ct("verbose", () => `[WebNN] onRunStart {sessionId: ${s}}`), this.activeSessionId = s;
        }
        onRunEnd(s) {
          ct("verbose", () => `[WebNN] onRunEnd {sessionId: ${s}}`);
          let o = this.temporarySessionTensorIds.get(s);
          if (o) {
            for (let d of o)
              ct("verbose", () => `[WebNN] releasing temporary tensor {tensorId: ${d}}`), this.tensorManager.releaseTensorId(d);
            this.temporarySessionTensorIds.delete(s), this.activeSessionId = void 0;
          }
        }
        async createMLContext(s) {
          if (s instanceof GPUDevice) {
            let d = this.mlContextCache.findIndex((g) => g.gpuDevice === s);
            if (d !== -1)
              return this.mlContextCache[d].mlContext;
            {
              let g = await navigator.ml.createContext(s);
              return this.mlContextCache.push({ gpuDevice: s, mlContext: g }), g;
            }
          } else if (s === void 0) {
            let d = this.mlContextCache.findIndex((g) => g.options === void 0 && g.gpuDevice === void 0);
            if (d !== -1)
              return this.mlContextCache[d].mlContext;
            {
              let g = await navigator.ml.createContext();
              return this.mlContextCache.push({ mlContext: g }), g;
            }
          }
          let o = this.mlContextCache.findIndex((d) => ui(d.options, s));
          if (o !== -1)
            return this.mlContextCache[o].mlContext;
          {
            let d = await navigator.ml.createContext(s);
            return this.mlContextCache.push({ options: s, mlContext: d }), d;
          }
        }
        registerMLContext(s, o) {
          this.mlContextBySessionId.set(s, o);
          let d = this.sessionIdsByMLContext.get(o);
          d || (d = /* @__PURE__ */ new Set(), this.sessionIdsByMLContext.set(o, d)), d.add(s), this.temporaryGraphInputs.length > 0 && (this.sessionGraphInputs.set(s, this.temporaryGraphInputs), this.temporaryGraphInputs = []);
        }
        onReleaseSession(s) {
          this.sessionGraphInputs.delete(s);
          let o = this.mlContextBySessionId.get(s);
          if (!o)
            return;
          this.tensorManager.releaseTensorsForSession(s), this.mlContextBySessionId.delete(s);
          let d = this.sessionIdsByMLContext.get(o);
          if (d.delete(s), d.size === 0) {
            this.sessionIdsByMLContext.delete(o);
            let g = this.mlContextCache.findIndex((y) => y.mlContext === o);
            g !== -1 && this.mlContextCache.splice(g, 1);
          }
        }
        getMLContext(s) {
          return this.mlContextBySessionId.get(s);
        }
        reserveTensorId() {
          return this.tensorManager.reserveTensorId();
        }
        releaseTensorId(s) {
          ct("verbose", () => `[WebNN] releaseTensorId {tensorId: ${s}}`), this.tensorManager.releaseTensorId(s);
        }
        async ensureTensor(s, o, d, g, y) {
          let x = Un.get(d);
          if (!x)
            throw new Error(`Unsupported ONNX data type: ${d}`);
          return this.tensorManager.ensureTensor(s ?? this.currentSessionId, o, x, g, y);
        }
        async createTemporaryTensor(s, o, d) {
          ct("verbose", () => `[WebNN] createTemporaryTensor {onnxDataType: ${o}, shape: ${d}}`);
          let g = Un.get(o);
          if (!g)
            throw new Error(`Unsupported ONNX data type: ${o}`);
          let y = this.tensorManager.reserveTensorId();
          await this.tensorManager.ensureTensor(s, y, g, d, !1);
          let x = this.temporarySessionTensorIds.get(s);
          return x ? x.push(y) : this.temporarySessionTensorIds.set(s, [y]), y;
        }
        uploadTensor(s, o) {
          if (!se().shouldTransferToMLTensor)
            throw new Error("Trying to upload to a MLTensor while shouldTransferToMLTensor is false");
          ct("verbose", () => `[WebNN] uploadTensor {tensorId: ${s}, data: ${o.byteLength}}`), this.tensorManager.upload(s, o);
        }
        async downloadTensor(s, o) {
          return this.tensorManager.download(s, o);
        }
        createMLTensorDownloader(s, o) {
          return async () => {
            let d = await this.tensorManager.download(s);
            return Ae(d, o);
          };
        }
        registerMLTensor(s, o, d, g) {
          let y = Un.get(d);
          if (!y)
            throw new Error(`Unsupported ONNX data type: ${d}`);
          let x = this.tensorManager.registerTensor(s, o, y, g);
          return ct("verbose", () => `[WebNN] registerMLTensor {tensor: ${o}, dataType: ${y}, dimensions: ${g}} -> {tensorId: ${x}}`), x;
        }
        registerMLConstant(s, o, d, g, y, x, b = !1) {
          if (!x)
            throw new Error("External mounted files are not available.");
          let P = s;
          s.startsWith("./") && (P = s.substring(2));
          let k = x.get(P);
          if (!k)
            throw new Error(`File with name ${P} not found in preloaded files.`);
          if (o + d > k.byteLength)
            throw new Error("Out of bounds: data offset and length exceed the external file data size.");
          let O = k.slice(o, o + d).buffer, $;
          switch (y.dataType) {
            case "float32":
              $ = new Float32Array(O);
              break;
            case "float16":
              $ = typeof Float16Array < "u" && Float16Array.from ? new Float16Array(O) : new Uint16Array(O);
              break;
            case "int32":
              $ = new Int32Array(O);
              break;
            case "uint32":
              $ = new Uint32Array(O);
              break;
            case "int64":
              b ? ($ = We(new Uint8Array(O), !1), y.dataType = "int32") : $ = new BigInt64Array(O);
              break;
            case "uint64":
              $ = new BigUint64Array(O);
              break;
            case "int8":
              $ = new Int8Array(O);
              break;
            case "int4":
            case "uint4":
            case "uint8":
              $ = new Uint8Array(O);
              break;
            default:
              throw new Error(`Unsupported data type: ${y.dataType} in creating WebNN Constant from external data.`);
          }
          return ct("verbose", () => `[WebNN] registerMLConstant {dataType: ${y.dataType}, shape: ${y.shape}}} ${b ? "(Note: it was int64 data type and registered to int32 as workaround)" : ""}`), g.constant(y, $);
        }
        registerGraphInput(s) {
          this.temporaryGraphInputs.push(s);
        }
        isGraphInput(s, o) {
          let d = this.sessionGraphInputs.get(s);
          return d ? d.includes(o) : !1;
        }
        isInt64Supported(s) {
          var o;
          return !!((o = this.mlContextBySessionId.get(s)) != null && o.opSupportLimits().input.dataTypes.includes("int64"));
        }
        flush() {
        }
      };
    }), ei = l(() => {
    }), gs, Cn, Vn, ii, Qi, Zi, si, es, Yn, jn = l(() => {
      Lt(), ei(), gs = /* @__PURE__ */ new Map([[64, 250], [128, 200], [256, 200], [512, 200], [2048, 230], [4096, 200], [8192, 50], [16384, 50], [32768, 50], [65536, 50], [131072, 50], [262144, 50], [524288, 50], [1048576, 50], [2097152, 30], [4194304, 20], [8388608, 10], [12582912, 10], [16777216, 10], [26214400, 15], [33554432, 22], [44236800, 2], [58982400, 6], [67108864, 6], [134217728, 6], [167772160, 6]]), Cn = [], Vn = (s) => Math.ceil(Number(s) / 16) * 16, ii = (s) => {
        for (let o = 0; o < Cn.length; o++) {
          let d = Cn[o];
          if (s <= d)
            return d;
        }
        return Math.ceil(s / 16) * 16;
      }, Qi = 1, Zi = () => Qi++, si = async (s, o, d, g) => {
        let y = Vn(d), x = s.device.createBuffer({ size: y, usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ });
        try {
          let b = s.getCommandEncoder();
          s.endComputePass(), b.copyBufferToBuffer(o, 0, x, 0, y), s.flush(), await x.mapAsync(GPUMapMode.READ);
          let P = x.getMappedRange();
          if (g) {
            let k = g();
            return k.set(new Uint8Array(P, 0, d)), k;
          } else
            return new Uint8Array(P.slice(0, d));
        } finally {
          x.destroy();
        }
      }, es = class {
        constructor(s) {
          this.backend = s, this.storageCache = /* @__PURE__ */ new Map(), this.freeBuffers = /* @__PURE__ */ new Map(), this.freeUniformBuffers = /* @__PURE__ */ new Map(), this.buffersPending = [], this.capturedPendingBuffers = /* @__PURE__ */ new Map();
          for (let [o] of gs)
            Cn.push(o), this.freeBuffers.set(o, []), this.freeUniformBuffers.set(o, []);
          this.sessionCount = 0;
        }
        upload(s, o) {
          let d = o.buffer, g = o.byteOffset, y = o.byteLength, x = Vn(y), b = this.storageCache.get(s);
          if (!b)
            throw new Error("gpu data for uploading does not exist");
          if (Number(b.originalSize) !== y)
            throw new Error(`inconsistent data size. gpu data size=${b.originalSize}, data size=${y}`);
          let P = this.backend.device.createBuffer({ mappedAtCreation: !0, size: x, usage: GPUBufferUsage.MAP_WRITE | GPUBufferUsage.COPY_SRC }), k = P.getMappedRange();
          new Uint8Array(k).set(new Uint8Array(d, g, y)), P.unmap();
          let O = this.backend.device.createCommandEncoder();
          O.copyBufferToBuffer(P, 0, b.gpuData.buffer, 0, x), this.backend.device.queue.submit([O.finish()]), P.destroy(), ct("verbose", () => `[WebGPU] GpuDataManager.upload(id=${s})`);
        }
        memcpy(s, o) {
          let d = this.storageCache.get(s);
          if (!d)
            throw new Error("source gpu data for memcpy does not exist");
          let g = this.storageCache.get(o);
          if (!g)
            throw new Error("destination gpu data for memcpy does not exist");
          if (d.originalSize !== g.originalSize)
            throw new Error("inconsistent source and destination gpu data size");
          let y = Vn(d.originalSize), x = this.backend.getCommandEncoder();
          this.backend.endComputePass(), x.copyBufferToBuffer(d.gpuData.buffer, 0, g.gpuData.buffer, 0, y);
        }
        registerExternalBuffer(s, o, d) {
          let g;
          if (d) {
            if (g = d[0], s === d[1])
              return ct("verbose", () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${o}) => id=${g}, buffer is the same, skip.`), g;
            if (this.backend.capturedCommandList.has(this.backend.currentSessionId))
              throw new Error(`Registering a different external buffer under graph capture mode is not supported yet.
             Please use the previous external buffer!`);
          } else
            g = Zi();
          return this.storageCache.set(g, { gpuData: { id: g, type: 0, buffer: s }, originalSize: o }), ct("verbose", () => `[WebGPU] GpuDataManager.registerExternalBuffer(size=${o}) => id=${g}, registered.`), g;
        }
        unregisterExternalBuffer(s) {
          s !== void 0 && (this.storageCache.delete(s), ct("verbose", () => `[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${s}`));
        }
        create(s, o = GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST) {
          let d = ii(s), g, y = (o & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE, x = (o & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM;
          if (y || x) {
            let P = (y ? this.freeBuffers : this.freeUniformBuffers).get(d);
            P ? P.length > 0 ? g = P.pop() : g = this.backend.device.createBuffer({ size: d, usage: o }) : g = this.backend.device.createBuffer({ size: d, usage: o });
          } else
            g = this.backend.device.createBuffer({ size: d, usage: o });
          let b = { id: Zi(), type: 0, buffer: g };
          return this.storageCache.set(b.id, { gpuData: b, originalSize: Number(s) }), ct("verbose", () => `[WebGPU] GpuDataManager.create(size=${s}) => id=${b.id}`), b;
        }
        get(s) {
          var o;
          return (o = this.storageCache.get(s)) == null ? void 0 : o.gpuData;
        }
        release(s) {
          let o = typeof s == "bigint" ? Number(s) : s, d = this.storageCache.get(o);
          if (!d) {
            if (this.storageCache.size === 0)
              return 0;
            throw new Error("releasing data does not exist");
          }
          return ct("verbose", () => `[WebGPU] GpuDataManager.release(id=${o}), gpuDataId=${d.gpuData.id}`), this.storageCache.delete(o), this.buffersPending.push(d.gpuData.buffer), d.originalSize;
        }
        async download(s, o) {
          let d = this.storageCache.get(Number(s));
          if (!d)
            throw new Error("data does not exist");
          await si(this.backend, d.gpuData.buffer, d.originalSize, o);
        }
        refreshPendingBuffers() {
          if (this.buffersPending.length !== 0)
            if (this.backend.sessionStatus === "default") {
              for (let s of this.buffersPending) {
                let o = gs.get(s.size);
                if ((s.usage & GPUBufferUsage.STORAGE) === GPUBufferUsage.STORAGE) {
                  let d = this.freeBuffers.get(s.size) || [];
                  o === void 0 || d.length >= o ? s.destroy() : d.push(s);
                } else if ((s.usage & GPUBufferUsage.UNIFORM) === GPUBufferUsage.UNIFORM) {
                  let d = this.freeUniformBuffers.get(s.size) || [];
                  o === void 0 || d.length >= o ? s.destroy() : d.push(s);
                } else
                  s.destroy();
              }
              this.buffersPending = [];
            } else {
              let s = this.capturedPendingBuffers.get(this.backend.currentSessionId);
              s || (s = [], this.capturedPendingBuffers.set(this.backend.currentSessionId, s));
              for (let o of this.buffersPending)
                s.push(o);
              this.buffersPending = [];
            }
        }
        dispose() {
          this.freeBuffers.forEach((s) => {
            s.forEach((o) => {
              o.destroy();
            });
          }), this.freeUniformBuffers.forEach((s) => {
            s.forEach((o) => {
              o.destroy();
            });
          }), this.storageCache.forEach((s) => {
            s.gpuData.buffer.destroy();
          }), this.capturedPendingBuffers.forEach((s) => {
            s.forEach((o) => {
              o.destroy();
            });
          }), this.storageCache = /* @__PURE__ */ new Map(), this.freeBuffers = /* @__PURE__ */ new Map(), this.freeUniformBuffers = /* @__PURE__ */ new Map(), this.capturedPendingBuffers = /* @__PURE__ */ new Map();
        }
        onCreateSession() {
          this.sessionCount += 1;
        }
        onReleaseSession(s) {
          let o = this.capturedPendingBuffers.get(s);
          o && (o.forEach((d) => {
            d.destroy();
          }), this.capturedPendingBuffers.delete(s)), this.sessionCount -= 1, this.sessionCount === 0 && (ct("warning", () => "[WebGPU] Clearing webgpu buffer cache"), this.storageCache.forEach((d) => {
            d.gpuData.buffer.destroy();
          }), this.storageCache = /* @__PURE__ */ new Map());
        }
      }, Yn = (...s) => new es(...s);
    }), Wn, Yt, pn = l(() => {
      Wn = class {
        constructor(s) {
          Object.assign(this, s);
        }
        get cacheKey() {
          return this.key || (this.key = Object.getOwnPropertyNames(this).sort().map((s) => `${this[s]}`).join(";")), this.key;
        }
      }, Yt = (s) => new Wn(s);
    }), ts, ns, Jn, di, Ut, Dn, Ta, is, Ls, Nt, zr, dt, $t, gr, Ea, Iu, Lu, sn = l(() => {
      jt(), ie(), ts = 64, ns = (s, o) => {
        if (o === 3)
          throw new Error("vec3 has same alignment as vec4, use vec4 instead");
        switch (Number(s)) {
          case 10:
            return o > 1 ? `vec${o}<f16>` : "f16";
          case 1:
            return o > 1 ? `vec${o}<f32>` : "f32";
          case 6:
            return o > 1 ? `vec${o}<i32>` : "i32";
          case 12:
            return o > 1 ? `vec${o}<u32>` : "u32";
          case 7:
            if (o > 1)
              throw new Error("currently not supported vecX of uint64 yet");
            return ["vec2<u32>", "i32"];
          case 13:
            if (o > 1)
              throw new Error("currently not supported vecX of uint64 yet");
            return ["vec2<u32>", "u32"];
          case 9:
            if (o !== 4)
              throw new Error("bool must be vec4");
            return ["u32", "vec4<bool>"];
          case 22:
            return "i32";
          case 21:
            return "u32";
          default:
            throw new Error(`Unknown data type: ${s}`);
        }
      }, Jn = (s, o = 1) => {
        let d = ns(s, o);
        return typeof d == "string" ? d : d[0];
      }, di = (s, o = 1) => {
        let d = ns(s, o);
        return typeof d == "string" ? d : d[1];
      }, Ut = (...s) => {
        let o = [];
        return s.forEach((d) => {
          d.length !== 0 && o.push({ type: 12, data: d }, { type: 12, data: it.computeStrides(d) });
        }), o;
      }, Dn = (s) => s % 4 === 0 ? 4 : s % 2 === 0 ? 2 : 1, Ta = (s = "f32", o, d = "0") => !o || o === 1 ? `${s}(${d})` : `vec${o}<${s}>(${d})`, is = (s, o, d) => s === "f32" ? d : o === 1 ? `f32(${d})` : `vec${o}<f32>(${d})`, Ls = (s, o) => o === 4 ? `(${s}.x + ${s}.y + ${s}.z + ${s}.w)` : o === 2 ? `(${s}.x + ${s}.y)` : o === 3 ? `(${s}.x + ${s}.y + ${s}.z)` : s, Nt = (s, o, d, g) => s.startsWith("uniforms.") && d > 4 ? typeof o == "string" ? g === "f16" ? `${s}[(${o}) / 8][(${o}) % 8 / 4][(${o}) % 8 % 4]` : `${s}[(${o}) / 4][(${o}) % 4]` : g === "f16" ? `${s}[${Math.floor(o / 8)}][${Math.floor(o % 8 / 4)}][${o % 8 % 4}]` : `${s}[${Math.floor(o / 4)}][${o % 4}]` : d > 1 ? `${s}[${o}]` : s, zr = (s, o, d, g, y) => {
        let x = typeof d == "number", b = x ? d : d.length, P = [...new Array(b).keys()], k = b < 2 ? "u32" : b <= 4 ? `vec${b}<u32>` : `array<u32, ${b}>`, O = ns(o, y), $ = typeof O == "string" ? O : O[1], V = typeof O == "string" ? O : O[0], G = { indices: k, value: $, storage: V, tensor: o }, ee = (Ze) => typeof Ze == "string" ? Ze : `${Ze}u`, X = { offsetToIndices: !1, indicesToOffset: !1, broadcastedIndicesToOffset: !1, set: !1, setByIndices: !1, get: !1, getByIndices: !1 }, re = x ? "uniforms." : "", Te = `${re}${s}_shape`, ue = `${re}${s}_strides`, ce = "";
        for (let Ze = 0; Ze < b - 1; Ze++)
          ce += `
    let dim${Ze} = current / ${Nt(ue, Ze, b)};
    let rest${Ze} = current % ${Nt(ue, Ze, b)};
    indices[${Ze}] = dim${Ze};
    current = rest${Ze};
    `;
        ce += `indices[${b - 1}] = current;`;
        let ke = b < 2 ? "" : `
  fn o2i_${s}(offset: u32) -> ${G.indices} {
    var indices: ${G.indices};
    var current = offset;
    ${ce}
    return indices;
  }`, Le = (Ze) => (X.offsetToIndices = !0, b < 2 ? Ze : `o2i_${s}(${Ze})`), M = [];
        if (b >= 2)
          for (let Ze = b - 1; Ze >= 0; Ze--)
            M.push(`${Nt(ue, Ze, b)} * (indices[${Ze}])`);
        let C = b < 2 ? "" : `
  fn i2o_${s}(indices: ${G.indices}) -> u32 {
    return ${M.join("+")};
  }`, z = (Ze) => (X.indicesToOffset = !0, b < 2 ? Ze : `i2o_${s}(${Ze})`), oe = (...Ze) => b === 0 ? "0u" : `${G.indices}(${Ze.map(ee).join(",")})`, ye = (Ze, ft) => b < 2 ? `${Ze}` : `${Nt(Ze, ft, b)}`, Pe = (Ze, ft, St) => b < 2 ? `${Ze}=${St};` : `${Nt(Ze, ft, b)}=${St};`, Ue = {}, Je = (Ze, ft) => {
          X.broadcastedIndicesToOffset = !0;
          let St = `${ft.name}broadcastedIndicesTo${s}Offset`;
          if (St in Ue)
            return `${St}(${Ze})`;
          let Ht = [];
          for (let cn = b - 1; cn >= 0; cn--) {
            let Sn = ft.indicesGet("outputIndices", cn + ft.rank - b);
            Ht.push(`${ye(ue, cn)} * (${Sn} % ${ye(Te, cn)})`);
          }
          return Ue[St] = `fn ${St}(outputIndices: ${ft.type.indices}) -> u32 {
             return ${Ht.length > 0 ? Ht.join("+") : "0u"};
           }`, `${St}(${Ze})`;
        }, st = (Ze, ft) => (() => {
          if (G.storage === G.value)
            return `${s}[${Ze}]=${ft};`;
          if (G.storage === "vec2<u32>" && G.value === "i32")
            return `${s}[${Ze}]=vec2<u32>(u32(${ft}), select(0u, 0xFFFFFFFFu, ${ft} < 0));`;
          if (G.storage === "vec2<u32>" && G.value === "u32")
            return `${s}[${Ze}]=vec2<u32>(u32(${ft}), 0u);`;
          if (G.storage === "u32" && G.value === "vec4<bool>")
            return `${s}[${Ze}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${ft}));`;
          throw new Error(`not supported combination of storage type ${G.storage} and value type ${G.value} yet`);
        })(), gt = (Ze) => (() => {
          if (G.storage === G.value)
            return `${s}[${Ze}]`;
          if (G.storage === "vec2<u32>" && G.value === "i32")
            return `i32(${s}[${Ze}].x)`;
          if (G.storage === "vec2<u32>" && G.value === "u32")
            return `u32(${s}[${Ze}].x)`;
          if (G.storage === "u32" && G.value === "vec4<bool>")
            return `vec4<bool>(bool(${s}[${Ze}] & 0xFFu), bool(${s}[${Ze}] & 0xFF00u), bool(${s}[${Ze}] & 0xFF0000u), bool(${s}[${Ze}] & 0xFF000000u))`;
          throw new Error(`not supported combination of storage type ${G.storage} and value type ${G.value} yet`);
        })(), wt = b < 2 ? "" : `
  fn get_${s}ByIndices(indices: ${G.indices}) -> ${$} {
    return ${gt(`i2o_${s}(indices)`)};
  }`, yt = b < 2 ? "" : (() => {
          let Ze = P.map((St) => `d${St}: u32`).join(", "), ft = P.map((St) => `d${St}`).join(", ");
          return `
  fn get_${s}(${Ze}) -> ${$} {
    return get_${s}ByIndices(${oe(ft)});
  }`;
        })(), ht = (...Ze) => {
          if (Ze.length !== b)
            throw new Error(`indices length must be ${b}`);
          let ft = Ze.map(ee).join(",");
          return b === 0 ? gt("0u") : b === 1 ? gt(ft[0]) : (X.get = !0, X.getByIndices = !0, X.indicesToOffset = !0, `get_${s}(${ft})`);
        }, Ot = (Ze) => b < 2 ? gt(Ze) : (X.getByIndices = !0, X.indicesToOffset = !0, `get_${s}ByIndices(${Ze})`), xt = b < 2 ? "" : `
  fn set_${s}ByIndices(indices: ${G.indices}, value: ${$}) {
    ${st(`i2o_${s}(indices)`, "value")}
  }`, Ct = b < 2 ? "" : (() => {
          let Ze = P.map((St) => `d${St}: u32`).join(", "), ft = P.map((St) => `d${St}`).join(", ");
          return `
  fn set_${s}(${Ze}, value: ${$}) {
    set_${s}ByIndices(${oe(ft)}, value);
  }`;
        })();
        return { impl: () => {
          let Ze = [], ft = !1;
          return X.offsetToIndices && (Ze.push(ke), ft = !0), X.indicesToOffset && (Ze.push(C), ft = !0), X.broadcastedIndicesToOffset && (Object.values(Ue).forEach((St) => Ze.push(St)), ft = !0), X.set && (Ze.push(Ct), ft = !0), X.setByIndices && (Ze.push(xt), ft = !0), X.get && (Ze.push(yt), ft = !0), X.getByIndices && (Ze.push(wt), ft = !0), !x && ft && Ze.unshift(`const ${Te} = ${G.indices}(${d.join(",")});`, `const ${ue} = ${G.indices}(${it.computeStrides(d).join(",")});`), Ze.join(`
`);
        }, type: G, offsetToIndices: Le, indicesToOffset: z, broadcastedIndicesToOffset: Je, indices: oe, indicesGet: ye, indicesSet: Pe, set: (...Ze) => {
          if (Ze.length !== b + 1)
            throw new Error(`indices length must be ${b}`);
          let ft = Ze[b];
          if (typeof ft != "string")
            throw new Error("value must be string");
          let St = Ze.slice(0, b).map(ee).join(",");
          return b === 0 ? st("0u", ft) : b === 1 ? st(St[0], ft) : (X.set = !0, X.setByIndices = !0, X.indicesToOffset = !0, `set_${s}(${St}, ${ft})`);
        }, setByOffset: st, setByIndices: (Ze, ft) => b < 2 ? st(Ze, ft) : (X.setByIndices = !0, X.indicesToOffset = !0, `set_${s}ByIndices(${Ze}, ${ft});`), get: ht, getByOffset: gt, getByIndices: Ot, usage: g, name: s, strides: ue, shape: Te, rank: b };
      }, dt = (s, o, d, g = 1) => zr(s, o, d, "input", g), $t = (s, o, d, g = 1) => zr(s, o, d, "output", g), gr = (s, o, d) => zr(s, o, d, "atomicOutput", 1), Ea = (s, o, d, g = 1) => zr(s, o, d, "internal", g), Iu = class {
        constructor(s, o) {
          this.normalizedDispatchGroup = s, this.limits = o, this.internalVariables = [], this.variables = [], this.uniforms = [], this.variableIndex = 0;
        }
        guardAgainstOutOfBoundsWorkgroupSizes(s) {
          return `if (global_idx >= ${typeof s == "number" ? `${s}u` : s}) { return; }`;
        }
        mainStart(s = ts) {
          let o = typeof s == "number" ? s : s[0], d = typeof s == "number" ? 1 : s[1], g = typeof s == "number" ? 1 : s[2];
          if (o > this.limits.maxComputeWorkgroupSizeX || d > this.limits.maxComputeWorkgroupSizeY || g > this.limits.maxComputeWorkgroupSizeZ)
            throw new Error(`workgroup size [${o}, ${d}, ${g}] exceeds the maximum workgroup size [${this.limits.maxComputeWorkgroupSizeX}, ${this.limits.maxComputeWorkgroupSizeY}, ${this.limits.maxComputeWorkgroupSizeZ}].`);
          if (o * d * g > this.limits.maxComputeInvocationsPerWorkgroup)
            throw new Error(`workgroup size [${o}, ${d}, ${g}] exceeds the maximum workgroup invocations ${this.limits.maxComputeInvocationsPerWorkgroup}.`);
          let y = this.normalizedDispatchGroup[1] === 1 && this.normalizedDispatchGroup[2] === 1, x = y ? `@builtin(global_invocation_id) global_id : vec3<u32>,
    @builtin(workgroup_id) workgroup_id : vec3<u32>,
    @builtin(local_invocation_index) local_idx : u32,
    @builtin(local_invocation_id) local_id : vec3<u32>` : `@builtin(global_invocation_id) global_id : vec3<u32>,
                                             @builtin(local_invocation_id) local_id : vec3<u32>,
    @builtin(local_invocation_index) local_idx : u32,
    @builtin(workgroup_id) workgroup_id : vec3<u32>,
    @builtin(num_workgroups) num_workgroups : vec3<u32>`, b = y ? `let global_idx = global_id.x;
         let workgroup_index = workgroup_id.x;` : `let workgroup_index = workgroup_id.z * num_workgroups[0] * num_workgroups[1] +
             workgroup_id.y * num_workgroups[0] + workgroup_id.x;
         let global_idx = workgroup_index * ${o * d * g}u + local_idx;`;
          return `@compute @workgroup_size(${o}, ${d}, ${g})
  fn main(${x}) {
    ${b}
  `;
        }
        appendVariableUniforms(s) {
          s.rank !== 0 && (s.shape.startsWith("uniforms.") && this.uniforms.push({ name: s.shape.replace("uniforms.", ""), type: "u32", length: s.rank }), s.strides.startsWith("uniforms.") && this.uniforms.push({ name: s.strides.replace("uniforms.", ""), type: "u32", length: s.rank }));
        }
        declareVariable(s, o) {
          if (s.usage === "internal")
            throw new Error("cannot use internal variable with declareVariable(). use registerInternalVariables() instead.");
          this.variables.push(s), this.appendVariableUniforms(s);
          let d = s.usage === "input" ? "read" : "read_write", g = s.usage === "atomicOutput" ? "atomic<i32>" : s.type.storage;
          return `@group(0) @binding(${o}) var<storage, ${d}> ${s.name}: array<${g}>;`;
        }
        declareVariables(...s) {
          return s.map((o) => this.declareVariable(o, this.variableIndex++)).join(`
`);
        }
        registerInternalVariable(s) {
          if (s.usage !== "internal")
            throw new Error("cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.");
          this.internalVariables.push(s), this.appendVariableUniforms(s);
        }
        registerInternalVariables(...s) {
          return s.forEach((o) => this.registerInternalVariable(o)), this;
        }
        registerUniform(s, o, d = 1) {
          return this.uniforms.push({ name: s, type: o, length: d }), this;
        }
        registerUniforms(s) {
          return this.uniforms = this.uniforms.concat(s), this;
        }
        uniformDeclaration() {
          if (this.uniforms.length === 0)
            return "";
          let s = [];
          for (let { name: o, type: d, length: g } of this.uniforms)
            if (g && g > 4)
              d === "f16" ? s.push(`@align(16) ${o}:array<mat2x4<${d}>, ${Math.ceil(g / 8)}>`) : s.push(`${o}:array<vec4<${d}>, ${Math.ceil(g / 4)}>`);
            else {
              let y = g == null || g === 1 ? d : `vec${g}<${d}>`;
              s.push(`${o}:${y}`);
            }
          return `
      struct Uniforms { ${s.join(", ")} };
      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`;
        }
        get additionalImplementations() {
          return this.uniformDeclaration() + this.variables.map((s) => s.impl()).join(`
`) + this.internalVariables.map((s) => s.impl()).join(`
`);
        }
        get variablesInfo() {
          if (this.uniforms.length === 0)
            return;
          let s = (o) => [12, 10, 1, 6][["u32", "f16", "f32", "i32"].indexOf(o)];
          return this.uniforms.map((o) => [s(o.type), o.length ?? 1]);
        }
      }, Lu = (s, o) => new Iu(s, o);
    }), Du, vo, ku, Ou, Sa, Fu, bi, Ru, Pa, Hs = l(() => {
      jt(), ie(), pn(), sn(), Du = (s, o) => {
        if (!s || s.length !== 1)
          throw new Error("Transpose requires 1 input.");
        if (o.length !== 0 && o.length !== s[0].dims.length)
          throw new Error(`perm size ${o.length} does not match input rank ${s[0].dims.length}`);
      }, vo = (s, o) => o.length !== 0 ? o : [...new Array(s).keys()].reverse(), ku = (s, o) => it.sortBasedOnPerm(s, vo(s.length, o)), Ou = (s, o, d, g) => {
        let y = `fn perm(i: ${g.type.indices}) -> ${d.type.indices} {
    var a: ${d.type.indices};`;
        for (let x = 0; x < o; ++x)
          y += `a[${s[x]}]=i[${x}];`;
        return y += "return a;}";
      }, Sa = (s, o) => {
        let d = [], g = [];
        for (let y = 0; y < s.length; ++y)
          s[y] !== 1 && d.push(s[y]), s[o[y]] !== 1 && g.push(o[y]);
        return { newShape: d, newPerm: g };
      }, Fu = (s, o) => {
        let d = 0;
        for (let g = 0; g < s.length; ++g)
          if (o[s[g]] !== 1) {
            if (s[g] < d)
              return !1;
            d = s[g];
          }
        return !0;
      }, bi = (s, o) => {
        let d = s.dataType, g = s.dims.length, y = vo(g, o), x = ku(s.dims, y), b = s.dims, P = x, k = g < 2 || Fu(y, s.dims), O;
        if (k)
          return O = (X) => {
            let re = dt("input", d, b, 4), Te = $t("output", d, P, 4);
            return `
  ${X.registerUniform("output_size", "u32").declareVariables(re, Te)}
  ${X.mainStart()}
    ${X.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    output[global_idx] = input[global_idx];
  }`;
          }, { name: "TransposeCopy", shaderCache: { inputDependencies: ["type"] }, getRunData: () => {
            let X = it.size(x);
            return { outputs: [{ dims: x, dataType: s.dataType }], dispatchGroup: { x: Math.ceil(X / 64 / 4) }, programUniforms: [{ type: 12, data: Math.ceil(X / 4) }] };
          }, getShaderSource: O };
        let { newShape: $, newPerm: V } = Sa(s.dims, y), G = it.areEqual(V, [2, 3, 1]), ee = it.areEqual(V, [3, 1, 2]);
        if ($.length === 2 || G || ee) {
          b = G ? [$[0], $[1] * $[2]] : ee ? [$[0] * $[1], $[2]] : $, P = [b[1], b[0]];
          let X = 16;
          return O = (re) => {
            let Te = dt("a", d, b.length), ue = $t("output", d, P.length);
            return `
  ${re.registerUniform("output_size", "u32").declareVariables(Te, ue)}
  var<workgroup> tile : array<array<${ue.type.value}, ${X + 1}>, ${X}>;
  ${re.mainStart([X, X, 1])}
    let stride = (uniforms.output_shape[1] - 1) / ${X} + 1;
    let workgroup_id_x = workgroup_index % stride;
    let workgroup_id_y = workgroup_index / stride;
    let input_col = workgroup_id_y * ${X}u + local_id.x;
    let input_row = workgroup_id_x * ${X}u + local_id.y;
    if (input_row < uniforms.a_shape[0] && input_col < uniforms.a_shape[1]) {
      tile[local_id.y][local_id.x] = ${Te.getByIndices(`${Te.type.indices}(input_row, input_col)`)};
    }
    workgroupBarrier();

    let output_col = workgroup_id_x * ${X}u + local_id.x;
    let output_row = workgroup_id_y * ${X}u + local_id.y;
    if (output_row < uniforms.output_shape[0] && output_col < uniforms.output_shape[1]) {
      ${ue.setByIndices(`${ue.type.indices}(output_row, output_col)`, "tile[local_id.x][local_id.y]")}
    }
  }`;
          }, { name: "TransposeShared", shaderCache: { inputDependencies: ["type"] }, getRunData: () => {
            let re = it.size(x);
            return { outputs: [{ dims: x, dataType: s.dataType }], dispatchGroup: { x: Math.ceil(P[1] / X), y: Math.ceil(P[0] / X) }, programUniforms: [{ type: 12, data: re }, ...Ut(b, P)] };
          }, getShaderSource: O };
        }
        return O = (X) => {
          let re = dt("a", d, b.length), Te = $t("output", d, P.length);
          return `
  ${X.registerUniform("output_size", "u32").declareVariables(re, Te)}

  ${Ou(y, g, re, Te)}

  ${X.mainStart()}
    ${X.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

    let indices = ${Te.offsetToIndices("global_idx")};
    let aIndices = perm(indices);

    ${Te.setByOffset("global_idx", re.getByIndices("aIndices"))}
  }`;
        }, { name: "Transpose", shaderCache: { hint: `${o}`, inputDependencies: ["rank"] }, getRunData: () => {
          let X = it.size(x);
          return { outputs: [{ dims: x, dataType: s.dataType }], dispatchGroup: { x: Math.ceil(X / 64) }, programUniforms: [{ type: 12, data: X }, ...Ut(b, P)] };
        }, getShaderSource: O };
      }, Ru = (s, o) => {
        Du(s.inputs, o.perm), s.compute(bi(s.inputs[0], o.perm));
      }, Pa = (s) => Yt({ perm: s.perm });
    }), Bu, Aa, Ca, wo, zu, $u, Nu, Uu, Gu, Vu, Fi, ju, Wu, Ia, Hu, xo, La, qu, Da, qs, Ku, Vy = l(() => {
      jt(), ie(), sn(), za(), Hs(), Bu = { max: "select(bestValue, candidate, candidate > bestValue)", min: "select(bestValue, candidate, candidate < bestValue)", mean: "bestValue + candidate", sum: "bestValue + candidate", prod: "bestValue * candidate", sumSquare: "bestValue + candidate * candidate", logSumExp: "bestValue + exp(candidate)", l1: "bestValue + abs(candidate)", l2: "bestValue + candidate * candidate", logSum: "bestValue + candidate" }, Aa = { max: "select(bestValue, candidate, candidate > bestValue)", min: "select(bestValue, candidate, candidate < bestValue)", mean: "bestValue + candidate", sum: "bestValue + candidate", prod: "bestValue * candidate", sumSquare: "bestValue + candidate", logSumExp: "bestValue + candidate", l1: "bestValue + candidate", l2: "bestValue + candidate", logSum: "bestValue + candidate" }, Ca = { max: "_A[offset]", min: "_A[offset]", mean: "0", sum: "0", prod: "1", sumSquare: "0", logSumExp: "0", l1: "0", l2: "0", logSum: "0" }, wo = { max: "bestValue", min: "bestValue", sum: "bestValue", prod: "bestValue", sumSquare: "bestValue", logSumExp: "log(bestValue)", l1: "bestValue", l2: "sqrt(bestValue)", logSum: "log(bestValue)" }, zu = (s, o) => {
        let d = [];
        for (let g = o - s; g < o; ++g)
          d.push(g);
        return d;
      }, $u = (s, o) => {
        let d = [], g = s.length;
        for (let x = 0; x < g; x++)
          o.indexOf(x) === -1 && d.push(s[x]);
        let y = o.map((x) => s[x]);
        return [d, y];
      }, Nu = (s, o) => {
        let d = s.length + o.length, g = [], y = 0;
        for (let x = 0; x < d; x++)
          o.indexOf(x) === -1 ? g.push(s[y++]) : g.push(1);
        return g;
      }, Uu = (s, o) => {
        for (let d = 0; d < s.length; ++d)
          if (s[s.length - d - 1] !== o - 1 - d)
            return !1;
        return !0;
      }, Gu = (s, o) => {
        let d = [];
        if (!Uu(s, o)) {
          for (let g = 0; g < o; ++g)
            s.indexOf(g) === -1 && d.push(g);
          s.forEach((g) => d.push(g));
        }
        return d;
      }, Vu = (s, o, d, g, y, x, b) => {
        let P = d[0].dims, k = it.size(x), O = it.size(b), $ = dt("_A", d[0].dataType, P), V = $t("output", y, x), G = 64;
        k === 1 && (G = 256);
        let ee = `
          var<workgroup> aBestValues : array<f32, ${G}>;
       `, X = (re) => `
        ${re.registerUniform("reduceSize", "u32").declareVariables($, V)}
        ${ee}
        fn DIV_CEIL(a : u32, b : u32) -> u32 {
          return ((a - 1u) / b + 1u);
         }
         ${re.mainStart(G)}

          let outputIndex = global_idx / ${G};
          let offset = outputIndex * uniforms.reduceSize;

          var bestValue = f32(${Ca[g]});
          let Length = uniforms.reduceSize;
          for (var k = local_idx; k < Length; k = k + ${G}) {
           let candidate = f32(${$.getByOffset("offset + k")});
           bestValue = ${Bu[g]};
          }
          aBestValues[local_idx] = bestValue;
          workgroupBarrier();

         var reduceSize = min(Length, ${G}u);
         for (var currentSize = reduceSize / 2u; reduceSize > 1u;
             currentSize = reduceSize / 2u) {
           let interval = DIV_CEIL(reduceSize, 2u);
           if (local_idx < currentSize) {
            let candidate = aBestValues[local_idx + interval];
            bestValue = ${Aa[g]};
            aBestValues[local_idx] = bestValue;
           }
           reduceSize = interval;
           workgroupBarrier();
         }

         if (local_idx == 0u) {
          ${V.setByOffset("outputIndex", `${g === "mean" ? `${V.type.storage}(bestValue / f32(uniforms.reduceSize))` : `${V.type.storage}(${wo[g]})`}`)};
         }
        }`;
        return { name: s, shaderCache: { hint: `${o};${G}`, inputDependencies: ["type"] }, getShaderSource: X, getRunData: () => ({ outputs: [{ dims: x, dataType: y }], dispatchGroup: { x: k }, programUniforms: [{ type: 12, data: O }] }) };
      }, Fi = (s, o, d, g) => {
        let y = s.inputs.length === 1 ? d : Mo(s.inputs, d), x = y.axes;
        x.length === 0 && !y.noopWithEmptyAxes && (x = s.inputs[0].dims.map((ee, X) => X));
        let b = it.normalizeAxes(x, s.inputs[0].dims.length), P = b, k = s.inputs[0], O = Gu(P, s.inputs[0].dims.length);
        O.length > 0 && (k = s.compute(bi(s.inputs[0], O), { inputs: [0], outputs: [-1] })[0], P = zu(P.length, k.dims.length));
        let [$, V] = $u(k.dims, P), G = $;
        y.keepDims && (G = Nu($, b)), s.compute(Vu(o, y.cacheKey, [k], g, s.inputs[0].dataType, G, V), { inputs: [k] });
      }, ju = (s, o) => {
        Fi(s, "ReduceMeanShared", o, "mean");
      }, Wu = (s, o) => {
        Fi(s, "ReduceL1Shared", o, "l1");
      }, Ia = (s, o) => {
        Fi(s, "ReduceL2Shared", o, "l2");
      }, Hu = (s, o) => {
        Fi(s, "ReduceLogSumExpShared", o, "logSumExp");
      }, xo = (s, o) => {
        Fi(s, "ReduceMaxShared", o, "max");
      }, La = (s, o) => {
        Fi(s, "ReduceMinShared", o, "min");
      }, qu = (s, o) => {
        Fi(s, "ReduceProdShared", o, "prod");
      }, Da = (s, o) => {
        Fi(s, "ReduceSumShared", o, "sum");
      }, qs = (s, o) => {
        Fi(s, "ReduceSumSquareShared", o, "sumSquare");
      }, Ku = (s, o) => {
        Fi(s, "ReduceLogSumShared", o, "logSum");
      };
    }), Gi, pg, bo, Mo, Vi, Xu, Yu, Ju, Qu, To, Zu, ed, td, ka, nd, ji, Oa, id, sd, Fa, rd, od, Ra, ad, ld, Ba, za = l(() => {
      jt(), ie(), pn(), sn(), Vy(), Gi = (s) => {
        if (!s || s.length === 0 || s.length > 2)
          throw new Error("Reduce op requires 1 or 2 inputs.");
        if (s.length === 2 && s[1].dims.length !== 1)
          throw new Error("Invalid axes input dims.");
      }, pg = (s) => ["", "", `var value = ${s.getByIndices("input_indices")};`, ""], bo = (s, o, d, g, y, x, b = !1, P = !1) => {
        let k = [], O = d[0].dims, $ = O.length, V = it.normalizeAxes(y, $), G = !P && V.length === 0;
        O.forEach((re, Te) => {
          G || V.indexOf(Te) >= 0 ? b && k.push(1) : k.push(re);
        });
        let ee = k.length, X = it.size(k);
        return { name: s, shaderCache: o, getShaderSource: (re) => {
          let Te = [], ue = dt("_A", d[0].dataType, $), ce = $t("output", x, ee), ke = g(ue, ce, V), Le = ke[2];
          for (let M = 0, C = 0; M < $; M++)
            G || V.indexOf(M) >= 0 ? (b && C++, Le = `for(var j${M}: u32 = 0; j${M} < ${O[M]}; j${M}++) {
                  ${ke[2].includes("last_index") ? `let last_index = j${M};` : ""}
                  ${ue.indicesSet("input_indices", M, `j${M}`)}
                  ${Le}
                }`) : (Te.push(`${ue.indicesSet("input_indices", M, ce.indicesGet("output_indices", C))};`), C++);
          return `

        ${re.registerUniform("output_size", "u32").declareVariables(ue, ce)}

        ${re.mainStart()}
          ${re.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
          var input_indices: ${ue.type.indices};
          let output_indices = ${ce.offsetToIndices("global_idx")};

          ${Te.join(`
`)}
          ${ke[0]}       // init ops for reduce max/min
          ${ke[1]}
          ${Le}
          ${ke[3]}
          ${ke.length === 4 ? ce.setByOffset("global_idx", "value") : ke.slice(4).join(`
`)}
        }`;
        }, getRunData: () => ({ outputs: [{ dims: k, dataType: x }], dispatchGroup: { x: Math.ceil(X / 64) }, programUniforms: [{ type: 12, data: X }, ...Ut(O, k)] }) };
      }, Mo = (s, o) => {
        let d = [];
        return s[1].dims[0] > 0 && s[1].getBigInt64Array().forEach((g) => d.push(Number(g))), Yt({ axes: d, keepDims: o.keepDims, noopWithEmptyAxes: o.noopWithEmptyAxes });
      }, Vi = (s, o, d, g) => {
        let y = s.inputs, x = y.length === 1 ? d : Mo(y, d);
        s.compute(bo(o, { hint: x.cacheKey, inputDependencies: ["rank"] }, [y[0]], x.noopWithEmptyAxes && x.axes.length === 0 ? pg : g, x.axes, y[0].dataType, x.keepDims, x.noopWithEmptyAxes), { inputs: [0] });
      }, Xu = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceLogSum", o, (d, g) => [`var value = ${g.type.storage}(0);`, "", `value += ${d.getByIndices("input_indices")};`, "value = log(value);"]);
      }, Yu = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceL1", o, (d, g) => [`var value = ${g.type.storage}(0);`, "", `value += abs(${d.getByIndices("input_indices")});`, ""]);
      }, Ju = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceL2", o, (d, g) => [`var t = ${g.type.value}(0); var value = ${g.type.value}(0);`, "", `t = ${d.getByIndices("input_indices")}; value += (t * t);`, "value = sqrt(value);"]);
      }, Qu = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceLogSumExp", o, (d, g) => [`var value = ${g.type.storage}(0);`, "", `value += exp(${d.getByIndices("input_indices")});`, "value = log(value);"]);
      }, To = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceMax", o, (d, g, y) => {
          let x = [];
          for (let b = 0; b < d.rank; b++)
            (y.indexOf(b) >= 0 || y.length === 0) && x.push(d.indicesSet("input_indices", b, 0));
          return [`${x.join(`
`)}`, `var value = ${d.getByIndices("input_indices")};`, `value = max(value, ${d.getByIndices("input_indices")});`, ""];
        });
      }, Zu = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceMean", o, (d, g, y) => {
          let x = 1;
          for (let b = 0; b < d.rank; b++)
            (y.indexOf(b) >= 0 || y.length === 0) && (x *= s.inputs[0].dims[b]);
          return ["var sum = f32(0);", "", `sum += f32(${d.getByIndices("input_indices")});`, `let value = ${g.type.value}(sum / ${x});`];
        });
      }, ed = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceMin", o, (d, g, y) => {
          let x = [];
          for (let b = 0; b < d.rank; b++)
            (y.indexOf(b) >= 0 || y.length === 0) && x.push(`input_indices[${b}] = 0;`);
          return [`${x.join(`
`)}`, `var value = ${d.getByIndices("input_indices")};`, `value = min(value, ${d.getByIndices("input_indices")});`, ""];
        });
      }, td = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceProd", o, (d, g) => [`var value = ${g.type.storage}(1);`, "", `value *= ${d.getByIndices("input_indices")};`, ""]);
      }, ka = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceSum", o, (d, g) => [`var value = ${g.type.storage}(0);`, "", `value += ${d.getByIndices("input_indices")};`, ""]);
      }, nd = (s, o) => {
        Gi(s.inputs), Vi(s, "ReduceSumSquare", o, (d, g) => [`var t = ${g.type.value}(0); var value = ${g.type.value}(0);`, "", `t = ${d.getByIndices("input_indices")}; value += t * t;`, ""]);
      }, ji = (s, o, d) => {
        if (o.length === 0)
          return d;
        let g = 1, y = 1;
        for (let x = 0; x < o.length; x++)
          o.indexOf(x) === -1 ? g *= s[x] : y *= s[x];
        return y < 32 && g > 1024;
      }, Oa = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? Zu(s, o) : ju(s, o);
      }, id = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? Yu(s, o) : Wu(s, o);
      }, sd = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? Ju(s, o) : Ia(s, o);
      }, Fa = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? Qu(s, o) : Hu(s, o);
      }, rd = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? To(s, o) : xo(s, o);
      }, od = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? ed(s, o) : La(s, o);
      }, Ra = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? td(s, o) : qu(s, o);
      }, ad = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? ka(s, o) : Da(s, o);
      }, ld = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? nd(s, o) : qs(s, o);
      }, Ba = (s, o) => {
        ji(s.inputs[0].dims, o.axes, o.noopWithEmptyAxes) ? Xu(s, o) : Ku(s, o);
      };
    }), $a, Na, cd, Ua, ud = l(() => {
      jt(), pn(), za(), $a = (s) => {
        if (!s || s.length === 0 || s.length > 2)
          throw new Error("ArgMinMaxOp op requires 1 or 2 inputs.");
        if (s[0].dataType !== 1)
          throw new Error("Invalid input type.");
      }, Na = (s, o) => {
        $a(s.inputs);
        let d = (g, y, x) => {
          let b = [];
          for (let P = 0; P < g.rank; P++)
            (x.indexOf(P) >= 0 || x.length === 0) && b.push(`input_indices[${P}] = 0;`);
          return [`${b.join(`
`)}`, `var value = ${g.getByIndices("input_indices")};
var best_index : i32 = 0;`, `if (${g.getByIndices("input_indices")} ${o.selectLastIndex > 0 ? "<=" : "<"} value) {
         value = ${g.getByIndices("input_indices")};
         best_index = i32(last_index);
       }`, "", y.setByOffset("global_idx", "best_index")];
        };
        s.compute(bo("ArgMin", { hint: o.cacheKey, inputDependencies: ["rank"] }, [s.inputs[0]], d, [o.axis], 7, o.keepDims), { inputs: [0] });
      }, cd = (s, o) => {
        $a(s.inputs);
        let d = (g, y, x) => {
          let b = [];
          for (let P = 0; P < g.rank; P++)
            (x.indexOf(P) >= 0 || x.length === 0) && b.push(`input_indices[${P}] = 0;`);
          return [`${b.join(`
`)}`, `var value = ${g.getByIndices("input_indices")};
var best_index : i32 = 0;`, `if (${g.getByIndices("input_indices")} ${o.selectLastIndex > 0 ? ">=" : ">"} value) {
         value = ${g.getByIndices("input_indices")};
         best_index = i32(last_index);
       }`, "", y.setByOffset("global_idx", "best_index")];
        };
        s.compute(bo("argMax", { hint: o.cacheKey, inputDependencies: ["rank"] }, [s.inputs[0]], d, [o.axis], 7, o.keepDims), { inputs: [0] });
      }, Ua = (s) => Yt(s);
    }), dd, Eo, Ga, hd, fd, _r, pd, md, Va = l(() => {
      jt(), ie(), ei(), sn(), dd = (s, o) => {
        let d = s[0], g = s[1], y = s[2], x = s[3], b = s[4], P = s[5];
        if (b && P)
          throw new Error("Attention cannot have both past and attention_bias");
        if (d.dims.length !== 3)
          throw new Error('Input "input" must have 3 dimensions');
        let k = d.dims[0], O = d.dims[1], $ = d.dims[2];
        if (y.dims.length !== 1)
          throw new Error('Input "bias" is expected to have 1 dimensions');
        if (g.dims.length !== 2)
          throw new Error('Input "weights" is expected to have 2 dimensions');
        if (g.dims[0] !== $)
          throw new Error("Input 1 dimension 0 should have same length as dimension 2 of input 0");
        if (y.dims[0] !== g.dims[1])
          throw new Error('Input "bias" dimension 0 should have same length as dimension 1 of input "weights"');
        let V = y.dims[0] / 3, G = V, ee = G;
        if (o.qkvHiddenSizes.length > 0) {
          if (o.qkvHiddenSizes.length !== 3)
            throw new Error("qkv_hidden_sizes attribute should have 3 elements");
          for (let ke of o.qkvHiddenSizes)
            if (ke % o.numHeads !== 0)
              throw new Error("qkv_hidden_sizes should be divisible by num_heads");
          V = o.qkvHiddenSizes[0], G = o.qkvHiddenSizes[1], ee = o.qkvHiddenSizes[2];
        }
        let X = O;
        if (V !== G)
          throw new Error("qkv_hidden_sizes first element should be same as the second");
        if (y.dims[0] !== V + G + ee)
          throw new Error('Input "bias" dimension 0 should have same length as sum of Q/K/V hidden sizes');
        let re = 0;
        if (b) {
          if (G !== ee)
            throw new Error('Input "past" expect k_hidden_size == v_hidden_size');
          if (b.dims.length !== 5)
            throw new Error('Input "past" must have 5 dimensions');
          if (b.dims[0] !== 2)
            throw new Error('Input "past" first dimension must be 2');
          if (b.dims[1] !== k)
            throw new Error('Input "past" second dimension must be batch_size');
          if (b.dims[2] !== o.numHeads)
            throw new Error('Input "past" third dimension must be num_heads');
          if (b.dims[4] !== G / o.numHeads)
            throw new Error('Input "past" fifth dimension must be k_hidden_size / num_heads');
          o.pastPresentShareBuffer || (re = b.dims[3]);
        }
        let Te = X + re, ue = -1, ce = 0;
        if (x)
          throw new Error("Mask not supported");
        if (b)
          throw new Error("past is not supported");
        if (P) {
          if (P.dims.length !== 4)
            throw new Error('Input "attention_bias" must have 4 dimensions');
          if (P.dims[0] !== k || P.dims[1] !== o.numHeads || P.dims[2] !== O || P.dims[3] !== Te)
            throw new Error('Expect "attention_bias" shape (batch_size, num_heads, sequence_length, total_sequence_length)');
        }
        return { batchSize: k, sequenceLength: O, pastSequenceLength: re, kvSequenceLength: X, totalSequenceLength: Te, maxSequenceLength: ue, inputHiddenSize: $, hiddenSize: V, vHiddenSize: ee, headSize: Math.floor(V / o.numHeads), vHeadSize: Math.floor(ee / o.numHeads), numHeads: o.numHeads, isUnidirectional: !1, pastPresentShareBuffer: !1, maskFilterValue: o.maskFilterValue, maskType: ce, scale: o.scale, broadcastResPosBias: !1, passPastInKv: !1, qkvFormat: 1 };
      }, Eo = (s, o, d) => o && s ? `
      let total_sequence_length_input = u32(${o.getByOffset("0")});
      let present_sequence_length = max(total_sequence_length_input, uniforms.past_sequence_length);
      let is_subsequent_prompt: bool = sequence_length > 1 && sequence_length != total_sequence_length_input;
      let is_first_prompt: bool = is_subsequent_prompt == false && sequence_length == total_sequence_length_input;
      total_sequence_length = u32(${s == null ? void 0 : s.getByOffset("batchIdx")}) + 1;
      var past_sequence_length: u32 = 0;
      if (is_first_prompt == false) {
        past_sequence_length = total_sequence_length - sequence_length;
      }
       ` : `
    ${d ? "let past_sequence_length = uniforms.past_sequence_length" : ""};
    let present_sequence_length = total_sequence_length;
    `, Ga = (s, o, d, g, y, x, b, P) => {
        let k = Dn(b ? 1 : x), O = 64, $ = x / k;
        $ < O && (O = 32);
        let V = Math.ceil(x / k / O), G = [{ type: 12, data: o }, { type: 12, data: d }, { type: 12, data: g }, { type: 12, data: y }, { type: 12, data: $ }, { type: 12, data: V }], ee = Jn(s.dataType, k), X = di(1, k), re = ["type"];
        b && re.push("type"), P && re.push("type");
        let Te = (ue) => {
          let ce = $t("x", s.dataType, s.dims, k), ke = [ce], Le = b ? dt("seq_lens", b.dataType, b.dims) : void 0;
          Le && ke.push(Le);
          let M = P ? dt("total_sequence_length_input", P.dataType, P.dims) : void 0;
          M && ke.push(M);
          let C = di(s.dataType), z = [{ name: "batch_size", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "past_sequence_length", type: "u32" }, { name: "sequence_length", type: "u32" }, { name: "total_sequence_length", type: "u32" }, { name: "elements_per_thread", type: "u32" }];
          return `
  var<workgroup> thread_max: array<f32, ${O}>;
  var<workgroup> thread_sum: array<f32, ${O}>;
  ${ue.registerUniforms(z).declareVariables(...ke)}
  ${ue.mainStart([O, 1, 1])}
    let batchIdx = workgroup_id.z / uniforms.num_heads;
    let headIdx = workgroup_id.z % uniforms.num_heads;
    let sequence_length = uniforms.sequence_length;
    var total_sequence_length = uniforms.total_sequence_length;
    ${Eo(Le, M, !1)}
    let local_offset = local_idx * uniforms.elements_per_thread;
    let offset = (global_idx / ${O}) * uniforms.total_sequence_length + local_offset;
    let seq_causal_length = ${b ? "u32(past_sequence_length + workgroup_id.y + 1)" : "total_sequence_length"};
    var thread_max_vector = ${X}(-3.402823e+38f);
    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
      thread_max_vector = max(${X}(x[offset + i]), thread_max_vector);
    }
    thread_max[local_idx] = ${(() => {
            switch (k) {
              case 1:
                return "thread_max_vector";
              case 2:
                return "max(thread_max_vector.x, thread_max_vector.y)";
              case 4:
                return "max(max(thread_max_vector.x, thread_max_vector.y), max(thread_max_vector.z, thread_max_vector.w))";
              default:
                throw new Error(`Unsupported components: ${k}`);
            }
          })()};
    workgroupBarrier();

    var max_value =  f32(-3.402823e+38f);
    for (var i = 0u; i < ${O}; i++) {
      max_value = max(thread_max[i], max_value);
    }

    var sum_vector = ${X}(0);
    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
      sum_vector += exp(${X}(x[offset + i]) - max_value);
    }
    thread_sum[local_idx] = ${(() => {
            switch (k) {
              case 1:
                return "sum_vector";
              case 2:
                return "sum_vector.x + sum_vector.y";
              case 4:
                return "sum_vector.x + sum_vector.y + sum_vector.z + sum_vector.w";
              default:
                throw new Error(`Unsupported components: ${k}`);
            }
          })()};
    workgroupBarrier();

    var sum: f32 = 0;
    for (var i = 0u; i < ${O}; i++) {
      sum += thread_sum[i];
    }

    if (sum == 0) {
      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
        x[offset + i] = ${ce.type.value}(${C}(1.0) / ${C}(seq_causal_length));
      }
    } else {
      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {
        var f32input = ${X}(x[offset + i]);
        x[offset + i] = ${ce.type.value}(exp(f32input - max_value) / sum);
      }
    }
      ${b ? `
        for (var total_seq_id: u32 = seq_causal_length; total_seq_id + local_offset < uniforms.total_sequence_length; total_seq_id++) {
          x[offset + total_seq_id] = ${ce.type.value}(${C}(0));
        }` : ""};
  }`;
        };
        return { name: "AttentionProbsSoftmax", shaderCache: { hint: `${O};${ee};${k}`, inputDependencies: re }, getShaderSource: Te, getRunData: () => ({ outputs: [], dispatchGroup: { x: 1, y, z: o * d }, programUniforms: G }) };
      }, hd = (s, o, d, g, y, x, b, P, k) => {
        let O = b + x.kvSequenceLength, $ = [x.batchSize, x.numHeads, x.sequenceLength, O], V = s > 1 && g, G = x.kvNumHeads ? x.kvNumHeads : x.numHeads, ee = V ? [x.batchSize, G, O, x.headSize] : void 0, X = x.nReps ? x.nReps : 1, re = x.scale === 0 ? 1 / Math.sqrt(x.headSize) : x.scale, Te = Dn(x.headSize), ue = x.headSize / Te, ce = 12, ke = { x: Math.ceil(O / ce), y: Math.ceil(x.sequenceLength / ce), z: x.batchSize * x.numHeads }, Le = [{ type: 12, data: x.sequenceLength }, { type: 12, data: ue }, { type: 12, data: O }, { type: 12, data: x.numHeads }, { type: 12, data: x.headSize }, { type: 1, data: re }, { type: 12, data: b }, { type: 12, data: x.kvSequenceLength }, { type: 12, data: X }], M = V && g && it.size(g.dims) > 0, C = ["type", "type"];
        M && C.push("type"), y && C.push("type"), P && C.push("type"), k && C.push("type");
        let z = [{ dims: $, dataType: o.dataType, gpuDataType: 0 }];
        V && z.push({ dims: ee, dataType: o.dataType, gpuDataType: 0 });
        let oe = (ye) => {
          let Pe = dt("q", o.dataType, o.dims, Te), Ue = dt("key", d.dataType, d.dims, Te), Je = [Pe, Ue];
          if (M) {
            let xt = dt("past_key", g.dataType, g.dims, Te);
            Je.push(xt);
          }
          y && Je.push(dt("attention_bias", y.dataType, y.dims));
          let st = P ? dt("seq_lens", P.dataType, P.dims) : void 0;
          st && Je.push(st);
          let gt = k ? dt("total_sequence_length_input", k.dataType, k.dims) : void 0;
          gt && Je.push(gt);
          let wt = $t("output", o.dataType, $), yt = [wt];
          V && yt.push($t("present_key", o.dataType, ee, Te));
          let ht = di(1, Te), Ot = [{ name: "M", type: "u32" }, { name: "K", type: "u32" }, { name: "N", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "head_size", type: "u32" }, { name: "alpha", type: "f32" }, { name: "past_sequence_length", type: "u32" }, { name: "kv_sequence_length", type: "u32" }, { name: "n_reps", type: "u32" }];
          return `
  const TILE_SIZE = ${ce}u;

  var<workgroup> tileQ: array<${Pe.type.storage}, ${ce * ce}>;
  var<workgroup> tileK: array<${Pe.type.storage}, ${ce * ce}>;
  ${ye.registerUniforms(Ot).declareVariables(...Je, ...yt)}
  ${ye.mainStart([ce, ce, 1])}
    // x holds the N and y holds the M
    let headIdx = workgroup_id.z % uniforms.num_heads;
    let kvHeadIdx = ${X === 1 ? "headIdx" : "headIdx / uniforms.n_reps"};
    let kv_num_heads = ${X === 1 ? "uniforms.num_heads" : "uniforms.num_heads / uniforms.n_reps"};
    let batchIdx = workgroup_id.z / uniforms.num_heads;
    let m = workgroup_id.y * TILE_SIZE;
    let n = workgroup_id.x * TILE_SIZE;
    let sequence_length = uniforms.M;
    var total_sequence_length = uniforms.N;
    ${Eo(st, gt, !0)}
    let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx;
    let qOffset = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;
    ${M && V ? "let pastKeyOffset = absKvHeadIdx * uniforms.past_sequence_length * uniforms.K;" : ""};
    let kOffset = absKvHeadIdx * uniforms.kv_sequence_length * uniforms.K;
    ${V ? "let presentKeyOffset = absKvHeadIdx * uniforms.N * uniforms.K;" : ""}
    var value = ${ht}(0);
    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {
      if (global_id.y < uniforms.M && w + local_id.x < uniforms.K) {
        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * uniforms.K + w + local_id.x];
      }
      if (n + local_id.y < uniforms.N && w + local_id.x < uniforms.K) {
        var idx = TILE_SIZE * local_id.y + local_id.x;
      ${M && V ? `
              if (n + local_id.y < past_sequence_length) {
                tileK[idx] = past_key[pastKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x];
              } else if (n + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {
                tileK[idx] = key[kOffset + (n + local_id.y - past_sequence_length) * uniforms.K + w + local_id.x];
              }` : `
          if (n + local_id.y < uniforms.kv_sequence_length) {
            tileK[idx] = key[kOffset + (n + local_id.y) * uniforms.K + w + local_id.x];
          }`}
      ${V ? `if (n + local_id.y < present_sequence_length) {
        present_key[presentKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x] = tileK[idx];
      }` : ""}
      }
      workgroupBarrier();

      for (var k: u32 = 0u; k < TILE_SIZE && w+k < uniforms.K; k++) {
          value += ${ht}(tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k]);
      }

      workgroupBarrier();
    }

    if (global_id.y < uniforms.M && global_id.x < total_sequence_length) {
      let headOffset = workgroup_id.z * uniforms.M * uniforms.N;
      let outputIdx = headOffset + global_id.y * uniforms.N + global_id.x;
      var sum: f32 = ${(() => {
            switch (Te) {
              case 1:
                return "value";
              case 2:
                return "value.x + value.y";
              case 4:
                return "value.x + value.y + value.z + value.w";
              default:
                throw new Error(`Unsupported components: ${Te}`);
            }
          })()};
        output[outputIdx] = ${wt.type.value} (sum * uniforms.alpha) + ${y ? "attention_bias[outputIdx]" : "0.0"};
    }
  }`;
        };
        return { name: "AttentionProbs", shaderCache: { hint: `${Te};${y !== void 0};${g !== void 0};${s}`, inputDependencies: C }, getRunData: () => ({ outputs: z, dispatchGroup: ke, programUniforms: Le }), getShaderSource: oe };
      }, fd = (s, o, d, g, y, x, b = void 0, P = void 0) => {
        let k = x + y.kvSequenceLength, O = y.nReps ? y.nReps : 1, $ = y.vHiddenSize * O, V = s > 1 && g, G = y.kvNumHeads ? y.kvNumHeads : y.numHeads, ee = V ? [y.batchSize, G, k, y.headSize] : void 0, X = [y.batchSize, y.sequenceLength, $], re = 12, Te = { x: Math.ceil(y.vHeadSize / re), y: Math.ceil(y.sequenceLength / re), z: y.batchSize * y.numHeads }, ue = [{ type: 12, data: y.sequenceLength }, { type: 12, data: k }, { type: 12, data: y.vHeadSize }, { type: 12, data: y.numHeads }, { type: 12, data: y.headSize }, { type: 12, data: $ }, { type: 12, data: x }, { type: 12, data: y.kvSequenceLength }, { type: 12, data: O }], ce = V && g && it.size(g.dims) > 0, ke = ["type", "type"];
        ce && ke.push("type"), b && ke.push("type"), P && ke.push("type");
        let Le = [{ dims: X, dataType: o.dataType, gpuDataType: 0 }];
        V && Le.push({ dims: ee, dataType: o.dataType, gpuDataType: 0 });
        let M = (C) => {
          let z = dt("probs", o.dataType, o.dims), oe = dt("v", d.dataType, d.dims), ye = [z, oe];
          ce && ye.push(dt("past_value", g.dataType, g.dims));
          let Pe = b ? dt("seq_lens", b.dataType, b.dims) : void 0;
          b && ye.push(Pe);
          let Ue = P ? dt("total_sequence_length_input", P.dataType, P.dims) : void 0;
          P && ye.push(Ue);
          let Je = [$t("output", o.dataType, X)];
          V && Je.push($t("present_value", o.dataType, ee));
          let st = [{ name: "M", type: "u32" }, { name: "K", type: "u32" }, { name: "N", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "head_size", type: "u32" }, { name: "v_hidden_size", type: "u32" }, { name: "past_sequence_length", type: "u32" }, { name: "kv_sequence_length", type: "u32" }, { name: "n_reps", type: "u32" }];
          return `
  const TILE_SIZE = ${re}u;
  var<workgroup> tileQ: array<${z.type.value}, ${re * re}>;
  var<workgroup> tileV: array<${z.type.value}, ${re * re}>;
  ${C.registerUniforms(st).declareVariables(...ye, ...Je)}
  ${C.mainStart([re, re, 1])}
   let headIdx = workgroup_id.z % uniforms.num_heads;
   let batchIdx = workgroup_id.z / uniforms.num_heads;
   let kvHeadIdx = ${O === 1 ? "headIdx" : "headIdx / uniforms.n_reps"};
   let kv_num_heads = ${O === 1 ? "uniforms.num_heads" : "uniforms.num_heads / uniforms.n_reps"};
   let m = global_id.y;
   let n = global_id.x;
   let sequence_length = uniforms.M;
   var total_sequence_length = uniforms.K;
   ${Eo(Pe, Ue, !0)}
   let offsetA = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;
   let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx; // kvHeadIdx is relative to the batch
   ${ce && V ? "let pastValueOffset = absKvHeadIdx * uniforms.N * uniforms.past_sequence_length + n;" : ""};
   let vOffset = absKvHeadIdx * uniforms.N * uniforms.kv_sequence_length + n;
   ${V ? "let presentValueOffset = absKvHeadIdx * uniforms.N * uniforms.K + n;" : ""}
   var value = ${z.type.storage}(0);
   for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {
      if (m < uniforms.M && w + local_id.x < uniforms.K) {
        tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];
      }
      if (n < uniforms.N && w + local_id.y < uniforms.K) {
        var idx = TILE_SIZE * local_id.y + local_id.x;
        ${ce && V ? `
        if (w + local_id.y < past_sequence_length) {
          tileV[idx] = past_value[pastValueOffset + (w + local_id.y) * uniforms.N];
        } else if (w + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {
          tileV[idx] = v[vOffset + (w + local_id.y - past_sequence_length) * uniforms.N];
        }
      ` : `
            if (w + local_id.y < uniforms.kv_sequence_length) {
              tileV[idx] = v[vOffset + (w + local_id.y) * uniforms.N];
            }`}
        ${V ? `
            if (w + local_id.y < present_sequence_length) {
          present_value[presentValueOffset + (w + local_id.y) * uniforms.N] = tileV[idx];
        }` : ""}
      }
     workgroupBarrier();
     for (var k: u32 = 0u; k < TILE_SIZE && w+k < total_sequence_length; k++) {
       value += tileQ[TILE_SIZE * local_id.y + k] * tileV[TILE_SIZE * k + local_id.x];
     }
     workgroupBarrier();
   }

   // we need to transpose output from BNSH_v to BSND_v
   if (m < uniforms.M && n < uniforms.N) {
     let outputIdx = batchIdx * uniforms.M * uniforms.v_hidden_size + m * uniforms.v_hidden_size
       + headIdx * uniforms.N + n;
     output[outputIdx] = value;
   }
  }`;
        };
        return { name: "AttentionScore", shaderCache: { hint: `${g !== void 0};${s}`, inputDependencies: ke }, getRunData: () => ({ outputs: Le, dispatchGroup: Te, programUniforms: ue }), getShaderSource: M };
      }, _r = (s, o, d, g, y, x, b, P, k, O, $ = void 0, V = void 0) => {
        let G = Math.min(s.outputCount, 1 + (b ? 1 : 0) + (P ? 1 : 0)), ee = G > 1 ? O.pastSequenceLength : 0, X = ee + O.kvSequenceLength, re = k && it.size(k.dims) > 0 ? k : void 0, Te = [o, d];
        G > 1 && b && it.size(b.dims) > 0 && Te.push(b), re && Te.push(re), $ && Te.push($), V && Te.push(V);
        let ue = s.compute(hd(G, o, d, b, re, O, ee, $, V), { inputs: Te, outputs: G > 1 ? [-1, 1] : [-1] })[0];
        s.compute(Ga(ue, O.batchSize, O.numHeads, ee, O.sequenceLength, X, $, V), { inputs: $ && V ? [ue, $, V] : [ue], outputs: [] });
        let ce = [ue, g];
        G > 1 && P && it.size(P.dims) > 0 && ce.push(P), $ && ce.push($), V && ce.push(V), s.compute(fd(G, ue, g, P, O, ee, $, V), { inputs: ce, outputs: G > 1 ? [0, 2] : [0] });
      }, pd = (s, o) => {
        let d = [o.batchSize, o.numHeads, o.sequenceLength, o.headSize], g = o.sequenceLength, y = o.inputHiddenSize, x = o.headSize, b = 12, P = { x: Math.ceil(o.headSize / b), y: Math.ceil(o.sequenceLength / b), z: o.batchSize * o.numHeads }, k = [s.inputs[0], s.inputs[1], s.inputs[2]], O = [{ type: 12, data: g }, { type: 12, data: y }, { type: 12, data: x }, { type: 12, data: o.numHeads }, { type: 12, data: o.headSize }, { type: 12, data: o.hiddenSize }, { type: 12, data: o.hiddenSize + o.hiddenSize + o.vHiddenSize }], $ = (V) => {
          let G = $t("output_q", k[0].dataType, d), ee = $t("output_k", k[0].dataType, d), X = $t("output_v", k[0].dataType, d), re = dt("input", k[0].dataType, k[0].dims), Te = dt("weight", k[1].dataType, k[1].dims), ue = dt("bias", k[2].dataType, k[2].dims), ce = re.type.storage, ke = [{ name: "M", type: "u32" }, { name: "K", type: "u32" }, { name: "N", type: "u32" }, { name: "num_heads", type: "u32" }, { name: "head_size", type: "u32" }, { name: "hidden_size", type: "u32" }, { name: "ldb", type: "u32" }];
          return `
  const TILE_SIZE = ${b}u;
  var<workgroup> tileInput: array<${ce}, ${b * b}>;
  var<workgroup> tileWeightQ: array<${ce}, ${b * b}>;
  var<workgroup> tileWeightK: array<${ce}, ${b * b}>;
  var<workgroup> tileWeightV: array<${ce}, ${b * b}>;
  ${V.registerUniforms(ke).declareVariables(re, Te, ue, G, ee, X)}
  ${V.mainStart([b, b, 1])}
    let batchIndex = workgroup_id.z / uniforms.num_heads;
    let headNumber = workgroup_id.z % uniforms.num_heads;
    let m = global_id.y;
    let n = global_id.x;

    let inputOffset = batchIndex * (uniforms.M * uniforms.K) + m * uniforms.K;
    let biasOffsetQ = headNumber * uniforms.head_size;
    let biasOffsetK = uniforms.hidden_size + biasOffsetQ;
    let biasOffsetV = uniforms.hidden_size + biasOffsetK;

    var valueQ = ${ce}(0);
    var valueK = ${ce}(0);
    var valueV = ${ce}(0);
    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {
      if (m < uniforms.M && w + local_id.x < uniforms.K) {
        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];
      }
      if (n < uniforms.N && w + local_id.y < uniforms.K) {
        let offset = n + (w + local_id.y) * uniforms.ldb;
        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];
        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];
        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];
      }
      workgroupBarrier();
      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {
        let inputTileOffset = TILE_SIZE * local_id.y + k;
        let weightTileOffset = TILE_SIZE * k + local_id.x;
        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];
        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];
        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];
      }

      workgroupBarrier();
    }

    let headOffset = (m * uniforms.N + n) % uniforms.head_size;
    valueQ += bias[headOffset + biasOffsetQ];
    valueK += bias[headOffset + biasOffsetK];
    valueV += bias[headOffset + biasOffsetV];

    let offset = workgroup_id.z * uniforms.M * uniforms.N;
    if (m < uniforms.M && n < uniforms.N) {
      let outputIdx = offset + m * uniforms.N + n;
      output_q[outputIdx] = valueQ;
      output_k[outputIdx] = valueK;
      output_v[outputIdx] = valueV;
    }
  }`;
        };
        return s.compute({ name: "AttentionPrepare", shaderCache: { inputDependencies: ["type", "type", "type"] }, getRunData: () => ({ outputs: [{ dims: d, dataType: s.inputs[0].dataType, gpuDataType: 0 }, { dims: d, dataType: s.inputs[0].dataType, gpuDataType: 0 }, { dims: d, dataType: s.inputs[0].dataType, gpuDataType: 0 }], dispatchGroup: P, programUniforms: O }), getShaderSource: $ }, { inputs: k, outputs: [-1, -1, -1] });
      }, md = (s, o) => {
        let d = dd(s.inputs, o), [g, y, x] = pd(s, d);
        return _r(s, g, y, x, s.inputs[4], void 0, void 0, void 0, s.inputs[5], d);
      };
    }), gd, ja, _d, yd, vd = l(() => {
      qe(), jt(), ie(), pn(), sn(), gd = (s, o) => {
        if (!s || s.length !== 5)
          throw new Error("BatchNormalization requires 5 inputs");
        let d = (g, y, x) => {
          let b = y.length;
          if (b !== g.length)
            throw new Error(`${x}: num dimensions != ${b}`);
          y.forEach((P, k) => {
            if (P !== g[k])
              throw new Error(`${x}: dim[${k}] do not match`);
          });
        };
        if (s[0].dims.length > 1) {
          let g = o.format === "NHWC" ? o.spatial ? s[0].dims.slice(-1) : s[0].dims.slice(-1).concat(s[0].dims.slice(1, s[0].dims.length - 1)) : s[0].dims.slice(1, o.spatial ? 2 : void 0);
          d(s[1].dims, g, "Invalid input scale"), d(s[2].dims, g, "Invalid input B"), d(s[3].dims, g, "Invalid input mean"), d(s[4].dims, g, "Invalid input var");
        } else
          d(s[1].dims, [1], "Invalid input scale"), d(s[2].dims, [1], "Invalid input B"), d(s[3].dims, [1], "Invalid input mean"), d(s[4].dims, [1], "Invalid input var");
      }, ja = (s, o) => {
        let { epsilon: d, spatial: g, format: y } = o, x = s[0].dims, b = g ? Dn(x[x.length - 1]) : 1, P = y === "NHWC" && x.length > 1 ? b : 1, k = it.size(x) / b, O = g, $ = O ? x.length : x, V = dt("x", s[0].dataType, s[0].dims, b), G = dt("scale", s[1].dataType, s[1].dims, P), ee = dt("bias", s[2].dataType, s[2].dims, P), X = dt("inputMean", s[3].dataType, s[3].dims, P), re = dt("inputVar", s[4].dataType, s[4].dims, P), Te = $t("y", s[0].dataType, $, b), ue = () => {
          let ke = "";
          if (g)
            ke = `let cOffset = ${x.length === 1 ? "0u" : y === "NHWC" ? `outputIndices[${x.length - 1}] / ${b}` : "outputIndices[1]"};`;
          else if (y === "NCHW")
            ke = `
            ${Te.indicesSet("outputIndices", "0", "0")}
            let cOffset = ${Te.indicesToOffset("outputIndices")};`;
          else {
            ke = `var cIndices = ${G.type.indices}(0);
                       cIndices[0] = outputIndices[${x.length - 1}];`;
            for (let Le = 1; Le < G.rank; Le++)
              ke += `cIndices[${Le}] = outputIndices[${Le}];`;
            ke += `let cOffset = ${G.indicesToOffset("cIndices")};`;
          }
          return ke;
        }, ce = (ke) => `
  const epsilon = ${d};
  ${ke.registerUniform("outputSize", "u32").declareVariables(V, G, ee, X, re, Te)}
  ${ke.mainStart()}
  ${ke.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
    var outputIndices = ${Te.offsetToIndices(`global_idx * ${b}`)};
    ${ue()}
    let scale = ${G.getByOffset("cOffset")};
    let bias = ${ee.getByOffset("cOffset")};
    let inputMean = ${X.getByOffset("cOffset")};
    let inputVar = ${re.getByOffset("cOffset")};
    let x = ${V.getByOffset("global_idx")};
    let value = (x - inputMean) * inverseSqrt(inputVar + epsilon) * scale + bias;
    ${Te.setByOffset("global_idx", "value")}
  }`;
        return { name: "BatchNormalization", shaderCache: { hint: `${o.epsilon}_${o.format}_${g}_${b}`, inputDependencies: O ? ["rank", "type", "type", "type", "type"] : void 0 }, getShaderSource: ce, getRunData: () => ({ outputs: [{ dims: s[0].dims, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(k / 64) }, programUniforms: O ? [{ type: 12, data: k }, ...Ut(x)] : [{ type: 12, data: k }] }) };
      }, _d = (s) => Yt(s), yd = (s, o) => {
        let { inputs: d, outputCount: g } = s, y = _d({ ...o, outputCount: g });
        if (R.webgpu.validateInputContent && gd(d, y), o.trainingMode)
          throw new Error("BatchNormalization trainingMode is not supported yet.");
        s.compute(ja(d, y));
      };
    }), wd, xd, Wa, mg = l(() => {
      ie(), sn(), wd = (s) => {
        if (s[0].dims.length !== 3)
          throw new Error("input should have 3 dimensions");
        if (![320, 640, 1280].includes(s[0].dims[2]))
          throw new Error("number of channels should be 320, 640 or 1280");
        if (s[1].dims.length !== 1)
          throw new Error("bias is expected to have 1 dimensions");
        if (s[0].dims[2] !== s[1].dims[0])
          throw new Error("last dimension of input and bias are not the same");
      }, xd = (s) => {
        let o = s[0].dims, d = s[0].dims[2], g = it.size(o) / 4, y = s[0].dataType, x = dt("input", y, o, 4), b = dt("bias", y, [d], 4), P = dt("residual", y, o, 4), k = $t("output", y, o, 4);
        return { name: "BiasAdd", getRunData: () => ({ outputs: [{ dims: o, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(g / 64) } }), getShaderSource: (O) => `
  const channels = ${d}u / 4;
  ${O.declareVariables(x, b, P, k)}

  ${O.mainStart()}
    ${O.guardAgainstOutOfBoundsWorkgroupSizes(g)}
    let value = ${x.getByOffset("global_idx")}
      + ${b.getByOffset("global_idx % channels")} + ${P.getByOffset("global_idx")};
    ${k.setByOffset("global_idx", "value")}
  }` };
      }, Wa = (s) => {
        wd(s.inputs), s.compute(xd(s.inputs));
      };
    }), bd, hn, Md, Td, Ha, Ed, Sd, qa, Pd, Ad, Ka, Cd, Id, Xa, Ld, Dd, yr, kd, So, Ya, Od, Fd, Ja, Rd, Bd, Qa, zd, $d, Za, Nd, Ud, el, Gd, Vd, tl, nl, jd, Po, il, Wd, sl, Hd, qd, rl, Kd, ol = l(() => {
      jt(), ie(), pn(), sn(), bd = (s, o, d, g, y, x, b) => {
        let P = Math.ceil(o / 4), k = "";
        typeof y == "string" ? k = `${y}(a)` : k = y("a");
        let O = dt("inputData", d, [P], 4), $ = $t("outputData", g, [P], 4), V = [{ name: "vec_size", type: "u32" }];
        return b && V.push(...b), `
      ${s.registerUniforms(V).declareVariables(O, $)}

  ${x ?? ""}

  ${s.mainStart()}
    ${s.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}

    let a = ${O.getByOffset("global_idx")};
    ${$.setByOffset("global_idx", k)}
  }`;
      }, hn = (s, o, d, g, y, x = s.dataType, b, P) => {
        let k = [{ type: 12, data: Math.ceil(it.size(s.dims) / 4) }];
        return b && k.push(...b), { name: o, shaderCache: { hint: y, inputDependencies: ["type"] }, getShaderSource: (O) => bd(O, it.size(s.dims), s.dataType, x, d, g, P), getRunData: (O) => ({ outputs: [{ dims: s.dims, dataType: x }], dispatchGroup: { x: Math.ceil(it.size(O[0].dims) / 64 / 4) }, programUniforms: k }) };
      }, Md = (s) => {
        s.compute(hn(s.inputs[0], "Abs", "abs"));
      }, Td = (s) => {
        s.compute(hn(s.inputs[0], "Acos", "acos"));
      }, Ha = (s) => {
        s.compute(hn(s.inputs[0], "Acosh", "acosh"));
      }, Ed = (s) => {
        s.compute(hn(s.inputs[0], "Asin", "asin"));
      }, Sd = (s) => {
        s.compute(hn(s.inputs[0], "Asinh", "asinh"));
      }, qa = (s) => {
        s.compute(hn(s.inputs[0], "Atan", "atan"));
      }, Pd = (s) => {
        s.compute(hn(s.inputs[0], "Atanh", "atanh"));
      }, Ad = (s) => Yt(s), Ka = (s, o) => {
        let d;
        switch (o.to) {
          case 10:
            d = "vec4<f16>";
            break;
          case 1:
            d = "vec4<f32>";
            break;
          case 12:
            d = "vec4<u32>";
            break;
          case 6:
            d = "vec4<i32>";
            break;
          case 9:
            d = "vec4<bool>";
            break;
          default:
            throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${o.to}`);
        }
        s.compute(hn(s.inputs[0], "Cast", d, void 0, o.cacheKey, o.to));
      }, Cd = (s) => {
        let o, d, g = s.length >= 2 && s[1].data !== 0, y = s.length >= 3 && s[2].data !== 0;
        switch (s[0].dataType) {
          case 1:
            o = g ? s[1].getFloat32Array()[0] : -34028234663852886e22, d = y ? s[2].getFloat32Array()[0] : 34028234663852886e22;
            break;
          case 10:
            o = g ? s[1].getUint16Array()[0] : 64511, d = y ? s[2].getUint16Array()[0] : 31743;
            break;
          default:
            throw new Error("Unsupport data type");
        }
        return Yt({ min: o, max: d });
      }, Id = (s, o) => {
        let d = o || Cd(s.inputs), g = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "Clip", (y) => `clamp(${y}, vec4<${g}>(uniforms.min), vec4<${g}>(uniforms.max))`, void 0, d.cacheKey, void 0, [{ type: s.inputs[0].dataType, data: d.min }, { type: s.inputs[0].dataType, data: d.max }], [{ name: "min", type: g }, { name: "max", type: g }]), { inputs: [0] });
      }, Xa = (s) => {
        s.compute(hn(s.inputs[0], "Ceil", "ceil"));
      }, Ld = (s) => {
        s.compute(hn(s.inputs[0], "Cos", "cos"));
      }, Dd = (s) => {
        s.compute(hn(s.inputs[0], "Cosh", "cosh"));
      }, yr = (s) => Yt(s), kd = (s, o) => {
        let d = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "Elu", (g) => `elu_vf32(${g})`, `
  const elu_alpha_ = ${d}(${o.alpha});

  fn elu_f32(a: ${d}) -> ${d} {
  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);
  }

  fn elu_vf32(v: vec4<${d}>) -> vec4<${d}> {
  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));
  }`, o.cacheKey));
      }, So = (s = "f32") => `
const r0: ${s} = 0.3275911;
const r1: ${s} = 0.254829592;
const r2: ${s} = -0.284496736;
const r3: ${s} = 1.421413741;
const r4: ${s} = -1.453152027;
const r5: ${s} = 1.061405429;

fn erf_vf32(v: vec4<${s}>) -> vec4<${s}> {
  let absv = abs(v);
  let x = 1.0 / (1.0 + r0 * absv);
  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));
}`, Ya = (s) => {
        let o = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "Erf", (d) => `erf_vf32(${d})`, So(o)));
      }, Od = (s) => {
        s.compute(hn(s.inputs[0], "Exp", "exp"));
      }, Fd = (s) => {
        s.compute(hn(s.inputs[0], "Floor", "floor"));
      }, Ja = (s) => {
        let o = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "Gelu", (d) => `0.5 * ${d} * (1.0 + erf_vf32(${d} * 0.7071067811865475))`, So(o)));
      }, Rd = (s, o) => {
        let d = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "LeakyRelu", (g) => `select(leaky_relu_alpha_ * ${g}, ${g}, ${g} >= vec4<${d}>(0.0))`, `const leaky_relu_alpha_ = ${d}(${o.alpha});`, o.cacheKey));
      }, Bd = (s) => {
        s.compute(hn(s.inputs[0], "Not", (o) => `!${o}`));
      }, Qa = (s) => {
        s.compute(hn(s.inputs[0], "Neg", (o) => `-${o}`));
      }, zd = (s) => {
        s.compute(hn(s.inputs[0], "Reciprocal", (o) => `1.0/${o}`));
      }, $d = (s) => {
        let o = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "Relu", (d) => `select(vec4<${o}>(0.0), ${d}, ${d} > vec4<${o}>(0.0))`));
      }, Za = (s) => {
        s.compute(hn(s.inputs[0], "Sigmoid", (o) => `(1.0 / (1.0 + exp(-${o})))`));
      }, Nd = (s) => Yt(s), Ud = (s, o) => {
        let d = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "HardSigmoid", (g) => `max(vec4<${d}>(0.0), min(vec4<${d}>(1.0), ${o.alpha} * ${g} + vec4<${d}>(${o.beta})))`, void 0, o.cacheKey));
      }, el = (s) => {
        s.compute(hn(s.inputs[0], "Sin", "sin"));
      }, Gd = (s) => {
        s.compute(hn(s.inputs[0], "Sinh", "sinh"));
      }, Vd = (s) => {
        s.compute(hn(s.inputs[0], "Sqrt", "sqrt"));
      }, tl = (s) => {
        s.compute(hn(s.inputs[0], "Tan", "tan"));
      }, nl = (s) => `sign(${s}) * (1 - exp(-2 * abs(${s}))) / (1 + exp(-2 * abs(${s})))`, jd = (s) => {
        s.compute(hn(s.inputs[0], "Tanh", nl));
      }, Po = (s = "f32") => `
const fast_gelu_a: ${s} = 0.5;
const fast_gelu_b: ${s} = 0.7978845608028654;
const fast_gelu_c: ${s} = 0.035677408136300125;

fn tanh_v(v: vec4<${s}>) -> vec4<${s}> {
  return ${nl("v")};
}
`, il = (s) => `(fast_gelu_a + fast_gelu_a * tanh_v(${s} * (fast_gelu_c * ${s} * ${s} + fast_gelu_b))) * ${s}`, Wd = (s) => {
        let o = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "FastGelu", il, Po(o), void 0, s.inputs[0].dataType));
      }, sl = (s, o) => {
        let d = di(s.inputs[0].dataType);
        return s.compute(hn(s.inputs[0], "ThresholdedRelu", (g) => `select(vec4<${d}>(0.0), ${g}, ${g} > thresholded_relu_alpha_)`, `const thresholded_relu_alpha_ = vec4<${d}>(${o.alpha});`, o.cacheKey)), 0;
      }, Hd = (s) => {
        s.compute(hn(s.inputs[0], "Log", "log"));
      }, qd = (s, o) => `
const alpha = vec4<${s}>(${o});
const one = ${s}(1.0);
const zero = ${s}(0.0);

fn quick_gelu_impl(x: vec4<${s}>) -> vec4<${s}> {
  let v = x *alpha;
  var x1 : vec4<${s}>;
  for (var i = 0; i < 4; i = i + 1) {
    if (v[i] >= zero) {
      x1[i] = one / (one + exp(-v[i]));
    } else {
      x1[i] = one - one / (one + exp(v[i]));
    }
  }
  return x * x1;
}
`, rl = (s) => `quick_gelu_impl(${s})`, Kd = (s, o) => {
        let d = di(s.inputs[0].dataType);
        s.compute(hn(s.inputs[0], "QuickGelu", rl, qd(d, o.alpha), o.cacheKey, s.inputs[0].dataType));
      };
    }), al, Xd, Yd, Jd = l(() => {
      ie(), sn(), ol(), al = (s) => {
        if (s[0].dims.length !== 3)
          throw new Error("input should have 3 dimensions");
        if (![2560, 5120, 10240].includes(s[0].dims[2]))
          throw new Error("hidden state should be 2560, 5120 or 10240");
        if (s[1].dims.length !== 1)
          throw new Error("bias is expected to have 1 dimensions");
        if (s[0].dims[2] !== s[1].dims[0])
          throw new Error("last dimension of input and bias are not the same");
      }, Xd = (s) => {
        let o = s[0].dims.slice();
        o[2] = o[2] / 2;
        let d = dt("input", s[0].dataType, s[0].dims, 4), g = dt("bias", s[0].dataType, [s[0].dims[2]], 4), y = $t("output", s[0].dataType, o, 4), x = it.size(o) / 4, b = Jn(s[0].dataType);
        return { name: "BiasSplitGelu", getRunData: () => ({ outputs: [{ dims: o, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(x / 64) } }), getShaderSource: (P) => `
  const M_SQRT2 = sqrt(2.0);
  const halfChannels = ${s[0].dims[2] / 4 / 2}u;

  ${P.declareVariables(d, g, y)}

  ${So(b)}

  ${P.mainStart()}
    ${P.guardAgainstOutOfBoundsWorkgroupSizes(x)}
    let biasIdx = global_idx % halfChannels;
    let batchIndex = global_idx / halfChannels;
    let inputOffset = biasIdx + batchIndex * halfChannels * 2;
    let valueLeft = input[inputOffset] + bias[biasIdx];
    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];
    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);

    ${y.setByOffset("global_idx", "valueLeft * geluRight")}
  }` };
      }, Yd = (s) => {
        al(s.inputs), s.compute(Xd(s.inputs));
      };
    }), Qd, Zd, Wi, eh, ll, th, nh, cl, ih, sh, ul, rh, oh, ah = l(() => {
      jt(), ie(), sn(), Qd = (s, o, d, g, y, x, b, P, k, O, $, V) => {
        let G, ee;
        typeof P == "string" ? G = ee = (ce, ke) => `${P}((${ce}),(${ke}))` : typeof P == "function" ? G = ee = P : (G = P.scalar, ee = P.vector);
        let X = $t("outputData", $, g.length, 4), re = dt("aData", k, o.length, 4), Te = dt("bData", O, d.length, 4), ue;
        if (y)
          if (x) {
            let ce = it.size(o) === 1, ke = it.size(d) === 1, Le = o.length > 0 && o[o.length - 1] % 4 === 0, M = d.length > 0 && d[d.length - 1] % 4 === 0;
            ce || ke ? ue = X.setByOffset("global_idx", ee(ce ? `${re.type.value}(${re.getByOffset("0")}.x)` : re.getByOffset("global_idx"), ke ? `${Te.type.value}(${Te.getByOffset("0")}.x)` : Te.getByOffset("global_idx"))) : ue = `
            let outputIndices = ${X.offsetToIndices("global_idx * 4u")};
            let offsetA = ${re.broadcastedIndicesToOffset("outputIndices", X)};
            let offsetB = ${Te.broadcastedIndicesToOffset("outputIndices", X)};
            ${X.setByOffset("global_idx", ee(b || Le ? re.getByOffset("offsetA / 4u") : `${re.type.value}(${re.getByOffset("offsetA / 4u")}[offsetA % 4u])`, b || M ? Te.getByOffset("offsetB / 4u") : `${Te.type.value}(${Te.getByOffset("offsetB / 4u")}[offsetB % 4u])`))}
          `;
          } else
            ue = X.setByOffset("global_idx", ee(re.getByOffset("global_idx"), Te.getByOffset("global_idx")));
        else {
          if (!x)
            throw new Error("no necessary to use scalar implementation for element-wise binary op implementation.");
          let ce = (ke, Le, M = "") => {
            let C = `aData[indexA${Le}][componentA${Le}]`, z = `bData[indexB${Le}][componentB${Le}]`;
            return `
            let outputIndices${Le} = ${X.offsetToIndices(`global_idx * 4u + ${Le}u`)};
            let offsetA${Le} = ${re.broadcastedIndicesToOffset(`outputIndices${Le}`, X)};
            let offsetB${Le} = ${Te.broadcastedIndicesToOffset(`outputIndices${Le}`, X)};
            let indexA${Le} = offsetA${Le} / 4u;
            let indexB${Le} = offsetB${Le} / 4u;
            let componentA${Le} = offsetA${Le} % 4u;
            let componentB${Le} = offsetB${Le} % 4u;
            ${ke}[${Le}] = ${M}(${G(C, z)});
          `;
          };
          $ === 9 ? ue = `
            var data = vec4<u32>(0);
            ${ce("data", 0, "u32")}
            ${ce("data", 1, "u32")}
            ${ce("data", 2, "u32")}
            ${ce("data", 3, "u32")}
            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));` : ue = `
            ${ce("outputData[global_idx]", 0)}
            ${ce("outputData[global_idx]", 1)}
            ${ce("outputData[global_idx]", 2)}
            ${ce("outputData[global_idx]", 3)}
          `;
        }
        return `
        ${s.registerUniform("vec_size", "u32").declareVariables(re, Te, X)}

        ${V ?? ""}

        ${s.mainStart()}
        ${s.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}
        ${ue}
      }`;
      }, Zd = (s, o, d, g, y, x, b = d.dataType) => {
        let P = d.dims.map((re) => Number(re) ?? 1), k = g.dims.map((re) => Number(re) ?? 1), O = !it.areEqual(P, k), $ = P, V = it.size(P), G = !1, ee = !1, X = [O];
        if (O) {
          let re = Ui.calcShape(P, k, !1);
          if (!re)
            throw new Error("Can't perform binary op on the given tensors");
          $ = re.slice(), V = it.size($);
          let Te = it.size(P) === 1, ue = it.size(k) === 1, ce = P.length > 0 && P[P.length - 1] % 4 === 0, ke = k.length > 0 && k[k.length - 1] % 4 === 0;
          X.push(Te), X.push(ue), X.push(ce), X.push(ke);
          let Le = 1;
          for (let M = 1; M < $.length; M++) {
            let C = P[P.length - M], z = k[k.length - M];
            if (C === z)
              Le *= C;
            else
              break;
          }
          Le % 4 === 0 ? (ee = !0, G = !0) : (Te || ue || ce || ke) && (G = !0);
        } else
          G = !0;
        return X.push(G), { name: s, shaderCache: { hint: o + X.map((re) => re.toString()).join("_"), inputDependencies: ["rank", "rank"] }, getShaderSource: (re) => Qd(re, P, k, $, G, O, ee, y, d.dataType, g.dataType, b, x), getRunData: () => ({ outputs: [{ dims: $, dataType: b }], dispatchGroup: { x: Math.ceil(V / 64 / 4) }, programUniforms: [{ type: 12, data: Math.ceil(it.size($) / 4) }, ...Ut(P, k, $)] }) };
      }, Wi = (s, o, d, g, y, x) => {
        s.compute(Zd(o, y ?? "", s.inputs[0], s.inputs[1], d, g, x));
      }, eh = (s) => {
        Wi(s, "Add", (o, d) => `${o}+${d}`);
      }, ll = (s) => {
        Wi(s, "Div", (o, d) => `${o}/${d}`);
      }, th = (s) => {
        Wi(s, "Equal", { scalar: (o, d) => `u32(${o}==${d})`, vector: (o, d) => `vec4<u32>(${o}==${d})` }, void 0, void 0, 9);
      }, nh = (s) => {
        Wi(s, "Mul", (o, d) => `${o}*${d}`);
      }, cl = (s) => {
        let o = dt("input", s.inputs[0].dataType, s.inputs[0].dims).type.value;
        Wi(s, "Pow", { scalar: (d, g) => `pow_custom(${d},${g})`, vector: (d, g) => `pow_vector_custom(${d},${g})` }, `
    fn pow_custom(a : ${o}, b : ${o}) -> ${o} {
      if (b == ${o}(0.0)) {
        return ${o}(1.0);
      } else if (a < ${o}(0.0) && f32(b) != floor(f32(b))) {
        return ${o}(pow(f32(a), f32(b))); // NaN
      }
      return select(sign(a), ${o}(1.0), round(f32(abs(b) % ${o}(2.0))) != 1.0) * ${o}(${o === "i32" ? "round" : ""}(pow(f32(abs(a)), f32(b))));
    }
    fn pow_vector_custom(a : vec4<${o}>, b : vec4<${o}>) -> vec4<${o}> {
      // TODO: implement vectorized pow
      return vec4<${o}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));
    }
      `);
      }, ih = (s) => {
        Wi(s, "Sub", (o, d) => `${o}-${d}`);
      }, sh = (s) => {
        Wi(s, "Greater", { scalar: (o, d) => `u32(${o}>${d})`, vector: (o, d) => `vec4<u32>(${o}>${d})` }, void 0, void 0, 9);
      }, ul = (s) => {
        Wi(s, "Less", { scalar: (o, d) => `u32(${o}<${d})`, vector: (o, d) => `vec4<u32>(${o}<${d})` }, void 0, void 0, 9);
      }, rh = (s) => {
        Wi(s, "GreaterOrEqual", { scalar: (o, d) => `u32(${o}>=${d})`, vector: (o, d) => `vec4<u32>(${o}>=${d})` }, void 0, void 0, 9);
      }, oh = (s) => {
        Wi(s, "LessOrEqual", { scalar: (o, d) => `u32(${o}<=${d})`, vector: (o, d) => `vec4<u32>(${o}<=${d})` }, void 0, void 0, 9);
      };
    }), lh, ch, dl, uh, dh, hl, gg = l(() => {
      jt(), ie(), pn(), sn(), lh = (s, o) => {
        if (!s || s.length < 1)
          throw new Error("too few inputs");
        let d = 0, g = s[d], y = g.dataType, x = g.dims.length;
        s.forEach((b, P) => {
          if (P !== d) {
            if (b.dataType !== y)
              throw new Error("input tensors should be one type");
            if (b.dims.length !== x)
              throw new Error("input tensors should have the same shape");
            b.dims.forEach((k, O) => {
              if (O !== o && k !== g.dims[O])
                throw new Error("non concat dimensions must match");
            });
          }
        });
      }, ch = (s, o) => `
  fn calculateInputIndex(index: u32) -> u32 {
    let sizeInConcatAxis = array<u32, ${s}u>(${o});
    for (var i: u32 = 0u; i < ${s}; i += 1u ) {
      if (index < sizeInConcatAxis[i]) {
        return i;
      }
    }
    return ${s}u;
  }`, dl = (s, o) => {
        let d = s.length, g = [];
        for (let y = 0; y < d; ++y) {
          let x = o.setByOffset("global_idx", s[y].getByIndices("indices"));
          d === 1 ? g.push(x) : y === 0 ? g.push(`if (inputIndex == ${y}u) { ${x} }`) : y === d - 1 ? g.push(`else { ${x} }`) : g.push(`else if (inputIndex == ${y}) { ${x} }`);
        }
        return g.join(`
`);
      }, uh = (s, o, d, g) => {
        let y = it.size(d), x = new Array(s.length), b = new Array(s.length), P = 0, k = [], O = [], $ = [{ type: 12, data: y }];
        for (let re = 0; re < s.length; ++re)
          P += s[re].dims[o], x[re] = P, O.push(s[re].dims.length), b[re] = dt(`input${re}`, g, O[re]), k.push("rank"), $.push({ type: 12, data: x[re] });
        for (let re = 0; re < s.length; ++re)
          $.push(...Ut(s[re].dims));
        $.push(...Ut(d));
        let V = $t("output", g, d.length), G = V.indicesGet("indices", o), ee = Array.from(Array(x.length).keys()).map((re) => `uniforms.sizeInConcatAxis${re}`).join(","), X = (re) => `

  ${(() => {
          re.registerUniform("outputSize", "u32");
          for (let Te = 0; Te < s.length; Te++)
            re.registerUniform(`sizeInConcatAxis${Te}`, "u32");
          return re.declareVariables(...b, V);
        })()}

  ${ch(x.length, ee)}

  ${re.mainStart()}
    ${re.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}

    var indices = ${V.offsetToIndices("global_idx")};

    let inputIndex = calculateInputIndex(${G});
    if (inputIndex != 0u) {
      let sizeInConcatAxis = array<u32, ${x.length}u>(${ee});
      ${G} -= sizeInConcatAxis[inputIndex - 1u];
    }

    ${dl(b, V)}
  }`;
        return { name: "Concat", shaderCache: { hint: `${o}`, inputDependencies: k }, getRunData: () => ({ outputs: [{ dims: d, dataType: g }], dispatchGroup: { x: Math.ceil(y / 64) }, programUniforms: $ }), getShaderSource: X };
      }, dh = (s, o) => {
        let d = s.inputs, g = d[0].dims, y = it.normalizeAxis(o.axis, g.length);
        lh(d, y);
        let x = g.slice();
        x[y] = d.reduce((P, k) => P + (k.dims.length > y ? k.dims[y] : 0), 0);
        let b = d.filter((P) => it.size(P.dims) > 0);
        s.compute(uh(b, y, x, d[0].dataType), { inputs: b });
      }, hl = (s) => Yt({ axis: s.axis });
    }), Ks, Ds, Xs, fl, Ys = l(() => {
      jt(), ie(), Ks = (s, o, d = "f32") => {
        switch (s.activation) {
          case "Relu":
            return `value = max(value, ${o}(0.0));`;
          case "Sigmoid":
            return `value = (${o}(1.0) / (${o}(1.0) + exp(-value)));`;
          case "Clip":
            return `value = clamp(value, ${o}(${d}(uniforms.clip_min)), ${o}(${d}(uniforms.clip_max)));`;
          case "HardSigmoid":
            return `value = max(${o}(0.0), min(${o}(1.0), ${d}(uniforms.alpha) * value + ${d}(uniforms.beta)));`;
          case "LeakyRelu":
            return `value = select(${d}(uniforms.alpha) * value, value, value >= ${o}(0.0));`;
          case "Tanh":
            return `let e2x = exp(-2.0 * abs(value));
              value = sign(value) * (1.0 - e2x) / (1.0 + e2x);
        `;
          case "":
            return "";
          default:
            throw new Error(`Unsupported activation ${s.activation}`);
        }
      }, Ds = (s, o) => {
        s.activation === "Clip" ? o.push({ type: 1, data: s.clipMax }, { type: 1, data: s.clipMin }) : s.activation === "HardSigmoid" ? o.push({ type: 1, data: s.alpha }, { type: 1, data: s.beta }) : s.activation === "LeakyRelu" && o.push({ type: 1, data: s.alpha });
      }, Xs = (s, o) => {
        s.activation === "Clip" ? o.push({ name: "clip_max", type: "f32" }, { name: "clip_min", type: "f32" }) : s.activation === "HardSigmoid" ? o.push({ name: "alpha", type: "f32" }, { name: "beta", type: "f32" }) : s.activation === "LeakyRelu" && o.push({ name: "alpha", type: "f32" });
      }, fl = (s) => {
        let o = (s == null ? void 0 : s.activation) || "";
        if (o === "HardSigmoid") {
          let [d, g] = (s == null ? void 0 : s.activation_params) || [0.2, 0.5];
          return { activation: o, alpha: d, beta: g };
        } else if (o === "Clip") {
          let [d, g] = (s == null ? void 0 : s.activation_params) || [Xe, j];
          return { activation: o, clipMax: g, clipMin: d };
        } else if (o === "LeakyRelu") {
          let [d] = (s == null ? void 0 : s.activation_params) || [0.01];
          return { activation: o, alpha: d };
        }
        return { activation: o };
      };
    }), ti, pl, ml = l(() => {
      ti = (s, o) => {
        switch (s) {
          case 1:
            return o;
          case 2:
            return `vec2<${o}>`;
          case 3:
            return `vec3<${o}>`;
          case 4:
            return `vec4<${o}>`;
          default:
            throw new Error(`${s}-component is not supported.`);
        }
      }, pl = (s) => `
      ${s ? "value = value + getBiasByOutputCoords(coords);" : ""}
      `;
    }), hh, _g = l(() => {
      hh = (s) => `
fn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {
  return dot(coords, vec4<i32>(
      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));
}
fn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {
  return dot(coords, vec4<i32>(
    i32(${s}.x), i32(${s}.y), i32(${s}.z), 1));
}
`;
    }), $r, Ao, gl = l(() => {
      jt(), ie(), sn(), Ys(), $r = (s, o, d, g, y) => {
        let x = g - d;
        return `
      ${Array.from({ length: d }).map((b, P) => `
      if (${Nt(o.shape, P, o.rank)} != 1) {
        ${o.indicesSet(s, P, Nt(y, P + x, g))}
      } else {
        ${o.indicesSet(s, P, 0)}
      }`).join("")}
`;
      }, Ao = (s, o, d, g, y = !1, x) => {
        let b = s[0].dims, P = s[1].dims, k = b[b.length - 2], O = P[P.length - 1], $ = b[b.length - 1], V = Dn(O), G = Dn($), ee = Dn(k), X = it.size(d) / V / ee, re = s.length > 2, Te = g ? g.slice(0, -2) : d.slice(0, -2), ue = [it.size(Te), k, O], ce = [{ type: 12, data: X }, { type: 12, data: k }, { type: 12, data: O }, { type: 12, data: $ }];
        Ds(o, ce), ce.push(...Ut(Te, b, P)), re && ce.push(...Ut(s[2].dims)), ce.push(...Ut(ue));
        let ke = (Le) => {
          let M = Ea("batch_dims", s[0].dataType, Te.length), C = dt("a", s[0].dataType, b.length, G), z = dt("b", s[1].dataType, P.length, V), oe = $t("output", s[0].dataType, ue.length, V), ye = Jn(oe.type.tensor), Pe = Ks(o, oe.type.value, ye), Ue = [C, z], Je = "";
          if (re) {
            let wt = y ? V : 1;
            Ue.push(dt("bias", s[2].dataType, s[2].dims.length, wt)), Je = `${y ? `value += bias[col / ${wt}];` : `value += ${oe.type.value}(bias[row + i]);`}`;
          }
          let st = [{ name: "output_size", type: "u32" }, { name: "M", type: "u32" }, { name: "N", type: "u32" }, { name: "K", type: "u32" }];
          Xs(o, st);
          let gt = () => {
            let wt = `var a_data: ${C.type.value};`;
            for (let yt = 0; yt < G; yt++)
              wt += `
              let b_data${yt} = b[(b_offset + (k + ${yt}) * uniforms.N + col) / ${V}];`;
            for (let yt = 0; yt < ee; yt++) {
              wt += `a_data = a[(a_offset + (row + ${yt}) * uniforms.K + k) / ${G}];`;
              for (let ht = 0; ht < G; ht++)
                wt += `
            values[${yt}] = fma(${z.type.value}(a_data${G === 1 ? "" : `[${ht}]`}), b_data${ht}, values[${yt}]);
`;
            }
            return wt;
          };
          return `
  ${Le.registerUniforms(st).registerInternalVariables(M).declareVariables(...Ue, oe)}
  ${Le.mainStart()}
    ${Le.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let col = (global_idx % (uniforms.N / ${V})) * ${V};
    var index1 = global_idx / (uniforms.N / ${V});
    let stride1 = uniforms.M / ${ee};
    let row = (index1 % stride1) * ${ee};
    let batch = index1 / stride1;

    ${d.length === 2 ? "" : `let batch_indices = ${M.offsetToIndices("batch")};`}

    var a_indices: ${C.type.indices};
    ${$r("a_indices", C, C.rank - 2, M.rank, "batch_indices")}
    ${C.indicesSet("a_indices", C.rank - 2, 0)}
    ${C.indicesSet("a_indices", C.rank - 1, 0)}
    let a_offset = ${C.indicesToOffset("a_indices")};

    var b_indices: ${z.type.indices};
    ${$r("b_indices", z, z.rank - 2, M.rank, "batch_indices")}
    ${z.indicesSet("b_indices", z.rank - 2, 0)}
    ${z.indicesSet("b_indices", z.rank - 1, 0)}
    let b_offset = ${z.indicesToOffset("b_indices")};
    var values: array<${oe.type.value}, ${ee}>;
    for (var k: u32 = 0u; k < uniforms.K; k = k + ${G}) {
      ${gt()}
    }
    for (var i = 0u; i < ${ee}u; i++) {
      var value = values[i];
      ${Je}
      ${Pe}
      let cur_indices = ${oe.type.indices}(batch, row + i, col);
      let offset = ${oe.indicesToOffset("cur_indices")};
      ${oe.setByOffset(`offset / ${V}`, "value")};
    }
  }
  `;
        };
        return { name: "MatMulNaive", shaderCache: { hint: `${o.activation};${V};${G};${ee};${y}`, inputDependencies: re ? ["rank", "rank", "rank"] : ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: x ? x(d) : d, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(X / 64) }, programUniforms: ce }), getShaderSource: ke };
      };
    }), fh, ph, _l, Co, mh, yl, gh, Io, Lo = l(() => {
      jt(), ie(), sn(), Ys(), gl(), ml(), fh = (s, o) => s ? `
        mm_Asub[inputRow][inputCol] = mm_readA(batch,
          kStart + inputRow,
          globalRowStart / innerElementSize + inputCol${o ? ", batchIndices" : ""});
        ` : `
        mm_Asub[inputRow][inputCol] = mm_readA(batch,
          globalRow + innerRow,
          kStart / innerElementSize + inputCol${o ? ", batchIndices" : ""});
        `, ph = (s, o) => s ? `
        let ACached0 = mm_Asub[k * innerElementSize][localRow];
        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];
        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];
        ${o === 3 ? "" : "let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];"}
        for (var i = 0; i < rowPerThread; i = i + 1) {
          acc[i] = BCached0 * ACached0[i] + acc[i];
          acc[i] = BCached1 * ACached1[i] + acc[i];
          acc[i] = BCached2 * ACached2[i] + acc[i];
          ${o === 3 ? "" : "acc[i] = BCached3 * ACached3[i] + acc[i];"}
        }` : `
        for (var i = 0; i < rowPerThread; i = i + 1) {
          let ACached = mm_Asub[tileRow + i][k];
          acc[i] = BCached0 * ACached.x + acc[i];
          acc[i] = BCached1 * ACached.y + acc[i];
          acc[i] = BCached2 * ACached.z + acc[i];
          ${o === 3 ? "" : "acc[i] = BCached3 * ACached.w + acc[i];"}
        }`, _l = (s, o, d = "f32", g, y = !1, x = 32, b = !1, P = 32) => {
        let k = o[1] * s[1], O = o[0] * s[0], $ = y ? k : x, V = y ? x : k, G = $ / o[0], ee = x / o[1];
        if (!((y && G === 4 && s[1] === 4 || !y && (G === 3 || G === 4)) && $ % o[0] === 0 && x % o[1] === 0 && s[0] === 4))
          throw new Error(`If transposeA ${y} is true, innerElementSize ${G} and workPerThread[1] ${s[1]} must be 4.
      Otherwise, innerElementSize ${G} must be 3 or 4.
  tileAWidth ${$} must be divisible by workgroupSize[0]${o[0]}. tileInner ${x} must be divisible by workgroupSize[1] ${o[1]}. colPerThread ${s[0]} must be 4.`);
        return `
var<workgroup> mm_Asub: array<array<vec${G}<${d}>, ${$ / G}>, ${V}>;
var<workgroup> mm_Bsub: array<array<vec4<${d}>, ${O / s[0]}>, ${x}>;

const rowPerThread = ${s[1]};
const colPerThread = ${s[0]};
const innerElementSize = ${G};
const tileInner = ${x};

@compute @workgroup_size(${o[0]}, ${o[1]}, ${o[2]})
fn main(@builtin(local_invocation_id) localId : vec3<u32>,
        @builtin(global_invocation_id) globalId : vec3<u32>,
        @builtin(workgroup_id) workgroupId : vec3<u32>) {
  let localRow = i32(localId.y);
  let tileRow = localRow * rowPerThread;
  let tileCol = i32(localId.x);

  let globalRow =i32(globalId.y) * rowPerThread;
  let globalCol = i32(globalId.x);
  let batch = ${b ? "0" : "i32(globalId.z)"};
  ${g ? `let batchIndices = ${g.offsetToIndices("u32(batch)")};` : ""}
  let globalRowStart = i32(workgroupId.y) * ${k};

  let num_tiles = ${b ? `${Math.ceil(P / x)}` : "(uniforms.dim_inner - 1) / tileInner + 1"};
  var kStart = ${b ? `i32(globalId.z) * ${P}` : "0"};

  var acc: array<vec4<${d}>, rowPerThread>;

  // Loop over shared dimension.
  let tileRowB = localRow * ${ee};
  for (var t = 0; t < num_tiles; t = t + 1) {
      // Load one tile of A into local memory.
      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
          let inputRow = tileRow + innerRow;
          let inputCol = tileCol;
          ${fh(y, g)}
      }

      // Load one tile of B into local memory.
      for (var innerRow = 0; innerRow < ${ee}; innerRow = innerRow + 1) {
          let inputRow = tileRowB + innerRow;
          let inputCol = tileCol;
          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${g ? ", batchIndices" : ""});
      }
      kStart = kStart + tileInner;
      workgroupBarrier();

      // Compute acc values for a single thread.
      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {
          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];
          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];
          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];
          ${G === 3 ? "" : "let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];"}

          ${ph(y, G)}
      }

      workgroupBarrier();
  }

  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);
  }
}`;
      }, Co = (s, o) => s ? `
            mm_Asub[inputRow][inputCol] = mm_readA(batch,
              kStart + inputRow,
              globalRowStart + inputCol${o ? ", batchIndices" : ""});
            ` : `
            mm_Asub[inputRow][inputCol] = mm_readA(batch,
              globalRowStart + inputRow,
              kStart + inputCol${o ? ", batchIndices" : ""});
            `, mh = (s) => s ? "let ACached = mm_Asub[k][tileRow + innerRow];" : "let ACached = mm_Asub[tileRow + innerRow][k];", yl = (s, o, d = "f32", g, y = !1, x = 32, b = !1, P = 32, k = !1) => {
        let O = s[1] * o[1], $ = s[0] * o[0], V = y ? O : x, G = y ? x : O;
        if (!(G % o[1] === 0 && V % o[0] === 0 && x % o[1] === 0))
          throw new Error(`tileAHight ${G} must be divisible by workgroupSize[1]${o[1]}, tileAWidth ${V} must be divisible by workgroupSize[0]${o[0]}, tileInner ${x} must be divisible by workgroupSize[1]${o[1]}`);
        let ee = G / o[1], X = V / o[0], re = x / o[1], Te = k ? `
    let localRow = i32(localId.y);
    let localCol = i32(localId.x);
    let globalRowStart = i32(workgroupId.y) * ${O};
    let globalColStart = i32(workgroupId.x) * ${$};

    // Loop over shared dimension.
    for (var t = 0; t < num_tiles; t = t + 1) {
      // Load one tile of A into local memory.
      for (var inputRow = localRow; inputRow < ${G}; inputRow = inputRow + ${o[1]}) {
        for (var inputCol = localCol; inputCol < ${V}; inputCol = inputCol + ${o[0]}) {
          ${Co(y, g)}
        }
      }
      // Load one tile of B into local memory.
      for (var inputRow = localRow; inputRow < ${x}; inputRow = inputRow + ${o[1]}) {
            for (var inputCol = localCol; inputCol < ${$}; inputCol = inputCol + ${o[0]}) {
          mm_Bsub[inputRow][inputCol] = mm_readB(batch,
            kStart + inputRow,
            globalColStart + inputCol${g ? ", batchIndices" : ""});
        }
      }
      kStart = kStart + tileInner;
      workgroupBarrier();

      // Compute acc values for a single thread.
      var BCached : array<${d}, colPerThread>;
      for (var k = 0; k < tileInner; k = k + 1) {
        for (var inner = 0; inner < colPerThread; inner = inner + 1) {
          BCached[inner] = mm_Bsub[k][localCol + inner * ${o[0]}];
        }
        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
          let ACached = ${y ? `mm_Asub[k][localRow + innerRow * ${o[1]}];` : `mm_Asub[localRow + innerRow * ${o[1]}][k];`}
          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
            acc[innerRow][innerCol] = acc[innerRow][innerCol] +
                ACached * BCached[innerCol];
          }
        }
      }
      workgroupBarrier();
    }
    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
      let gRow = globalRowStart + localRow + innerRow * ${o[1]};
      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
        let gCol = globalColStart + localCol + innerCol * ${o[0]};
        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);
      }
    }
    ` : `
let tileRow = i32(localId.y) * rowPerThread;
let tileCol = i32(localId.x) * colPerThread;

let globalRow = i32(globalId.y) * rowPerThread;
let globalCol = i32(globalId.x) * colPerThread;
let globalRowStart = i32(workgroupId.y) * ${O};

let tileRowA = i32(localId.y) * ${ee};
let tileColA = i32(localId.x) * ${X};
let tileRowB = i32(localId.y) * ${re};
// Loop over shared dimension.
for (var t = 0; t < num_tiles; t = t + 1) {
  // Load one tile of A into local memory.
  for (var innerRow = 0; innerRow < ${ee}; innerRow = innerRow + 1) {
    for (var innerCol = 0; innerCol < ${X}; innerCol = innerCol + 1) {
      let inputRow = tileRowA + innerRow;
      let inputCol = tileColA + innerCol;
      ${Co(y, g)}
    }
  }

  // Load one tile of B into local memory.
  for (var innerRow = 0; innerRow < ${re}; innerRow = innerRow + 1) {
    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
      let inputRow = tileRowB + innerRow;
      let inputCol = tileCol + innerCol;
      mm_Bsub[inputRow][inputCol] = mm_readB(batch,
        kStart + inputRow,
        globalCol + innerCol${g ? ", batchIndices" : ""});
    }
  }
  kStart = kStart + tileInner;
  workgroupBarrier();

  // Compute acc values for a single thread.
  var BCached : array<${d}, colPerThread>;
  for (var k = 0; k < tileInner; k = k + 1) {
    for (var inner = 0; inner < colPerThread; inner = inner + 1) {
      BCached[inner] = mm_Bsub[k][tileCol + inner];
    }

    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
      ${mh(y)}
      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];
      }
    }
  }

  workgroupBarrier();
}

for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {
  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {
    mm_write(batch, globalRow + innerRow, globalCol + innerCol,
        acc[innerRow][innerCol]);
  }
}
`;
        return `
  var<workgroup> mm_Asub : array<array<${d}, ${V}>, ${G}>;
  var<workgroup> mm_Bsub : array<array<${d}, ${$}>, ${x}>;
  const rowPerThread = ${s[1]};
  const colPerThread = ${s[0]};
  const tileInner = ${x};

@compute @workgroup_size(${o[0]}, ${o[1]}, ${o[2]})
fn main(@builtin(local_invocation_id) localId : vec3<u32>,
        @builtin(global_invocation_id) globalId : vec3<u32>,
        @builtin(workgroup_id) workgroupId : vec3<u32>) {
    let batch = ${b ? "0" : "i32(globalId.z)"};
    ${g ? `let batchIndices = ${g.offsetToIndices("u32(batch)")};` : ""}
    let num_tiles = ${b ? `${Math.ceil(P / x)}` : "(uniforms.dim_inner - 1) / tileInner + 1"};
    var kStart = ${b ? `i32(globalId.z) * ${P}` : "0"};

    var acc : array<array<${d}, colPerThread>, rowPerThread>;
    ${Te}
  }
`;
      }, gh = (s, o, d, g, y = !1) => {
        let [x, b, P, k] = g, O = Jn(g[0].type.tensor);
        return `
    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${x.type.indices}) -> ${ti(s, O)} {
      var value = ${ti(s, O)}(0.0);
      let col = colIn * ${s};
      if(row < uniforms.dim_a_outer && col < uniforms.dim_inner)
      {
        var aIndices: ${b.type.indices};
        ${$r("aIndices", b, b.rank - 2, x.rank, "batchIndices")}
        ${b.indicesSet("aIndices", b.rank - 2, "u32(row)")}
        ${b.indicesSet("aIndices", b.rank - 1, "u32(colIn)")}
        value = ${b.getByIndices("aIndices")};
      }
      return value;
    }

    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${x.type.indices}) -> ${ti(s, O)} {
      var value = ${ti(s, O)}(0.0);
      let col = colIn * ${s};
      if(row < uniforms.dim_inner && col < uniforms.dim_b_outer)
      {
        var bIndices: ${P.type.indices};
        ${$r("bIndices", P, P.rank - 2, x.rank, "batchIndices")}
        ${P.indicesSet("bIndices", P.rank - 2, "u32(row)")}
        ${P.indicesSet("bIndices", P.rank - 1, "u32(colIn)")}
        value = ${P.getByIndices("bIndices")};
      }
      return value;
    }

    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${ti(s, O)}) {
      let col = colIn * ${s};
      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer) {
        var value = valueIn;
        let coords = vec3<i32>(batch, row, colIn);
        ${o ? `value = value + ${y ? "bias[colIn]" : `${ti(s, O)}(bias[row])`};` : ""}
        ${d}
        ${k.setByIndices("vec3<u32>(coords)", "value")}
      }
    }
    `;
      }, Io = (s, o, d, g, y = !1, x) => {
        let b = s[0].dims, P = s[1].dims, k = b.slice(0, -2), O = P.slice(0, -2), $ = g ? g.slice(0, -2) : d.slice(0, -2), V = it.size($), G = b[b.length - 2], ee = b[b.length - 1], X = P[P.length - 1], re = ee % 4 === 0 && X % 4 === 0, Te = G <= 8 ? [4, 1, 1] : [4, 4, 1], ue = [8, 8, 1], ce = [Math.ceil(X / ue[0] / Te[0]), Math.ceil(G / ue[1] / Te[1]), Math.ceil(V / ue[2] / Te[2])], ke = re ? 4 : 1, Le = [...k, G, ee / ke], M = Le.length, C = [...O, ee, X / ke], z = C.length, oe = [V, G, X / ke], ye = [{ type: 6, data: G }, { type: 6, data: X }, { type: 6, data: ee }];
        Ds(o, ye), ye.push(...Ut($, Le, C));
        let Pe = ["rank", "rank"], Ue = s.length > 2;
        Ue && (ye.push(...Ut(s[2].dims)), Pe.push("rank")), ye.push(...Ut(oe));
        let Je = (st) => {
          let gt = $.length, wt = Ea("batchDims", s[0].dataType, gt, 1), yt = Jn(s[0].dataType), ht = dt("a", s[0].dataType, M, ke), Ot = dt("b", s[1].dataType, z, ke), xt = $t("result", s[0].dataType, oe.length, ke), Ct = [ht, Ot];
          if (Ue) {
            let cn = y ? ke : 1;
            Ct.push(dt("bias", s[2].dataType, s[2].dims.length, cn));
          }
          let Ze = [{ name: "dim_a_outer", type: "i32" }, { name: "dim_b_outer", type: "i32" }, { name: "dim_inner", type: "i32" }];
          Xs(o, Ze);
          let ft = Jn(xt.type.tensor), St = Ks(o, xt.type.value, ft), Ht = gh(ke, Ue, St, [wt, ht, Ot, xt], y);
          return `
  ${st.registerUniforms(Ze).registerInternalVariables(wt).declareVariables(...Ct, xt)}
  ${Ht}
  ${re ? _l(Te, ue, yt, wt) : yl(Te, ue, yt, wt)}
                   `;
        };
        return { name: "MatMul", shaderCache: { hint: `${Te};${o.activation};${re};${y}`, inputDependencies: Pe }, getRunData: () => ({ outputs: [{ dims: x ? x(d) : d, dataType: s[0].dataType }], dispatchGroup: { x: ce[0], y: ce[1], z: ce[2] }, programUniforms: ye }), getShaderSource: Je };
      };
    }), _h, yh, vh = l(() => {
      jt(), Lt(), sn(), Ys(), ml(), _g(), Lo(), _h = (s, o, d, g, y = !1, x, b = 4, P = 4, k = 4, O = "f32") => {
        let $ = (ye) => {
          switch (ye) {
            case 1:
              return "resData = x[xIndex];";
            case 3:
              return `resData = vec3<${O}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;
            case 4:
              return "resData = x[xIndex / 4];";
            default:
              throw new Error(`innerElementSize ${ye} is not supported.`);
          }
        }, V = (ye) => {
          switch (ye) {
            case 1:
              return "return w[row * i32(uniforms.w_shape[3]) + colIn];";
            case 4:
              return "return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];";
            default:
              throw new Error(`innerElementSize ${ye} is not supported.`);
          }
        }, G = s ? `
    let coord = vec4<i32>(batch, xRow, xCol, xCh);
    ` : `
    let coord = vec4<i32>(batch, xCh, xRow, xCol);
    `, ee = s ? `
    let coords = vec4<i32>(
      batch,
      row / outWidth,
      row % outWidth,
      col);
    ` : `
    let coords = vec4<i32>(
      batch,
      row,
      col / outWidth,
      col % outWidth);
    `, X = s ? "i32(uniforms.x_shape[1])" : "i32(uniforms.x_shape[2])", re = s ? "i32(uniforms.x_shape[2])" : "i32(uniforms.x_shape[3])", Te = s ? "row" : "col", ue = s ? "col" : "row", ce = `
    let inChannels = i32(uniforms.w_shape[2]);
    let outWidth = ${s ? "i32(uniforms.result_shape[2])" : "i32(uniforms.result_shape[3])"};
    let outRow = ${Te} / outWidth;
    let outCol = ${Te} % outWidth;

    let WRow = ${ue} / (i32(uniforms.w_shape[1]) * inChannels);
    let WCol = ${ue} / inChannels % i32(uniforms.w_shape[1]);
    let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * WRow - uniforms.pad[0];
    let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * WCol - uniforms.pad[1];
    let xCh = ${ue} % inChannels;
    var resData = ${ti(b, O)}(0.0);
    // The bounds checking is always needed since we use it to pad zero for
    // the 'same' padding type.
    if (xRow >= 0 && xRow < ${X} && xCol >= 0 && xCol < ${re}) {
      ${G}
      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));
      ${$(b)}
    }
    return resData;`, ke = s ? o && g ? `
    let col = colIn * ${b};
    ${ce}` : `
    let col = colIn * ${b};
    if (row < uniforms.dim_a_outer && col < uniforms.dim_inner) {
      ${ce}
    }
    return ${ti(b, O)}(0.0);` : g && d ? `
    let col = colIn * ${b};
    ${ce}` : `
    let col = colIn * ${b};
    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {
      ${ce}
    }
    return ${ti(b, O)}(0.0);`, Le = s ? g && d ? V(P) : `
    let col = colIn * ${P};
    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {
      ${V(P)}
    }
    return ${ti(P, O)}(0.0);` : `
    let col = colIn * ${P};
    if (row < uniforms.dim_inner && col < uniforms.dim_a_outer) {
      ${V(P)}
    }
    return ${ti(P, O)}(0.0);`, M = ti(k, O), C = ti(s ? b : P, O), z = ti(s ? P : b, O), oe = Ks(x, M, O);
        return `
    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${C} {
      ${s ? ke : Le}
    }

    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${z} {
      ${s ? Le : ke}
    }

    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${M}) {
      let col = colIn * ${k};
      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer)
      {
      var value = valueIn;
      let outWidth = ${s ? "i32(uniforms.result_shape[2])" : "i32(uniforms.result_shape[3])"};
      ${ee}
      ${pl(y)}
      ${oe}
      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);
      }
    }`;
      }, yh = (s, o, d, g, y, x, b, P, k) => {
        let O = o.format === "NHWC", $ = O ? s[0].dims[3] : s[0].dims[1], V = d[0], G = O ? d[2] : d[3], ee = O ? d[1] : d[2], X = O ? d[3] : d[1], re = O && ($ % 4 === 0 || $ % 3 === 0) && X % 4 === 0, Te = O ? X : G * ee, ue = O ? G * ee : X, ce = [8, 8, 1], ke = g <= 8 ? [4, 1, 1] : [4, 4, 1], Le = [Math.ceil(Te / ce[0] / ke[0]), Math.ceil(ue / ce[1] / ke[1]), Math.ceil(V / ce[2] / ke[2])];
        ct("verbose", () => `[conv2d_mm_webgpu] dispatch = ${Le}`);
        let M = re ? O && $ % 4 !== 0 ? 3 : 4 : 1, C = ce[1] * ke[1], z = ce[0] * ke[0], oe = Math.max(ce[0] * M, ce[1]), ye = g % C === 0, Pe = y % z === 0, Ue = x % oe === 0, Je = re ? [M, 4, 4] : [1, 1, 1], st = [{ type: 6, data: g }, { type: 6, data: y }, { type: 6, data: x }, { type: 6, data: [o.pads[0], o.pads[1]] }, { type: 6, data: o.strides }, { type: 6, data: o.dilations }];
        Ds(o, st), st.push(...Ut(s[0].dims, s[1].dims));
        let gt = ["rank", "rank"];
        b && (st.push(...Ut(s[2].dims)), gt.push("rank")), st.push(...Ut(d));
        let wt = (yt) => {
          let ht = [{ name: "dim_a_outer", type: "i32" }, { name: "dim_b_outer", type: "i32" }, { name: "dim_inner", type: "i32" }, { name: "pad", type: "i32", length: 2 }, { name: "stride", type: "i32", length: 2 }, { name: "dilation", type: "i32", length: 2 }];
          Xs(o, ht);
          let Ot = re ? 4 : 1, xt = Jn(s[0].dataType), Ct = `
      fn setOutputAtIndex(flatIndex : i32, value : ${re ? `vec4<${xt}>` : xt}) {
        result[flatIndex] = ${re ? `vec4<${xt}>` : xt}(value);
      }
      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${re ? `vec4<${xt}>` : xt}) {
        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));
        setOutputAtIndex(flatIndex ${re ? "/ 4" : ""}, value);
      }`, Ze = dt("x", s[0].dataType, s[0].dims.length, M === 3 ? 1 : M), ft = dt("w", s[1].dataType, s[1].dims.length, Ot), St = [Ze, ft], Ht = $t("result", s[0].dataType, d.length, Ot);
          if (b) {
            let cn = dt("bias", s[2].dataType, s[2].dims.length, Ot);
            St.push(cn), Ct += `
        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${re ? `vec4<${xt}>` : xt} {
          return bias[coords.${O ? "w" : "y"}${re ? "/ 4" : ""}];
        }`;
          }
          return `
        ${hh("uniforms.result_strides")}
        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,
        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,
        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };
        ${yt.registerUniforms(ht).declareVariables(...St, Ht)}
        ${Ct}
        ${_h(O, ye, Pe, Ue, b, o, Je[0], Je[1], Je[2], xt)}
        ${re ? _l(ke, ce, xt, void 0, !O, oe) : yl(ke, ce, xt, void 0, !O, oe, !1, void 0, P)}`;
        };
        return { name: "Conv2DMatMul", shaderCache: { hint: `${o.cacheKey};${M};${re};${ye};${Pe};${Ue};${C};${z};${oe}`, inputDependencies: gt }, getRunData: () => ({ outputs: [{ dims: k ? k(d) : d, dataType: s[0].dataType }], dispatchGroup: { x: Le[0], y: Le[1], z: Le[2] }, programUniforms: st }), getShaderSource: wt };
      };
    }), wh, vl, vr, xh, wl, xl, bh, Mh, Th = l(() => {
      jt(), Lt(), ie(), sn(), Ys(), ml(), wh = (s) => {
        let o = 1;
        for (let d = 0; d < s.length; d++)
          o *= s[d];
        return o;
      }, vl = (s) => typeof s == "number" ? [s, s, s] : s, vr = (s, o) => o <= 1 ? s : s + (s - 1) * (o - 1), xh = (s, o, d, g = 1) => {
        let y = vr(o, g);
        return Math.floor((s[0] * (d - 1) - d + y) / 2);
      }, wl = (s, o, d, g, y) => {
        y == null && (y = xh(s, o[0], g[0]));
        let x = [0, 0, 0, d];
        for (let b = 0; b < 3; b++)
          s[b] + 2 * y >= o[b] && (x[b] = Math.trunc((s[b] - o[b] + 2 * y) / g[b] + 1));
        return x;
      }, xl = (s, o, d, g, y, x, b, P, k, O) => {
        let $, V, G, ee;
        if (s === "VALID" && (s = 0), typeof s == "number") {
          $ = { top: s, bottom: s, left: s, right: s, front: s, back: s };
          let X = wl([o, d, g, 1], [P, k, O], 1, [y, x, b], s);
          V = X[0], G = X[1], ee = X[2];
        } else if (Array.isArray(s)) {
          if (!s.every((re, Te, ue) => re === ue[0]))
            throw Error(`Unsupported padding parameter: ${s}`);
          $ = { top: s[0], bottom: s[1], left: s[2], right: s[3], front: s[4], back: s[5] };
          let X = wl([o, d, g, 1], [P, k, O], 1, [y, x, b], s[0]);
          V = X[0], G = X[1], ee = X[2];
        } else if (s === "SAME_UPPER") {
          V = Math.ceil(o / y), G = Math.ceil(d / x), ee = Math.ceil(g / b);
          let X = (V - 1) * y + P - o, re = (G - 1) * x + k - d, Te = (ee - 1) * b + O - g, ue = Math.floor(X / 2), ce = X - ue, ke = Math.floor(re / 2), Le = re - ke, M = Math.floor(Te / 2), C = Te - M;
          $ = { top: ke, bottom: Le, left: M, right: C, front: ue, back: ce };
        } else
          throw Error(`Unknown padding parameter: ${s}`);
        return { padInfo: $, outDepth: V, outHeight: G, outWidth: ee };
      }, bh = (s, o, d, g, y, x = !1, b = "channelsLast") => {
        let P, k, O, $, V;
        if (b === "channelsLast")
          [P, k, O, $, V] = s;
        else if (b === "channelsFirst")
          [P, V, k, O, $] = s;
        else
          throw new Error(`Unknown dataFormat ${b}`);
        let [G, , ee, X, re] = o, [Te, ue, ce] = vl(d), [ke, Le, M] = vl(g), C = vr(ee, ke), z = vr(X, Le), oe = vr(re, M), { padInfo: ye, outDepth: Pe, outHeight: Ue, outWidth: Je } = xl(y, k, O, $, Te, ue, ce, C, z, oe), st = x ? G * V : G, gt = [0, 0, 0, 0, 0];
        return b === "channelsFirst" ? gt = [P, st, Pe, Ue, Je] : b === "channelsLast" && (gt = [P, Pe, Ue, Je, st]), { batchSize: P, dataFormat: b, inDepth: k, inHeight: O, inWidth: $, inChannels: V, outDepth: Pe, outHeight: Ue, outWidth: Je, outChannels: st, padInfo: ye, strideDepth: Te, strideHeight: ue, strideWidth: ce, filterDepth: ee, filterHeight: X, filterWidth: re, effectiveFilterDepth: C, effectiveFilterHeight: z, effectiveFilterWidth: oe, dilationDepth: ke, dilationHeight: Le, dilationWidth: M, inShape: s, outShape: gt, filterShape: o };
      }, Mh = (s, o, d, g, y, x) => {
        let b = x === "channelsLast";
        b ? s[0].dims[3] : s[0].dims[1];
        let P = [64, 1, 1], k = { x: d.map((Te, ue) => ue) }, O = [Math.ceil(wh(k.x.map((Te) => d[Te])) / P[0]), 1, 1];
        ct("verbose", () => `[conv3d_naive_webgpu] dispatch = ${O}`);
        let $ = 1, V = it.size(d), G = [{ type: 12, data: V }, { type: 12, data: g }, { type: 12, data: y }, { type: 12, data: o.strides }, { type: 12, data: o.dilations }];
        Ds(o, G), G.push(...Ut(s[0].dims, s[1].dims));
        let ee = ["rank", "rank"], X = s.length === 3;
        X && (G.push(...Ut(s[2].dims)), ee.push("rank")), G.push(...Ut(d));
        let re = (Te) => {
          let ue = [{ name: "output_size", type: "u32" }, { name: "filter_dims", type: "u32", length: g.length }, { name: "pads", type: "u32", length: y.length }, { name: "strides", type: "u32", length: o.strides.length }, { name: "dilations", type: "u32", length: o.dilations.length }];
          Xs(o, ue);
          let ce = 1, ke = Jn(s[0].dataType), Le = dt("x", s[0].dataType, s[0].dims.length, $), M = dt("W", s[1].dataType, s[1].dims.length, ce), C = [Le, M], z = $t("result", s[0].dataType, d.length, ce), oe = "";
          if (X) {
            let Ue = dt("bias", s[2].dataType, s[2].dims.length, ce);
            C.push(Ue), oe += `
        fn getBiasByOutputCoords(coords : array<u32, 5>) -> ${ke} {
          return bias[${b ? Nt("coords", 4, 5) : Nt("coords", 1, 5)}];
        }`;
          }
          let ye = ti($, ke), Pe = Ks(o, ye, ke);
          return `
            ${oe}
            fn getX(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {
              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);
              return ${Le.getByIndices("aIndices")};
            }
            fn getW(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {
              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);
              return ${M.getByIndices("aIndices")};
            }
          ${Te.registerUniforms(ue).declareVariables(...C, z)}
          ${Te.mainStart()}
          ${Te.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
              let coords = ${z.offsetToIndices("global_idx")};
              let batch = ${Nt("coords", 0, Le.rank)};
              let d2 = ${b ? Nt("coords", Le.rank - 1, Le.rank) : Nt("coords", 1, Le.rank)};
              let xFRCCorner = vec3<u32>(${b ? Nt("coords", 1, Le.rank) : Nt("coords", 2, Le.rank)},
              ${b ? Nt("coords", 2, Le.rank) : Nt("coords", 3, Le.rank)},
              ${b ? Nt("coords", 3, Le.rank) : Nt("coords", 4, Le.rank)}) * uniforms.strides - uniforms.pads;
              let xFCorner = xFRCCorner.x;
              let xRCorner = xFRCCorner.y;
              let xCCorner = xFRCCorner.z;
              let xShapeY = ${b ? Nt("uniforms.x_shape", 1, Le.rank) : Nt("uniforms.x_shape", 2, Le.rank)};
              let xShapeZ = ${b ? Nt("uniforms.x_shape", 2, Le.rank) : Nt("uniforms.x_shape", 3, Le.rank)};
              let xShapeW = ${b ? Nt("uniforms.x_shape", 3, Le.rank) : Nt("uniforms.x_shape", 4, Le.rank)};
              let xShapeU = ${b ? Nt("uniforms.x_shape", 4, Le.rank) : Nt("uniforms.x_shape", 1, Le.rank)};
              let inputDepthNearestVec4 = (xShapeU / 4) * 4;
              let inputDepthVec4Remainder = xShapeU % 4;

              var value = 0.0;
              for (var wF = 0u; wF < uniforms.filter_dims[0]; wF++) {
                let xF = xFCorner + wF * uniforms.dilations[0];
                if (xF < 0 || xF >= xShapeY) {
                  continue;
                }

                for (var wR = 0u; wR < uniforms.filter_dims[1]; wR++) {
                  let xR = xRCorner + wR * uniforms.dilations[1];
                  if (xR < 0 || xR >= xShapeZ) {
                    continue;
                  }

                  for (var wC = 0u; wC < uniforms.filter_dims[2]; wC++) {
                    let xC = xCCorner + wC * uniforms.dilations[2];
                    if (xC < 0 || xC >= xShapeW) {
                      continue;
                    }

                    for (var d1 = 0u; d1 < inputDepthNearestVec4; d1 += 4) {
                      ${b ? `let xValues = vec4<f32>(
                               getX(batch, xF, xR, xC, d1),
                               getX(batch, xF, xR, xC, d1 + 1),
                               getX(batch, xF, xR, xC, d1 + 2),
                               getX(batch, xF, xR, xC, d1 + 3));
                            ` : `let xValues = vec4<f32>(
                               getX(batch, d1, xF, xR, xC),
                               getX(batch, d1 + 1, xF, xR, xC),
                               getX(batch, d1 + 2, xF, xR, xC),
                               getX(batch, d1 + 3, xF, xR, xC));
                            `}
                            let wValues = vec4<f32>(
                              getW(d2, d1, wF, wR, wC),
                              getW(d2, d1 + 1, wF, wR, wC),
                              getW(d2, d1 + 2, wF, wR, wC),
                              getW(d2, d1 + 3, wF, wR, wC));
                      value += dot(xValues, wValues);
                    }
                    if (inputDepthVec4Remainder == 1) {
                        ${b ? `value += getX(batch, xF, xR, xC, inputDepthNearestVec4)
                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);` : `value += getX(batch, inputDepthNearestVec4, xF, xR, xC)
                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);`}
                    } else if (inputDepthVec4Remainder == 2) {
                      ${b ? `let xValues = vec2<f32>(
                        getX(batch, xF, xR, xC, inputDepthNearestVec4),
                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1));
                      ` : `let xValues = vec2<f32>(
                        getX(batch, inputDepthNearestVec4, xF, xR, xC),
                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC));
                    `}
                    let wValues = vec2<f32>(
                      getW(d2, inputDepthNearestVec4, wF, wR, wC),
                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC));
                      value += dot(xValues, wValues);
                    } else if (inputDepthVec4Remainder == 3) {
                      ${b ? `let xValues = vec3<f32>(
                        getX(batch, xF, xR, xC, inputDepthNearestVec4),
                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1),
                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 2));
                      ` : `let xValues = vec3<f32>(
                        getX(batch, inputDepthNearestVec4, xF, xR, xC),
                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC),
                        getX(batch, inputDepthNearestVec4 + 2, xF, xR, xC));
                    `}
                    let wValues = vec3<f32>(
                      getW(d2, inputDepthNearestVec4, wF, wR, wC),
                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC),
                      getW(d2, inputDepthNearestVec4 + 2, wF, wR, wC));
                      value += dot(xValues, wValues);
                    }
                  }
                }
              }
              ${X ? "value = value + getBiasByOutputCoords(coords)" : ""};
              ${Pe}
              result[global_idx] = f32(value);
          }`;
        };
        return { name: "Conv3DNaive", shaderCache: { hint: `${o.cacheKey};${b};${$};${X}`, inputDependencies: ee }, getRunData: () => ({ outputs: [{ dims: d, dataType: s[0].dataType }], dispatchGroup: { x: O[0], y: O[1], z: O[2] }, programUniforms: G }), getShaderSource: re };
      };
    }), Eh, Sh, bl = l(() => {
      jt(), ie(), sn(), Ys(), Eh = (s, o, d, g) => {
        let y = s.length > 2, x = y ? "value += b[output_channel];" : "", b = s[0].dims, P = s[1].dims, k = o.format === "NHWC", O = k ? d[3] : d[1], $ = O / o.group, V = k && $ >= 4 ? Dn(O) : 1, G = it.size(d) / V, ee = [{ type: 12, data: G }, { type: 12, data: o.dilations }, { type: 12, data: [o.strides[0], o.strides[1]] }, { type: 12, data: [o.pads[0], o.pads[1]] }, { type: 12, data: $ }];
        Ds(o, ee), ee.push(...Ut(b, [P[0], P[1], P[2], P[3] / V]));
        let X = y ? ["rank", "rank", "rank"] : ["rank", "rank"];
        ee.push(...Ut([d[0], d[1], d[2], d[3] / V]));
        let re = (Te) => {
          let ue = $t("output", s[0].dataType, d.length, V), ce = Jn(ue.type.tensor), ke = Ks(o, ue.type.value, ce), Le = dt("x", s[0].dataType, b.length), M = dt("w", s[1].dataType, P.length, V), C = [Le, M];
          y && C.push(dt("b", s[2].dataType, s[2].dims, V));
          let z = [{ name: "output_size", type: "u32" }, { name: "dilations", type: "u32", length: o.dilations.length }, { name: "strides", type: "u32", length: 2 }, { name: "pads", type: "u32", length: 2 }, { name: "output_channels_per_group", type: "u32" }];
          Xs(o, z);
          let oe = k ? `
      for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[0]; wHeight++) {
        let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];

        if (xHeight < 0u || xHeight >= uniforms.x_shape[1]) {
          continue;
        }

        for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[1]; wWidth++) {
          let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];
          if (xWidth < 0u || xWidth >= uniforms.x_shape[2]) {
            continue;
          }

          for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[2]; wInChannel++) {
            let input_channel = in_channel_offset + wInChannel;
            let xVal = ${Le.get("batch", "xHeight", "xWidth", "input_channel")};
            let wVal = ${M.get("wHeight", "wWidth", "wInChannel", "output_channel")};
            value += xVal * wVal;
          }
        }
      }
      ` : `
      for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[1]; wInChannel++) {
        let input_channel = in_channel_offset + wInChannel;
        for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[2]; wHeight++) {
          let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];

          if (xHeight < 0u || xHeight >= uniforms.x_shape[2]) {
            continue;
          }

          for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[3]; wWidth++) {
            let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];
            if (xWidth < 0u || xWidth >= uniforms.x_shape[3]) {
              continue;
            }

            let xVal = ${Le.get("batch", "input_channel", "xHeight", "xWidth")};
            let wVal = ${M.get("output_channel", "wInChannel", "wHeight", "wWidth")};
            value += xVal * wVal;
          }
        }
      }
      `;
          return `
  ${Te.registerUniforms(z).declareVariables(...C, ue)}

  ${Te.mainStart()}
    ${Te.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

    let outputIndices = ${ue.offsetToIndices("global_idx")};
    let batch: u32 = outputIndices[0];
    let output_channel: u32 = outputIndices[${k ? 3 : 1}];
    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${k ? 1 : 2}], outputIndices[${k ? 2 : 3}]) * uniforms.strides - uniforms.pads;
    let group_id: u32 = output_channel * ${V} / uniforms.output_channels_per_group;
    var in_channel_offset = group_id * uniforms.w_shape[${k ? 2 : 1}];

    var value: ${ue.type.value} = ${ue.type.value}(0);
    ${oe}
    ${x}
    ${ke}
    ${ue.setByOffset("global_idx", "value")}
  }`;
        };
        return { name: "GroupedConv", shaderCache: { hint: `${o.cacheKey}_${V}`, inputDependencies: X }, getRunData: () => ({ outputs: [{ dims: g ? g(d) : d, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(G / 64) }, programUniforms: ee }), getShaderSource: re };
      }, Sh = (s, o, d, g) => {
        let y = s.length > 2, x = Dn(d[3]), b = Dn(d[2]), P = it.size(d) / x / b, k = [s[0].dims[0], s[0].dims[1], s[0].dims[2], s[0].dims[3] / x], O = [s[1].dims[0], s[1].dims[1], s[1].dims[2], s[1].dims[3] / x], $ = [d[0], d[1], d[2], d[3] / x], V = [{ type: 12, data: P }, { type: 6, data: [o.strides[0], o.strides[1]] }, { type: 6, data: [o.pads[0], o.pads[1]] }];
        Ds(o, V), V.push(...Ut(k, O, $));
        let G = (b - 1) * o.strides[1] + O[1], ee = (X) => {
          let re = $t("output", s[0].dataType, $.length, x), Te = Jn(re.type.tensor), ue = Ks(o, re.type.value, Te), ce = dt("x", s[0].dataType, k.length, x), ke = dt("w", s[1].dataType, O.length, x), Le = [ce, ke];
          y && Le.push(dt("b", s[2].dataType, s[2].dims, x));
          let M = y ? "value += b[output_channel];" : "", C = [{ name: "output_size", type: "u32" }, { name: "strides", type: "i32", length: 2 }, { name: "pads", type: "i32", length: 2 }];
          return Xs(o, C), `
  ${X.registerUniforms(C).declareVariables(...Le, re)}
  ${X.mainStart()}
    ${X.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let width0 = uniforms.output_shape[3];
    let output_channel = global_idx % width0;
    var index1 = global_idx / width0;
    let width1 = uniforms.output_shape[2] / ${b}u;
    let col = (index1 % width1) * ${b}u;
    index1 = index1 / width1;
    let row = index1 % uniforms.output_shape[1];
    let batch = index1 / uniforms.output_shape[1];

    let x_corner = vec2<i32>(i32(row), i32(col)) * uniforms.strides - uniforms.pads;

    var x_vals: array<${ce.type.value}, ${G}>;
    var values: array<${re.type.value}, ${b}>;
    let input_channel = output_channel;
    // Use constant instead of uniform can give better performance for w's height/width.
    for (var w_height: u32 = 0u; w_height < ${O[0]}; w_height++) {
      let x_height = x_corner.x + i32(w_height);
      if (x_height >= 0 && u32(x_height) < uniforms.x_shape[1]) {
        for (var i = 0; i < ${G}; i++) {
          let x_width = x_corner.y + i;
          if (x_width >= 0 && u32(x_width) < uniforms.x_shape[2]) {
            x_vals[i] = ${ce.get("batch", "u32(x_height)", "u32(x_width)", "input_channel")};
          } else {
            x_vals[i] = ${ce.type.value}(0);
          }
        }
        for (var w_width: u32 = 0u; w_width < ${O[1]}; w_width++) {
          let w_val = ${ke.get("w_height", "w_width", "0", "output_channel")};
          for (var i = 0u; i < ${b}u; i++) {
            values[i] = fma(x_vals[i * u32(uniforms.strides[1]) + w_width], w_val, values[i]);
          }
        }
      }
    }

    for (var i = 0u; i < ${b}u; i++) {
      var value = values[i];
      ${M}
      ${ue}
      ${re.set("batch", "row", "col + i", "output_channel", "value")};
    }
  }`;
        };
        return { name: "GroupedConv-Vectorize", shaderCache: { hint: `${o.cacheKey};${x};${b};${G};${O[0]};${O[1]}`, inputDependencies: y ? ["rank", "rank", "type"] : ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: g ? g(d) : d, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(P / 64) }, programUniforms: V }), getShaderSource: ee };
      };
    }), Ph, Do, Ml, Nr, Tl, ko, Ah, Ch, wr, Ih = l(() => {
      ie(), vh(), Th(), Lo(), bl(), Ys(), gl(), Hs(), Ph = (s, o, d, g, y, x) => {
        let b = s[0], P = s.slice(x ? 1 : 2, x ? 3 : 4), k = P.length, O = o[0], $ = o.slice(2).map((G, ee) => G + (G - 1) * (d[ee] - 1)), V = P.map((G, ee) => G + g[ee] + g[ee + k]).map((G, ee) => Math.floor((G - $[ee] + y[ee]) / y[ee]));
        return V.splice(0, 0, b), V.splice(x ? 3 : 1, 0, O), V;
      }, Do = [2, 3, 1, 0], Ml = (s, o) => {
        if (!s || s.length !== 2 && s.length !== 3)
          throw new Error("Conv requires 2 or 3 inputs");
        if (s[0].dims.length > 5)
          throw new Error("greater than 5D is not supported");
        if (s[0].dims.length !== s[1].dims.length)
          throw new Error("filter does not have same dimension as input");
        let d = s[0].dims[o.format === "NHWC" ? s[0].dims.length - 1 : 1], g = s[1].dims[1] * o.group;
        if (d !== g)
          throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");
        if (s.length === 3 && (s[2].dims.length !== 1 || s[1].dims[0] !== s[2].dims[0]))
          throw new Error("invalid bias");
        let y = s[0].dims.length - 2;
        if (o.dilations.length !== y)
          throw new Error(`dilations should be ${y}D`);
        if (o.strides.length !== y)
          throw new Error(`strides should be ${y}D`);
        if (o.pads.length !== y * 2)
          throw new Error(`pads should be ${y * 2}D`);
        if (o.kernelShape.length !== 0 && o.kernelShape.length !== s[1].dims.length - 2)
          throw new Error("invalid kernel shape");
      }, Nr = (s, o) => {
        let d = s.kernelShape.slice();
        d.length < o[1].dims.length - 2 && d.push(...Array(o[1].dims.length - 2 - d.length).fill(0));
        for (let x = 2; x < o[1].dims.length; ++x)
          d[x - 2] === 0 && (d[x - 2] = o[1].dims[x]);
        let g = s.pads.slice();
        ps.adjustPadsBasedOnAutoPad(o[0].dims, s.strides, s.dilations, d, g, s.format === "NHWC", s.autoPad);
        let y = Object.assign({}, s);
        return Object.assign(y, { kernelShape: d, pads: g }), y;
      }, Tl = (s) => {
        let o = fl(s), d = s.format, g = ["NOTSET", "VALID", "SAME_UPPER", "SAME_LOWER"][s.auto_pad], y = s.dilations, x = s.group, b = s.kernel_shape, P = s.pads, k = s.strides, O = s.w_is_const();
        return { autoPad: g, format: d, dilations: y, group: x, kernelShape: b, pads: P, strides: k, wIsConst: O, ...o, cacheKey: `${s.format};${o.activation};` };
      }, ko = (s, o, d, g) => {
        let y = d.format === "NHWC", x = Ph(o[0].dims, o[1].dims, d.dilations, d.pads, d.strides, y);
        if (d.group !== 1) {
          let C = [o[0]];
          if (y) {
            let z = s.kernelCustomData.wT ?? s.compute(bi(o[1], Do), { inputs: [1], outputs: [d.wIsConst ? -2 : -1] })[0];
            d.wIsConst && !s.kernelCustomData.wT && (s.kernelCustomData.wT = z), C.push(z);
          } else
            C.push(o[1]);
          o.length === 3 && C.push(o[2]), !s.adapterInfo.isArchitecture("ampere") && y && o[1].dims[0] === d.group && o[1].dims[1] === 1 && d.dilations[0] === 1 && d.dilations[1] === 1 ? s.compute(Sh(C, d, x, g), { inputs: C }) : s.compute(Eh(C, d, x, g), { inputs: C });
          return;
        }
        let b = o.length === 3, P = o[0].dims[y ? 1 : 2], k = o[0].dims[y ? 2 : 3], O = o[0].dims[y ? 3 : 1], $ = o[1].dims[2], V = o[1].dims[3], G = x[y ? 1 : 2], ee = x[y ? 2 : 3], X = x[y ? 3 : 1], re = y && $ === P && V === k && d.pads[0] === 0 && d.pads[1] === 0;
        if (re || $ === 1 && V === 1 && d.dilations[0] === 1 && d.dilations[1] === 1 && d.strides[0] === 1 && d.strides[1] === 1 && d.pads[0] === 0 && d.pads[1] === 0) {
          let C = x[0], z, oe, ye, Pe = [];
          if (y) {
            let st = s.kernelCustomData.wT ?? s.compute(bi(o[1], Do), { inputs: [1], outputs: [d.wIsConst ? -2 : -1] })[0];
            if (d.wIsConst && !s.kernelCustomData.wT && (s.kernelCustomData.wT = st), re) {
              let gt = P * k * O;
              z = o[0].reshape([1, C, gt]), oe = st.reshape([1, gt, X]), ye = [1, C, X];
            } else
              z = o[0].reshape([C, P * k, O]), oe = st.reshape([1, O, X]), ye = [C, G * ee, X];
            Pe.push(z), Pe.push(oe);
          } else
            z = o[0].reshape([C, O, P * k]), oe = o[1].reshape([1, X, O]), ye = [C, X, G * ee], Pe.push(oe), Pe.push(z);
          b && Pe.push(o[2]);
          let Ue = ye[2], Je = Pe[0].dims[Pe[0].dims.length - 1];
          Ue < 8 && Je < 8 ? s.compute(Ao(Pe, d, x, ye, y, g), { inputs: Pe }) : s.compute(Io(Pe, d, x, ye, y, g), { inputs: Pe });
          return;
        }
        let Te = !0, ue = s.kernelCustomData.wT ?? s.compute(bi(o[1], Do), { inputs: [1], outputs: [d.wIsConst ? -2 : -1] })[0];
        d.wIsConst && !s.kernelCustomData.wT && (s.kernelCustomData.wT = ue);
        let ce = [o[0], ue];
        b && ce.push(o[2]);
        let ke = y ? G * ee : X, Le = y ? X : G * ee, M = $ * V * O;
        s.compute(yh(ce, d, x, ke, Le, M, b, Te, g), { inputs: ce });
      }, Ah = (s, o) => {
        let d = o.format === "NHWC", g = [s.inputs[0].reshape(d ? [s.inputs[0].dims[0], 1, s.inputs[0].dims[1], s.inputs[0].dims[2]] : [s.inputs[0].dims[0], s.inputs[0].dims[1], 1, s.inputs[0].dims[2]]), s.inputs[1].reshape([s.inputs[1].dims[0], s.inputs[1].dims[1], 1, s.inputs[1].dims[2]])];
        s.inputs.length === 3 && g.push(s.inputs[2]);
        let y = [0, o.pads[0], 0, o.pads[1]], x = [1].concat(o.strides), b = [1].concat(o.dilations), P = [1].concat(o.kernelShape), k = Nr({ ...o, pads: y, strides: x, dilations: b, kernelShape: P }, g);
        ko(s, g, k, (O) => d ? [O[0], O[2], O[3]] : [O[0], O[1], O[3]]);
      }, Ch = (s, o, d) => {
        let g = d.format === "NHWC" ? "channelsLast" : "channelsFirst", y = Nr(d, o), x = d.autoPad === "NOTSET" ? d.pads : d.autoPad, b = bh(o[0].dims, o[1].dims, d.strides, d.dilations, x, !1, g);
        s.compute(Mh(o, y, b.outShape, [b.filterDepth, b.filterHeight, b.filterWidth], [b.padInfo.front, b.padInfo.top, b.padInfo.left], g));
      }, wr = (s, o) => {
        if (Ml(s.inputs, o), s.inputs[0].dims.length === 3)
          Ah(s, o);
        else if (s.inputs[0].dims.length === 5)
          Ch(s, s.inputs, o);
        else {
          let d = Nr(o, s.inputs);
          ko(s, s.inputs, d);
        }
      };
    }), Lh, yg = l(() => {
      jt(), Lt(), ie(), sn(), Lh = (s, o, d) => {
        let g = s.length > 2, y = o.outputShape, x = o.format === "NHWC", b = o.group, P = s[1].dims, k = P[2] / b, O = P[3], $ = x ? Dn(k) : 1, V = x && O === 1 && k >= 4, G = V ? Math.floor(k / 4) * 4 : Math.floor(k / $) * $, ee = k - G, X = x ? Dn(O) : 1, re = x ? O === 1 ? $ : X : 1, Te = it.size(y) / X, ue = [Math.ceil(Te / 64), 1, 1];
        ct("verbose", () => `[conv2d_backprop_webgpu] dispatch = ${ue}`);
        let ce = ["rank", "rank"], ke = [o.strides[0], o.strides[1]], Le = [o.kernelShape[x ? 1 : 2], o.kernelShape[x ? 2 : 3]], M = [o.dilations[0], o.dilations[1]], C = [Le[0] + (o.dilations[0] <= 1 ? 0 : (o.kernelShape[x ? 1 : 2] - 1) * (o.dilations[0] - 1)), Le[1] + (o.dilations[1] <= 1 ? 0 : (o.kernelShape[x ? 2 : 3] - 1) * (o.dilations[1] - 1))], z = [C[0] - 1 - Math.floor((o.pads[0] + o.pads[2]) / 2), C[1] - 1 - Math.floor((o.pads[1] + o.pads[3]) / 2)], oe = [{ type: 12, data: Te }, { type: 12, data: ke }, { type: 12, data: Le }, { type: 12, data: M }, { type: 12, data: C }, { type: 6, data: z }, { type: 12, data: G }, { type: 12, data: k }, { type: 12, data: O }, ...Ut(s[0].dims, s[1].dims)];
        g && (oe.push(...Ut(s[2].dims)), ce.push("rank")), oe.push(...Ut(y));
        let ye = (Pe) => {
          let Ue = [{ name: "output_size", type: "u32" }, { name: "strides", type: "u32", length: ke.length }, { name: "filter_dims", type: "u32", length: Le.length }, { name: "dilations", type: "u32", length: Le.length }, { name: "effective_filter_dims", type: "u32", length: C.length }, { name: "pads", type: "i32", length: z.length }, { name: "input_channels_per_group_int", type: "u32" }, { name: "input_channels_per_group", type: "u32" }, { name: "output_channels_per_group", type: "u32" }], Je = Jn(s[0].dataType), st = x ? 1 : 2, gt = x ? 2 : 3, wt = x ? 3 : 1, yt = dt("W", s[1].dataType, s[1].dims.length, re), ht = dt("Dy", s[0].dataType, s[0].dims.length, $), Ot = [ht, yt];
          g && Ot.push(dt("bias", s[2].dataType, [y[wt]].length, X));
          let xt = $t("result", s[0].dataType, y.length, X), Ct = () => {
            let St = "";
            if (V)
              $ === 4 ? St += `
        let xValue = ${ht.getByOffset("x_offset")};
        let wValue = ${yt.getByOffset("w_offset")};
        dotProd = dotProd + dot(xValue, wValue);
        x_offset += 1u;
        w_offset += 1u;` : $ === 2 ? St += `
          dotProd = dotProd + dot(vec4<${Je}>(${ht.getByOffset("x_offset")}, ${ht.getByOffset("x_offset + 1u")}), vec4<${Je}>(${yt.getByOffset("w_offset")}, ${yt.getByOffset("w_offset + 1u")}));
          x_offset += 2u;
          w_offset += 2u;` : $ === 1 && (St += `
          dotProd = dotProd + dot(vec4<${Je}>(${ht.getByOffset("x_offset")}, ${ht.getByOffset("x_offset + 1u")}, ${ht.getByOffset("x_offset + 2u")}, ${ht.getByOffset("x_offset + 3u")}), vec4<${Je}>(${yt.getByOffset("w_offset")}, ${yt.getByOffset("w_offset + 1u")}, ${yt.getByOffset("w_offset + 2u")}, ${yt.getByOffset("w_offset + 3u")}));
          x_offset += 4u;
          w_offset += 4u;`);
            else if (St += `
                  let xValue = ${x ? ht.getByOffset(`${ht.indicesToOffset(`${ht.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${$}`) : ht.get("batch", "inputChannel", "idyR", "idyC")};
        `, $ === 1)
              St += `
          let w_offset = ${yt.indicesToOffset(`${yt.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel, wOutChannel)`)};
          let wValue = ${yt.getByOffset(`w_offset / ${re}`)};
          dotProd = dotProd + xValue * wValue;`;
            else
              for (let Ht = 0; Ht < $; Ht++)
                St += `
            let wValue${Ht} = ${yt.getByOffset(`${yt.indicesToOffset(`${yt.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel + ${Ht}, wOutChannel)`)} / ${re}`)};
            dotProd = dotProd + xValue[${Ht}] * wValue${Ht};`;
            return St;
          }, Ze = () => {
            if (ee === 0)
              return "";
            if (!V)
              throw new Error(`packInputAs4 ${V} is not true.`);
            let St = "";
            if ($ === 1) {
              St += "dotProd = dotProd";
              for (let Ht = 0; Ht < ee; Ht++)
                St += `
            + ${ht.getByOffset(`x_offset + ${Ht}`)} * ${yt.getByOffset(`w_offset + ${Ht}`)}`;
              St += ";";
            } else if ($ === 2) {
              if (ee !== 2)
                throw new Error(`Invalid inputChannelsRemainder ${ee}.`);
              St += `
          let xValue = ${ht.getByOffset("x_offset")};
          let wValue = ${yt.getByOffset("w_offset")};
          dotProd = dotProd + dot(xValue, wValue);`;
            }
            return St;
          }, ft = `
            let outputIndices = ${xt.offsetToIndices(`global_idx * ${X}`)};
            let batch = ${xt.indicesGet("outputIndices", 0)};
            let d1 = ${xt.indicesGet("outputIndices", wt)};
            let r = ${xt.indicesGet("outputIndices", st)};
            let c = ${xt.indicesGet("outputIndices", gt)};
            let dyCorner = vec2<i32>(i32(r), i32(c)) - uniforms.pads;
            let dyRCorner = dyCorner.x;
            let dyCCorner = dyCorner.y;
            let groupId = d1 / uniforms.output_channels_per_group;
            let wOutChannel = d1 - groupId * uniforms.output_channels_per_group;
            // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
            // ? = to be determined. : = across all values in that axis.
            var dotProd = ${xt.type.value}(0.0);
            var wR: u32 = 0;
            if (uniforms.dilations.x == 1) {
              // Minimum wR >= 0 that satisfies (dyRCorner + wR) % (uniforms.strides.x) == 0
              wR = u32(((dyRCorner + i32(uniforms.strides.x) - 1) / i32(uniforms.strides.x)) * i32(uniforms.strides.x) - dyRCorner);
            }
            for (; wR < uniforms.effective_filter_dims.x; wR = wR + 1) {
              if (wR % uniforms.dilations.x != 0) {
                continue;
              }
              let dyR = (${Je}(dyRCorner) + ${Je}(wR)) / ${Je}(uniforms.strides[0]);
              let wRPerm = uniforms.filter_dims.x - 1 - wR / uniforms.dilations.x;
              if (dyR < 0.0 || dyR >= ${Je}(uniforms.Dy_shape[${st}]) || fract(dyR) > 0.0 ||
                  wRPerm < 0) {
                continue;
              }
              let idyR: u32 = u32(dyR);
              var wC: u32 = 0;
              if (uniforms.dilations.y == 1) {
                // Minimum wC >= 0 that satisfies (dyCCorner + wC) % (uniforms.strides.y) == 0
                wC = u32(((dyCCorner + i32(uniforms.strides.y) - 1) / i32(uniforms.strides.y)) * i32(uniforms.strides.y) - dyCCorner);
              }
              for (; wC < uniforms.effective_filter_dims.y; wC = wC + 1) {
                if (wC % uniforms.dilations.y != 0) {
                  continue;
                }
                let dyC = (${Je}(dyCCorner) + ${Je}(wC)) / ${Je}(uniforms.strides.y);
                let wCPerm = uniforms.filter_dims.y - 1 - wC / uniforms.dilations.y;
                if (dyC < 0.0 || dyC >= ${Je}(uniforms.Dy_shape[${gt}]) ||
                    fract(dyC) > 0.0 || wCPerm < 0) {
                  continue;
                }
                let idyC: u32 = u32(dyC);
                var inputChannel = groupId * uniforms.input_channels_per_group;
                ${V ? `
                var x_offset = ${ht.indicesToOffset(`${ht.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${$};
                var w_offset = ${yt.indicesToOffset(`${yt.type.indices}(wRPerm, wCPerm, inputChannel, wOutChannel)`)} / ${re};
                  ` : ""}
                for (var d2: u32 = 0; d2 < uniforms.input_channels_per_group_int; d2 = d2 + ${V ? 4 : $}) {
                  ${Ct()}
                  inputChannel = inputChannel + ${V ? 4 : $};
                }
                ${Ze()}
                wC = wC + uniforms.strides.y - 1;
              }
              wR = wR + uniforms.strides[0] - 1;
            }
            let value = dotProd${g ? ` + bias[d1 / ${X}]` : ""};
            ${xt.setByOffset("global_idx", "value")};
          `;
          return `
    ${Pe.registerUniforms(Ue).declareVariables(...Ot, xt)}
      ${Pe.mainStart()}
      ${Pe.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")};
    ${ft}}`;
        };
        return { name: "ConvTranspose2D", shaderCache: { hint: `${o.cacheKey};${$}${re}${X}${V}${ee}`, inputDependencies: ce }, getRunData: () => ({ dispatchGroup: { x: ue[0], y: ue[1], z: ue[2] }, outputs: [{ dims: d ? d(y) : y, dataType: s[0].dataType }], programUniforms: oe }), getShaderSource: ye };
      };
    }), Dh, El, kh, Sl, Oh, Pl, Al, Fh, Cl, vg = l(() => {
      yg(), Ys(), Hs(), Dh = (s, o, d, g, y, x) => (s - 1) * o + d + (g - 1) * y + 1 - x, El = (s, o, d, g, y) => {
        let x = Math.floor(s / 2);
        o === "SAME_UPPER" ? (d[g] = x, d[y] = s - x) : o === "SAME_LOWER" && (d[g] = s - x, d[y] = x);
      }, kh = (s, o, d, g, y, x, b, P, k, O) => {
        let $ = s.length - 2, V = O.length === 0;
        k.length < $ && k.push(...Array($ - k.length).fill(0));
        let G = s[0], ee = o[P ? 3 : 1] * y;
        for (let X = 0, re = s.length - $ - (P ? 1 : 0); X < $; ++X, ++re) {
          let Te = s[re], ue = V ? Te * b[X] : O[X], ce = Dh(Te, b[X], x[X], o[re], d[X], ue);
          El(ce, g, x, X, X + $), V && O.push(b[X] * (Te - 1) + k[X] + (o[re] - 1) * d[X] + 1 - x[X] - x[X + $]);
        }
        O.splice(0, 0, G), O.splice(P ? 3 : 1, 0, ee);
      }, Sl = (s, o) => {
        let d = s.kernelShape.slice();
        if (s.kernelShape.length === 0 || s.kernelShape.reduce((V, G) => V * G, 1) === 0) {
          d.length = 0;
          for (let V = 2; V < o[1].dims.length; ++V)
            d.push(o[1].dims[V]);
        }
        let g = s.format === "NHWC";
        d.splice(0, 0, o[1].dims[0]), d.splice(g ? 3 : 1, 0, o[1].dims[1]);
        let y = s.pads.slice(), x = s.outputShape.slice(), b = s.outputPadding.slice(), P = o[0].dims, k = s.dilations.slice();
        if (k.reduce((V, G) => V + G, 0) === 0) {
          let V = o[0].dims.length - 2;
          k = new Array(V).fill(1);
        }
        let O = s.strides.slice();
        if (O.reduce((V, G) => V + G, 0) === 0) {
          let V = o[0].dims.length - 2;
          O = new Array(V).fill(1);
        }
        kh(P, d, k, s.autoPad, s.group, y, O, g, b, x);
        let $ = Object.assign({}, s);
        return Object.assign($, { kernelShape: d, pads: y, outputPadding: b, outputShape: x, dilations: k, strides: O }), $;
      }, Oh = (s) => {
        let o = fl(s), d = s.format, g = ["NOTSET", "VALID", "SAME_UPPER", "SAME_LOWER"][typeof s.autoPad > "u" ? 0 : s.autoPad], y = s.dilations, x = s.group, b = s.kernelShape, P = s.pads, k = s.strides, O = s.wIsConst(), $ = s.outputPadding, V = s.outputShape;
        return { autoPad: g, format: d, dilations: y, group: x, kernelShape: b, outputPadding: $, outputShape: V, pads: P, strides: k, wIsConst: O, ...o, cacheKey: `${s.format};${o.activation};` };
      }, Pl = (s, o) => {
        if (!s || s.length !== 2 && s.length !== 3)
          throw new Error("Conv requires 2 or 3 inputs");
        if (s[0].dims.length !== 4 && s[0].dims.length !== 3)
          throw new Error("currently only support 2-dimensional conv");
        if (s[0].dims.length !== s[1].dims.length)
          throw new Error("filter does not have same dimension as input");
        let d = s[0].dims[o.format === "NHWC" ? s[0].dims.length - 1 : 1], g = s[1].dims[0];
        if (d !== g)
          throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");
        let y = s[1].dims[1] * o.group;
        if (s.length === 3 && (s[2].dims.length !== 1 || s[2].dims[0] !== y))
          throw new Error("invalid bias");
        let x = s[0].dims.length - 2;
        if (o.dilations.reduce((b, P) => b + P, 0) > 0 && o.dilations.length !== x)
          throw new Error(`dilations should be ${x}D`);
        if (o.strides.reduce((b, P) => b + P, 0) > 0 && o.strides.length !== x)
          throw new Error(`strides should be ${x}D`);
        if (o.pads.reduce((b, P) => b + P, 0) > 0 && o.pads.length !== x * 2)
          throw new Error(`pads should be ${x * 2}D`);
        if (o.outputPadding.length !== x && o.outputPadding.length !== 0)
          throw new Error(`output_padding should be ${x}D`);
        if (o.kernelShape.reduce((b, P) => b + P, 0) > 0 && o.kernelShape.length !== 0 && o.kernelShape.length !== s[1].dims.length - 2)
          throw new Error("invalid kernel shape");
        if (o.outputShape.length !== 0 && o.outputShape.length !== s[0].dims.length - 2)
          throw new Error("invalid output shape");
      }, Al = (s, o, d, g) => {
        let y = s.kernelCustomData.wT ?? s.compute(bi(o[1], [2, 3, 0, 1]), { inputs: [1], outputs: [d.wIsConst ? -2 : -1] })[0];
        d.wIsConst && !s.kernelCustomData.wT && (s.kernelCustomData.wT = y);
        let x = [o[0], y];
        o.length === 3 && x.push(o[2]), s.compute(Lh(x, d, g), { inputs: x });
      }, Fh = (s, o) => {
        let d = o.format === "NHWC", g = [s.inputs[0].reshape(d ? [s.inputs[0].dims[0], 1, s.inputs[0].dims[1], s.inputs[0].dims[2]] : [s.inputs[0].dims[0], s.inputs[0].dims[1], 1, s.inputs[0].dims[2]]), s.inputs[1].reshape([s.inputs[1].dims[0], s.inputs[1].dims[1], 1, s.inputs[1].dims[2]])];
        s.inputs.length === 3 && g.push(s.inputs[2]);
        let y = o.kernelShape;
        (y.length === 0 || y[0] === 0) && (y = [s.inputs[1].dims[2]]);
        let x = o.dilations;
        (x.length === 0 || x[0] === 0) && (x = [1]);
        let b = o.strides;
        (b.length === 0 || b[0] === 0) && (b = [1]);
        let P = o.pads;
        P.length === 0 && (P = [0, 0]), P = [0, P[0], 0, P[1]], b = [1].concat(b), x = [1].concat(x), y = [1].concat(y);
        let k = o.outputPadding;
        k = [0].concat(k);
        let O = Sl({ ...o, pads: P, strides: b, dilations: x, kernelShape: y, outputPadding: k }, g);
        Al(s, g, O, ($) => d ? [$[0], $[2], $[3]] : [$[0], $[1], $[3]]);
      }, Cl = (s, o) => {
        if (Pl(s.inputs, o), s.inputs[0].dims.length === 3)
          Fh(s, o);
        else {
          let d = Sl(o, s.inputs);
          Al(s, s.inputs, d);
        }
      };
    }), Rh, Bh, Il, wg = l(() => {
      jt(), ie(), pn(), sn(), Rh = (s, o, d, g) => {
        let y = it.size(o), x = o.length, b = dt("input", s, x), P = $t("output", s, x), k = d.dataType === 6 ? d.getInt32Array()[0] : Number(d.getBigInt64Array()[0]), O = it.normalizeAxis(k, x), $ = (V) => {
          let G = ` i32(${b.indicesGet("inputIndices", "uniforms.axis")}) `, ee = Nt("uniforms.input_shape", "uniforms.axis", x), X = g.reverse ? G + (g.exclusive ? " + 1" : "") : "0", re = g.reverse ? ee : G + (g.exclusive ? "" : " + 1");
          return `
                ${V.registerUniform("outputSize", "u32").registerUniform("axis", "u32").declareVariables(b, P)}
                ${V.mainStart()}
                  ${V.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
                  var inputIndices = ${P.offsetToIndices("global_idx")};
                  var sum = ${P.type.value}(0);
                  let first : i32 = ${X};
                  let last : i32 = ${re};
                  for (var i : i32 = first; i < last; i++) {
                    ${b.indicesSet("inputIndices", "uniforms.axis", "u32(i)")};
                    sum = sum + ${b.getByIndices("inputIndices")};
                  }
                  ${P.setByOffset("global_idx", "sum")};
                }`;
        };
        return { name: "CumSum", shaderCache: { hint: g.cacheKey, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: o, dataType: s }], dispatchGroup: { x: Math.ceil(y / 64) }, programUniforms: [{ type: 12, data: y }, { type: 12, data: O }, ...Ut(o, o)] }), getShaderSource: $ };
      }, Bh = (s, o) => {
        let d = s.inputs[0].dims, g = s.inputs[0].dataType, y = s.inputs[1];
        s.compute(Rh(g, d, y, o), { inputs: [0] });
      }, Il = (s) => {
        let o = s.exclusive === 1, d = s.reverse === 1;
        return Yt({ exclusive: o, reverse: d });
      };
    }), zh, Ll, $h, Nh, Dl, xg = l(() => {
      jt(), ie(), pn(), sn(), zh = (s) => {
        if (!s || s.length !== 1)
          throw new Error("DepthToSpace requires 1 input.");
        if (s[0].dims.length !== 4)
          throw new Error("DepthToSpace requires 4D input.");
      }, Ll = (s, o, d, g) => {
        let y = [];
        y.push(`fn perm(i: ${g.type.indices}) -> ${d.type.indices} {
    var a: ${d.type.indices};`);
        for (let x = 0; x < o; ++x)
          y.push(d.indicesSet("a", s[x], `i[${x}]`));
        return y.push("return a;}"), y.join(`
`);
      }, $h = (s, o) => {
        let d, g, y, x, b, P, k = o.format === "NHWC", O = o.blocksize, $ = o.mode === "DCR";
        k ? ([d, g, y, x] = s.dims, b = $ ? [d, g, y, O, O, x / O ** 2] : [d, g, y, x / O ** 2, O, O], P = $ ? [0, 1, 3, 2, 4, 5] : [0, 1, 4, 2, 5, 3]) : ([d, g, y, x] = [s.dims[0], s.dims[2], s.dims[3], s.dims[1]], b = $ ? [d, O, O, x / O ** 2, g, y] : [d, x / O ** 2, O, O, g, y], P = $ ? [0, 3, 4, 1, 5, 2] : [0, 1, 4, 2, 5, 3]);
        let V = s.reshape(b), G = V.dims.length, ee = s.dataType, X = dt("a", ee, G), re = $t("output", ee, G), Te = (ue) => `
  ${ue.registerUniform("output_size", "u32").declareVariables(X, re)}

  ${Ll(P, G, X, re)}

  ${ue.mainStart()}
    ${ue.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

    let indices = ${re.offsetToIndices("global_idx")};
    let aIndices = perm(indices);

    ${re.setByOffset("global_idx", X.getByIndices("aIndices"))}
  }`;
        return { name: "DepthToSpace", shaderCache: { hint: `${s.dims};${o.blocksize};${o.mode}`, inputDependencies: ["rank"] }, getRunData: (ue) => {
          let ce = k ? [d, g * O, y * O, x / O ** 2] : [d, x / O ** 2, g * O, y * O], ke = it.size(ce), Le = V.dims, M = it.sortBasedOnPerm(Le, P);
          return { outputs: [{ dims: ce, dataType: ue[0].dataType }], dispatchGroup: { x: Math.ceil(ke / 64) }, programUniforms: [{ type: 12, data: ke }, ...Ut(Le, M)] };
        }, getShaderSource: Te };
      }, Nh = (s, o) => {
        zh(s.inputs), s.compute($h(s.inputs[0], o));
      }, Dl = (s) => Yt({ blocksize: s.blocksize, mode: s.mode, format: s.format });
    }), Oo, Js, kl, Uh, Gh, Ol, Vh, Fl, Rl, jh, Wh, bg = l(() => {
      jt(), ie(), pn(), sn(), Oo = "[a-zA-Z]|\\.\\.\\.", Js = "(" + Oo + ")+", kl = "^" + Js + "$", Uh = "(" + Js + ",)*" + Js, Gh = "^" + Uh + "$", Ol = class {
        constructor(s = -1) {
          this.symbolToIndices = /* @__PURE__ */ new Map(), this.inputIndex = s;
        }
        addSymbol(s, o) {
          let d = this.symbolToIndices.get(s);
          d === void 0 ? d = [o] : d.push(o), this.symbolToIndices.set(s, d);
        }
      }, Vh = class {
        constructor(s, o) {
          var y;
          this.equation = o, this.hasEllipsis = !1, this.symbolToInfo = /* @__PURE__ */ new Map(), this.lhs = new Array(), this.outputDims = [];
          let [d, g] = o.includes("->") ? o.split("->", 2) : [o, ""];
          if (!d.match(RegExp(Gh)))
            throw new Error("Invalid LHS term");
          if (d.split(",").forEach((x, b) => {
            let P = s[b].dims.slice();
            if (!x.match(RegExp(kl)))
              throw new Error("Invalid LHS term");
            let k = this.processTerm(x, !0, P, b);
            this.lhs.push(k);
          }), g === "")
            g += [...this.symbolToInfo.entries()].filter(([x, b]) => b.count === 1 || x === "...").map(([x]) => x).join("");
          else if (!g.match(RegExp(Js)))
            throw new Error("Invalid RHS");
          (y = g.match(RegExp(Oo, "g"))) == null || y.forEach((x) => {
            if (x === "...")
              this.outputDims = this.outputDims.concat(this.ellipsisDims);
            else {
              let b = this.symbolToInfo.get(x);
              if (b === void 0)
                throw new Error("Invalid RHS symbol");
              this.outputDims.push(b.dimValue);
            }
          }), this.rhs = this.processTerm(g, !1, this.outputDims);
        }
        addSymbol(s, o, d) {
          let g = this.symbolToInfo.get(s);
          if (g !== void 0) {
            if (g.dimValue !== o && g.count !== 1)
              throw new Error("Dimension mismatch");
            g.count++, g.inputIndices.push(d);
          } else
            g = { count: 1, dimValue: o, inputIndices: [d] };
          this.symbolToInfo.set(s, g);
        }
        processTerm(s, o, d, g = -1) {
          let y = d.length, x = !1, b = [], P = 0;
          if (!s.match(RegExp(kl)) && !o && s !== "")
            throw new Error("Invalid LHS term");
          let k = s.match(RegExp(Oo, "g")), O = new Ol(g);
          return k == null || k.forEach(($, V) => {
            if ($ === "...") {
              if (x)
                throw new Error("Only one ellipsis is allowed per input term");
              x = !0;
              let G = y - k.length + 1;
              if (G < 0)
                throw new Error("Ellipsis out of bounds");
              if (b = d.slice(P, P + G), this.hasEllipsis) {
                if (this.ellipsisDims.length !== b.length || this.ellipsisDims.toString() !== b.toString())
                  throw new Error("Ellipsis dimensions mismatch");
              } else if (o)
                this.hasEllipsis = !0, this.ellipsisDims = b;
              else
                throw new Error("Ellipsis must be specified in the LHS");
              for (let ee = 0; ee < b.length; ee++) {
                let X = String.fromCharCode(48 + ee);
                O.addSymbol(X, V + ee), this.addSymbol(X, d[P++], g);
              }
            } else
              O.addSymbol($, V + (this.hasEllipsis ? this.ellipsisDims.length - 1 : 0)), this.addSymbol($, d[P++], g);
          }), O;
        }
      }, Fl = (s) => s + "_max", Rl = (s, o, d, g) => {
        let y = s.map((O) => O.length).map((O, $) => dt(`input${$}`, o, O)), x = it.size(g), b = $t("output", o, g.length), P = [...d.symbolToInfo.keys()].filter((O) => !d.rhs.symbolToIndices.has(O)), k = (O) => {
          let $ = [], V = "var prod = 1.0;", G = "var sum = 0.0;", ee = "sum += prod;", X = [], re = [], Te = [], ue = [], ce = d.symbolToInfo.size === d.rhs.symbolToIndices.size;
          d.symbolToInfo.forEach((Le, M) => {
            var C;
            if (d.rhs.symbolToIndices.has(M)) {
              let z = (C = d.rhs.symbolToIndices.get(M)) == null ? void 0 : C[0];
              z !== void 0 && d.lhs.forEach((oe, ye) => {
                if (Le.inputIndices.includes(ye)) {
                  let Pe = oe.symbolToIndices.get(M);
                  if (Pe === void 0)
                    throw new Error("Invalid symbol error");
                  Pe.forEach((Ue) => {
                    $.push(`${y[ye].indicesSet(`input${ye}Indices`, Ue, b.indicesGet("outputIndices", z))}`);
                  });
                }
              });
            } else
              d.lhs.forEach((z, oe) => {
                if (Le.inputIndices.includes(oe)) {
                  let ye = z.symbolToIndices.get(M);
                  if (ye === void 0)
                    throw new Error("Invalid symbol error");
                  ye.forEach((Pe) => {
                    X.push(`${y[oe].indicesSet(`input${oe}Indices`, Pe, `${M}`)}`);
                  }), ue.push(`prod *= ${y[oe].getByIndices(`input${oe}Indices`)};`);
                }
              }), re.push(`for(var ${M}: u32 = 0; ${M} < uniforms.${Fl(M)}; ${M}++) {`), Te.push("}");
          });
          let ke = ce ? [...$, `let sum = ${y.map((Le, M) => Le.getByIndices(`input${M}Indices`)).join(" * ")};`] : [...$, G, ...re, ...X, V, ...ue, ee, ...Te];
          return `
            ${O.registerUniforms(P.map((Le) => ({ name: `${Fl(Le)}`, type: "u32" }))).registerUniform("outputSize", "u32").declareVariables(...y, b)}

            ${O.mainStart()}
            ${O.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
            var outputIndices = ${b.offsetToIndices("global_idx")};
            ${y.map((Le, M) => `var input${M}Indices: ${y[M].type.indices};`).join(`
`)}
            ${ke.join(`
`)};
            ${b.setByOffset("global_idx", "sum")};
          }`;
        };
        return { name: "Einsum", shaderCache: { hint: d.equation, inputDependencies: s.map(() => "rank") }, getRunData: () => {
          let O = P.filter((V) => d.symbolToInfo.has(V)).map((V) => {
            var G;
            return { type: 12, data: ((G = d.symbolToInfo.get(V)) == null ? void 0 : G.dimValue) || 0 };
          });
          O.push({ type: 12, data: x });
          let $ = s.map((V, G) => [...Ut(V)]).reduce((V, G) => V.concat(G), O);
          return $.push(...Ut(g)), { outputs: [{ dims: g, dataType: o }], dispatchGroup: { x: Math.ceil(x / 64) }, programUniforms: $ };
        }, getShaderSource: k };
      }, jh = (s, o) => {
        let d = new Vh(s.inputs, o.equation), g = d.outputDims, y = s.inputs.map((x, b) => x.dims);
        s.compute(Rl(y, s.inputs[0].dataType, d, g));
      }, Wh = (s) => {
        let o = s.equation.replace(/\s+/g, "");
        return Yt({ equation: o });
      };
    }), Hh, Ur, qh, Kh, Xh, Mg = l(() => {
      jt(), ie(), sn(), Hh = (s) => {
        if (!s || s.length !== 2)
          throw new Error("Expand requires 2 input.");
        let o = s[0].dims, d = Array.from(s[1].getBigInt64Array(), Number), g = d.length < o.length ? 0 : d.length - o.length, y = o.length < d.length ? 0 : o.length - d.length;
        for (; g < d.length && y < o.length; ++g, ++y)
          if (d[g] !== o[y] && d[g] !== 1 && o[y] !== 1)
            throw new Error("Expand requires shape to be broadcastable to input");
      }, Ur = (s, o) => {
        let d = s.length - o.length, g = [];
        for (let y = 0; y < d; ++y)
          g.push(s[y]);
        for (let y = 0; y < o.length; ++y)
          g.push(o[y] === 1 ? s[y + d] : o[y]);
        return g;
      }, qh = (s, o) => s.length > o.length ? Ur(s, o) : Ur(o, s), Kh = (s) => {
        let o = s[0].dims, d = Array.from(s[1].getBigInt64Array(), Number), g = qh(o, d), y = s[0].dataType, x = y === 9 || it.size(o) === 1, b = y === 9 || o.length > 0 && o[o.length - 1] % 4 === 0 ? 4 : 1, P = x || g.length > 0 && g[g.length - 1] % 4 === 0 ? 4 : 1, k = Math.ceil(it.size(g) / P), O = (V) => {
          let G = dt("input", y, o.length, b), ee = $t("output", y, g.length, P), X;
          if (y === 9) {
            let re = (Te, ue, ce = "") => `
          let outputIndices${ue} = ${ee.offsetToIndices(`outputOffset + ${ue}u`)};
          let offset${ue} = ${G.broadcastedIndicesToOffset(`outputIndices${ue}`, ee)};
          let index${ue} = offset${ue} / 4u;
          let component${ue} = offset${ue} % 4u;
          ${Te}[${ue}] = ${ce}(${G.getByOffset(`index${ue}`)}[component${ue}]);
        `;
            X = `
        let outputOffset = global_idx * ${P};
        var data = vec4<u32>(0);
        ${re("data", 0, "u32")}
        ${re("data", 1, "u32")}
        ${re("data", 2, "u32")}
        ${re("data", 3, "u32")}
        ${ee.setByOffset("global_idx", "data")}
      }`;
          } else
            X = `
        let outputIndices = ${ee.offsetToIndices(`global_idx * ${P}`)};
        let inputOffset = ${G.broadcastedIndicesToOffset("outputIndices", ee)};
        let data = ${ee.type.value}(${G.getByOffset(`inputOffset / ${b}`)});
        ${ee.setByOffset("global_idx", "data")}
      }`;
          return `
    ${V.registerUniform("vec_size", "u32").declareVariables(G, ee)}
    ${V.mainStart()}
    ${V.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}
    ${X}`;
        }, $ = [{ type: 12, data: k }, ...Ut(o, g)];
        return { name: "Expand", shaderCache: { hint: `${g.length};${b}${P}`, inputDependencies: ["rank"] }, getShaderSource: O, getRunData: () => ({ outputs: [{ dims: g, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(k / 64) }, programUniforms: $ }) };
      }, Xh = (s) => {
        Hh(s.inputs), s.compute(Kh(s.inputs), { inputs: [0] });
      };
    }), Yh, Jh, Tg = l(() => {
      jt(), ie(), sn(), ol(), Yh = (s) => {
        let o = s[0].dataType, d = it.size(s[0].dims), g = it.size(s[1].dims), y = g % 4 === 0, x = (b) => {
          let P = dt("x", o, [1], 4), k = dt("bias", o, [1], 4), O = $t("y", o, [1], 4), $ = [{ name: "output_vec_size", type: "u32" }, { name: "bias_size", type: "u32" }], V = (ee) => `
      let bias${ee}_offset: u32 = (global_idx * 4 + ${ee}) % uniforms.bias_size;
      let bias${ee} = ${k.getByOffset(`bias${ee}_offset / 4`)}[bias${ee}_offset % 4];`, G = y ? `
      let bias = ${k.getByOffset("global_idx % (uniforms.bias_size / 4)")};` : `${V(0)}${V(1)}${V(2)}${V(3)}
      let bias = ${P.type.value}(bias0, bias1, bias2, bias3);`;
          return `${b.registerUniforms($).declareVariables(P, k, O)}

    ${Po(di(o))}

    ${b.mainStart(ts)}
      ${b.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_vec_size")}

      let x = ${P.getByOffset("global_idx")};
      ${G}
      let x_in = x + bias;
      ${O.setByOffset("global_idx", il("x_in"))}
    }`;
        };
        return { name: "FastGeluWithBias", shaderCache: { hint: `${y}`, inputDependencies: ["type", "type"] }, getShaderSource: x, getRunData: (b) => ({ outputs: [{ dims: b[0].dims, dataType: b[0].dataType }], programUniforms: [{ type: 12, data: Math.ceil(d / 4) }, { type: 12, data: g }], dispatchGroup: { x: Math.ceil(d / ts / 4) } }) };
      }, Jh = (s) => {
        s.inputs.length < 2 || it.size(s.inputs[1].dims) === 0 ? Wd(s) : s.compute(Yh(s.inputs));
      };
    }), Qh, Zh, Bl, ef, Eg = l(() => {
      jt(), ie(), pn(), sn(), Qh = (s) => {
        if (!s || s.length !== 2)
          throw new Error("Gather requires 2 inputs.");
      }, Zh = (s, o) => {
        let d = s[0].dims, g = s[1].dims, y = d.length, x = it.normalizeAxis(o.axis, y), b = d.slice(0);
        b.splice(x, 1, ...g);
        let P = d[x], k = s[0].dataType === 9 ? 4 : 1, O = Math.ceil(it.size(b) / k), $ = [{ type: 12, data: O }, { type: 6, data: P }, { type: 12, data: x }, ...Ut(s[0].dims, s[1].dims, b)], V = (G) => {
          let ee = dt("data", s[0].dataType, s[0].dims.length, k), X = dt("inputIndices", s[1].dataType, s[1].dims.length), re = $t("output", s[0].dataType, b.length, k), Te = (ce) => {
            let ke = g.length, Le = `var indicesIndices${ce}  = ${X.type.indices}(0);`;
            for (let M = 0; M < ke; M++)
              Le += `${ke > 1 ? `indicesIndices${ce}[${M}]` : `indicesIndices${ce}`} = ${b.length > 1 ? `outputIndices${ce}[uniforms.axis + ${M}]` : `outputIndices${ce}`};`;
            Le += `
          var idx${ce} = ${X.getByIndices(`indicesIndices${ce}`)};
          if (idx${ce} < 0) {
            idx${ce} = idx${ce} + uniforms.axisDimLimit;
          }
          var dataIndices${ce} : ${ee.type.indices};
        `;
            for (let M = 0, C = 0; M < y; M++)
              M === x ? (Le += `${y > 1 ? `dataIndices${ce}[${M}]` : `dataIndices${ce}`} = u32(idx${ce});`, C += ke) : (Le += `${y > 1 ? `dataIndices${ce}[${M}]` : `dataIndices${ce}`} = ${b.length > 1 ? `outputIndices${ce}[${C}]` : `outputIndices${ce}`};`, C++);
            return Le;
          }, ue;
          if (s[0].dataType === 9) {
            let ce = (ke, Le, M = "") => `
          let outputIndices${Le} = ${re.offsetToIndices(`outputOffset + ${Le}u`)};
          ${Te(Le)};
          let offset${Le} = ${ee.indicesToOffset(`dataIndices${Le}`)};
          let index${Le} = offset${Le} / 4u;
          let component${Le} = offset${Le} % 4u;
          ${ke}[${Le}] = ${M}(${ee.getByOffset(`index${Le}`)}[component${Le}]);
        `;
            ue = `
        let outputOffset = global_idx * ${k};
        var value = vec4<u32>(0);
        ${ce("value", 0, "u32")}
        ${ce("value", 1, "u32")}
        ${ce("value", 2, "u32")}
        ${ce("value", 3, "u32")}
        ${re.setByOffset("global_idx", "value")}
      `;
          } else
            ue = `
      let outputIndices = ${re.offsetToIndices("global_idx")};
      ${Te("")};
      let value = ${ee.getByIndices("dataIndices")};
      ${re.setByOffset("global_idx", "value")};
      `;
          return `
      ${G.registerUniform("outputSize", "u32").registerUniform("axisDimLimit", "i32").registerUniform("axis", "u32").declareVariables(ee, X, re)}
      ${G.mainStart()}
        ${G.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
        ${ue}
      }`;
        };
        return { name: "Gather", shaderCache: { hint: o.cacheKey, inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: b, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(O / 64) }, programUniforms: $ }), getShaderSource: V };
      }, Bl = (s) => Yt({ axis: s.axis }), ef = (s, o) => {
        let d = s.inputs;
        Qh(d), s.compute(Zh(s.inputs, o));
      };
    }), zl, tf, nf, Sg = l(() => {
      jt(), ie(), sn(), zl = (s, o, d, g, y, x, b, P, k) => {
        let O = [{ type: 12, data: x }, { type: 12, data: g }, { type: 12, data: y }, { type: 12, data: d }, { type: 12, data: b }, { type: 12, data: P }, { type: 12, data: k }], $ = [x];
        O.push(...Ut(o.dims, $));
        let V = (G) => {
          let ee = dt("indices_data", o.dataType, o.dims.length), X = $t("input_slice_offsets_data", 12, 1, 1), re = [ee, X], Te = [{ name: "output_size", type: "u32" }, { name: "batch_dims", type: "u32" }, { name: "input_dims", type: "u32", length: y.length }, { name: "sizes_from_slice_dims_data", type: "u32", length: d.length }, { name: "num_slices_per_batch", type: "u32" }, { name: "input_batch_stride", type: "u32" }, { name: "num_slice_dims", type: "u32" }];
          return `
  ${G.registerUniforms(Te).declareVariables(...re)}
  ${G.mainStart()}
    ${G.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let batch_idx = global_idx / uniforms.num_slices_per_batch;
    let base_offset = batch_idx * uniforms.input_batch_stride;

    let slice_indices_base_offset = global_idx * uniforms.num_slice_dims;
    var relative_slice_offset = 0;
    for (var dim_idx = 0u; dim_idx < uniforms.num_slice_dims; dim_idx ++) {
      var index = i32(indices_data[dim_idx + slice_indices_base_offset].x);
      let input_dim_idx = uniforms.batch_dims + dim_idx;
      if (index < 0) {
        ${y.length === 1 ? "index += i32(uniforms.input_dims);" : "index += i32(uniforms.input_dims[input_dim_idx]);"}
      }
      ${d.length === 1 ? "relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data);" : "relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data[dim_idx]);"}
    }

    input_slice_offsets_data[global_idx] =  base_offset + u32(relative_slice_offset);
  }`;
        };
        return s.compute({ name: "computeSliceOffsets", shaderCache: { hint: `${y.length}_${d.length}`, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: $, dataType: s.inputs[1].dataType }], dispatchGroup: { x: Math.ceil(x / 64) }, programUniforms: O }), getShaderSource: V }, { inputs: [o], outputs: [-1] })[0];
      }, tf = (s, o) => {
        let d = s.inputs, g = d[0].dims, y = d[0].dataType, x = d[1].dims, b = x[x.length - 1], P = it.sizeToDimension(x, x.length - 1), k = it.sizeFromDimension(g, o.batchDims + b), O = it.sizeToDimension(g, o.batchDims), $ = it.sizeFromDimension(g, o.batchDims), V = P / O, G = new Array(b), ee = k;
        for (let Le = 0; Le < b; ++Le)
          G[b - 1 - Le] = ee, ee *= g[o.batchDims + b - 1 - Le];
        let X = zl(s, d[1], G, o.batchDims, g, P, V, $, b), re = o.batchDims + b;
        if (re > g.length)
          throw new Error("last dimension of indices must not be larger than rank of input tensor");
        let Te = x.slice(0, -1).concat(g.slice(re)), ue = it.size(Te), ce = [{ type: 12, data: ue }, { type: 12, data: k }, ...Ut(d[0].dims, X.dims, Te)], ke = (Le) => {
          let M = dt("data", d[0].dataType, d[0].dims.length), C = dt("slice_offsets", 12, X.dims.length), z = $t("output", d[0].dataType, Te.length);
          return `
          ${Le.registerUniform("output_size", "u32").registerUniform("slice_size", "u32").declareVariables(M, C, z)}
            ${Le.mainStart()}
            ${Le.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
          let slice_offset = slice_offsets[global_idx / uniforms.slice_size];
          output[global_idx] = data[u32(slice_offset) + global_idx % uniforms.slice_size];
        }`;
        };
        s.compute({ name: "GatherND", shaderCache: { hint: o.cacheKey, inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: Te, dataType: y }], dispatchGroup: { x: Math.ceil(ue / 64) }, programUniforms: ce }), getShaderSource: ke }, { inputs: [d[0], X] });
      }, nf = (s) => ({ batchDims: s.batch_dims, cacheKey: "" });
    }), sf, $l, rf, of, af = l(() => {
      jt(), ie(), pn(), sn(), sf = (s, o) => {
        if (s.length < 3 || s.length > 4)
          throw new Error("GatherBlockQuantized requires 3 or 4 inputs.");
        let d = it.normalizeAxis(o.quantizeAxis, s[0].dims.length), g = o.blockSize, y = s[0], x = s[2], b = s.length === 4 ? s[3] : void 0;
        if (x.dims.length !== y.dims.length || !y.dims.map((P, k) => k === d ? Math.ceil(P / g) === x.dims[k] : P === x.dims[k]).reduce((P, k) => P && k, !0))
          throw new Error("Scales must have the same rank as the input tensor and the dims should match except on gatherAxis.");
        if (b) {
          if (b.dataType !== y.dataType)
            throw new Error("Zero point must have the same data type as the input tensor.");
          if (b.dims.length !== x.dims.length || !b.dims.map((P, k) => P === x.dims[k]).reduce((P, k) => P && k, !0))
            throw new Error("Zero point must have the same rank as the input tensor and the dims should match except on quantizeAxis.");
        }
      }, $l = (s, o) => {
        let d = s[0].dims, g = s[1].dims, y = d.length, x = it.normalizeAxis(o.gatherAxis, y), b = it.normalizeAxis(o.quantizeAxis, y), P = d.slice(0);
        P.splice(x, 1, ...g);
        let k = it.size(P), O = s[2].dataType, $ = s[0].dataType === 22, V = [{ type: 12, data: k }, { type: 12, data: b }, { type: 12, data: x }, { type: 12, data: o.blockSize }, ...Ut(...s.map((ee, X) => ee.dims), P)], G = (ee) => {
          let X = dt("data", s[0].dataType, s[0].dims.length), re = dt("inputIndices", s[1].dataType, s[1].dims.length), Te = dt("scales", s[2].dataType, s[2].dims.length), ue = s.length > 3 ? dt("zeroPoint", s[3].dataType, s[3].dims.length) : void 0, ce = $t("output", O, P.length), ke = [X, re, Te];
          ue && ke.push(ue);
          let Le = [{ name: "output_size", type: "u32" }, { name: "quantize_axis", type: "u32" }, { name: "gather_axis", type: "u32" }, { name: "block_size", type: "u32" }];
          return `
        ${ee.registerUniforms(Le).declareVariables(...ke, ce)}
        ${ee.mainStart()}
        let output_indices = ${ce.offsetToIndices("global_idx")};
        var indices_indices = ${re.type.indices}(0);
        ${g.length > 1 ? `
          for (var i: u32 = 0; i < ${g.length}; i++) {
            let index = ${ce.indicesGet("output_indices", "uniforms.gather_axis + i")};
            ${re.indicesSet("indices_indices", "i", "index")};
          }` : `indices_indices = ${ce.indicesGet("output_indices", "uniforms.gather_axis")};`};
        var data_indices = ${X.type.indices}(0);
        for (var i: u32 = 0; i < uniforms.gather_axis; i++) {
          let index = ${ce.indicesGet("output_indices", "i")};
          ${X.indicesSet("data_indices", "i", "index")};
        }
        var index_from_indices = ${re.getByIndices("indices_indices")};
        if (index_from_indices < 0) {
          index_from_indices += ${d[x]};
        }
        ${X.indicesSet("data_indices", "uniforms.gather_axis", "u32(index_from_indices)")};
        for (var i = uniforms.gather_axis + 1; i < ${P.length}; i++) {
          let index = ${ce.indicesGet("output_indices", `i + ${g.length} - 1`)};
          ${X.indicesSet("data_indices", "i", "index")};
        }
        let data_offset = ${X.indicesToOffset("data_indices")};
        let data_index = data_offset % 8;
        // Convert 4-bit packed data to 8-bit packed data.
        let packed_4bit_quantized_data = ${X.getByOffset("data_offset / 8")};
        let packed_8bit_quantized_data = (packed_4bit_quantized_data >> (4 * (data_index % 2))) & 0x0f0f0f0f;
        let quantized_data_vec = ${$ ? "unpack4xI8" : "unpack4xU8"}(u32(packed_8bit_quantized_data));
        let quantized_data = quantized_data_vec[data_index / 2];
        var scale_indices = data_indices;
        let quantize_axis_index = ${Te.indicesGet("data_indices", "uniforms.quantize_axis")} / uniforms.block_size;
        ${Te.indicesSet("scale_indices", "uniforms.quantize_axis", "quantize_axis_index")};
        var scale = ${Te.getByIndices("scale_indices")};
        ${ue ? `
              let zero_point_indices = scale_indices;
              let zero_point_offset = ${ue.indicesToOffset("zero_point_indices")};
              let zero_point_index = zero_point_offset % 8;
              let packed_4bit_zero_points = ${ue.getByOffset("zero_point_offset / 8")};
              let packed_8bit_zero_points = (packed_4bit_zero_points >> (4 * (zero_point_index % 2))) & 0x0f0f0f0f;
              let zero_point_vec = ${$ ? "unpack4xI8" : "unpack4xU8"}(u32(packed_8bit_zero_points));
              let zero_point = zero_point_vec[zero_point_index / 2];` : "var zero_point = 0"};
        let dequantized_data = ${di(O)}(quantized_data - zero_point) * scale;
        ${ce.setByOffset("global_idx", "dequantized_data")};
    }`;
        };
        return { name: "GatherBlockQuantized", shaderCache: { hint: `${o.cacheKey};${s.filter((ee, X) => X !== 1).map((ee) => ee.dims.join("_")).join(";")}`, inputDependencies: Array.from({ length: s.length }, (ee, X) => "rank") }, getRunData: () => ({ outputs: [{ dims: P, dataType: O }], dispatchGroup: { x: Math.ceil(k / 64) }, programUniforms: V }), getShaderSource: G };
      }, rf = (s, o) => {
        let d = s.inputs;
        sf(d, o), s.compute($l(s.inputs, o));
      }, of = (s) => Yt({ blockSize: s.blockSize, gatherAxis: s.gatherAxis, quantizeAxis: s.quantizeAxis });
    }), lf, cf, Nl, uf, Pg = l(() => {
      jt(), ie(), pn(), sn(), lf = (s) => {
        if (!s || s.length !== 2)
          throw new Error("GatherElements requires 2 inputs.");
        if (s[0].dims.length < 1)
          throw new Error("GatherElements requires that the data input be rank >= 1.");
        if (s[0].dims.length !== s[1].dims.length)
          throw new Error(`GatherElements requires that the data input and
                     indices input tensors be of same rank.`);
      }, cf = (s, o) => {
        let d = s[0].dims, g = s[0].dataType, y = d.length, x = s[1].dims, b = s[1].dataType, P = it.normalizeAxis(o.axis, y), k = d[P], O = x.slice(0), $ = it.size(O), V = dt("input", g, y), G = dt("indicesInput", b, x.length), ee = $t("output", g, O.length), X = [{ type: 12, data: $ }, { type: 6, data: k }, { type: 12, data: P }];
        return X.push(...Ut(d, x, O)), { name: "GatherElements", shaderCache: { inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: O, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil($ / 64) }, programUniforms: X }), getShaderSource: (re) => `
      ${re.registerUniform("outputSize", "u32").registerUniform("axisDimLimit", "i32").registerUniform("axis", "u32").declareVariables(V, G, ee)}
      ${re.mainStart()}
      ${re.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}

      let outputIndices = ${ee.offsetToIndices("global_idx")};

      var idx = ${G.getByOffset("global_idx")};
      if (idx < 0) {
        idx = idx + uniforms.axisDimLimit;
      }
      var inputIndices = ${V.type.indices}(outputIndices);
      ${V.indicesSet("inputIndices", "uniforms.axis", "u32(idx)")};
      let value = ${V.getByIndices("inputIndices")};

      ${ee.setByOffset("global_idx", "value")};
  }` };
      }, Nl = (s) => Yt({ axis: s.axis }), uf = (s, o) => {
        let d = s.inputs;
        lf(d), s.compute(cf(s.inputs, o));
      };
    }), Ul, df, hf, ff, Ag = l(() => {
      jt(), ie(), sn(), Ul = (s) => {
        if (!s)
          throw new Error("Input is missing");
        if (s.length < 2 || s.length > 3)
          throw new Error("Invaid input number.");
        if (s.length === 3 && s[2].dims.length > 2)
          throw new Error("Invalid input shape of C");
        if (s[0].dataType !== s[1].dataType || s.length === 3 && s[0].dataType !== s[2].dataType)
          throw new Error("Input types are mismatched");
      }, df = (s, o) => {
        let d = s[0].dims.slice(), g = s[1].dims.slice(), [y, x, b] = Br.getShapeOfGemmResult(d, o.transA, g, o.transB, s.length === 3 ? s[2].dims : void 0), P = [y, x];
        if (!P)
          throw new Error("Can't use gemm on the given tensors");
        let k = 16, O = Math.ceil(x / k), $ = Math.ceil(y / k), V = !0, G = it.size(P), ee = [{ type: 12, data: V ? O : G }, { type: 12, data: y }, { type: 12, data: x }, { type: 12, data: b }, { type: 1, data: o.alpha }, { type: 1, data: o.beta }], X = ["type", "type"];
        s.length === 3 && (ee.push(...Ut(s[2].dims)), X.push("rank")), ee.push(...Ut(P));
        let re = (ue) => {
          let ce = "";
          o.transA && o.transB ? ce = "value += a[k * uniforms.M + m] * b[n * uniforms.K + k];" : o.transA && !o.transB ? ce = "value += a[k * uniforms.M + m] * b[k * uniforms.N + n];" : !o.transA && o.transB ? ce = "value += a[m * uniforms.K + k] * b[n * uniforms.K + k];" : !o.transA && !o.transB && (ce = "value += a[m * uniforms.K + k] * b[k * uniforms.N + n];");
          let ke = o.alpha === 1 ? "" : "value *= uniforms.alpha;", Le = dt("a", s[0].dataType, s[0].dims), M = dt("b", s[1].dataType, s[1].dims), C = Le.type.value, z = null, oe = [Le, M];
          s.length === 3 && (z = dt("c", s[2].dataType, s[2].dims.length), oe.push(z));
          let ye = $t("output", s[0].dataType, P.length);
          oe.push(ye);
          let Pe = [{ name: "output_size", type: "u32" }, { name: "M", type: "u32" }, { name: "N", type: "u32" }, { name: "K", type: "u32" }, { name: "alpha", type: "f32" }, { name: "beta", type: "f32" }];
          return `
  ${ue.registerUniforms(Pe).declareVariables(...oe)}

  ${ue.mainStart()}
    ${ue.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

    let m = global_idx / uniforms.N;
    let n = global_idx % uniforms.N;

    var value = ${C}(0);
    for (var k: u32 = 0u; k < uniforms.K; k++) {
      ${ce}
    }

    ${ke}
    ${z != null ? `let cOffset = ${z.broadcastedIndicesToOffset("vec2(m, n)", ye)}; value += ${C}(uniforms.beta) * ${z.getByOffset("cOffset")};` : ""}
    output[global_idx] = value;
  }`;
        }, Te = (ue) => {
          let ce = dt("a", s[0].dataType, s[0].dims), ke = dt("b", s[1].dataType, s[1].dims), Le = null, M = [ce, ke];
          s.length === 3 && (Le = dt("c", s[2].dataType, s[2].dims.length), M.push(Le));
          let C = $t("output", s[0].dataType, P.length);
          M.push(C);
          let z = [{ name: "num_tile_n", type: "u32" }, { name: "M", type: "u32" }, { name: "N", type: "u32" }, { name: "K", type: "u32" }, { name: "alpha", type: "f32" }, { name: "beta", type: "f32" }], oe = "", ye = "";
          o.transA && o.transB ? (ye = `
      var col = tile_row_start + local_id.x;
      var row = k_start + local_id.y;
      if (col < uniforms.M && row < uniforms.K) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${ce.type.value}(0);
      }

      col = k_start + local_id.x;
      row = tile_col_start + local_id.y;
      if (col < uniforms.K && row < uniforms.N) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${ke.type.value}(0);
      }
      `, oe = "value += tile_a[k][local_id.y] * tile_b[local_id.x][k];") : o.transA && !o.transB ? (ye = `
      var col = tile_row_start + local_id.x;
      var row = k_start + local_id.y;
      if (col < uniforms.M && row < uniforms.K) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${ce.type.value}(0);
      }

      col = tile_col_start + local_id.x;
      row = k_start + local_id.y;
      if (col < uniforms.N && row < uniforms.K) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${ke.type.value}(0);
      }
      `, oe = "value += tile_a[k][local_id.y] * tile_b[k][local_id.x];") : !o.transA && o.transB ? (ye = `
      var col = k_start + local_id.x;
      var row = tile_row_start + local_id.y;
      if (col < uniforms.K && row < uniforms.M) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${ce.type.value}(0);
      }

      col = k_start + local_id.x;
      row = tile_col_start + local_id.y;
      if (col < uniforms.K && row < uniforms.N) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${ke.type.value}(0);
      }
      `, oe = "value += tile_a[local_id.y][k] * tile_b[local_id.x][k];") : !o.transA && !o.transB && (ye = `
      var col = k_start + local_id.x;
      var row = tile_row_start + local_id.y;
      if (col < uniforms.K && row < uniforms.M) {
        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];
      } else {
        tile_a[local_id.y][local_id.x] = ${ce.type.value}(0);
      }

      col = tile_col_start + local_id.x;
      row = k_start + local_id.y;
      if (col < uniforms.N && row < uniforms.K) {
        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];
      } else {
        tile_b[local_id.y][local_id.x] = ${ke.type.value}(0);
      }
      `, oe = "value += tile_a[local_id.y][k] * tile_b[k][local_id.x];");
          let Pe = o.alpha === 1 ? "" : "value *= uniforms.alpha;";
          return `
  ${ue.registerUniforms(z).declareVariables(...M)}
  var<workgroup> tile_a: array<array<${ce.type.storage}, ${k}>, ${k}>;
  var<workgroup> tile_b: array<array<${ke.type.storage}, ${k}>, ${k}>;
  ${ue.mainStart([k, k, 1])}
    let tile_col_start = (workgroup_index % uniforms.num_tile_n) * ${k};
    let tile_row_start = (workgroup_index / uniforms.num_tile_n) * ${k};
    let num_tiles = (uniforms.K - 1) / ${k} + 1;
    var k_start = 0u;
    var value = ${C.type.value}(0);
    for (var t: u32 = 0u; t < num_tiles; t++) {
      ${ye}
      k_start = k_start + ${k};
      workgroupBarrier();

      for (var k: u32 = 0u; k < ${k}; k++) {
        ${oe}
      }
      workgroupBarrier();
    }

    ${Pe}
    let m = tile_row_start + local_id.y;
    let n = tile_col_start + local_id.x;
    ${Le != null ? `let cOffset = ${Le.broadcastedIndicesToOffset("vec2(m, n)", C)}; value += ${C.type.value}(uniforms.beta) * ${Le.getByOffset("cOffset")};` : ""}
    if (m < uniforms.M && n < uniforms.N) {
      output[m * uniforms.N + n] = value;
    }
  }`;
        };
        return V ? { name: "GemmShared", shaderCache: { hint: `${o.cacheKey}`, inputDependencies: X }, getRunData: () => ({ outputs: [{ dims: P, dataType: s[0].dataType }], dispatchGroup: { x: O * $ }, programUniforms: ee }), getShaderSource: Te } : { name: "Gemm", shaderCache: { hint: `${o.cacheKey}`, inputDependencies: X }, getRunData: () => ({ outputs: [{ dims: P, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(G / 64) }, programUniforms: ee }), getShaderSource: re };
      }, hf = (s) => {
        let o = s.transA, d = s.transB, g = s.alpha, y = s.beta;
        return { transA: o, transB: d, alpha: g, beta: y, cacheKey: `${s.transA};${s.transB};${s.alpha === 1}` };
      }, ff = (s, o) => {
        Ul(s.inputs), s.compute(df(s.inputs, o));
      };
    }), ss, _s, Qs, Zs, Gl, pf, mf, gf, _f, yf, vf, wf, xf, Fo, Cg = l(() => {
      jt(), ie(), pn(), sn(), [ss, _s, Qs, Zs] = [0, 1, 2, 3], Gl = (s) => {
        if (s[0].dims.length !== 4)
          throw new Error("only 4-D tensor is supported.");
        if (s[0].dims.length !== s[1].dims.length)
          throw new Error("input dimensions must be equal to grid dimensions");
        if (s[0].dims.length - 2 !== s[1].dims[s[1].dims.length - 1])
          throw new Error(`last dimension of grid must be equal to ${s[0].dims.length - 2}`);
        if (s[0].dims[0] !== s[1].dims[0])
          throw new Error("grid batch size must match input batch size");
      }, pf = `
  fn gs_get_cubic_coeffs(x: f32) -> vec4<f32> {
    let cubic_alpha = -0.75f;
    let x_abs = abs(x);
    var coeffs: vec4<f32>;
    coeffs[0] = (((cubic_alpha * (x_abs + 1) - 5 * cubic_alpha) * (x_abs + 1) + 8 * cubic_alpha) * (x_abs + 1) - 4 * cubic_alpha);
    coeffs[1] = (((cubic_alpha + 2) * x_abs - (cubic_alpha + 3)) * x_abs * x_abs + 1);
    coeffs[2] = (((cubic_alpha + 2) * (1 - x_abs) - (cubic_alpha + 3)) * (1 - x_abs) * (1 - x_abs) + 1);
    coeffs[3] = (((cubic_alpha * (2 - x_abs) - 5 * cubic_alpha) * (2 - x_abs) + 8 * cubic_alpha) * (2 - x_abs) - 4 * cubic_alpha);
    return coeffs;
  }
`, mf = (s) => `
  fn gs_bicubic_interpolate(p: mat4x4<${s}>, x: f32, y: f32) -> ${s} {
    var v: vec4<f32>;
    var coeffs = gs_get_cubic_coeffs(x);
    for (var i = 0; i < 4; i++) {
      v[i] = coeffs[0] * p[i][0] + coeffs[1] * p[i][1] + coeffs[2] * p[i][2] + coeffs[3] * p[i][3];
    }
    coeffs = gs_get_cubic_coeffs(y);
    let pixel = ${s}(coeffs[0] * v[0] + coeffs[1] * v[1] + coeffs[2] * v[2] + coeffs[3] * v[3]);
    return pixel;
  }
`, gf = (s) => `
  fn gs_denormalize(n: f32, length: i32) -> f32 {
    ${s.alignCorners === 0 ? `
    // alignCorners: false => [-1, 1] to [-0.5, length - 0.5]
    return ((n + 1.0) * f32(length) - 1.0) / 2.0;
    ` : `
    // alignCorners: true => [-1, 1] to [0, length - 1]
    return (n + 1.0) / 2.0 * (f32(length - 1));
    `}
  }
`, _f = (s) => `
  ${s.paddingMode === "reflection" ? `
      fn gs_reflect(x: i32, x_min: f32, x_max: f32) -> u32 {
        var dx = 0.0;
        var fx = f32(x);
        let range = x_max - x_min;
        if (fx < x_min) {
          dx = x_min - fx;
          let n = u32(dx / range);
          let r = dx - f32(n) * range;
          if (n % 2 == 0) {
            fx = x_min + r;
          } else {
            fx = x_max - r;
          }
        } else if (fx > x_max) {
          dx = fx - x_max;
          let n = u32(dx / range);
          let r = dx - f32(n) * range;
          if (n % 2 == 0) {
            fx = x_max - r;
          } else {
            fx = x_min + r;
          }
        }
        return u32(fx);
      }` : ""}
`, yf = (s, o, d) => `
  fn pixel_at_grid(r: i32, c: i32, H: i32, W: i32, batch: u32, channel: u32, border: vec4<f32>) -> ${o} {
     var pixel = ${o}(0);
     var indices = vec4<u32>(0);
     indices[${ss}] = batch;
     indices[${_s}] = channel;` + (() => {
        switch (d.paddingMode) {
          case "zeros":
            return `
          if (r >= 0 && r < H && c >=0 && c < W) {
            indices[${Qs}] = u32(r);
            indices[${Zs}] = u32(c);
          } else {
            return ${o}(0);
          }
        `;
          case "border":
            return `
          indices[${Qs}] = u32(clamp(r, 0, H - 1));
          indices[${Zs}] = u32(clamp(c, 0, W - 1));
        `;
          case "reflection":
            return `
          indices[${Qs}] = gs_reflect(r, border[1], border[3]);
          indices[${Zs}] = gs_reflect(c, border[0], border[2]);
        `;
          default:
            throw new Error(`padding mode ${d.paddingMode} is not supported`);
        }
      })() + `
    return ${s.getByIndices("indices")};
  }
`, vf = (s, o, d) => (() => {
        switch (d.mode) {
          case "nearest":
            return `
          let result = pixel_at_grid(i32(round(y)), i32(round(x)), H_in, W_in, indices[${ss}], indices[${_s}], border);
        `;
          case "bilinear":
            return `
          let x1 = i32(floor(x));
          let y1 = i32(floor(y));
          let x2 = x1 + 1;
          let y2 = y1 + 1;

          let p11 = pixel_at_grid(y1, x1, H_in, W_in, indices[${ss}], indices[${_s}], border);
          let p12 = pixel_at_grid(y1, x2, H_in, W_in, indices[${ss}], indices[${_s}], border);
          let p21 = pixel_at_grid(y2, x1, H_in, W_in, indices[${ss}], indices[${_s}], border);
          let p22 = pixel_at_grid(y2, x2, H_in, W_in, indices[${ss}], indices[${_s}], border);

          let dx2 = ${o}(f32(x2) - x);
          let dx1 = ${o}(x - f32(x1));
          let dy2 = ${o}(f32(y2) - y);
          let dy1 = ${o}(y - f32(y1));
          let result = dy2 * (dx2 * p11 + dx1 * p12) + dy1 * (dx2 * p21 + dx1 * p22);
        `;
          case "bicubic":
            return `
          let x0 = i32(floor(x)) - 1;
          let y0 = i32(floor(y)) - 1;
          var p: mat4x4<${o}>;
          for (var h = 0; h < 4; h++) {
            for (var w = 0; w < 4; w++) {
              p[h][w] = pixel_at_grid(h + y0, w + x0, H_in, W_in, indices[${ss}], indices[${_s}], border);
            }
          }

          let dx = x - f32(x0 + 1);
          let dy = y - f32(y0 + 1);
          let result = gs_bicubic_interpolate(p, dx, dy);
        `;
          default:
            throw new Error(`mode ${d.mode} is not supported`);
        }
      })() + `${s.setByOffset("global_idx", "result")}`, wf = (s, o) => {
        let d = dt("x", s[0].dataType, s[0].dims.length), g = [s[1].dims[0], s[1].dims[1], s[1].dims[2]], y = dt("grid", s[1].dataType, g.length, 2), x = [s[0].dims[0], s[0].dims[1], s[1].dims[1], s[1].dims[2]];
        o.format === "NHWC" && (x = [s[0].dims[0], s[1].dims[1], s[1].dims[2], s[0].dims[3]], [ss, _s, Qs, Zs] = [0, 3, 1, 2]);
        let b = $t("output", s[0].dataType, x.length), P = d.type.value, k = it.size(x), O = [{ type: 12, data: k }, ...Ut(s[0].dims, g, x)], $ = (V) => `
  ${V.registerUniform("output_size", "u32").declareVariables(d, y, b)}
  ${pf}
  ${mf(P)}
  ${gf(o)}
  ${_f(o)}
  ${yf(d, P, o)}

  ${V.mainStart()}
    ${V.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
      let H_in = i32(uniforms.x_shape[${Qs}]);
      let W_in = i32(uniforms.x_shape[${Zs}]);

      ${o.alignCorners === 0 ? `
      let x_min = -0.5;
      let x_max = f32(W_in) - 0.5;
      let y_min = -0.5;
      let y_max = f32(H_in) - 0.5;
      ` : `
      let x_min = 0.0;
      let x_max = f32(W_in) - 1.0;
      let y_min = 0.0;
      let y_max = f32(H_in) - 1.0;
      `};
      let border = vec4<f32>(x_min, y_min, x_max, y_max);

      let indices = ${b.offsetToIndices("global_idx")};
      var grid_indices = vec3<u32>(indices[${ss}], indices[${Qs}], indices[${Zs}]);
      let nxy = ${y.getByIndices("grid_indices")};
      var x = gs_denormalize(f32(nxy[0]), W_in);
      var y = gs_denormalize(f32(nxy[1]), H_in);

      ${vf(b, P, o)}
  }`;
        return { name: "GridSample", shaderCache: { hint: `${o.cacheKey}`, inputDependencies: ["type", "type"] }, getRunData: (V) => {
          let G = it.size(x);
          return { outputs: [{ dims: x, dataType: V[0].dataType }], dispatchGroup: { x: Math.ceil(G / 64) }, programUniforms: O };
        }, getShaderSource: $ };
      }, xf = (s, o) => {
        Gl(s.inputs), s.compute(wf(s.inputs, o));
      }, Fo = (s) => Yt({ alignCorners: s.align_corners, mode: s.mode, paddingMode: s.padding_mode, format: s.format });
    }), mi, Vl, bf, jl, Wl, Gr, Mf, ks = l(() => {
      jt(), ie(), pn(), ei(), Va(), sn(), Hs(), mi = (s, o) => s.length > o && s[o].dims.length > 0 ? s[o] : void 0, Vl = (s, o) => {
        let d = s[0], g = mi(s, 1), y = mi(s, 2), x = mi(s, 3), b = mi(s, 4), P = mi(s, 5), k = mi(s, 6), O = mi(s, 7);
        if (d.dims.length !== 3 && d.dims.length !== 5)
          throw new Error("Input query is expected to have 3 or 5 dimensions");
        let $ = d.dims[0], V = d.dims[1], G = d.dims.length === 3 ? d.dims[2] : o.numHeads * d.dims[4], ee = V, X = 0, re = 0, Te = Math.floor(G / o.numHeads);
        if (k && O && it.size(k.dims) && it.size(O.dims)) {
          if (k.dims.length !== 4)
            throw new Error('Input "past_key" is expected to have 4 dimensions');
          if (k.dims[0] !== $ || k.dims[1] !== o.numHeads || k.dims[3] !== Te)
            throw new Error('Input "past_key" shape (batch_size, num_heads, past_sequence_length, head_size)');
          if (O.dims[0] !== $ || O.dims[1] !== o.numHeads || O.dims[3] !== Te)
            throw new Error('Input "past_value" shape (batch_size, num_heads, past_sequence_length, head_size)');
          if (k.dims[2] !== O.dims[2])
            throw new Error('Input "past_key" and "past_value" shall have same dim 2 (past_sequence_length)');
          if (O.dims.length !== 4)
            throw new Error('Input "past_value" is expected to have 4 dimensions');
          X = k.dims[2], re = k.dims[2];
        } else if (k && it.size(k.dims) || O && it.size(O.dims))
          throw new Error('Input "past_key" and "past_value" shall be both present or both absent');
        let ue;
        if (g && it.size(g.dims) > 0) {
          if (d.dims.length !== 3)
            throw new Error('Input "query" is expected to have 3 dimensions when key is given');
          if (g.dims.length < 3 || g.dims.length > 5)
            throw new Error('Input "key" is expected to have 3, 4, or 5 dimensions');
          if (d.dims[0] !== g.dims[0])
            throw new Error('Input "query" and "key" shall have same dim 0 (batch size)');
          if (g.dims.length === 3) {
            if (g.dims[2] !== d.dims[2])
              throw new Error('Input "query" and "key" shall have same dim 2 (hidden_size)');
            ue = 2, ee = g.dims[1];
          } else if (g.dims.length === 5) {
            if (g.dims[2] !== o.numHeads || g.dims[3] !== 2 || g.dims[4] !== Te)
              throw new Error('Expect "key" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');
            if (y)
              throw new Error('Expect "value" be none when "key" has packed kv format.');
            ue = 5, ee = g.dims[1];
          } else {
            if (g.dims[1] !== o.numHeads || g.dims[3] !== Te)
              throw new Error('Expect "key" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');
            ue = 0, ee = g.dims[2];
          }
        } else {
          if (d.dims.length !== 5)
            throw new Error('Input "query" is expected to have 5 dimensions when key is empty');
          if (d.dims[2] !== o.numHeads || d.dims[3] !== 3)
            throw new Error('Expect "query" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');
          ue = 3;
        }
        if (x && it.size(x.dims) > 0) {
          if (x.dims.length !== 1)
            throw new Error('Input "bias" is expected to have 1 dimension');
          if (g && g.dims.length === 5 && g.dims[3] === 2)
            throw new Error("bias is not allowed for packed kv.");
        }
        let ce = X + ee, ke = 0;
        if (b && it.size(b.dims) > 0) {
          ke = 8;
          let z = b.dims;
          throw z.length === 1 ? z[0] === $ ? ke = 1 : z[0] === 3 * $ + 2 && (ke = 3) : z.length === 2 && z[0] === $ && z[1] === ce && (ke = 5), ke === 8 ? new Error('Input "key_padding_mask" shape shall be (batch_size) or (batch_size, total_sequence_length)') : new Error("Mask not supported");
        }
        let Le = !1, M = G;
        if (y && it.size(y.dims) > 0) {
          if (y.dims.length !== 3 && y.dims.length !== 4)
            throw new Error('Input "value" is expected to have 3 or 4 dimensions');
          if (d.dims[0] !== y.dims[0])
            throw new Error('Input "query" and "value" shall have same dim 0 (batch_size)');
          if (y.dims.length === 3) {
            if (ee !== y.dims[1])
              throw new Error('Input "key" and "value" shall have the same dim 1 (kv_sequence_length)');
            M = y.dims[2];
          } else {
            if (ee !== y.dims[2])
              throw new Error('Input "key" and "value" shall have the same dim 2 (kv_sequence_length)');
            M = y.dims[1] * y.dims[3], Le = !0;
          }
        }
        let C = !1;
        if (b && it.size(b.dims) > 0)
          throw new Error("Key padding mask is not supported");
        if (P && it.size(P.dims) > 0) {
          if (P.dims.length !== 4)
            throw new Error('Input "attention_bias" is expected to have 4 dimensions');
          if (P.dims[0] !== $ || P.dims[1] !== o.numHeads || P.dims[2] !== V || P.dims[3] !== ce)
            throw new Error('Expect "attention_bias" shape (batch_size, num_heads, sequence_length, total_sequence_length)');
        }
        return { batchSize: $, sequenceLength: V, pastSequenceLength: X, kvSequenceLength: ee, totalSequenceLength: ce, maxSequenceLength: re, inputHiddenSize: 0, hiddenSize: G, vHiddenSize: M, headSize: Te, vHeadSize: Math.floor(M / o.numHeads), numHeads: o.numHeads, isUnidirectional: !1, pastPresentShareBuffer: !1, maskFilterValue: o.maskFilterValue, maskType: ke, scale: o.scale, broadcastResPosBias: C, passPastInKv: Le, qkvFormat: ue };
      }, bf = (s) => Yt({ ...s }), jl = Yt({ perm: [0, 2, 1, 3] }), Wl = (s, o, d, g, y, x, b) => {
        let P = [g, y, x], k = it.size(P), O = [{ type: 12, data: k }, { type: 12, data: b }, { type: 12, data: x }], $ = (V) => {
          let G = $t("qkv_with_bias", o.dataType, P), ee = dt("qkv", o.dataType, P), X = dt("bias", d.dataType, P), re = [{ name: "output_size", type: "u32" }, { name: "bias_offset", type: "u32" }, { name: "hidden_size", type: "u32" }];
          return `
  ${V.registerUniforms(re).declareVariables(ee, X, G)}
  ${V.mainStart()}
    ${V.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let bias_offset_idx = (global_idx % uniforms.hidden_size) + uniforms.bias_offset;

    qkv_with_bias[global_idx] = qkv[global_idx] + bias[bias_offset_idx];
  }`;
        };
        return s.compute({ name: "MultiHeadAttentionAddBias", shaderCache: { inputDependencies: ["type", "type"] }, getRunData: () => ({ outputs: [{ dims: P, dataType: o.dataType, gpuDataType: 0 }], dispatchGroup: { x: Math.ceil(k / 64) }, programUniforms: O }), getShaderSource: $ }, { inputs: [o, d], outputs: [-1] })[0];
      }, Gr = (s, o, d, g, y, x, b, P) => {
        let k = x;
        if (b && it.size(b.dims) > 0) {
          if (g === 1)
            throw new Error("AddBiasReshape is not implemented. Please export your model with packed QKV or KV");
          return k = Wl(s, x, b, o, g, d * y, P), k = k.reshape([o, g, d, y]), d === 1 || g === 1 ? k : s.compute(bi(k, jl.perm), { inputs: [k], outputs: [-1] })[0];
        } else
          return x.dims.length === 3 && (k = x.reshape([o, g, d, y])), d === 1 || g === 1 ? k : s.compute(bi(k, jl.perm), { inputs: [k], outputs: [-1] })[0];
      }, Mf = (s, o) => {
        let d = Vl(s.inputs, o), g = s.inputs[0], y = mi(s.inputs, 1), x = mi(s.inputs, 2), b = mi(s.inputs, 3), P = mi(s.inputs, 4), k = mi(s.inputs, 5), O = mi(s.inputs, 6), $ = mi(s.inputs, 7);
        if (g.dims.length === 5)
          throw new Error("Packed QKV is not implemented");
        if ((y == null ? void 0 : y.dims.length) === 5)
          throw new Error("Packed KV is not implemented");
        let V = y && x && y.dims.length === 4 && x.dims.length === 4, G = Gr(s, d.batchSize, d.numHeads, d.sequenceLength, d.headSize, g, b, 0);
        if (V)
          return _r(s, G, y, x, P, void 0, O, $, k, d);
        if (!y || !x)
          throw new Error("key and value must be provided");
        let ee = Gr(s, d.batchSize, d.numHeads, d.kvSequenceLength, d.headSize, y, b, d.hiddenSize), X = Gr(s, d.batchSize, d.numHeads, d.kvSequenceLength, d.vHeadSize, x, b, 2 * d.hiddenSize);
        _r(s, G, ee, X, P, void 0, O, $, k, d);
      };
    }), Tf, Ef, Sf, Pf, Hl, Af, ql, Cf = l(() => {
      jt(), ie(), pn(), sn(), Tf = (s) => {
        if (!s || s.length < 1)
          throw new Error("too few inputs");
      }, Ef = (s, o) => {
        let d = [], g = o.numOutputs;
        return s[1].dims[0] > 0 && (s[1].getBigInt64Array().forEach((y) => d.push(Number(y))), g = d.length), Yt({ numOutputs: g, axis: o.axis, splitSizes: d });
      }, Sf = (s) => `
fn calculateOutputIndex(index: u32) -> u32 {
    for (var i: u32 = 0u; i < ${s}u; i += 1u ) {
    if (index < ${Nt("uniforms.size_in_split_axis", "i", s)}) {
        return i;
    }
    }
    return ${s}u;
}`, Pf = (s) => {
        let o = s.length, d = [];
        for (let g = 0; g < o; ++g) {
          let y = s[g].setByIndices("indices", "input[global_idx]");
          o === 1 ? d.push(y) : g === 0 ? d.push(`if (output_number == ${g}u) { ${y} }`) : g === o - 1 ? d.push(`else { ${y} }`) : d.push(`else if (output_number == ${g}) { ${y} }`);
        }
        return `
      fn writeBufferData(output_number: u32, indices: ${s[0].type.indices}, global_idx: u32) {
        ${d.join(`
`)}
      }`;
      }, Hl = (s, o) => {
        let d = s[0].dims, g = it.size(d), y = s[0].dataType, x = it.normalizeAxis(o.axis, d.length), b = new Array(o.numOutputs), P = dt("input", y, d.length), k = new Array(o.numOutputs), O = [], $ = [], V = 0, G = [{ type: 12, data: g }];
        for (let X = 0; X < o.numOutputs; X++) {
          V += o.splitSizes[X], k[X] = V;
          let re = d.slice();
          re[x] = o.splitSizes[X], $.push(re), b[X] = $t(`output${X}`, y, re.length), O.push({ dims: $[X], dataType: s[0].dataType });
        }
        G.push({ type: 12, data: k }, ...Ut(d, ...$));
        let ee = (X) => `
  ${X.registerUniform("input_size", "u32").registerUniform("size_in_split_axis", "u32", k.length).declareVariables(P, ...b)}
  ${Sf(k.length)}
  ${Pf(b)}

  ${X.mainStart()}
    ${X.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.input_size")}

    var indices = ${P.offsetToIndices("global_idx")};
    var index = ${P.indicesGet("indices", x)};
    let output_number = calculateOutputIndex(index);
    if (output_number != 0) {
      index -= ${Nt("uniforms.size_in_split_axis", "output_number - 1u", k.length)};
      ${P.indicesSet("indices", x, "index")};
    }
    writeBufferData(output_number, indices, global_idx);
  }`;
        return { name: "Split", shaderCache: { hint: o.cacheKey, inputDependencies: ["rank"] }, getShaderSource: ee, getRunData: () => ({ outputs: O, dispatchGroup: { x: Math.ceil(g / 64) }, programUniforms: G }) };
      }, Af = (s, o) => {
        Tf(s.inputs);
        let d = s.inputs.length === 1 ? o : Ef(s.inputs, o);
        s.compute(Hl(s.inputs, d), { inputs: [0] });
      }, ql = (s) => {
        let o = s.axis, d = s.splitSizes, g = s.numOutputs < 0 ? d.length : s.numOutputs;
        if (g !== d.length)
          throw new Error("numOutputs and splitSizes lengh must be equal");
        return Yt({ axis: o, numOutputs: g, splitSizes: d });
      };
    }), If, Ro, Lf, Bo = l(() => {
      jt(), ie(), pn(), sn(), If = (s, o) => {
        let [d, g, y, x] = s, { numHeads: b, rotaryEmbeddingDim: P } = o;
        if (d.dims.length !== 3 && d.dims.length !== 4)
          throw new Error(`Input 'x' is expected to have 3 or 4 dimensions, got ${d.dims.length}`);
        if (!it.areEqual(g.dims, []) && !it.areEqual(g.dims, [1]) && g.dims.length !== 2)
          throw new Error(`Input 'position_ids' is expected to have 0, 1, or 2 dimensions, got ${g.dims.length}`);
        if (y.dims.length !== 2)
          throw new Error(`Input 'cos_cache' is expected to have 2 dimensions, got ${y.dims.length}`);
        if (x.dims.length !== 2)
          throw new Error(`Input 'sin_cache' is expected to have 2 dimensions, got ${x.dims.length}`);
        if (!it.areEqual(y.dims, x.dims))
          throw new Error("Inputs 'cos_cache' and 'sin_cache' are expected to have the same shape");
        if (P > 0 && b === 0)
          throw new Error("num_heads must be provided if rotary_embedding_dim is specified");
        let k = d.dims[0], O = d.dims[d.dims.length - 2], $ = y.dims[0], V = it.sizeFromDimension(d.dims, 1) / O, G = P === 0 ? y.dims[1] * 2 : V / b;
        if (P > G)
          throw new Error("rotary_embedding_dim must be less than or equal to head_size");
        if (g.dims.length === 2) {
          if (k !== g.dims[0])
            throw new Error(`Input 'position_ids' dimension 0 should be of size batch_size, got ${g.dims[0]}`);
          if (O !== g.dims[1])
            throw new Error(`Input 'position_ids' dimension 1 should be of size sequence_length, got ${g.dims[1]}`);
        }
        if (G / 2 !== y.dims[1] && P / 2 !== y.dims[1])
          throw new Error(`Input 'cos_cache' dimension 1 should be same as head_size / 2 or rotary_embedding_dim / 2, got ${y.dims[1]}`);
        if (O > $)
          throw new Error("Updating cos_cache and sin_cache in RotaryEmbedding is not currently supported");
      }, Ro = (s, o) => {
        let { interleaved: d, numHeads: g, rotaryEmbeddingDim: y, scale: x } = o, b = s[0].dims[0], P = it.sizeFromDimension(s[0].dims, 1), k = s[0].dims[s[0].dims.length - 2], O = P / k, $ = s[2].dims[1], V = y === 0 ? $ * 2 : O / g, G = new Array(b, k, O / V, V - $), ee = it.computeStrides(G), X = [{ type: 1, data: x }, { type: 12, data: G }, { type: 12, data: ee }, ...s[0].dims.length === 3 ? new Array({ type: 12, data: [P, O, V, 1] }) : [], ...s[0].dims.length === 4 ? new Array({ type: 12, data: [P, V, k * V, 1] }) : [], ...Ut(s[0].dims, s[1].dims, s[2].dims, s[3].dims, s[0].dims)], re = (Te) => {
          let ue = dt("input", s[0].dataType, s[0].dims.length), ce = dt("position_ids", s[1].dataType, s[1].dims.length), ke = dt("cos_cache", s[2].dataType, s[2].dims.length), Le = dt("sin_cache", s[3].dataType, s[3].dims.length), M = $t("output", s[0].dataType, s[0].dims.length);
          return Te.registerUniforms([{ name: "scale", type: "f32" }, { name: "global_shape", type: "u32", length: G.length }, { name: "global_strides", type: "u32", length: ee.length }, { name: "input_output_strides", type: "u32", length: ee.length }]), `
        ${Te.declareVariables(ue, ce, ke, Le, M)}

        ${Te.mainStart(ts)}
          let half_rotary_emb_dim = uniforms.${ke.name}_shape[1];
          let bsnh = global_idx / uniforms.global_strides % uniforms.global_shape;
          let size = uniforms.global_shape[0] * uniforms.global_strides[0];
          ${Te.guardAgainstOutOfBoundsWorkgroupSizes("size")}

          if (bsnh[3] < half_rotary_emb_dim) {
            let position_ids_idx =
                ${ce.broadcastedIndicesToOffset("bsnh.xy", $t("", ce.type.tensor, 2))};
            let position_id =
                u32(${ce.getByOffset("position_ids_idx")}) + select(0, bsnh[1], position_ids_idx == 0);
            let i = dot(bsnh, uniforms.input_output_strides) + select(0, bsnh[3], ${d});
            let j = i + select(half_rotary_emb_dim, 1, ${d});
            let re = ${ue.getByOffset("i")} * ${ke.get("position_id", "bsnh[3]")} -
                ${ue.getByOffset("j")} * ${Le.get("position_id", "bsnh[3]")};
            ${M.setByOffset("i", "re")}
            let im = ${ue.getByOffset("i")} * ${Le.get("position_id", "bsnh[3]")} +
                ${ue.getByOffset("j")} * ${ke.get("position_id", "bsnh[3]")};
            ${M.setByOffset("j", "im")}
          } else {
            let k = dot(bsnh, uniforms.input_output_strides) + half_rotary_emb_dim;
            ${M.setByOffset("k", ue.getByOffset("k"))}
          }
        }`;
        };
        return { name: "RotaryEmbedding", shaderCache: { hint: Yt({ interleaved: d }).cacheKey, inputDependencies: ["rank", "rank", "rank", "rank"] }, getShaderSource: re, getRunData: () => ({ outputs: [{ dims: s[0].dims, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(it.size(G) / ts) }, programUniforms: X }) };
      }, Lf = (s, o) => {
        If(s.inputs, o), s.compute(Ro(s.inputs, o));
      };
    }), Df, kf, Kl, Vr, Of, Ig = l(() => {
      pn(), jt(), Va(), ks(), Cf(), Hs(), Bo(), sn(), Df = (s, o) => {
        if (o.doRotary && s.length <= 7)
          throw new Error("cos_cache and sin_cache inputs are required if do_rotary is specified");
        let d = s[0], g = s[1], y = s[2], x = s[3], b = s[4];
        if (o.doRotary !== 0 && s.length <= 7)
          throw new Error("cos_cast and sin_cache are expected if do_rotary attribute is non-zero");
        if (o.localWindowSize !== -1)
          throw new Error("Local attention is not supported");
        if (o.softcap !== 0)
          throw new Error("Softcap is not supported");
        if (o.rotaryInterleaved !== 0)
          throw new Error("Rotary interleaved is not supported");
        if (o.smoothSoftmax)
          throw new Error("Smooth softmax is not supported");
        if (d.dims.length !== 3 && d.dims.length !== 5)
          throw new Error("Input query is expected to have 3 or 5 dimensions");
        let P = !1, k = d.dims[0], O = d.dims[1], $ = d.dims.length === 3 ? P ? d.dims[2] / 3 : d.dims[2] : o.numHeads * d.dims[4], V = O, G = 0, ee = !g || g.dims.length === 0, X = Math.floor(ee ? $ / (o.numHeads + 2 * o.kvNumHeads) : $ / o.numHeads);
        ee && ($ = X * o.numHeads);
        let re = x && x.dims.length !== 0, Te = b && b.dims.length !== 0;
        if (re && x.dims.length === 4 && x.dims[0] === k && x.dims[1] !== o.kvNumHeads && x.dims[2] === o.kvNumHeads && x.dims[3] === X)
          throw new Error("BSNH pastKey/pastValue is not supported");
        if (re && Te) {
          if (x.dims.length !== 4)
            throw new Error('Input "past_key" is expected to have 4 dimensions');
          if (b.dims.length !== 4)
            throw new Error('Input "past_value" is expected to have 4 dimensions');
          G = x.dims[2];
        } else if (re || Te)
          throw new Error('Input "past_key" and "past_value" shall be both present or both absent');
        let ue = 1;
        if (g && g.dims.length > 0) {
          if (d.dims.length !== 3)
            throw new Error('Input "query" is expected to have 3 dimensions when key is given');
          if (g.dims.length < 3 || g.dims.length > 5)
            throw new Error('Input "key" is expected to have 3, 4, or 5 dimensions');
          if (d.dims[0] !== g.dims[0])
            throw new Error('Input "query" and "key" shall have same dim 0 (batch size)');
          if (g.dims.length === 3) {
            if (d.dims[2] % g.dims[2] !== 0)
              throw new Error('Dimension 2 of "query" should be a multiple of "key"');
            V = g.dims[1];
          } else if (g.dims.length === 5) {
            if (g.dims[2] !== o.numHeads || g.dims[3] !== 2 || g.dims[4] !== X)
              throw new Error('Expect "key" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');
            if (y)
              throw new Error('Expect "value" be none when "key" has packed kv format.');
            V = g.dims[1];
          } else {
            if (g.dims[1] !== o.numHeads || g.dims[3] !== X)
              throw new Error('Expect "key" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');
            V = g.dims[2];
          }
        } else {
          if (d.dims.length !== 3 && d.dims.length !== 5)
            throw new Error('Input "query" is expected to have 3 or 5 dimensions when key is empty');
          if (d.dims.length === 5 && (d.dims[2] !== o.numHeads || d.dims[3] !== 3))
            throw new Error('Expect "query" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');
          ue = 3;
        }
        let ce = 0, ke = !1, Le = o.kvNumHeads ? X * o.kvNumHeads : $;
        if (y && y.dims.length > 0) {
          if (y.dims.length !== 3 && y.dims.length !== 4)
            throw new Error('Input "value" is expected to have 3 or 4 dimensions');
          if (d.dims[0] !== y.dims[0])
            throw new Error('Input "query" and "value" shall have same dim 0 (batch_size)');
          if (y.dims.length === 3) {
            if (V !== y.dims[1])
              throw new Error('Input "key" and "value" shall have the same dim 1 (kv_sequence_length)');
            Le = y.dims[2];
          } else {
            if (V !== y.dims[2])
              throw new Error('Input "past_key" and "past_value" shall have the same dim 2 (kv_sequence_length)');
            Le = y.dims[1] * y.dims[3], ke = !0;
          }
        }
        let M = s.length > 4 ? s[5] : void 0;
        if (M && M.dims.length !== 1 && M.dims[0] !== k)
          throw new Error('Input "seqlens" is expected to have 1 dimension and the same dim 0 as batch_size');
        return { batchSize: k, sequenceLength: O, pastSequenceLength: G, kvSequenceLength: V, totalSequenceLength: -1, maxSequenceLength: -1, inputHiddenSize: 0, hiddenSize: $, vHiddenSize: Le, headSize: X, vHeadSize: Math.floor(Le / o.kvNumHeads), numHeads: o.numHeads, kvNumHeads: o.kvNumHeads, nReps: o.numHeads / o.kvNumHeads, pastPresentShareBuffer: !1, maskType: ce, scale: o.scale, broadcastResPosBias: !1, passPastInKv: ke, qkvFormat: ue };
      }, kf = Yt({ perm: [0, 2, 1, 3] }), Kl = (s, o, d) => {
        let g = o, y = d.kvNumHeads;
        return o.dims.length === 3 && d.kvSequenceLength !== 0 && (g = o.reshape([d.batchSize, d.kvSequenceLength, y, d.headSize]), g = s.compute(bi(g, kf.perm), { inputs: [g], outputs: [-1] })[0]), g;
      }, Vr = (s, o, d, g) => {
        let y = 7, x = ["type", "type"], b = [s * o], P = s * o, k = [{ type: 12, data: P }, { type: 12, data: o }, { type: 12, data: s }], O = ($) => {
          let V = dt("seq_lens", d.dataType, d.dims), G = dt("total_seq_lens", g.dataType, g.dims), ee = $t("pos_ids", y, b), X = [{ name: "output_size", type: "u32" }, { name: "sequence_length", type: "u32" }, { name: "batch_size", type: "u32" }];
          return `
  ${$.registerUniforms(X).declareVariables(V, G, ee)}
  ${$.mainStart()}
    ${$.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
    let total_sequence_length = u32(${G.getByOffset("0")});
    let is_subsequent_prompt = uniforms.sequence_length > 1 && uniforms.sequence_length != total_sequence_length;
    let is_first_prompt = !is_subsequent_prompt && uniforms.sequence_length == total_sequence_length;
    let batch_idx = global_idx / uniforms.sequence_length;
    let sequence_idx = i32(global_idx % uniforms.sequence_length);
    var pos_id: i32 = 0;
    let seqlen = ${V.getByOffset("batch_idx")};
    let total_seqlen = seqlen + 1;
    if (is_first_prompt) {
      if (sequence_idx < total_seqlen) {
        pos_id = sequence_idx;
      } else {
        pos_id = 1;
      }
      ${ee.setByOffset("global_idx", "pos_id")}
    } else if (is_subsequent_prompt) {
      let past_seqlen = total_seqlen - i32(uniforms.sequence_length);
      if (past_seqlen + sequence_idx < total_seqlen) {
        pos_id = past_seqlen + sequence_idx;
      } else {
        pos_id = 1;
      }
      ${ee.setByOffset("global_idx", "pos_id")}
    } else if (global_idx < uniforms.batch_size) {
      ${ee.setByOffset("global_idx", "seqlen")}
    };
  }
  `;
        };
        return { name: "GeneratePositionIds", shaderCache: { hint: `${s};${o}`, inputDependencies: x }, getRunData: () => ({ outputs: [{ dims: b, dataType: y }], dispatchGroup: { x: Math.ceil(P / 64) }, programUniforms: k }), getShaderSource: O };
      }, Of = (s, o) => {
        var Le;
        let d = Df(s.inputs, o);
        if (s.inputs[0].dims.length === 5)
          throw new Error("Packed QKV is not implemented");
        if (((Le = s.inputs[1]) == null ? void 0 : Le.dims.length) === 5)
          throw new Error("Packed KV is not implemented");
        let g = s.inputs[0], y = s.inputs[1] && s.inputs[1].dims.length > 0 ? s.inputs[1] : void 0, x = s.inputs[2] && s.inputs[2].dims.length > 0 ? s.inputs[2] : void 0, b = s.inputs[3] && s.inputs[3].dims.length !== 0 ? s.inputs[3] : void 0, P = s.inputs[4] && s.inputs[4].dims.length !== 0 ? s.inputs[4] : void 0, k = s.inputs.length > 4 ? s.inputs[5] : void 0, O = s.inputs.length > 5 ? s.inputs[6] : void 0, $ = d.kvNumHeads ? d.kvNumHeads : d.numHeads, V = Yt({ axis: 2, numOutputs: 3, splitSizes: [d.numHeads * d.headSize, $ * d.headSize, $ * d.headSize] }), [G, ee, X] = !y && !x ? s.compute(Hl([g], V), { inputs: [g], outputs: [-1, -1, -1] }) : [g, y, x], re, Te;
        if (o.doRotary) {
          let M = s.compute(Vr(d.batchSize, d.sequenceLength, k, O), { inputs: [k, O], outputs: [-1] })[0], C = s.inputs[7], z = s.inputs[8], oe = Yt({ interleaved: o.rotaryInterleaved !== 0, numHeads: d.numHeads, rotaryEmbeddingDim: 0, scale: o.scale }), ye = [G, M, C, z], Pe = [-1];
          re = s.compute(Ro(ye, oe), { inputs: ye, outputs: Pe })[0], ye.splice(0, 1, ee);
          let Ue = Yt({ interleaved: o.rotaryInterleaved !== 0, numHeads: d.kvNumHeads, rotaryEmbeddingDim: 0, scale: o.scale });
          Te = s.compute(Ro(ye, Ue), { inputs: ye, outputs: Pe })[0];
        }
        let ue = Gr(s, d.batchSize, d.numHeads, d.sequenceLength, d.headSize, o.doRotary ? re : G, void 0, 0), ce = Kl(s, o.doRotary ? Te : ee, d), ke = Kl(s, X, d);
        _r(s, ue, ce, ke, void 0, void 0, b, P, void 0, d, k, O);
      };
    }), Xl, Ff, zo, Rf, Lg = l(() => {
      jt(), ie(), Hs(), sn(), Xl = (s, o, d, g, y, x, b, P) => {
        let k = Dn(x), O = k === 1 ? "f32" : `vec${k}f`, $ = k === 1 ? "vec2f" : `mat2x${k}f`, V = y * b, G = 64;
        V === 1 && (G = 256);
        let ee = [y, b, x / k], X = [y, b, 2], re = ["rank", "type", "type"], Te = [];
        Te.push(...Ut(ee, X));
        let ue = (ce) => {
          let ke = dt("x", o.dataType, 3, k), Le = dt("scale", d.dataType, d.dims), M = dt("bias", g.dataType, g.dims), C = $t("output", 1, 3, 2), z = [ke, Le, M, C];
          return `
  var<workgroup> workgroup_shared : array<${$}, ${G}>;
  const workgroup_size = ${G}u;
  ${ce.declareVariables(...z)}
  ${ce.mainStart(G)}
    let batch = workgroup_index / uniforms.x_shape[1];
    let channel = workgroup_index % uniforms.x_shape[1];
    let hight = uniforms.x_shape[2];
    // initialize workgroup memory
    var sum = ${O}(0);
    var squared_sum = ${O}(0);
    for (var h = local_idx; h < hight; h += workgroup_size) {
      let value = ${O}(${ke.get("batch", "channel", "h")});
      sum += value;
      squared_sum += value * value;
    }
    workgroup_shared[local_idx] = ${$}(sum, squared_sum);
    workgroupBarrier();

    for (var currSize = workgroup_size >> 1;  currSize > 0; currSize = currSize >> 1) {
      if (local_idx < currSize) {
        workgroup_shared[local_idx] = workgroup_shared[local_idx] + workgroup_shared[local_idx + currSize];
      }
      workgroupBarrier();
    }
    if (local_idx == 0) {
      let sum_final = ${Ls("workgroup_shared[0][0]", k)} / f32(hight * ${k});
      let squared_sum_final = ${Ls("workgroup_shared[0][1]", k)} / f32(hight * ${k});

      let inv_std_dev = inverseSqrt(squared_sum_final - sum_final * sum_final + f32(${P}));
      let channel_scale = inv_std_dev * f32(scale[channel]);
      let channel_shift = f32(bias[channel]) - sum_final * channel_scale;
      output[workgroup_index] = vec2f(channel_scale, channel_shift);
    }
  }`;
        };
        return s.compute({ name: "InstanceNormComputeChannelScaleShift", shaderCache: { hint: `${k};${P};${G}`, inputDependencies: re }, getRunData: () => ({ outputs: [{ dims: X, dataType: 1 }], dispatchGroup: { x: V }, programUniforms: Te }), getShaderSource: ue }, { inputs: [o, d, g], outputs: [-1] })[0];
      }, Ff = (s, o, d) => {
        let g = o[0].dims, y = g, x = 2, b = g[0], P = g[1], k = it.sizeFromDimension(g, x), O = Dn(k), $ = it.size(y) / O, V = Xl(s, o[0], o[1], o[2], b, k, P, d.epsilon), G = [b, P, k / O], ee = [b, P], X = ["type", "none"], re = (Te) => {
          let ue = dt("x", o[0].dataType, G.length, O), ce = dt("scale_shift", 1, ee.length, 2), ke = $t("output", o[0].dataType, G.length, O), Le = [ue, ce, ke];
          return `
  ${Te.registerUniform("output_size", "u32").declareVariables(...Le)}
  ${Te.mainStart()}
  ${Te.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
      let outputIndices = ${ke.offsetToIndices("global_idx")};
      let batch = outputIndices[0];
      let channel = outputIndices[1];
      let scale_shift = ${ce.getByIndices("vec2<u32>(batch, channel)")};
      let value = ${ue.getByOffset("global_idx")} * ${ke.type.value}(scale_shift.x) + ${ke.type.value}(scale_shift.y);
      ${ke.setByOffset("global_idx", "value")};
  }`;
        };
        s.compute({ name: "InstanceNormalization", shaderCache: { hint: `${O}`, inputDependencies: X }, getRunData: () => ({ outputs: [{ dims: y, dataType: o[0].dataType }], dispatchGroup: { x: Math.ceil($ / 64) }, programUniforms: [{ type: 12, data: $ }, ...Ut(G, ee, G)] }), getShaderSource: re }, { inputs: [o[0], V] });
      }, zo = (s, o, d) => {
        let g = o[0].dims, y = g, x = g[0], b = g[g.length - 1], P = it.sizeFromDimension(g, 1) / b, k = Dn(b), O = it.size(y) / k, $ = [{ type: 12, data: P }, { type: 12, data: Math.floor(b / k) }], V = ["type", "type"], G = !1, ee = [0, g.length - 1];
        for (let ue = 0; ue < g.length - 2; ue++)
          G = G || g[ue + 1] !== 1, ee.push(ue + 1);
        G = G && g[g.length - 1] !== 1;
        let X = G ? s.compute(bi(s.inputs[0], ee), { inputs: [s.inputs[0]], outputs: [-1] })[0] : s.inputs[0].reshape(Array.from({ length: g.length }, (ue, ce) => g[ee[ce]])), re = Xl(s, X, o[1], o[2], x, P, b, d.epsilon), Te = (ue) => {
          let ce = Jn(o[0].dataType), ke = k === 1 ? "vec2f" : `mat${k}x2f`, Le = (z) => {
            let oe = z === 0 ? "x" : "y", ye = k === 1 ? "f32" : `vec${k}f`;
            switch (k) {
              case 1:
                return `${ce}(${ye}(scale.${oe}))`;
              case 2:
                return `vec2<${ce}>(${ye}(scale[0].${oe}, scale[1].${oe}))`;
              case 4:
                return `vec4<${ce}>(${ye}(scale[0].${oe}, scale[1].${oe}, scale[2].${oe}, scale[3].${oe}))`;
              default:
                throw new Error(`Not supported compoents ${k}`);
            }
          }, M = dt("input", o[0].dataType, o[0].dims, k), C = $t("output", o[0].dataType, y, k);
          return `
  @group(0) @binding(0) var<storage, read> input : array<${M.type.storage}>;
  @group(0) @binding(1) var<storage, read> scale_input : array<${ke}>;
  @group(0) @binding(2) var<storage, read_write> output : array<${C.type.storage}>;
  struct Uniforms {H: u32, C : u32};
  @group(0) @binding(3) var<uniform> uniforms: Uniforms;

  ${ue.mainStart()}
    let current_image_number = global_idx / (uniforms.C * uniforms.H);
    let current_channel_number = global_idx % uniforms.C;

    let scale_offset = current_image_number * uniforms.C + current_channel_number;
    let scale = scale_input[scale_offset];
    output[global_idx] = fma(input[global_idx], ${Le(0)}, ${Le(1)});
  }`;
        };
        s.compute({ name: "InstanceNormalizationNHWC", shaderCache: { hint: `${k}`, inputDependencies: V }, getRunData: () => ({ outputs: [{ dims: y, dataType: o[0].dataType }], dispatchGroup: { x: Math.ceil(O / 64) }, programUniforms: $ }), getShaderSource: Te }, { inputs: [o[0], re] });
      }, Rf = (s, o) => {
        o.format === "NHWC" ? zo(s, s.inputs, o) : Ff(s, s.inputs, o);
      };
    }), Bf, Dg, zf, kg = l(() => {
      jt(), ie(), sn(), Bf = (s) => {
        if (!s || s.length < 2)
          throw new Error("layerNorm requires at least 2 inputs.");
      }, Dg = (s, o, d) => {
        let g = o.simplified, y = s[0].dims, x = s[1], b = !g && s[2], P = y, k = it.normalizeAxis(o.axis, y.length), O = it.sizeToDimension(y, k), $ = it.sizeFromDimension(y, k), V = it.size(x.dims), G = b ? it.size(b.dims) : 0;
        if (V !== $ || b && G !== $)
          throw new Error(`Size of X.shape()[axis:] == ${$}.
       Size of scale and bias (if provided) must match this.
       Got scale size of ${V} and bias size of ${G}`);
        let ee = [];
        for (let M = 0; M < y.length; ++M)
          M < k ? ee.push(y[M]) : ee.push(1);
        let X = Dn($), re = ["type", "type"], Te = [{ type: 12, data: O }, { type: 1, data: $ }, { type: 12, data: Math.floor($ / X) }, { type: 1, data: o.epsilon }];
        b && re.push("type");
        let ue = d > 1, ce = d > 2, ke = (M) => {
          let C = Jn(s[0].dataType), z = [dt("x", s[0].dataType, s[0].dims, X), dt("scale", x.dataType, x.dims, X)];
          b && z.push(dt("bias", b.dataType, b.dims, X)), z.push($t("output", s[0].dataType, P, X)), ue && z.push($t("mean_data_output", 1, ee)), ce && z.push($t("inv_std_output", 1, ee));
          let oe = [{ name: "norm_count", type: "u32" }, { name: "norm_size", type: "f32" }, { name: "norm_size_vectorized", type: "u32" }, { name: "epsilon", type: "f32" }];
          return `
  ${M.registerUniforms(oe).declareVariables(...z)}
  ${M.mainStart()}
    ${M.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.norm_count")}
    let offset = global_idx * uniforms.norm_size_vectorized;
    var mean_vector = ${Ta("f32", X)};
    var mean_square_vector = ${Ta("f32", X)};

    for (var h: u32 = 0u; h < uniforms.norm_size_vectorized; h++) {
      let value = ${is(C, X, "x[h + offset]")};
      mean_vector += value;
      mean_square_vector += value * value;
    }
    let mean = ${Ls("mean_vector", X)} / uniforms.norm_size;
    let inv_std_dev = inverseSqrt(${Ls("mean_square_vector", X)} / uniforms.norm_size ${g ? "" : "- mean * mean"} + uniforms.epsilon);

    for (var j: u32 = 0; j < uniforms.norm_size_vectorized; j++) {
      let f32input = ${is(C, X, "x[j + offset]")};
      let f32scale = ${is(C, X, "scale[j]")};
      output[j + offset] = ${z[0].type.value}((f32input ${g ? "" : "- mean"}) * inv_std_dev * f32scale
        ${b ? `+ ${is(C, X, "bias[j]")}` : ""}
      );
    }

    ${ue ? "mean_data_output[global_idx] = mean" : ""};
    ${ce ? "inv_std_output[global_idx] = inv_std_dev" : ""};
  }`;
        }, Le = [{ dims: P, dataType: s[0].dataType }];
        return ue && Le.push({ dims: ee, dataType: 1 }), ce && Le.push({ dims: ee, dataType: 1 }), { name: "LayerNormalization", shaderCache: { hint: `${X};${d};${g}`, inputDependencies: re }, getRunData: () => ({ outputs: Le, dispatchGroup: { x: Math.ceil(O / 64) }, programUniforms: Te }), getShaderSource: ke };
      }, zf = (s, o) => {
        Bf(s.inputs), s.compute(Dg(s.inputs, o, s.outputCount));
      };
    }), $f, xr, Og = l(() => {
      ie(), gl(), Lo(), $f = (s) => {
        if (!s || s.length !== 2)
          throw new Error("MatMul requires 2 inputs.");
        if (s[0].dims[s[0].dims.length - 1] !== s[1].dims[s[1].dims.length - 2])
          throw new Error("shared dimension does not match.");
      }, xr = (s) => {
        $f(s.inputs);
        let o = Ui.calcShape(s.inputs[0].dims, s.inputs[1].dims, !0);
        if (!o)
          throw new Error("Can't use matmul on the given tensors");
        let d = o[o.length - 1], g = s.inputs[0].dims[s.inputs[0].dims.length - 1];
        if (d < 8 && g < 8)
          s.compute(Ao(s.inputs, { activation: "" }, o));
        else {
          let y = o[o.length - 2], x = it.size(s.inputs[0].dims.slice(0, -2)), b = it.size(s.inputs[1].dims.slice(0, -2));
          if (x !== 1 && y === 1 && b === 1) {
            let P = s.inputs[0].reshape([1, x, g]), k = s.inputs[1].reshape([1, g, d]), O = [1, x, d], $ = [P, k];
            s.compute(Io($, { activation: "" }, o, O), { inputs: $ });
          } else
            s.compute(Io(s.inputs, { activation: "" }, o));
        }
      };
    }), Nf, Uf, Gf, Vf, jf, Fg = l(() => {
      jt(), ie(), pn(), sn(), Nf = (s, o) => {
        if (s.length < 3 || s.length > 4)
          throw new Error("MatMulNBits requires 3 or 4 inputs");
        let d = s[0], g = d.dims.length;
        if (d.dims[g - 1] !== o.k)
          throw new Error("The last dim of input shape does not match the k value");
        let y = Math.floor((o.k + o.blockSize - 1) / o.blockSize), x = o.blockSize / 8 * o.bits, b = s[1];
        if (!it.areEqual(b.dims, [o.n, y, x]))
          throw new Error("The second inputs must be 3D tensor with shape N X nBlocksPerCol X blobSize");
        let P = s[2].dims;
        if (it.size(P) !== o.n * y)
          throw new Error("scales input size error.");
        if (s.length === 4) {
          let k = s[3].dims, O = o.bits > 4 ? o.n * y : o.n * Math.floor((y + 1) / 2);
          if (it.size(k) !== O)
            throw new Error("zeroPoints input size error.");
        }
      }, Uf = (s, o) => {
        let d = s[0].dims, g = d.length, y = d[g - 2], x = o.k, b = o.n, P = d.slice(0, g - 2), k = it.size(P), O = s[1].dims[2] / 4, $ = s[0].dataType, V = Dn(o.k), G = Dn(O), ee = Dn(b), X = P.concat([y, b]), re = y > 1 && b / ee % 2 === 0 ? 2 : 1, Te = it.size(X) / ee / re, ue = 64, ce = [], ke = [k, y, x / V], Le = it.convertShape(s[1].dims).slice();
        Le.splice(-1, 1, O / G), ce.push(...Ut(ke)), ce.push(...Ut(Le)), ce.push(...Ut(s[2].dims)), s.length === 4 && ce.push(...Ut(it.convertShape(s[3].dims)));
        let M = [k, y, b / ee];
        ce.push(...Ut(M));
        let C = (z) => {
          let oe = ke.length, ye = dt("a", s[0].dataType, oe, V), Pe = dt("b", 12, Le.length, G), Ue = dt("scales", s[2].dataType, s[2].dims.length), Je = [ye, Pe, Ue], st = s.length === 4 ? dt("zero_points", 12, s[3].dims.length) : void 0;
          st && Je.push(st);
          let gt = M.length, wt = $t("output", s[0].dataType, gt, ee), yt = Jn(s[0].dataType), ht = (() => {
            switch (V) {
              case 1:
                return `array<${yt}, 8>`;
              case 2:
                return `mat4x2<${yt}>`;
              case 4:
                return `mat2x4<${yt}>`;
              default:
                throw new Error(`${V}-component is not supported.`);
            }
          })(), Ot = () => {
            let Ze = `
          // reuse a data
            var input_offset = ${ye.indicesToOffset(`${ye.type.indices}(batch, row, word_offset)`)};
            var a_data: ${ht};
            for (var j: u32 = 0; j < ${8 / V}; j++) {
              a_data[j] = ${ye.getByOffset("input_offset")};
              input_offset++;
            }
          `;
            for (let ft = 0; ft < ee * re; ft++)
              Ze += `
            b_value = ${G === 1 ? `b${ft}_data` : `b${ft}_data[i]`};
            b_value_lower = unpack4xU8(b_value & b_mask);
            b_value_upper = unpack4xU8((b_value >> 4) & b_mask);
            b_quantized_values = ${ht}(${Array.from({ length: 4 }, (St, Ht) => `${yt}(b_value_lower[${Ht}]), ${yt}(b_value_upper[${Ht}])`).join(", ")});
            b_dequantized_values = ${V === 1 ? `${ht}(${Array.from({ length: 8 }, (St, Ht) => `(b_quantized_values[${Ht}] - ${st ? `zero_point${ft}` : "zero_point"}) * scale${ft}`).join(", ")});` : `(b_quantized_values - ${ht}(${Array(8).fill(`${st ? `zero_point${ft}` : "zero_point"}`).join(",")})) * scale${ft};`};
            workgroup_shared[local_id.x * ${re} + ${Math.floor(ft / ee)}]${ee > 1 ? `[${ft % ee}]` : ""} += ${Array.from({ length: 8 / V }, (St, Ht) => `${V === 1 ? `a_data[${Ht}] * b_dequantized_values[${Ht}]` : `dot(a_data[${Ht}], b_dequantized_values[${Ht}])`}`).join(" + ")};
          `;
            return Ze;
          }, xt = () => {
            let Ze = `
            var col_index = col * ${ee};
            ${st ? `
            let zero_point_bytes_per_col = (nBlocksPerCol + 1) / 2;
            var zero_point_byte_count: u32;
            var zero_point_word_index: u32;
            var zero_point_byte_offset: u32;
            let zero_point_nibble_offset: u32 = block & 0x1u;
            var zero_point_bits_offset: u32;
            var zero_point_word: u32;` : `
            // The default zero point is 8 for unsigned 4-bit quantization.
            let zero_point = ${yt}(8);`}
            `;
            for (let ft = 0; ft < ee * re; ft++)
              Ze += `
            let scale${ft} = ${Ue.getByOffset("col_index * nBlocksPerCol + block")};
            ${st ? `
            zero_point_byte_count = col_index * zero_point_bytes_per_col + (block >> 0x1u);
            zero_point_word_index = zero_point_byte_count >> 0x2u;
            zero_point_byte_offset = zero_point_byte_count & 0x3u;
            zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);
            zero_point_word = ${st.getByOffset("zero_point_word_index")} >> zero_point_bits_offset;
            let zero_point${ft} = ${yt}((zero_point_word) & 0xFu);` : ""}
            col_index += 1;`;
            return Ze;
          }, Ct = () => {
            let Ze = `col_index = col * ${ee};`;
            for (let ft = 0; ft < ee * re; ft++)
              Ze += `
            let b${ft}_data = ${Pe.getByIndices(`${Pe.type.indices}(col_index, block, word)`)};
            col_index += 1;`;
            return Ze += `
            var b_value: u32;
            let b_mask: u32 = 0x0F0F0F0Fu;
            var b_value_lower: vec4<u32>;
            var b_value_upper: vec4<u32>;
            var b_quantized_values: ${ht};
            var b_dequantized_values: ${ht};`, Ze;
          };
          return `
        var<workgroup> workgroup_shared: array<${wt.type.value}, ${re * ue}>;
        ${z.declareVariables(...Je, wt)}
        ${z.mainStart([ue, 1, 1])}
          let output_indices = ${wt.offsetToIndices(`(global_idx / ${ue}) * ${re}`)};
          let col = output_indices[2];
          let row = output_indices[1];
          let batch = output_indices[0];
          let nBlocksPerCol = uniforms.b_shape[1];

          for (var block = local_id.x; block < nBlocksPerCol; block += ${ue}) {
            //process one block
            var word_offset: u32 = block * ${o.blockSize / V};
            ${xt()}
            for (var word: u32 = 0; word < ${O}; word += ${G}) {
              ${Ct()}
              for (var i: u32 = 0; i < ${G}; i++) {
                ${Ot()}
                word_offset += ${8 / V};
              }
            }
          }
          workgroupBarrier();

          if (local_id.x < ${re}) {
            var output_value: ${wt.type.value} = ${wt.type.value}(0);
            var workgroup_shared_offset: u32 = local_id.x;
            for (var b: u32 = 0u; b < ${ue}u; b++) {
              output_value += workgroup_shared[workgroup_shared_offset];
              workgroup_shared_offset += ${re};
            }
            ${wt.setByIndices(`${wt.type.indices}(batch, row, col + local_id.x)`, "output_value")};
          }
        }`;
        };
        return { name: "MatMulNBits", shaderCache: { hint: `${o.blockSize};${o.bits};${V};${G};${ee};${re};${ue}`, inputDependencies: Array(s.length).fill("rank") }, getRunData: () => ({ outputs: [{ dims: X, dataType: $ }], dispatchGroup: { x: Te }, programUniforms: ce }), getShaderSource: C };
      }, Gf = (s, o) => {
        let d = s[0].dims, g = d.length, y = d[g - 2], x = o.k, b = o.n, P = d.slice(0, g - 2), k = it.size(P), O = s[1].dims[2] / 4, $ = s[0].dataType, V = Dn(o.k), G = Dn(O), ee = P.concat([y, b]), X = 128, re = b % 8 === 0 ? 8 : b % 4 === 0 ? 4 : 1, Te = X / re, ue = Te * G * 8, ce = ue / V, ke = ue / o.blockSize, Le = it.size(ee) / re, M = [], C = [k, y, x / V], z = it.convertShape(s[1].dims).slice();
        z.splice(-1, 1, O / G), M.push(...Ut(C)), M.push(...Ut(z)), M.push(...Ut(s[2].dims)), s.length === 4 && M.push(...Ut(it.convertShape(s[3].dims)));
        let oe = [k, y, b];
        M.push(...Ut(oe));
        let ye = (Pe) => {
          let Ue = C.length, Je = dt("a", s[0].dataType, Ue, V), st = dt("b", 12, z.length, G), gt = dt("scales", s[2].dataType, s[2].dims.length), wt = [Je, st, gt], yt = s.length === 4 ? dt("zero_points", 12, s[3].dims.length) : void 0;
          yt && wt.push(yt);
          let ht = oe.length, Ot = $t("output", s[0].dataType, ht), xt = Jn(s[0].dataType), Ct = () => {
            switch (V) {
              case 1:
                return `
          let a_data0 = vec4<${xt}>(sub_a[word_offset], sub_a[word_offset + 1], sub_a[word_offset + 2], sub_a[word_offset + 3]);
          let a_data1 = vec4<${xt}>(sub_a[word_offset + 4], sub_a[word_offset + 5], sub_a[word_offset + 6], sub_a[word_offset + 7]);`;
              case 2:
                return `
          let a_data0 = vec4<${xt}>(sub_a[word_offset], sub_a[word_offset + 1]);
          let a_data1 = vec4<${xt}>(sub_a[word_offset + 2], sub_a[word_offset + 3]);`;
              case 4:
                return `
          let a_data0 = sub_a[word_offset];
          let a_data1 = sub_a[word_offset + 1];`;
              default:
                throw new Error(`${V}-component is not supported.`);
            }
          };
          return `
        var<workgroup> sub_a: array<${Je.type.value}, ${ce}>;
        var<workgroup> inter_results: array<array<${Ot.type.value}, ${Te}>, ${re}>;
        ${Pe.declareVariables(...wt, Ot)}
        ${Pe.mainStart([Te, re, 1])}
          let output_indices = ${Ot.offsetToIndices(`workgroup_index * ${re}`)};
          let col = output_indices[2];
          let row = output_indices[1];
          let batch = output_indices[0];
          let n_blocks_per_col = uniforms.b_shape[1];
          let num_tiles =  (n_blocks_per_col - 1) / ${ke} + 1;

          // Loop over shared dimension.
          for (var tile: u32 = 0; tile < num_tiles; tile += 1) {
            let a_col_start = tile * ${ce};
            // load one tile A data into shared memory.
            for (var a_offset = local_idx; a_offset < ${ce}; a_offset += ${X})
            {
              let a_col = a_col_start + a_offset;
              if (a_col < uniforms.a_shape[2])
              {
                sub_a[a_offset] = ${Je.getByIndices(`${Je.type.indices}(batch, row, a_col)`)};
              } else {
                sub_a[a_offset] = ${Je.type.value}(0);
              }
            }
            workgroupBarrier();

            // each thread process one block
            let b_row = col + local_id.y;
            let block = tile * ${ke} + local_id.x;
            ${yt ? `
            let zero_point_bytes_per_col = (n_blocks_per_col + 1) / 2;
            let zero_point_byte_count = b_row * zero_point_bytes_per_col + (block >> 0x1u);
            let zero_point_word_index = zero_point_byte_count >> 0x2u;
            let zero_point_byte_offset = zero_point_byte_count & 0x3u;
            let zero_point_nibble_offset: u32 = block & 0x1u;
            let zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);
            let zero_point_word = ${yt.getByOffset("zero_point_word_index")} >> zero_point_bits_offset;
            let zero_point = ${xt}((zero_point_word) & 0xFu);` : `
            // The default zero point is 8 for unsigned 4-bit quantization.
            let zero_point = ${xt}(8);`}
            let scale = ${gt.getByOffset("b_row * n_blocks_per_col + block")};
            let b_data = ${st.getByIndices(`${st.type.indices}(b_row, block, 0)`)};
            var word_offset = local_id.x * ${o.blockSize / V};
            for (var i: u32 = 0; i < ${G}; i++) {
              ${Ct()}
              let b_value = ${G === 1 ? "b_data" : "b_data[i]"};
              let b_value_lower = unpack4xU8(b_value & 0x0F0F0F0Fu);
              let b_value_upper = unpack4xU8((b_value >> 4) & 0x0F0F0F0Fu);
              let b_quantized_values = mat2x4<${xt}>(${Array.from({ length: 4 }, (Ze, ft) => `${xt}(b_value_lower[${ft}]), ${xt}(b_value_upper[${ft}])`).join(", ")});
              let b_dequantized_values = (b_quantized_values - mat2x4<${xt}>(${Array(8).fill("zero_point").join(",")})) * scale;
              inter_results[local_id.y][local_id.x] += ${Array.from({ length: 2 }, (Ze, ft) => `${`dot(a_data${ft}, b_dequantized_values[${ft}])`}`).join(" + ")};
              word_offset += ${8 / V};
            }
            workgroupBarrier();
          }

          if (local_idx < ${re}) {
            var output_value: ${Ot.type.value} = ${Ot.type.value}(0);
            for (var b = 0u; b < ${Te}; b++) {
              output_value += inter_results[local_idx][b];
            }
            if (col + local_idx < uniforms.output_shape[2])
            {
              ${Ot.setByIndices(`${Ot.type.indices}(batch, row, col + local_idx)`, "output_value")}
            }
          }
        }`;
        };
        return { name: "BlockwiseMatMulNBits32", shaderCache: { hint: `${o.blockSize};${V};${G};${Te};${re}`, inputDependencies: Array(s.length).fill("rank") }, getRunData: () => ({ outputs: [{ dims: ee, dataType: $ }], dispatchGroup: { x: Le }, programUniforms: M }), getShaderSource: ye };
      }, Vf = (s, o) => {
        Nf(s.inputs, o), o.blockSize === 32 && s.adapterInfo.isVendor("intel") && s.adapterInfo.isArchitecture("gen-12lp") ? s.compute(Gf(s.inputs, o)) : s.compute(Uf(s.inputs, o));
      }, jf = (s) => Yt(s);
    }), $o, Rg, Wf, Hf, qf, Kf, Yl, Xf, Yf, Jf = l(() => {
      jt(), ie(), sn(), $o = (s) => {
        if (!s || s.length < 1)
          throw new Error("Too few inputs");
        if (s[0].dataType !== 1 && s[0].dataType !== 10)
          throw new Error("Input type must be float or float16.");
        if (s.length >= 2) {
          let o = s[0].dims.length * 2 === s[1].dims[0];
          if (s.length === 4 && (o = s[3].dims[0] * 2 === s[1].dims[0]), !o)
            throw new Error("The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].");
        }
      }, Rg = (s, o, d) => {
        let g = "";
        for (let y = o - 1; y >= 0; --y)
          g += `
            k = i32(${s.indicesGet("indices", y)}) - ${Nt("uniforms.pads", y, d)};
            if (k < 0) {
              break;
            }
            if (k >= i32(${Nt("uniforms.x_shape", y, o)})) {
              break;
            }
            offset += k * i32(${Nt("uniforms.x_strides", y, o)});
        `;
        return `
          value = ${s.type.value}(uniforms.constant_value);
          for (var i = 0; i < 1; i++) {
            var offset = 0;
            var k = 0;
            ${g}
            value = x[offset];
          }
      `;
      }, Wf = (s, o, d) => {
        let g = "";
        for (let y = o - 1; y >= 0; --y)
          g += `
                k = i32(${s.indicesGet("indices", y)}) - ${Nt("uniforms.pads", y, d)};
                if (k < 0) {
                  k = -k;
                }
                {
                  let _2n_1 = 2 * (i32(${Nt("uniforms.x_shape", y, o)}) - 1);
                  k = k % _2n_1;
                  if(k >= i32(${Nt("uniforms.x_shape", y, o)})) {
                    k = _2n_1 - k;
                  }
                }
                offset += k * i32(${Nt("uniforms.x_strides", y, o)});
            `;
        return `
              var offset = 0;
              var k = 0;
              ${g}
              value = x[offset];
          `;
      }, Hf = (s, o, d) => {
        let g = "";
        for (let y = o - 1; y >= 0; --y)
          g += `
                k = i32(${s.indicesGet("indices", y)}) - ${Nt("uniforms.pads", y, d)};
                if (k < 0) {
                  k = 0;
                }
                if (k >= i32(${Nt("uniforms.x_shape", y, o)})) {
                  k = i32(${Nt("uniforms.x_shape", y, o)}) - 1;
                }
                offset += k * i32(${Nt("uniforms.x_strides", y, o)});
            `;
        return `
              var offset = 0;
              var k = 0;
              ${g}
              value = x[offset];
          `;
      }, qf = (s, o, d) => {
        let g = "";
        for (let y = o - 1; y >= 0; --y)
          g += `
                k = i32(${s.indicesGet("indices", y)}) - ${Nt("uniforms.pads", y, d)};
                if (k < 0)  {
                  k += i32(${Nt("uniforms.x_shape", y, o)}]);
                }
                if (k >= i32(${Nt("uniforms.x_shape", y, o)})) {
                  k -= i32(${Nt("uniforms.x_shape", y, o)});
                }
                offset += k * i32(${Nt("uniforms.x_strides", y, o)});
            `;
        return `
              var offset = 0;
              var k = 0;
              ${g}
              value = x[offset];
          `;
      }, Kf = (s, o, d) => {
        switch (d.mode) {
          case 0:
            return Rg(s, o, d.pads.length);
          case 1:
            return Wf(s, o, d.pads.length);
          case 2:
            return Hf(s, o, d.pads.length);
          case 3:
            return qf(s, o, d.pads.length);
          default:
            throw new Error("Invalid mode");
        }
      }, Yl = (s, o) => {
        let d = it.padShape(s[0].dims.slice(), o.pads), g = s[0].dims, y = it.size(d), x = [{ type: 12, data: y }, { type: 6, data: o.pads }], b = s.length >= 3 && s[2].data;
        o.mode === 0 && x.push({ type: b ? s[2].dataType : 1, data: o.value }), x.push(...Ut(s[0].dims, d));
        let P = ["rank"], k = (O) => {
          let $ = $t("output", s[0].dataType, d.length), V = dt("x", s[0].dataType, g.length), G = V.type.value, ee = Kf($, g.length, o), X = [{ name: "output_size", type: "u32" }, { name: "pads", type: "i32", length: o.pads.length }];
          return o.mode === 0 && X.push({ name: "constant_value", type: b ? G : "f32" }), `
            ${O.registerUniforms(X).declareVariables(V, $)}
            ${O.mainStart()}
            ${O.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}

            let indices = ${$.offsetToIndices("global_idx")};

            var value = ${G}(0);
            ${ee}
            output[global_idx] = value;
        }`;
        };
        return { name: "Pad", shaderCache: { hint: `${o.mode}${b}`, inputDependencies: P }, getRunData: () => ({ outputs: [{ dims: d, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(it.size(d) / 64) }, programUniforms: x }), getShaderSource: k };
      }, Xf = (s, o) => {
        if (s.length > 1) {
          let d = s[1].getBigInt64Array(), g = s.length >= 3 && s[2].data ? s[2].dataType === 10 ? s[2].getUint16Array()[0] : s[2].getFloat32Array()[0] : 0, y = s[0].dims.length, x = new Int32Array(2 * y).fill(0);
          if (s.length >= 4) {
            let P = s[3].getBigInt64Array();
            for (let k = 0; k < P.length; k++)
              x[Number(P[k])] = Number(d[k]), x[Number(P[k]) + y] = Number(d[k + P.length]);
          } else
            d.forEach((P, k) => x[Number(k)] = Number(P));
          let b = [];
          return x.forEach((P) => b.push(P)), { mode: o.mode, value: g, pads: b };
        } else
          return o;
      }, Yf = (s, o) => {
        $o(s.inputs);
        let d = Xf(s.inputs, o);
        s.compute(Yl(s.inputs, d), { inputs: [0] });
      };
    }), jr, Jl, No, Ql, Zl, ec, Qf, tc, Uo, Zf, ep, Go, tp, np, Vo, ip, sp, jo, rp, Bg = l(() => {
      qe(), jt(), ie(), sn(), jr = (s) => {
        if (R.webgpu.validateInputContent && (!s || s.length !== 1))
          throw new Error("Pool ops requires 1 input.");
      }, Jl = (s, o, d) => {
        let g = o.format === "NHWC", y = s.dims.slice();
        g && y.splice(1, 0, y.pop());
        let x = Object.hasOwnProperty.call(o, "dilations"), b = o.kernelShape.slice(), P = o.strides.slice(), k = x ? o.dilations.slice() : [], O = o.pads.slice();
        ps.adjustPoolAttributes(d, y, b, P, k, O);
        let $ = ps.computePoolOutputShape(d, y, P, k, b, O, o.autoPad), V = Object.assign({}, o);
        x ? Object.assign(V, { kernelShape: b, strides: P, pads: O, dilations: k, cacheKey: o.cacheKey }) : Object.assign(V, { kernelShape: b, strides: P, pads: O, cacheKey: o.cacheKey });
        let G = $.slice();
        return G.push(G.splice(1, 1)[0]), [V, g ? G : $];
      }, No = (s, o) => {
        let d = o.format === "NHWC", g = it.size(s), y = it.size(o.kernelShape), x = [{ type: 12, data: g }, { type: 12, data: y }], b = [{ name: "outputSize", type: "u32" }, { name: "kernelSize", type: "u32" }];
        if (o.kernelShape.length <= 2) {
          let P = o.kernelShape[o.kernelShape.length - 1], k = o.strides[o.strides.length - 1], O = o.pads[o.pads.length / 2 - 1], $ = o.pads[o.pads.length - 1], V = !!(O + $);
          x.push({ type: 12, data: P }, { type: 12, data: k }, { type: 12, data: O }, { type: 12, data: $ }), b.push({ name: "kw", type: "u32" }, { name: "sw", type: "u32" }, { name: "pwStart", type: "u32" }, { name: "pwEnd", type: "u32" });
          let G = !1;
          if (o.kernelShape.length === 2) {
            let ee = o.kernelShape[o.kernelShape.length - 2], X = o.strides[o.strides.length - 2], re = o.pads[o.pads.length / 2 - 2], Te = o.pads[o.pads.length - 2];
            G = !!(re + Te), x.push({ type: 12, data: ee }, { type: 12, data: X }, { type: 12, data: re }, { type: 12, data: Te }), b.push({ name: "kh", type: "u32" }, { name: "sh", type: "u32" }, { name: "phStart", type: "u32" }, { name: "phEnd", type: "u32" });
          }
          return [x, b, !0, V, G];
        } else {
          if (d)
            throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");
          let P = it.computeStrides(o.kernelShape);
          x.push({ type: 12, data: P }, { type: 12, data: o.pads }, { type: 12, data: o.strides }), b.push({ name: "kernelStrides", type: "u32", length: P.length }, { name: "pads", type: "u32", length: o.pads.length }, { name: "strides", type: "u32", length: o.strides.length });
          let k = o.pads.reduce((O, $) => O + $);
          return [x, b, !!k, !1, !1];
        }
      }, Ql = (s, o, d, g, y, x, b, P, k, O, $, V) => {
        let G = y.format === "NHWC", ee = o.type.value, X = $t("output", o.type.tensor, g);
        if (y.kernelShape.length <= 2) {
          let re = "", Te = "", ue = "", ce = d - (G ? 2 : 1);
          if ($ ? re = `
                for (var i: u32 = 0u; i < uniforms.kw; i++) {
                  xIndices[${ce}] = indices[${ce}] * uniforms.sw - uniforms.pwStart + i;
                  if (xIndices[${ce}] < 0 || xIndices[${ce}]
                      >= uniforms.x_shape[${ce}]) {
                    pad++;
                    continue;
                  }
                  let x_val = x[${o.indicesToOffset("xIndices")}];
                  ${x}
                }` : re = `
                for (var i: u32 = 0u; i < uniforms.kw; i++) {
                  xIndices[${ce}] = indices[${ce}] * uniforms.sw - uniforms.pwStart + i;
                  let x_val = x[${o.indicesToOffset("xIndices")}];
                  ${x}
                }`, y.kernelShape.length === 2) {
            let ke = d - (G ? 3 : 2);
            V ? Te = `
                for (var j: u32 = 0u; j < uniforms.kh; j++) {
                  xIndices[${ke}] = indices[${ke}] * uniforms.sh - uniforms.phStart + j;
                  if (xIndices[${ke}] < 0 || xIndices[${ke}] >= uniforms.x_shape[${ke}]) {
                    pad += i32(uniforms.kw);
                    continue;
                  }
              ` : Te = `
                for (var j: u32 = 0u; j < uniforms.kh; j++) {
                  xIndices[${ke}] = indices[${ke}] * uniforms.sh - uniforms.phStart + j;
                `, ue = `
              }
            `;
          }
          return `
            ${s.registerUniforms(k).declareVariables(o, X)}

            ${s.mainStart()}
              ${s.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}

              let indices = ${X.offsetToIndices("global_idx")};
              var xIndices = ${X.offsetToIndices("global_idx")};

              var value = ${ee}(${P});
              var pad = 0;
              ${Te}
              ${re}
              ${ue}
              ${b}

              output[global_idx] = value;
            }`;
        } else {
          if (G)
            throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");
          let re = y.kernelShape.length, Te = y.pads.length, ue = "";
          return O ? ue = `
                if (xIndices[j] >= uniforms.x_shape[j]) {
                  pad++;
                  isPad = true;
                  break;
                }
              }
              if (!isPad) {
                let x_val = x[${o.indicesToOffset("xIndices")}];
                ${x}
              }` : ue = `
              }
              let x_val = x[${o.indicesToOffset("xIndices")}];
              ${x}
            `, `
            ${s.registerUniforms(k).declareVariables(o, X)}

            ${s.mainStart()}
              ${s.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
              let indices = ${X.offsetToIndices("global_idx")};
              var xIndices = ${X.offsetToIndices("global_idx")};

              var offsets: array<u32, ${re}>;

              var value = ${ee}(${P});
              var pad = 0;
              var isPad = false;

              for (var i: u32 = 0u; i < uniforms.kernelSize; i++) {
                var offset = i;
                for (var j = 0u; j < ${re - 1}u; j++) {
                  offsets[j] = offset / ${Nt("uniforms.kernelStrides", "j", re)};
                  offset -= offsets[j] * ${Nt("uniforms.kernelStrides", "j", re)};
                }
                offsets[${re - 1}] = offset;

                isPad = false;
                for (var j = ${d - re}u; j < ${d}u; j++) {
                  xIndices[j] = indices[j] * ${Nt("uniforms.strides", `j - ${d - re}u`, re)}
                    + offsets[j - ${d - re}u] - ${Nt("uniforms.pads", "j - 2u", Te)};
                  ${ue}
              }
              ${b}

              output[global_idx] = value;
            }`;
        }
      }, Zl = (s) => `${s.format};${s.ceilMode};${s.autoPad};${s.kernelShape.length}`, ec = (s) => `${Zl(s)};${s.countIncludePad}`, Qf = (s) => `${Zl(s)};${s.storageOrder};${s.dilations}`, tc = (s) => ({ format: s.format, autoPad: ["NOTSET", "VALID", "SAME_UPPER", "SAME_LOWER"][s.auto_pad], ceilMode: s.ceil_mode, kernelShape: s.kernel_shape, strides: s.strides, pads: s.pads }), Uo = (s, o, d, g) => {
        let [y, x] = Jl(o, g, d), b = dt("x", o.dataType, o.dims.length), P = b.type.value, k = "value += x_val;", O = "";
        y.countIncludePad ? O += `value /= ${P}(uniforms.kernelSize);` : O += `value /= ${P}(i32(uniforms.kernelSize) - pad);`;
        let [$, V, G, ee, X] = No(x, y);
        $.push(...Ut(o.dims, x));
        let re = ["rank"];
        return { name: s, shaderCache: { hint: `${g.cacheKey};${G};${ee};${X}`, inputDependencies: re }, getRunData: () => ({ outputs: [{ dims: x, dataType: o.dataType }], dispatchGroup: { x: Math.ceil(it.size(x) / 64) }, programUniforms: $ }), getShaderSource: (Te) => Ql(Te, b, o.dims.length, x.length, y, k, O, 0, V, G, ee, X) };
      }, Zf = (s) => {
        let o = s.count_include_pad !== 0, d = tc(s);
        if (d.ceilMode !== 0)
          throw new Error("using ceil() in shape computation is not yet supported for AveragePool");
        let g = { countIncludePad: o, ...d, cacheKey: "" };
        return { ...g, cacheKey: ec(g) };
      }, ep = (s, o) => {
        jr(s.inputs), s.compute(Uo("AveragePool", s.inputs[0], !1, o));
      }, Go = { autoPad: "", ceilMode: 0, countIncludePad: !1, kernelShape: [], strides: [], pads: [], storageOrder: 0, dilations: [] }, tp = (s) => {
        let o = s.format;
        return { format: o, ...Go, cacheKey: o };
      }, np = (s, o) => {
        jr(s.inputs), s.compute(Uo("GlobalAveragePool", s.inputs[0], !0, o));
      }, Vo = (s, o, d, g) => {
        let [y, x] = Jl(o, g, d), b = `
      value = max(x_val, value);
    `, P = "", k = dt("x", o.dataType, o.dims.length), O = ["rank"], [$, V, G, ee, X] = No(x, y);
        return $.push(...Ut(o.dims, x)), { name: s, shaderCache: { hint: `${g.cacheKey};${G};${ee};${X}`, inputDependencies: O }, getRunData: () => ({ outputs: [{ dims: x, dataType: o.dataType }], dispatchGroup: { x: Math.ceil(it.size(x) / 64) }, programUniforms: $ }), getShaderSource: (re) => Ql(re, k, o.dims.length, x.length, y, b, P, o.dataType === 10 ? -65504 : -1e5, V, G, ee, X) };
      }, ip = (s, o) => {
        jr(s.inputs), s.compute(Vo("MaxPool", s.inputs[0], !1, o));
      }, sp = (s) => {
        let o = s.storage_order, d = s.dilations, g = tc(s);
        if (o !== 0)
          throw new Error("column major storage order is not yet supported for MaxPool");
        if (g.ceilMode !== 0)
          throw new Error("using ceil() in shape computation is not yet supported for MaxPool");
        let y = { storageOrder: o, dilations: d, ...g, cacheKey: "" };
        return { ...y, cacheKey: Qf(y) };
      }, jo = (s) => {
        let o = s.format;
        return { format: o, ...Go, cacheKey: o };
      }, rp = (s, o) => {
        jr(s.inputs), s.compute(Vo("GlobalMaxPool", s.inputs[0], !0, o));
      };
    }), op, ap, nc, Wo, jy = l(() => {
      jt(), ie(), pn(), sn(), op = (s, o) => {
        if (s.length < 2 || s.length > 3)
          throw new Error("DequantizeLinear requires 2 or 3 inputs.");
        if (s.length === 3 && s[1].dims === s[2].dims)
          throw new Error("x-scale and x-zero-point must have the same shape.");
        if (s.length === 3 && s[0].dataType !== s[2].dataType)
          throw new Error("x and x-zero-point must have the same data type.");
        if (s[0].dataType === 6 && s.length > 2)
          throw new Error("In the case of dequantizing int32 there is no zero point.");
        if (s[1].dims.length !== 0 && s[1].dims.length !== 1 && s[1].dims.length !== s[0].dims.length)
          throw new Error("scale input must be a scalar, a 1D tensor, or have the same rank as the input tensor.");
        if (s.length > 2) {
          if (s[0].dataType !== s[2].dataType)
            throw new Error("x and x-zero-point must have the same data type.");
          if (s[1].dims.length !== s[2].dims.length)
            throw new Error("scale and zero-point inputs must have the same rank.");
          if (!s[1].dims.map((d, g) => d === s[2].dims[g]).reduce((d, g) => d && g, !0))
            throw new Error("scale and zero-point inputs must have the same shape.");
        }
        if (o.blockSize > 0) {
          if (s[1].dims.length === 0 || s[1].dims.length === 1 && s[1].dims[0] === 1)
            throw new Error("blockSize must be set only for block quantization.");
          if (!s[1].dims.map((y, x) => x === o.axis || y === s[0].dims[x]).reduce((y, x) => y && x, !0))
            throw new Error("For block qunatization, scale input shape to match the input shape except for the axis");
          if (s[1].dims.length !== s[0].dims.length)
            throw new Error("For block qunatization the scale input rank must be the same as the x rank.");
          let d = s[0].dims[o.axis], g = s[1].dims[o.axis];
          if (o.blockSize < Math.ceil(d / g) || o.blockSize > Math.ceil(d / (g - 1) - 1))
            throw new Error("blockSize must be with in the range [ceil(dI / Si), ceil(dI / (Si - 1) - 1)].");
        }
      }, ap = (s, o) => {
        let d = it.normalizeAxis(o.axis, s[0].dims.length), g = s[0].dataType, y = g === 3, x = s[0].dims, b = s[1].dataType, P = it.size(x), k = g === 3 || g === 2, O = k ? [Math.ceil(it.size(s[0].dims) / 4)] : s[0].dims, $ = s[1].dims, V = s.length > 2 ? s[2] : void 0, G = V ? k ? [Math.ceil(it.size(V.dims) / 4)] : V.dims : void 0, ee = $.length === 0 || $.length === 1 && $[0] === 1, X = ee === !1 && $.length === 1, re = Dn(P), Te = ee && (!k || re === 4), ue = Te ? re : 1, ce = Te && !k ? re : 1, ke = dt("input", k ? 12 : g, O.length, ce), Le = dt("scale", b, $.length), M = V ? dt("zero_point", k ? 12 : g, G.length) : void 0, C = $t("output", b, x.length, ue), z = [ke, Le];
        M && z.push(M);
        let oe = [O, $];
        V && oe.push(G);
        let ye = [{ type: 12, data: P / ue }, { type: 12, data: d }, { type: 12, data: o.blockSize }, ...Ut(...oe, x)], Pe = (Ue) => {
          let Je = [{ name: "output_size", type: "u32" }, { name: "axis", type: "u32" }, { name: "block_size", type: "u32" }];
          return `
      ${Ue.registerUniforms(Je).declareVariables(...z, C)}
      ${Ue.mainStart()}
          ${Ue.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
          let output_indices = ${C.offsetToIndices("global_idx")};

          // Set input x
          ${k ? `
            let input = ${ke.getByOffset("global_idx / 4")};
            let x_vec = ${y ? "unpack4xI8(input)" : "unpack4xU8(input)"};
            let x_value = ${ue === 1 ? "x_vec[global_idx % 4]" : "x_vec"};` : `let x_value = ${ke.getByOffset("global_idx")};`};

          // Set scale input
          ${ee ? `let scale_value= ${Le.getByOffset("0")}` : X ? `
            let scale_index = ${C.indicesGet("output_indices", "uniforms.axis")};
            let scale_value= ${Le.getByOffset("scale_index")};` : `
            var scale_indices: ${Le.type.indices} = output_indices;
            let index = ${Le.indicesGet("scale_indices", "uniforms.axis")} / uniforms.block_size;
            ${Le.indicesSet("scale_indices", "uniforms.axis", "index")};
            let scale_value= ${Le.getByIndices("scale_indices")};`};

          // Set zero-point input
          ${M ? ee ? k ? `
                let zero_point_input = ${M.getByOffset("0")};
                let zero_point_vec =  ${y ? "unpack4xI8(zero_point_input)" : "unpack4xU8(zero_point_input)"};
                let zero_point_value= zero_point_vec[0]` : `let zero_point_value = ${M.getByOffset("0")}` : X ? k ? `
                let zero_point_index = ${C.indicesGet("output_indices", "uniforms.axis")};
                let zero_point_input = ${M.getByOffset("zero_point_index / 4")};
                let zero_point_vec =  ${y ? "unpack4xI8(zero_point_input)" : "unpack4xU8(zero_point_input)"};
                let zero_point_value = zero_point_vec[zero_point_index % 4]` : `
                let zero_point_index = ${C.indicesGet("output_indices", "uniforms.axis")};
                let zero_point_value = ${M.getByOffset("zero_point_index")};` : k ? `
                let zero_point_offset = ${Le.indicesToOffset("scale_indices")};
                let zero_point_input = ${M.getByOffset("zero_point_offset / 4")};
                let zero_point_vec = ${y ? "unpack4xI8(zero_point_input)" : "unpack4xU8(zero_point_input)"};
                let zero_point_value = zero_point_vec[zero_point_offset % 4];` : `let zero_point_value = ${M.getByIndices("scale_indices")};` : `let zero_point_value = ${k ? y ? "i32" : "u32" : ke.type.value}(0);`};
      // Compute and write output
      ${C.setByOffset("global_idx", `${C.type.value}(x_value - zero_point_value) * scale_value`)};
      }`;
        };
        return { name: "DequantizeLinear", shaderCache: { hint: o.cacheKey, inputDependencies: M ? ["rank", "rank", "rank"] : ["rank", "rank"] }, getShaderSource: Pe, getRunData: () => ({ outputs: [{ dims: x, dataType: b }], dispatchGroup: { x: Math.ceil(P / ue / 64), y: 1, z: 1 }, programUniforms: ye }) };
      }, nc = (s, o) => {
        op(s.inputs, o), s.compute(ap(s.inputs, o));
      }, Wo = (s) => Yt({ axis: s.axis, blockSize: s.blockSize });
    }), lp, cp, ic, zg = l(() => {
      qe(), jt(), sn(), lp = (s, o, d) => {
        let g = s === o, y = s < o && d < 0, x = s > o && d > 0;
        if (g || y || x)
          throw new Error("Range these inputs' contents are invalid.");
      }, cp = (s, o, d, g) => {
        let y = Math.abs(Math.ceil((o - s) / d)), x = [y], b = y, P = [{ type: 12, data: b }, { type: g, data: s }, { type: g, data: d }, ...Ut(x)], k = (O) => {
          let $ = $t("output", g, x.length), V = $.type.value, G = [{ name: "outputSize", type: "u32" }, { name: "start", type: V }, { name: "delta", type: V }];
          return `
        ${O.registerUniforms(G).declareVariables($)}
        ${O.mainStart()}
        ${O.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
        output[global_idx] = uniforms.start + ${V}(global_idx) * uniforms.delta;
      }`;
        };
        return { name: "Range", shaderCache: { hint: `${g}` }, getShaderSource: k, getRunData: () => ({ outputs: [{ dims: x, dataType: g }], dispatchGroup: { x: Math.ceil(b / 64) }, programUniforms: P }) };
      }, ic = (s) => {
        let o = 0, d = 0, g = 0;
        s.inputs[0].dataType === 6 ? (o = s.inputs[0].getInt32Array()[0], d = s.inputs[1].getInt32Array()[0], g = s.inputs[2].getInt32Array()[0]) : s.inputs[0].dataType === 1 && (o = s.inputs[0].getFloat32Array()[0], d = s.inputs[1].getFloat32Array()[0], g = s.inputs[2].getFloat32Array()[0]), R.webgpu.validateInputContent && lp(o, d, g), s.compute(cp(o, d, g, s.inputs[0].dataType), { inputs: [] });
      };
    }), up, Ho, sc, dp, rc, $g, Wy = l(() => {
      jt(), ie(), pn(), sn(), up = (s, o, d, g) => {
        if (s !== "none" && g !== "i32" && g !== "u32" && g !== "f32")
          throw new Error(`Input ${g} is not supported with reduction ${s}.`);
        let y = `{
                var oldValue = 0;
                loop {
                  let newValueF32 =`, x = `;
                  let newValue = bitcast<i32>(newValueF32);
                  let res = atomicCompareExchangeWeak(&${o}, oldValue, newValue);
                  if res.exchanged {
                    break;
                  }
                  oldValue = res.old_value;
                }
              }`;
        switch (s) {
          case "none":
            return `${o}=${d};`;
          case "add":
            return g === "i32" || g === "u32" ? `atomicAdd(&${o}, bitcast<${g}>(${d}));` : `
              ${y}bitcast<${g}>(oldValue) + (${d})${x}`;
          case "max":
            return g === "i32" || g === "u32" ? `atomicMax(&${o}, bitcast<${g}>(${d}));` : `
                ${y}max(bitcast<f32>(oldValue), (${d}))${x}`;
          case "min":
            return g === "i32" || g === "u32" ? `atomicMin(&${o}, bitcast<${g}>(${d}));` : `${y}min(bitcast<${g}>(oldValue), (${d}))${x}`;
          case "mul":
            return `${y}(bitcast<${g}>(oldValue) * (${d}))${x}`;
          default:
            throw new Error(`Reduction ${s} is not supported.`);
        }
      }, Ho = (s, o) => `${s === 1 ? `
    let element_count_dim = uniforms.output_strides;
    let dim_value = uniforms.output_shape;` : `
    let element_count_dim = uniforms.output_strides[${o ? "i - indices_start" : "i"}];
    let dim_value = uniforms.output_shape[${o ? "i - indices_start" : "i"} + uniforms.last_index_dimension];`}
    
    if (index >= 0) {
      if (index >= i32(dim_value)) {
        index = i32(dim_value - 1);
      }
    } else {
      if (index < -i32(dim_value)) {
        index = 0;
      } else {
        index += i32(dim_value);
      }
    }
    data_offset += u32((u32(index) * element_count_dim));`, sc = (s, o, d) => `for (var i = 0u; i < uniforms.num_updates_elements; i++) {
        let value = updates[uniforms.num_updates_elements * ${d ? "global_idx" : "idx"} + i];
        ${up(s.reduction, "output[data_offset + i]", "value", o)}
      }`, dp = (s, o) => {
        let d = s[0].dims, g = s[1].dims, y = d, x = 1, b = Math.ceil(it.size(g) / x), P = g[g.length - 1], k = it.sizeFromDimension(d, P), O = it.sizeFromDimension(g, 0) / P, $ = [{ type: 12, data: b }, { type: 12, data: P }, { type: 12, data: k }, ...Ut(s[1].dims, s[2].dims, y)], V = (G) => {
          let ee = dt("indices", s[1].dataType, s[1].dims.length), X = dt("updates", s[2].dataType, s[2].dims.length, x), re = o.reduction !== "none" && o.reduction !== "" ? gr("output", s[0].dataType, y.length) : $t("output", s[0].dataType, y.length, x);
          return `
      ${G.registerUniform("output_size", "u32").registerUniform("last_index_dimension", "u32").registerUniform("num_updates_elements", "u32").declareVariables(ee, X, re)}
      ${G.mainStart()}
        ${G.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
  var hasDuplicates = false;
  if (${o.reduction === "none"}) {
    for (var i = 0; i < ${O}; i = i + 1) {
      for (var j = i + 1; j < ${O}; j = j + 1) {
        var index_i = i32(indices[i].x);
        var index_j = i32(indices[j].x);
        if (index_i == index_j) {
          hasDuplicates = true;
          break;
        }
      }
      if (hasDuplicates) {
        break;
      }
    }
  }

  if (${o.reduction === "none"} && hasDuplicates) {
    if (global_idx != 0u) {
      return;
    }
    // Process each index-update pair individually when duplicates exist
    for (var idx = 0u; idx < ${O}u; idx++) {
      var data_offset = 0u;
      for (var i = 0u; i < uniforms.last_index_dimension; i++) {
        var index = i32(indices[idx * uniforms.last_index_dimension + i].x);
        ${Ho(d.length, !1)}
      }
      ${sc(o, re.type.value, !1)}
    }
    return;
  }

  var data_offset = 0u;
  var indices_start = uniforms.last_index_dimension * global_idx;
  var indices_end = indices_start + uniforms.last_index_dimension;
  for (var i = indices_start; i < indices_end; i++) {
    var index = i32(indices[i].x);
    ${Ho(d.length, !0)}
  }
  ${sc(o, re.type.value, !0)}
  }`;
        };
        return { name: "ScatterND", shaderCache: { hint: `${o.cacheKey}_${o.reduction}`, inputDependencies: ["rank", "rank"] }, getRunData: () => ({ outputs: [{ dims: y, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(b / 64) }, programUniforms: $ }), getShaderSource: V };
      }, rc = (s) => Yt({ reduction: s.reduction }), $g = (s, o) => {
        s.compute(dp(s.inputs, o), { inputs: [s.inputs[1], s.inputs[2]], outputs: [] });
      };
    }), oc, qo, hp, ac, fp, Ko, pp, mp, gp, Xo, _p, yp, lc, Yo, vp, wp, xp, bp, Mp, Tp, Ng = l(() => {
      jt(), ie(), pn(), sn(), oc = (s, o) => {
        if (s.every((d) => d > 0 || (() => {
          throw new Error("Resize requires scales input values to be positive");
        })), s.length > 0) {
          if (o.mode === "linear") {
            if (!(s.length === 2 || s.length === 3 || s.length === 4 && s[0] === 1 && s[1] === 1 || s.length === 4 && s[0] === 1 && s[3] === 1 || s.length === 5 && s[0] === 1 && s[1] === 1))
              throw new Error(`For linear mode, Resize requires scales to be 2D, 3D, 4D with either two outermost or one innermost and
            one outermost scale values equal to 1, or 5D with two outermost scale values equal to 1`);
          } else if (o.mode === "cubic" && !(s.length === 2 || s.length === 4 && s[0] === 1 && s[1] === 1 || s.length === 4 && s[0] === 1 && s[3] === 1))
            throw new Error("Resize requires scales input size to be 2 or 4 for cubic mode");
        }
      }, qo = (s, o, d) => {
        o.every((y) => y >= 0 && y < d || (() => {
          throw new Error("Resize requires axes input values to be positive and less than rank");
        }));
        let g = new Array(d).fill(1);
        return o.forEach((y, x) => g[y] = s[x]), g;
      }, hp = (s, o, d, g, y, x) => {
        let [b, P, k] = d > 10 ? [1, 2, 3] : [-1, s.length > 1 ? 1 : -1, -1], O = s[0].dims.length;
        if (b > 0 && s.length > b && s[b].dims.length > 0)
          s[b].getFloat32Array().forEach(($) => x.push($));
        else if (o.coordinateTransformMode === "tf_crop_and_resize")
          throw new Error("Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize");
        if (P > 0 && s.length > P && s[P].dims.length === 1 && s[P].dims[0] > 0) {
          if (s[P].getFloat32Array().forEach(($) => g.push($)), g.length !== 0 && g.length !== O && d >= 18 && g.length !== o.axes.length)
            throw new Error("Resize requires scales input size to be same as input rank or axes size for opset 18 and up");
          oc(g, o), o.axes.length > 0 && qo(g, o.axes, O).forEach(($, V) => g[V] = $);
        }
        if (k > 0 && s.length > k && s[k].dims.length === 1 && s[k].dims[0] > 0 && (s[k].getBigInt64Array().forEach(($) => y.push(Number($))), y.length !== 0 && y.length !== O && d >= 18 && y.length !== o.axes.length))
          throw new Error("Resize requires sizes input size to be same as input rank or axes size for opset 18 and up");
        if (o.axes.length > 0) {
          if (g.length !== 0 && g.length !== o.axes.length)
            throw new Error('Resize requires "scales" input size to be of axes rank when axes attributes is specified');
          if (y.length !== 0 && y.length !== o.axes.length)
            throw new Error('Resize requires "sizes" input size to be of rank axes rank when axes attributes is specified');
        }
        if (typeof g < "u" && typeof y < "u" && g.length > 0 && y.length > O)
          throw new Error("Resize requires only of scales or sizes to be specified");
      }, ac = (s, o, d, g) => `
  // The whole part and the fractional part are calculated separately due to inaccuracy of floating
  // point division. As an example, f32(21) / f32(7) may evaluate to 2.99... instead of 3, causing an
  // offset-by-one error later in floor().
  let big = (${s}) * (${o});
  let whole = ${g}(big / (${d}));
  let fract = ${g}(big % (${d})) / ${g}(${d});
  return whole + fract;
`, fp = (s, o) => `fn getOriginalCoordinateFromResizedCoordinate(xResized: u32, xScale: f32, lengthResized: u32,
     lengthOriginal: u32, roiStart: f32, roiEnd: f32) -> ${o} { ` + (() => {
        switch (s) {
          case "asymmetric":
            return `
          if (xScale < 1.0 || floor(xScale) != xScale) {
            return ${o}(xResized) / ${o}(xScale);
          } else {
            ${ac("xResized", "lengthOriginal", "lengthResized", o)}
          }
        `;
          case "pytorch_half_pixel":
            return `if (lengthResized > 1) {
                    return (${o}(xResized) + 0.5) / ${o}(xScale) - 0.5;
                  } else {
                    return 0.0;
                  }`;
          case "tf_half_pixel_for_nn":
            return `return (${o}(xResized) + 0.5) / ${o}(xScale);`;
          case "align_corners":
            return `if (lengthResized == 1) {
                    return 0.0;
                  } else {
                    ${ac("xResized", "lengthOriginal - 1", "lengthResized - 1", o)}
                  }`;
          case "tf_crop_and_resize":
            return `if (lengthResized > 1) {
                    return ${o}(roiStart) * ${o}(lengthOriginal - 1) +
                        (${o}(xResized) * ${o}(roiEnd - roiStart) * ${o}(lengthOriginal - 1)) /
                        ${o}(lengthResized - 1);
                  } else {
                    return 0.5 * ${o}(roiStart + roiEnd) * ${o}(lengthOriginal - 1);
                  }`;
          case "half_pixel_symmetric":
            return `const outputWidth = ${o}xScale * ${o}(lengthResized);
                  const adjustment = ${o}(lengthResized) / outputWidth;
                  const center = ${o}(lengthOriginal) / 2;
                  const offset = center * (1 - adjustment);
                  return offset + ((${o}(xResized) + 0.5) / ${o}(xScale)) - 0.5;`;
          case "half_pixel":
            return `return ((${o}(xResized) + 0.5) / ${o}(xScale)) - 0.5;`;
          default:
            throw new Error(`Coordinate transform mode ${s} is not supported`);
        }
      })() + "}", Ko = (s, o, d) => `fn getNearestPixelFromOriginal(xOriginal: ${d}, isDownSample: bool) -> ${d} {` + (() => {
        switch (s) {
          case "round_prefer_ceil":
            return "if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }";
          case "floor":
            return "return floor(xOriginal);";
          case "ceil":
            return "return ceil(xOriginal);";
          case "round_prefer_floor":
            return "if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }";
          case "simple":
          default:
            if (o < 11)
              return "if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }";
            throw new Error(`Nearest mode ${s} is not supported`);
        }
      })() + "}", pp = (s, o, d) => {
        let g = new Array(d).fill(0).concat(new Array(d).fill(1)), y = s.length === 0 ? g : s.slice();
        return o.length > 0 ? (o.forEach((x, b) => {
          g[x] = y[b], g[b + d] = y[o.length + b];
        }), g) : y;
      }, mp = (s, o, d, g) => {
        let y = [];
        if (d.length > 0)
          if (g.length > 0) {
            if (s.forEach((x) => y.push(x)), Math.max(...g) > s.length)
              throw new Error("axes is out of bound");
            g.forEach((x, b) => y[x] = d[b]);
          } else
            d.forEach((x) => y.push(x));
        else {
          if (o.length === 0)
            throw new Error("Resize requires either scales or sizes.");
          y = s.map((x, b) => Math.round(x * o[b]));
        }
        return y;
      }, gp = (s, o, d) => {
        let g = (() => {
          switch (d.keepAspectRatioPolicy) {
            case "not_larger":
              return d.axes.length > 0 ? Math.min(...d.axes.map((x) => o[x]), Number.MAX_VALUE) : Math.min(...o, Number.MAX_VALUE);
            case "not_smaller":
              return d.axes.length > 0 ? Math.max(...d.axes.map((x) => o[x]), Number.MIN_VALUE) : Math.max(...o, Number.MIN_VALUE);
            default:
              throw new Error(`Keep aspect ratio policy ${d.keepAspectRatioPolicy} is not supported`);
          }
        })();
        o.fill(1, 0, o.length);
        let y = s.slice();
        return d.axes.length > 0 ? (d.axes.forEach((x) => o[x] = g), d.axes.forEach((x) => y[x] = Math.round(s[x] * o[x]))) : (o.fill(g, 0, o.length), y.forEach((x, b) => y[b] = Math.round(x * o[b]))), y;
      }, Xo = (s, o, d, g, y) => `
    fn calculateOriginalIndicesFromOutputIndices(output_indices: ${s.type.indices}) -> array<${s.type.value}, ${d.length}> {
      var original_indices: array<${s.type.value}, ${d.length}>;
      for (var i:u32 = 0; i < ${d.length}; i++) {
        var output_index = ${s.indicesGet("output_indices", "i")};
        var scale = ${Nt("uniforms.scales", "i", g)};
        var roi_low = ${Nt("uniforms.roi", "i", y)};
        var roi_hi = ${Nt("uniforms.roi", `i + ${o.length}`, y)};
        if (scale == 1.0) {
          original_indices[i] = ${s.type.value}(output_index);
        } else {
          var input_shape_i = ${Nt("uniforms.input_shape", "i", o.length)};
          var output_shape_i = ${Nt("uniforms.output_shape", "i", d.length)};
          original_indices[i] = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,
                                                                           input_shape_i, roi_low, roi_hi);
        }
      }
      return original_indices;
    }`, _p = (s, o, d, g, y, x, b) => `
    fn calculateInputIndicesFromOutputIndices(output_indices: ${o.type.indices}) -> ${s.type.indices} {
      var input_indices: ${s.type.indices};
      for (var i:u32 = 0; i < ${g.length}; i++) {
        var output_index = ${o.indicesGet("output_indices", "i")};
        var input_index: u32;
        var scale = ${Nt("uniforms.scales", "i", y)};
        if (scale == 1.0) {
          input_index = output_index;
        } else {
          var roi_low = ${Nt("uniforms.roi", "i", x)};
          var roi_hi = ${Nt("uniforms.roi", `i + ${d.length}`, x)};
          var input_shape_i = ${Nt("uniforms.input_shape", "i", d.length)};
          var output_shape_i = ${Nt("uniforms.output_shape", "i", g.length)};
          var original_idx = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,
                                                                        input_shape_i, roi_low, roi_hi);
          if (!${b} || (original_idx >= 0 && original_idx < ${o.type.value}(input_shape_i))) {
            if (original_idx < 0) {
              input_index = 0;
            } else if (original_idx > ${o.type.value}(input_shape_i - 1)) {
              input_index = input_shape_i - 1;
            } else {
              input_index = u32(getNearestPixelFromOriginal(original_idx, scale < 1));
            }
          } else {
            input_index = u32(original_idx);
          }
        }
        ${s.indicesSet("input_indices", "i", "input_index")}
      }
      return input_indices;
    }`, yp = (s, o) => `
    fn checkInputIndices(input_indices: ${s.type.indices}) -> bool {
      for (var i:u32 = 0; i < ${o.length}; i++) {
        var input_index = ${s.indicesGet("input_indices", "i")};
        if (input_index < 0 || input_index >= ${Nt("uniforms.input_shape", "i", o.length)}) {
          return false;
        }
      }
      return true;
    }`, lc = (s, o, d, g) => s.rank > g ? `
    ${s.indicesSet("input_indices", o, "channel")};
    ${s.indicesSet("input_indices", d, "batch")};
` : "", Yo = (s, o, d, g, y) => {
        let [x, b, P, k] = d.length === 2 ? [-1, 0, 1, -1] : [0, 2, 3, 1], O = s.type.value;
        return `
    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${O} {
      var input_indices: ${s.type.indices};
      ${s.indicesSet("input_indices", b, `max(0, min(row, ${d[b]} - 1))`)};
      ${s.indicesSet("input_indices", P, `max(0, min(col, ${d[P]} - 1))`)};
      ${lc(s, k, x, 2)}
      return ${s.getByIndices("input_indices")};
    }

    fn bilinearInterpolation(output_indices: ${o.type.indices}) -> ${O} {
      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);
      var row:${O} = originalIndices[${b}];
      var col:${O} = originalIndices[${P}];
      ${g ? `if (row < 0 || row > (${d[b]} - 1) || col < 0 || col > (${d[P]} - 1)) {
        return ${y};
      }` : ""};
      row = max(0, min(row, ${d[b]} - 1));
      col = max(0, min(col, ${d[P]} - 1));
      var row1: u32 = u32(row);
      var col1: u32 = u32(col);
      var row2: u32 = u32(row + 1);
      var col2: u32 = u32(col + 1);
      var channel: u32 = ${d.length > 2 ? `u32(originalIndices[${k}])` : "0"};
      var batch: u32 =  ${d.length > 2 ? `u32(originalIndices[${x}])` : "0"};
      var x11: ${O} = getInputValue(batch, channel, row1, col1);
      var x12: ${O} = getInputValue(batch, channel, row1, col2);
      var x21: ${O} = getInputValue(batch, channel, row2, col1);
      var x22: ${O} = getInputValue(batch, channel, row2, col2);
      var dx1: ${O} = abs(row - ${O}(row1));
      var dx2: ${O} = abs(${O}(row2) - row);
      var dy1: ${O} = abs(col - ${O}(col1));
      var dy2: ${O} = abs(${O}(col2) - col);
      if (row1 == row2) {
        dx1 = 0.5;
        dx2 = 0.5;
      }
      if (col1 == col2) {
        dy1 = 0.5;
        dy2 = 0.5;
      }
      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);
    }`;
      }, vp = (s, o, d, g, y, x, b, P, k, O) => {
        let $ = d.length === 2, [V, G] = $ ? [0, 1] : [2, 3], ee = s.type.value, X = (re) => {
          let Te = re === V ? "row" : "col";
          return `
      fn ${Te}CubicInterpolation(input_indices: ${s.type.indices}, output_indices: ${o.type.indices}) -> ${ee} {
        var output_index = ${o.indicesGet("output_indices", re)};
        var originalIdx: ${ee} = getOriginalCoordinateFromResizedCoordinate(output_index, ${y[re]},
        ${g[re]}, ${d[re]}, ${x[re]}, ${x[re]} + ${d.length});
        var fractOriginalIdx: ${ee} = originalIdx - floor(originalIdx);
        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);

        if (${P} && (originalIdx < 0 || originalIdx > (${d[re]} - 1))) {
          return ${k};
        }
        var data: array<${ee}, 4> = array<${ee}, 4>(0.0, 0.0, 0.0, 0.0);
        for (var i: i32 = -1; i < 3; i++) {
          var ${Te}: ${ee} = originalIdx + ${ee}(i);
          if (${Te} < 0 || ${Te} >= ${d[re]}) {
            ${O ? `coefs[i + 1] = 0.0;
                        continue;` : P ? `return ${k};` : `${Te} = max(0, min(${Te}, ${d[re]} - 1));`};
          }
        var input_indices_copy: ${s.type.indices} = input_indices;
          ${s.indicesSet("input_indices_copy", re, `u32(${Te})`)};
          data[i + 1] = ${re === V ? s.getByIndices("input_indices_copy") : "rowCubicInterpolation(input_indices_copy, output_indices)"};
        }
        return cubicInterpolation1D(data, coefs);
      }`;
        };
        return `
    ${X(V)};
    ${X(G)};
  fn getCubicInterpolationCoefs(s: ${ee}) -> array<${ee}, 4> {
    var absS = abs(s);
    var coeffs: array<${ee}, 4> = array<${ee}, 4>(0.0, 0.0, 0.0, 0.0);
    var oneMinusAbsS: ${ee} = 1.0 - absS;
    var twoMinusAbsS: ${ee} = 2.0 - absS;
    var onePlusAbsS: ${ee} = 1.0 + absS;
    coeffs[0] = ((${b} * onePlusAbsS - 5 * ${b}) * onePlusAbsS + 8 * ${b}) * onePlusAbsS - 4 * ${b};
    coeffs[1] = ((${b} + 2) * absS - (${b} + 3)) * absS * absS + 1;
    coeffs[2] = ((${b} + 2) * oneMinusAbsS - (${b} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;
    coeffs[3] = ((${b} * twoMinusAbsS - 5 * ${b}) * twoMinusAbsS + 8 * ${b}) * twoMinusAbsS - 4 * ${b};
    return coeffs;
  }

  fn cubicInterpolation1D(x: array<${ee}, 4>, coefs: array<${ee}, 4>) -> ${ee} {
    var coefsSum: ${ee} = coefs[0] + coefs[1] + coefs[2] + coefs[3];
    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;
  }

  fn bicubicInterpolation(output_indices: ${o.type.indices}) -> ${ee} {
    var input_indices: ${s.type.indices} = output_indices;
    return colCubicInterpolation(input_indices, output_indices);
  }
    `;
      }, wp = (s, o, d, g, y) => {
        let [x, b, P, k, O] = d.length === 3 ? [-1, 0, 1, 2, -1] : [0, 2, 3, 4, 1], $ = s.type.value;
        return `
    fn getInputValue(batch: u32, channel: u32, depth:u32, height: u32, width: u32) -> ${$} {
      var input_indices: ${s.type.indices};
      ${s.indicesSet("input_indices", b, `max(0, min(depth, ${d[b]} - 1))`)};
      ${s.indicesSet("input_indices", P, `max(0, min(height, ${d[P]} - 1))`)};
      ${s.indicesSet("input_indices", k, `max(0, min(width, ${d[k]} - 1))`)};
      ${lc(s, O, x, 3)}
      return ${s.getByIndices("input_indices")};
    }

    fn trilinearInterpolation(output_indices: ${o.type.indices}) -> ${$} {
      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);
      var depth:${$} = originalIndices[${b}];
      var height:${$} = originalIndices[${P}];
      var width:${$} = originalIndices[${k}];
      ${g ? `if (depth < 0 || depth > (${d[b]} - 1) || height < 0 || height > (${d[P]} - 1) || width < 0 || (width > ${d[k]} - 1)) {
      return ${y};
        }` : ""};

    depth = max(0, min(depth, ${d[b]} - 1));
      height = max(0, min(height, ${d[P]} - 1));
      width = max(0, min(width, ${d[k]} - 1));
      var depth1: u32 = u32(depth);
      var height1: u32 = u32(height);
      var width1: u32 = u32(width);
      var depth2: u32 = u32(depth + 1);
      var height2: u32 = u32(height + 1);
      var width2: u32 = u32(width + 1);
      var channel: u32 = ${d.length > 3 ? `u32(originalIndices[${O}])` : "0"};
      var batch: u32 =  ${d.length > 3 ? `u32(originalIndices[${x}])` : "0"};

      var x111: ${$} = getInputValue(batch, channel, depth1, height1, width1);
      var x112: ${$} = getInputValue(batch, channel, depth1, height1, width2);
      var x121: ${$} = getInputValue(batch, channel, depth1, height2, width1);
      var x122: ${$} = getInputValue(batch, channel, depth1, height2, width2);
      var x211: ${$} = getInputValue(batch, channel, depth2, height1, width1);
      var x212: ${$} = getInputValue(batch, channel, depth2, height1, width2);
      var x221: ${$} = getInputValue(batch, channel, depth2, height2, width1);
      var x222: ${$} = getInputValue(batch, channel, depth2, height2, width2);
      var dx1: ${$} = abs(depth - ${$}(depth1));
      var dx2: ${$} = abs(${$}(depth2) - depth);
      var dy1: ${$} = abs(height - ${$}(height1));
      var dy2: ${$} = abs(${$}(height2) - height);
      var dz1: ${$} = abs(width - ${$}(width1));
      var dz2: ${$} = abs(${$}(width2) - width);
      if (depth1 == depth2) {
        dx1 = 0.5;
        dx2 = 0.5;
      }
      if (height1 == height2) {
        dy1 = 0.5;
        dy2 = 0.5;
      }
      if (width1 == width2) {
        dz1 = 0.5;
        dz2 = 0.5;
      }
      return (x111 * dx2 * dy2 * dz2 + x112 * dx2 * dy2 * dz1 + x121 * dx2 * dy1 *dz2 + x122 * dx2 * dy1 * dz1 +
              x211 * dx1 * dy2 * dz2 + x212 * dx1 * dy2 * dz1 + x221 * dx1 * dy1 *dz2 + x222 * dx1 * dy1 * dz1);
    }`;
      }, xp = (s, o, d, g, y, x) => {
        let b = s.dims, P = pp(x, o.axes, b.length), k = mp(b, g, y, o.axes), O = g.slice();
        g.length === 0 && (O = b.map((ce, ke) => ce === 0 ? 1 : k[ke] / ce), o.keepAspectRatioPolicy !== "stretch" && (k = gp(b, O, o)));
        let $ = $t("output", s.dataType, k.length), V = dt("input", s.dataType, b.length), G = it.size(k), ee = b.length === k.length && b.every((ce, ke) => ce === k[ke]), X = o.coordinateTransformMode === "tf_crop_and_resize", re = o.extrapolationValue, Te = V.type.value, ue = (ce) => `
      ${ee ? "" : `
      ${fp(o.coordinateTransformMode, Te)};
      ${(() => {
          switch (o.mode) {
            case "nearest":
              return `
              ${yp(V, b)};
              ${Ko(o.nearestMode, d, Te)};
              ${_p(V, $, b, k, O.length, P.length, X)};
              `;
            case "linear":
              return `
              ${Xo($, b, k, O.length, P.length)};
              ${(() => {
                if (b.length === 2 || b.length === 4)
                  return `${Yo(V, $, b, X, re)}`;
                if (b.length === 3 || b.length === 5)
                  return `${wp(V, $, b, X, re)}`;
                throw Error("Linear mode only supports input dims 2, 3, 4 and 5 are supported in linear mode.");
              })()};
            `;
            case "cubic":
              return `
            ${(() => {
                if (b.length === 2 || b.length === 4)
                  return `${vp(V, $, b, k, O, P, o.cubicCoeffA, X, o.extrapolationValue, o.excludeOutside)}`;
                throw Error("Cubic mode only supports input dims 2 and 4 are supported in linear mode.");
              })()};
            `;
            default:
              throw Error("Invalid resize mode");
          }
        })()};
      `}
      ${ce.registerUniform("output_size", "u32").registerUniform("scales", "f32", O.length).registerUniform("roi", "f32", P.length).declareVariables(V, $)}
      ${ce.mainStart()}
        ${ce.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
        ${ee ? "output[global_idx] = input[global_idx];" : `
        let output_indices = ${$.offsetToIndices("global_idx")};
        var input_indices: ${V.type.indices};
        ${(() => {
          switch (o.mode) {
            case "nearest":
              return `input_indices = calculateInputIndicesFromOutputIndices(output_indices);
                if (checkInputIndices(input_indices)) {
                  output[global_idx] = ${V.getByIndices("input_indices")};
                } else {
                  output[global_idx] = ${o.extrapolationValue};
                }`;
            case "linear":
              return `output[global_idx] = ${b.length === 2 || b.length === 4 ? "bilinearInterpolation" : "trilinearInterpolation"}(output_indices);`;
            case "cubic":
              return "output[global_idx] = bicubicInterpolation(output_indices);";
            default:
              throw Error(`Unsupported resize mode: ${o.mode}`);
          }
        })()};
`}
      }`;
        return { name: "Resize", shaderCache: { hint: `${o.cacheKey}|${d}|${O.length > 0 ? o.mode === "cubic" ? O : O.length : ""}|${y.length > 0 ? y : ""}|${P.length > 0 ? P : ""}|${ee}|${o.mode === "nearest" ? b.length : b}`, inputDependencies: ["rank"] }, getShaderSource: ue, getRunData: () => ({ outputs: [{ dims: k, dataType: s.dataType }], dispatchGroup: { x: Math.ceil(G / 64) }, programUniforms: [{ type: 12, data: G }, { type: 1, data: O }, { type: 1, data: P }, ...Ut(b, k)] }) };
      }, bp = (s) => {
        let o = s.customDataBuffer;
        return new Uint32Array(o, o.byteOffset, 1)[0];
      }, Mp = (s, o) => {
        let d = [], g = [], y = [], x = bp(s);
        if (o.antialias !== 0)
          throw Error("Only default value (0) for Antialias attribute is supported");
        hp(s.inputs, o, x, d, g, y), s.compute(xp(s.inputs[0], o, x, d, g, y), { inputs: [0] });
      }, Tp = (s) => {
        let o = s.antialias, d = s.axes, g = s.coordinateTransformMode, y = s.cubicCoeffA, x = s.excludeOutside !== 0, b = s.extrapolationValue, P = s.keepAspectRatioPolicy, k = s.mode, O = s.nearestMode === "" ? "simple" : s.nearestMode;
        return Yt({ antialias: o, axes: d, coordinateTransformMode: g, cubicCoeffA: y, excludeOutside: x, extrapolationValue: b, keepAspectRatioPolicy: P, mode: k, nearestMode: O });
      };
    }), Ep, Sp, Pp, Ap = l(() => {
      jt(), ie(), sn(), Ep = (s) => {
        if (!s || s.length < 3)
          throw new Error("layerNorm requires at least 3 inputs.");
        let o = s[0], d = s[1], g = s[2];
        if (o.dataType !== d.dataType || o.dataType !== g.dataType)
          throw new Error("All inputs must have the same data type");
        if (o.dims.length !== 3 && o.dims.length !== 2)
          throw new Error("Input must be 2D or 3D");
        if (d.dims.length !== 3 && d.dims.length !== 2)
          throw new Error("Skip must be 2D or 3D");
        let y = o.dims[o.dims.length - 1], x = o.dims[o.dims.length - 2];
        if (d.dims[d.dims.length - 1] !== y)
          throw new Error("Skip must have the same hidden size as input");
        if (d.dims[d.dims.length - 2] !== x)
          throw new Error("Skip must have the same sequence length as input");
        if (g.dims.length !== 1)
          throw new Error("Gamma must be 1D");
        if (g.dims[g.dims.length - 1] !== y)
          throw new Error("Gamma must have the same hidden size as input");
        if (s.length > 3) {
          let b = s[3];
          if (b.dims.length !== 1)
            throw new Error("Beta must be 1D");
          if (b.dims[b.dims.length - 1] !== y)
            throw new Error("Beta must have the same hidden size as input");
        }
        if (s.length > 4) {
          let b = s[4];
          if (b.dims.length !== 1)
            throw new Error("Bias must be 1D");
          if (b.dims[b.dims.length - 1] !== y)
            throw new Error("Bias must have the same hidden size as input");
        }
      }, Sp = (s, o, d, g) => {
        let y = o.simplified, x = s[0].dims, b = it.size(x), P = x, k = b, O = x.slice(-1)[0], $ = g ? x.slice(0, -1).concat(1) : [], V = !y && s.length > 3, G = s.length > 4, ee = g && d > 1, X = g && d > 2, re = d > 3, Te = 64, ue = Dn(O), ce = [{ type: 12, data: k }, { type: 12, data: ue }, { type: 12, data: O }, { type: 1, data: o.epsilon }], ke = (M) => {
          let C = [{ name: "output_size", type: "u32" }, { name: "components", type: "u32" }, { name: "hidden_size", type: "u32" }, { name: "epsilon", type: "f32" }], z = [dt("x", s[0].dataType, s[0].dims, ue), dt("skip", s[1].dataType, s[1].dims, ue), dt("gamma", s[2].dataType, s[2].dims, ue)];
          V && z.push(dt("beta", s[3].dataType, s[3].dims, ue)), G && z.push(dt("bias", s[4].dataType, s[4].dims, ue)), z.push($t("output", s[0].dataType, P, ue)), ee && z.push($t("mean_output", 1, $)), X && z.push($t("inv_std_output", 1, $)), re && z.push($t("input_skip_bias_sum", s[0].dataType, P, ue));
          let oe = Jn(s[0].dataType), ye = Jn(1, ue);
          return `

      ${M.registerUniforms(C).declareVariables(...z)}
      var<workgroup> sum_shared : array<${ye}, ${Te}>;
      var<workgroup> sum_squared_shared : array<${ye}, ${Te}>;

      ${M.mainStart([Te, 1, 1])}
        let ix = local_id.x;
        let iy = global_id.x / ${Te};

        let hidden_size_vectorized: u32 = uniforms.hidden_size / uniforms.components;
        var stride = hidden_size_vectorized / ${Te};
        let offset = ix * stride + iy * hidden_size_vectorized;
        let offset1d = stride * ix;
        if (ix == ${Te - 1}) {
          stride = hidden_size_vectorized - stride * ix;
        }
        for (var i: u32 = 0; i < stride; i++) {
          let skip_value = skip[offset + i];
          let bias_value = ${G ? "bias[offset1d + i]" : oe + "(0.0)"};
          let input_value = x[offset + i];
          let value = input_value + skip_value + bias_value;
          ${re ? "input_skip_bias_sum[offset + i] = value;" : ""}
          output[offset + i] = value;
          let f32_value = ${is(oe, ue, "value")};
          sum_shared[ix] += f32_value;
          sum_squared_shared[ix] += f32_value * f32_value;
        }
        workgroupBarrier();

        var reduce_size : u32 = ${Te};
        for (var curr_size = reduce_size >> 1;  curr_size > 0; curr_size = reduce_size >> 1) {
          reduce_size = curr_size + (reduce_size & 1);
          if (ix < curr_size) {
            sum_shared[ix] += sum_shared[ix + reduce_size];
            sum_squared_shared[ix] += sum_squared_shared[ix + reduce_size];
          }
          workgroupBarrier();
        }

        let sum = sum_shared[0];
        let square_sum = sum_squared_shared[0];
        let mean = ${Ls("sum", ue)} / f32(uniforms.hidden_size);
        let inv_std_dev = inverseSqrt(${Ls("square_sum", ue)} / f32(uniforms.hidden_size) ${y ? "" : "- mean * mean"} + uniforms.epsilon);
        ${ee ? "mean_output[global_idx] = mean;" : ""}
        ${X ? "inv_std_output[global_idx] = inv_std_dev;" : ""}

        for (var i: u32 = 0; i < stride; i++) {
          output[offset + i] = (output[offset + i] ${y ? "" : `- ${oe}(mean)`}) *
            ${oe}(inv_std_dev) * gamma[offset1d + i]
            ${V ? "+ beta[offset1d + i]" : ""};
        }
      }`;
        }, Le = [{ dims: P, dataType: s[0].dataType }];
        return d > 1 && Le.push({ dims: $, dataType: 1 }), d > 2 && Le.push({ dims: $, dataType: 1 }), d > 3 && Le.push({ dims: x, dataType: s[0].dataType }), { name: "SkipLayerNormalization", shaderCache: { hint: `${ue};${ee};${X};${re}`, inputDependencies: s.map((M, C) => "type") }, getShaderSource: ke, getRunData: () => ({ outputs: Le, dispatchGroup: { x: Math.ceil(k / O) }, programUniforms: ce }) };
      }, Pp = (s, o) => {
        Ep(s.inputs);
        let d = [0];
        s.outputCount > 1 && d.push(-3), s.outputCount > 2 && d.push(-3), s.outputCount > 3 && d.push(3), s.compute(Sp(s.inputs, o, s.outputCount, !1), { outputs: d });
      };
    }), Cp, Wr, cc, uc, Ip, Lp, dc, Dp, hc = l(() => {
      jt(), ie(), pn(), sn(), Cp = (s, o) => {
        if (!s || s.length < 1)
          throw new Error("too few inputs");
        if (o.axes.length !== 0) {
          if (o.axes.length !== o.starts.length || o.axes.length !== o.ends.length)
            throw new Error("axes, starts and ends must have the same length");
        } else if (o.starts.length !== o.ends.length)
          throw new Error("starts and ends must have the same length");
        s.slice(1).forEach((d, g) => {
          if (s[g + 1].dataType !== 6 && s[g + 1].dataType !== 7)
            throw new Error(`Input ${g} must be an array of int32 or int64`);
        });
      }, Wr = (s, o) => {
        let d = [];
        if (s.length > o)
          if (s[o].dataType === 7)
            s[o].getBigInt64Array().forEach((g) => d.push(Number(g)));
          else if (s[o].dataType === 6)
            s[o].getInt32Array().forEach((g) => d.push(Number(g)));
          else
            throw new Error(`Input ${o} must be an array of int32 or int64`);
        return d;
      }, cc = (s, o) => {
        if (s.length > 1) {
          let d = Wr(s, 1), g = Wr(s, 2), y = Wr(s, 3);
          return y.length === 0 && (y = [...Array(s[0].dims.length).keys()]), Yt({ starts: d, ends: g, axes: y });
        } else
          return o;
      }, uc = (s, o, d, g, y) => {
        let x = s;
        return s < 0 && (x += d[g[o]]), y[o] < 0 ? Math.max(0, Math.min(x, d[g[o]] - 1)) : Math.max(0, Math.min(x, d[g[o]]));
      }, Ip = (s, o, d) => `fn calculateInputIndices(output_indices: ${o.type.indices}) -> ${s.type.indices} {
          var input_indices: ${s.type.indices};
          var carry = 0u;
          for (var i = ${d.length}; i >= 0; i--) {
            let input_shape_i = ${Nt("uniforms.input_shape", "i", d.length)};
            let steps_i = ${Nt("uniforms.steps", "i", d.length)};
            let signs_i = ${Nt("uniforms.signs", "i", d.length)};
            let starts_i = ${Nt("uniforms.starts", "i", d.length)};
            var output_index = ${o.indicesGet("output_indices", "i")};
            var input_index = output_index * steps_i + starts_i + carry;
            carry = input_index / input_shape_i;
            input_index = input_index % input_shape_i;
            if (signs_i < 0) {
              input_index = input_shape_i - input_index - 1u + starts_i;
            }
            ${s.indicesSet("input_indices", "i", "input_index")};
          }
          return input_indices;
      }`, Lp = (s, o) => {
        let d = s[0].dims, g = it.size(d), y = o.axes.length > 0 ? it.normalizeAxes(o.axes, d.length) : [...Array(d.length).keys()], x = Wr(s, 4);
        x.forEach((ue) => ue !== 0 || (() => {
          throw new Error("step cannot be 0");
        })), x.length === 0 && (x = Array(y.length).fill(1));
        let b = o.starts.map((ue, ce) => uc(ue, ce, d, y, x)), P = o.ends.map((ue, ce) => uc(ue, ce, d, y, x));
        if (y.length !== b.length || y.length !== P.length)
          throw new Error("start, ends and axes should have the same number of elements");
        if (y.length !== d.length)
          for (let ue = 0; ue < d.length; ++ue)
            y.includes(ue) || (b.splice(ue, 0, 0), P.splice(ue, 0, d[ue]), x.splice(ue, 0, 1));
        let k = x.map((ue) => Math.sign(ue));
        x.forEach((ue, ce, ke) => {
          if (ue < 0) {
            let Le = (P[ce] - b[ce]) / ue, M = b[ce], C = M + Le * x[ce];
            b[ce] = C, P[ce] = M, ke[ce] = -ue;
          }
        });
        let O = d.slice(0);
        y.forEach((ue, ce) => {
          O[ue] = Math.ceil((P[ue] - b[ue]) / x[ue]);
        });
        let $ = { dims: O, dataType: s[0].dataType }, V = $t("output", s[0].dataType, O.length), G = dt("input", s[0].dataType, s[0].dims.length), ee = it.size(O), X = [{ name: "outputSize", type: "u32" }, { name: "starts", type: "u32", length: b.length }, { name: "signs", type: "i32", length: k.length }, { name: "steps", type: "u32", length: x.length }], re = [{ type: 12, data: ee }, { type: 12, data: b }, { type: 6, data: k }, { type: 12, data: x }, ...Ut(s[0].dims, O)], Te = (ue) => `
      ${ue.registerUniforms(X).declareVariables(G, V)}
        ${Ip(G, V, d)}
        ${ue.mainStart()}
          ${ue.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}
          let output_indices = ${V.offsetToIndices("global_idx")};
          let input_indices = calculateInputIndices(output_indices);
          ${V.setByOffset("global_idx", G.getByIndices("input_indices"))}
      }`;
        return { name: "Slice", shaderCache: { hint: `${k.length}_${b.length}_${x.length}`, inputDependencies: ["rank"] }, getShaderSource: Te, getRunData: () => ({ outputs: [$], dispatchGroup: { x: Math.ceil(g / 64) }, programUniforms: re }) };
      }, dc = (s, o) => {
        Cp(s.inputs, o);
        let d = cc(s.inputs, o);
        s.compute(Lp(s.inputs, d), { inputs: [0] });
      }, Dp = (s) => {
        let o = s.starts, d = s.ends, g = s.axes;
        return Yt({ starts: o, ends: d, axes: g });
      };
    }), kp, Op, Fp, Rp, Ug = l(() => {
      jt(), ie(), pn(), Hs(), sn(), kp = (s) => {
        if (!s || s.length !== 1)
          throw new Error("Softmax op requires 1 input.");
      }, Op = (s, o) => {
        let d = s.inputs[0], g = d.dims, y = it.size(g), x = g.length, b = it.normalizeAxis(o.axis, x), P = b < g.length - 1, k, O = [];
        P ? (O = Array.from({ length: x }, (z, oe) => oe), O[b] = x - 1, O[x - 1] = b, k = s.compute(bi(d, O), { inputs: [d], outputs: [-1] })[0]) : k = d;
        let $ = k.dims, V = $[x - 1], G = y / V, ee = Dn(V), X = V / ee, re = 64;
        G === 1 && (re = 256);
        let Te = (z, oe) => oe === 4 ? `max(max(${z}.x, ${z}.y), max(${z}.z, ${z}.w))` : oe === 2 ? `max(${z}.x, ${z}.y)` : oe === 3 ? `max(max(${z}.x, ${z}.y), ${z}.z)` : z, ue = dt("x", k.dataType, k.dims, ee), ce = $t("result", k.dataType, k.dims, ee), ke = ue.type.value, Le = Jn(k.dataType) === "f32" ? `var threadMax = ${ke}(-3.402823e+38f);` : `var threadMax = ${ke}(-65504.0h);`, M = (z) => `
      var<workgroup> rowMaxShared : ${ke};
      var<workgroup> rowSumShared : ${ke};
      var<workgroup> threadShared : array<${ke}, ${re}>;

      fn getValue(row: i32, col: i32, row_stride: i32) -> ${ke} {
        let index = row * row_stride + col;
        return x[index];
      }

      fn setValue(row: i32, col: i32, row_stride: i32, value: ${ke}) {
        let index = row * row_stride + col;
        result[index] = value;
      }
      ${z.registerUniform("packedCols", "i32").declareVariables(ue, ce)}
      ${z.mainStart(re)}
        let gindex = i32(global_idx);
        let lindex = i32(local_idx);
        const wg = ${re};
        let row = gindex / wg;
        let cols = uniforms.packedCols;
        let row_stride : i32 = uniforms.packedCols;

        // find the rows max
        ${Le}
        for (var col = lindex; col < cols; col += wg) {
          let value = getValue(row, col, row_stride);
          threadMax = max(threadMax, value);
        }
        if (lindex < cols) {
          threadShared[lindex] = threadMax;
        }
        workgroupBarrier();

        var reduceSize = min(cols, wg);
        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {
          reduceSize = currSize + (reduceSize & 1);
          if (lindex < currSize) {
            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);
          }
          workgroupBarrier();
        }
        if (lindex == 0) {
          rowMaxShared = ${ke}(${Te("threadShared[0]", ee)});
        }
        workgroupBarrier();

        // find the rows sum
        var threadSum = ${ke}(0.0);
        for (var col = lindex; col < cols; col += wg) {
          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);
          threadSum += subExp;
        }
        threadShared[lindex] = threadSum;
        workgroupBarrier();

        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {
          if (lindex < currSize) {
            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];
          }
          workgroupBarrier();
        }
        if (lindex == 0) {
          rowSumShared = ${ke}(${Ls("threadShared[0]", ee)});
        }
        workgroupBarrier();

        // calculate final value for each element in the row
        for (var col = lindex; col < cols; col += wg) {
          let value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;
          setValue(row, col, row_stride, value);
        }
      }`, C = s.compute({ name: "Softmax", shaderCache: { hint: `${ee};${re}`, inputDependencies: ["type"] }, getRunData: () => ({ outputs: [{ dims: $, dataType: k.dataType }], dispatchGroup: { x: G }, programUniforms: [{ type: 6, data: X }] }), getShaderSource: M }, { inputs: [k], outputs: [P ? -1 : 0] })[0];
        P && s.compute(bi(C, O), { inputs: [C] });
      }, Fp = (s, o) => {
        kp(s.inputs), Op(s, o);
      }, Rp = (s) => Yt({ axis: s.axis });
    }), Hr, Bp, zp, $p, Np, Gg = l(() => {
      jt(), ie(), sn(), Hr = (s) => Array.from(s.getBigInt64Array(), Number), Bp = (s) => {
        if (!s || s.length !== 2)
          throw new Error("Tile requires 2 inputs.");
        if (s[0].dataType !== 1 && s[0].dataType !== 10 && s[0].dataType !== 6 && s[0].dataType !== 12)
          throw new Error("Tile only support float, float16, int32, and uint32 data types");
        if (s[1].dataType !== 7)
          throw new Error("Tile `repeats` input should be of int64 data type");
        if (s[1].dims.length !== 1)
          throw new Error("Tile `repeats` input should be 1-D");
        if (Hr(s[1]).length !== s[0].dims.length)
          throw new Error("Tile `repeats` input should have same number of elements as rank of input data tensor");
      }, zp = (s, o) => {
        let d = [];
        for (let g = 0; g < s.length; ++g)
          d.push(s[g] * o[g]);
        return d;
      }, $p = (s, o) => {
        let d = s[0].dims, g = o ?? Hr(s[1]), y = zp(d, g), x = it.size(y), b = s[0].dataType, P = dt("input", b, d.length), k = $t("output", b, y.length), O = ($) => `
      const inputShape = ${P.indices(...d)};
      ${$.registerUniform("output_size", "u32").declareVariables(P, k)}
      ${$.mainStart()}
      ${$.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}
      let output_indices = ${k.offsetToIndices("global_idx")};
      var input_indices: ${P.type.indices};
      for (var i = 0; i < ${d.length}; i++) {
        let input_dim_i = ${P.indicesGet("uniforms.input_shape", "i")};
        let input_dim_value = ${k.indicesGet("output_indices", "i")}  % input_dim_i;

        ${P.indicesSet("input_indices", "i", "input_dim_value")}
      }
      ${k.setByOffset("global_idx", P.getByIndices("input_indices"))}
    }`;
        return { name: "Tile", shaderCache: { hint: `${g}`, inputDependencies: ["rank"] }, getRunData: () => ({ outputs: [{ dims: y, dataType: s[0].dataType }], dispatchGroup: { x: Math.ceil(x / 64) }, programUniforms: [{ type: 12, data: x }, ...Ut(s[0].dims, y)] }), getShaderSource: O };
      }, Np = (s) => {
        Bp(s.inputs), s.compute($p(s.inputs), { inputs: [0] });
      };
    }), Jo, Up, Gp, Vg = l(() => {
      jt(), ie(), sn(), Jo = (s, o, d, g, y) => {
        let x = $t("output_data", y, d.length, 4), b = dt("a_data", o[1].dataType, o[1].dims.length, 4), P = dt("b_data", o[2].dataType, o[2].dims.length, 4), k = dt("c_data", o[0].dataType, o[0].dims.length, 4), O, $ = (V, G, ee) => `select(${G}, ${V}, ${ee})`;
        if (!g)
          O = x.setByOffset("global_idx", $(b.getByOffset("global_idx"), P.getByOffset("global_idx"), k.getByOffset("global_idx")));
        else {
          let V = (G, ee, X = "") => {
            let re = `a_data[index_a${ee}][component_a${ee}]`, Te = `b_data[index_b${ee}][component_b${ee}]`, ue = `bool(c_data[index_c${ee}] & (0xffu << (component_c${ee} * 8)))`;
            return `
            let output_indices${ee} = ${x.offsetToIndices(`global_idx * 4u + ${ee}u`)};
            let offset_a${ee} = ${b.broadcastedIndicesToOffset(`output_indices${ee}`, x)};
            let offset_b${ee} = ${P.broadcastedIndicesToOffset(`output_indices${ee}`, x)};
            let offset_c${ee} = ${k.broadcastedIndicesToOffset(`output_indices${ee}`, x)};
            let index_a${ee} = offset_a${ee} / 4u;
            let index_b${ee} = offset_b${ee} / 4u;
            let index_c${ee} = offset_c${ee} / 4u;
            let component_a${ee} = offset_a${ee} % 4u;
            let component_b${ee} = offset_b${ee} % 4u;
            let component_c${ee} = offset_c${ee} % 4u;
            ${G}[${ee}] = ${X}(${$(re, Te, ue)});
          `;
          };
          y === 9 ? O = `
            var data = vec4<u32>(0);
            ${V("data", 0, "u32")}
            ${V("data", 1, "u32")}
            ${V("data", 2, "u32")}
            ${V("data", 3, "u32")}
            output_data[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));` : O = `
            ${V("output_data[global_idx]", 0)}
            ${V("output_data[global_idx]", 1)}
            ${V("output_data[global_idx]", 2)}
            ${V("output_data[global_idx]", 3)}
          `;
        }
        return `
        ${s.registerUniform("vec_size", "u32").declareVariables(k, b, P, x)}
        ${s.mainStart()}
        ${s.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}
        ${O}
      }`;
      }, Up = (s) => {
        let o = s[1].dims, d = s[2].dims, g = s[0].dims, y = s[1].dataType, x = !(it.areEqual(o, d) && it.areEqual(d, g)), b = o, P = it.size(o);
        if (x) {
          let O = Ui.calcShape(Ui.calcShape(o, d, !1), g, !1);
          if (!O)
            throw new Error("Can't perform where op on the given tensors");
          b = O, P = it.size(b);
        }
        let k = Math.ceil(P / 4);
        return { name: "Where", shaderCache: { inputDependencies: ["rank", "rank", "rank"] }, getShaderSource: (O) => Jo(O, s, b, x, y), getRunData: () => ({ outputs: [{ dims: b, dataType: y }], dispatchGroup: { x: Math.ceil(P / 64 / 4) }, programUniforms: [{ type: 12, data: k }, ...Ut(g, o, d, b)] }) };
      }, Gp = (s) => {
        s.compute(Up(s.inputs));
      };
    }), mn, Hy = l(() => {
      ud(), Va(), vd(), mg(), Jd(), ah(), gg(), Ih(), vg(), wg(), xg(), bg(), Mg(), Tg(), Eg(), Sg(), af(), Pg(), Ag(), Cg(), Ig(), Lg(), kg(), Og(), Fg(), ks(), Jf(), Bg(), jy(), zg(), Wy(), za(), Ng(), Bo(), Ap(), hc(), Ug(), Cf(), Gg(), Hs(), ol(), Vg(), mn = /* @__PURE__ */ new Map([["Abs", [Md]], ["Acos", [Td]], ["Acosh", [Ha]], ["Add", [eh]], ["ArgMax", [cd, Ua]], ["ArgMin", [Na, Ua]], ["Asin", [Ed]], ["Asinh", [Sd]], ["Atan", [qa]], ["Atanh", [Pd]], ["Attention", [md]], ["AveragePool", [ep, Zf]], ["BatchNormalization", [yd]], ["BiasAdd", [Wa]], ["BiasSplitGelu", [Yd]], ["Cast", [Ka, Ad]], ["Ceil", [Xa]], ["Clip", [Id]], ["Concat", [dh, hl]], ["Conv", [wr, Tl]], ["ConvTranspose", [Cl, Oh]], ["Cos", [Ld]], ["Cosh", [Dd]], ["CumSum", [Bh, Il]], ["DepthToSpace", [Nh, Dl]], ["DequantizeLinear", [nc, Wo]], ["Div", [ll]], ["Einsum", [jh, Wh]], ["Elu", [kd, yr]], ["Equal", [th]], ["Erf", [Ya]], ["Exp", [Od]], ["Expand", [Xh]], ["FastGelu", [Jh]], ["Floor", [Fd]], ["FusedConv", [wr, Tl]], ["Gather", [ef, Bl]], ["GatherElements", [uf, Nl]], ["GatherBlockQuantized", [rf, of]], ["GatherND", [tf, nf]], ["Gelu", [Ja]], ["Gemm", [ff, hf]], ["GlobalAveragePool", [np, tp]], ["GlobalMaxPool", [rp, jo]], ["Greater", [sh]], ["GreaterOrEqual", [rh]], ["GridSample", [xf, Fo]], ["GroupQueryAttention", [Of]], ["HardSigmoid", [Ud, Nd]], ["InstanceNormalization", [Rf]], ["LayerNormalization", [zf]], ["LeakyRelu", [Rd, yr]], ["Less", [ul]], ["LessOrEqual", [oh]], ["Log", [Hd]], ["MatMul", [xr]], ["MatMulNBits", [Vf, jf]], ["MaxPool", [ip, sp]], ["Mul", [nh]], ["MultiHeadAttention", [Mf, bf]], ["Neg", [Qa]], ["Not", [Bd]], ["Pad", [Yf]], ["Pow", [cl]], ["QuickGelu", [Kd, yr]], ["Range", [ic]], ["Reciprocal", [zd]], ["ReduceMin", [od]], ["ReduceMean", [Oa]], ["ReduceMax", [rd]], ["ReduceSum", [ad]], ["ReduceProd", [Ra]], ["ReduceL1", [id]], ["ReduceL2", [sd]], ["ReduceLogSum", [Ba]], ["ReduceLogSumExp", [Fa]], ["ReduceSumSquare", [ld]], ["Relu", [$d]], ["Resize", [Mp, Tp]], ["RotaryEmbedding", [Lf]], ["ScatterND", [$g, rc]], ["Sigmoid", [Za]], ["Sin", [el]], ["Sinh", [Gd]], ["Slice", [dc, Dp]], ["SkipLayerNormalization", [Pp]], ["Split", [Af, ql]], ["Sqrt", [Vd]], ["Softmax", [Fp, Rp]], ["Sub", [ih]], ["Tan", [tl]], ["Tanh", [jd]], ["ThresholdedRelu", [sl, yr]], ["Tile", [Np]], ["Transpose", [Ru, Pa]], ["Where", [Gp]]]);
    }), jg, qy = l(() => {
      qe(), Lt(), sn(), jg = class {
        constructor(s) {
          this.backend = s, this.repo = /* @__PURE__ */ new Map(), this.attributesBound = !1;
        }
        getArtifact(s) {
          return this.repo.get(s);
        }
        setArtifact(s, o) {
          this.repo.set(s, o);
        }
        run(s, o, d, g, y) {
          ze(s.programInfo.name);
          let x = this.backend.device, b = this.backend.getComputePassEncoder();
          this.backend.writeTimestamp(this.backend.pendingDispatchNumber * 2);
          let P = [];
          for (let O of o)
            P.push({ binding: P.length, resource: { buffer: O.buffer } });
          for (let O of d)
            P.push({ binding: P.length, resource: { buffer: O.buffer } });
          y && P.push({ binding: P.length, resource: y });
          let k = x.createBindGroup({ layout: s.computePipeline.getBindGroupLayout(0), entries: P, label: s.programInfo.name });
          if (this.backend.sessionStatus === "capturing") {
            let O = { kernelId: this.backend.currentKernelId, computePipeline: s.computePipeline, bindGroup: k, dispatchGroup: g };
            this.backend.capturedCommandList.get(this.backend.currentSessionId).push(O);
          }
          b.setPipeline(s.computePipeline), b.setBindGroup(0, k), b.dispatchWorkgroups(...g), this.backend.writeTimestamp(this.backend.pendingDispatchNumber * 2 + 1), this.backend.pendingDispatchNumber++, (this.backend.pendingDispatchNumber >= this.backend.maxDispatchNumber || this.backend.queryType === "at-passes") && this.backend.endComputePass(), this.backend.pendingDispatchNumber >= this.backend.maxDispatchNumber && this.backend.flush(), Oe(s.programInfo.name);
        }
        dispose() {
        }
        build(s, o) {
          ze(s.name);
          let d = this.backend.device, g = [];
          [{ feature: "shader-f16", extension: "f16" }, { feature: "subgroups", extension: "subgroups" }].forEach((O) => {
            d.features.has(O.feature) && g.push(`enable ${O.extension};`);
          });
          let y = Lu(o, this.backend.device.limits), x = s.getShaderSource(y), b = `${g.join(`
`)}
${y.additionalImplementations}
${x}`, P = d.createShaderModule({ code: b, label: s.name });
          ct("verbose", () => `[WebGPU] ${s.name} shader code: ${b}`);
          let k = d.createComputePipeline({ compute: { module: P, entryPoint: "main" }, layout: "auto", label: s.name });
          return Oe(s.name), { programInfo: s, computePipeline: k, uniformVariablesInfo: y.variablesInfo };
        }
        normalizeDispatchGroupSize(s) {
          let o = typeof s == "number" ? s : s.x, d = typeof s == "number" ? 1 : s.y || 1, g = typeof s == "number" ? 1 : s.z || 1, y = this.backend.device.limits.maxComputeWorkgroupsPerDimension;
          if (o <= y && d <= y && g <= y)
            return [o, d, g];
          let x = o * d * g, b = Math.ceil(Math.sqrt(x));
          if (b > y) {
            if (b = Math.ceil(Math.cbrt(x)), b > y)
              throw new Error("Total dispatch size exceeds WebGPU maximum.");
            return [b, b, b];
          } else
            return [b, b, 1];
        }
      };
    }), Wg = {};
    f(Wg, { WebGpuBackend: () => Wp });
    var fc, Vp, jp, Wp, Hg = l(() => {
      qe(), jt(), Lt(), Re(), jn(), Hy(), qy(), fc = (s, o) => {
        if (o.length !== s.length)
          throw new Error(`inputDependencies length ${o.length} is not equal to inputTensors length ${s.length}.`);
        let d = [];
        for (let g = 0; g < s.length; ++g) {
          let y = s[g].dataType;
          switch (o[g]) {
            case "none": {
              d.push("");
              break;
            }
            case "type": {
              d.push(`${y}`);
              break;
            }
            case "rank": {
              let x = s[g].dims.length;
              d.push(`${y};${x}`);
              break;
            }
            case "dims": {
              let x = s[g].dims.join(",");
              d.push(`${y};${x}`);
              break;
            }
            default:
              throw new Error(`unsupported input dependency: ${o[g]}`);
          }
        }
        return d.join("|");
      }, Vp = (s, o, d) => {
        var y, x;
        let g = s.name;
        return (y = s.shaderCache) != null && y.hint && (g += "[" + s.shaderCache.hint + "]"), g += ":" + d + `:${fc(o, ((x = s.shaderCache) == null ? void 0 : x.inputDependencies) ?? new Array(o.length).fill("dims"))}`, g;
      }, jp = class {
        constructor(s) {
          s && (this.architecture = s.architecture, this.vendor = s.vendor);
        }
        isArchitecture(s) {
          return this.architecture === s;
        }
        isVendor(s) {
          return this.vendor === s;
        }
      }, Wp = class {
        constructor() {
          this.currentSessionId = null, this.currentKernelId = null, this.commandEncoder = null, this.computePassEncoder = null, this.maxDispatchNumber = 16, this.pendingDispatchNumber = 0, this.pendingKernels = [], this.pendingQueries = /* @__PURE__ */ new Map(), this.sessionStatus = "default", this.capturedCommandList = /* @__PURE__ */ new Map(), this.capturedPendingKernels = /* @__PURE__ */ new Map(), this.sessionExternalDataMapping = /* @__PURE__ */ new Map();
        }
        get currentKernelCustomData() {
          if (this.currentKernelId === null)
            throw new Error("currentKernelCustomData(): currentKernelId is null. (should not happen)");
          let s = this.kernelCustomData.get(this.currentKernelId);
          return s || (s = {}, this.kernelCustomData.set(this.currentKernelId, s)), s;
        }
        async initialize(s, o) {
          this.env = s;
          let d = [], g = { requiredLimits: { maxComputeWorkgroupStorageSize: o.limits.maxComputeWorkgroupStorageSize, maxComputeWorkgroupsPerDimension: o.limits.maxComputeWorkgroupsPerDimension, maxStorageBufferBindingSize: o.limits.maxStorageBufferBindingSize, maxBufferSize: o.limits.maxBufferSize, maxComputeInvocationsPerWorkgroup: o.limits.maxComputeInvocationsPerWorkgroup, maxComputeWorkgroupSizeX: o.limits.maxComputeWorkgroupSizeX, maxComputeWorkgroupSizeY: o.limits.maxComputeWorkgroupSizeY, maxComputeWorkgroupSizeZ: o.limits.maxComputeWorkgroupSizeZ }, requiredFeatures: d }, y = (x) => o.features.has(x) && d.push(x) && !0;
          y("chromium-experimental-timestamp-query-inside-passes") || y("timestamp-query"), y("shader-f16"), y("subgroups"), this.device = await o.requestDevice(g), this.adapterInfo = new jp(o.info || await o.requestAdapterInfo()), this.gpuDataManager = Yn(this), this.programManager = new jg(this), this.kernels = /* @__PURE__ */ new Map(), this.kernelPersistentData = /* @__PURE__ */ new Map(), this.kernelCustomData = /* @__PURE__ */ new Map(), pi(s.logLevel, !!s.debug), this.device.onuncapturederror = (x) => {
            x.error instanceof GPUValidationError && console.error(`An uncaught WebGPU validation error was raised: ${x.error.message}`);
          }, Object.defineProperty(this.env.webgpu, "device", { value: this.device, writable: !1, enumerable: !0, configurable: !1 }), Object.defineProperty(this.env.webgpu, "adapter", { value: o, writable: !1, enumerable: !0, configurable: !1 }), this.setQueryType();
        }
        dispose() {
          typeof this.querySet < "u" && this.querySet.destroy(), this.gpuDataManager.dispose();
        }
        getCommandEncoder() {
          return this.commandEncoder || (this.commandEncoder = this.device.createCommandEncoder()), this.commandEncoder;
        }
        getComputePassEncoder() {
          if (!this.computePassEncoder) {
            let s = this.getCommandEncoder(), o = {};
            this.queryType === "at-passes" && (o.timestampWrites = { querySet: this.querySet, beginningOfPassWriteIndex: this.pendingDispatchNumber * 2, endOfPassWriteIndex: this.pendingDispatchNumber * 2 + 1 }), this.computePassEncoder = s.beginComputePass(o);
          }
          return this.computePassEncoder;
        }
        endComputePass() {
          this.computePassEncoder && (this.computePassEncoder.end(), this.computePassEncoder = null);
        }
        flush() {
          if (!this.commandEncoder)
            return;
          ze(), this.endComputePass();
          let s;
          this.queryType !== "none" && (this.commandEncoder.resolveQuerySet(this.querySet, 0, this.pendingDispatchNumber * 2, this.queryResolveBuffer, 0), s = this.device.createBuffer({ size: this.pendingDispatchNumber * 2 * 8, usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST }), this.pendingQueries.set(s, this.pendingKernels), this.pendingKernels = [], this.commandEncoder.copyBufferToBuffer(this.queryResolveBuffer, 0, s, 0, this.pendingDispatchNumber * 2 * 8)), this.device.queue.submit([this.commandEncoder.finish()]), this.gpuDataManager.refreshPendingBuffers(), this.commandEncoder = null, this.pendingDispatchNumber = 0, this.queryType !== "none" && s.mapAsync(GPUMapMode.READ).then(() => {
            var g;
            let o = new BigUint64Array(s.getMappedRange()), d = this.pendingQueries.get(s);
            for (let y = 0; y < o.length / 2; y++) {
              let x = d[y], b = x.kernelId, P = this.kernels.get(b), k = P.kernelType, O = P.kernelName, $ = x.programName, V = x.inputTensorViews, G = x.outputTensorViews, ee = o[y * 2], X = o[y * 2 + 1];
              typeof this.queryTimeBase > "u" && (this.queryTimeBase = ee);
              let re = Number(ee - this.queryTimeBase), Te = Number(X - this.queryTimeBase);
              if (!Number.isSafeInteger(re) || !Number.isSafeInteger(Te))
                throw new RangeError("incorrect timestamp range");
              if ((g = this.env.webgpu.profiling) != null && g.ondata)
                this.env.webgpu.profiling.ondata({ version: 1, inputsMetadata: V.map((ue) => ({ dims: ue.dims, dataType: fi(ue.dataType) })), outputsMetadata: G.map((ue) => ({ dims: ue.dims, dataType: fi(ue.dataType) })), kernelId: b, kernelType: k, kernelName: O, programName: $, startTime: re, endTime: Te });
              else {
                let ue = "";
                V.forEach((ke, Le) => {
                  ue += `input[${Le}]: [${ke.dims}] | ${fi(ke.dataType)}, `;
                });
                let ce = "";
                G.forEach((ke, Le) => {
                  ce += `output[${Le}]: [${ke.dims}] | ${fi(ke.dataType)}, `;
                }), console.log(`[profiling] kernel "${b}|${k}|${O}|${$}" ${ue}${ce}execution time: ${Te - re} ns`);
              }
              U("GPU", `${$}::${ee}::${X}`);
            }
            s.unmap(), this.pendingQueries.delete(s);
          }), Oe();
        }
        run(s, o, d, g, y, x) {
          ze(s.name);
          let b = [];
          for (let ce = 0; ce < o.length; ++ce) {
            let ke = o[ce].data;
            if (ke === 0)
              continue;
            let Le = this.gpuDataManager.get(ke);
            if (!Le)
              throw new Error(`no GPU data for input: ${ke}`);
            b.push(Le);
          }
          let { outputs: P, dispatchGroup: k, programUniforms: O } = s.getRunData(o), $ = d.length === 0 ? P.map((ce, ke) => ke) : d;
          if ($.length !== P.length)
            throw new Error(`Output size ${$.length} must be equal to ${P.length}.`);
          let V = [], G = [];
          for (let ce = 0; ce < P.length; ++ce) {
            if (!Number.isInteger($[ce]) || $[ce] < -3 || $[ce] >= x)
              throw new Error(`Invalid output index: ${$[ce]}`);
            if ($[ce] === -3)
              continue;
            let ke = $[ce] === -1, Le = $[ce] === -2, M = ke || Le ? y(P[ce].dataType, P[ce].dims) : g($[ce], P[ce].dataType, P[ce].dims);
            if (V.push(M), M.data === 0)
              continue;
            let C = this.gpuDataManager.get(M.data);
            if (!C)
              throw new Error(`no GPU data for output: ${M.data}`);
            if (ke && this.temporaryData.push(C), Le) {
              let z = this.kernelPersistentData.get(this.currentKernelId);
              z || (z = [], this.kernelPersistentData.set(this.currentKernelId, z)), z.push(C);
            }
            G.push(C);
          }
          if (b.length !== o.length || G.length !== V.length) {
            if (G.length === 0)
              return Oe(s.name), V;
            throw new Error(`Program ${s.name} has zero-sized tensor(s) in inputs or outputs. This is not supported now.`);
          }
          let ee;
          if (O) {
            let ce = 0, ke = [];
            O.forEach((z) => {
              let oe = typeof z.data == "number" ? [z.data] : z.data;
              if (oe.length === 0)
                return;
              let ye = z.type === 10 ? 2 : 4, Pe, Ue;
              z.type === 10 ? (Ue = oe.length > 4 ? 16 : oe.length > 2 ? 8 : oe.length * ye, Pe = oe.length > 4 ? 16 : ye * oe.length) : (Ue = oe.length <= 2 ? oe.length * ye : 16, Pe = 16), ce = Math.ceil(ce / Ue) * Ue, ke.push(ce);
              let Je = z.type === 10 ? 8 : 4;
              ce += oe.length > 4 ? Math.ceil(oe.length / Je) * Pe : oe.length * ye;
            });
            let Le = 16;
            ce = Math.ceil(ce / Le) * Le;
            let M = new ArrayBuffer(ce);
            O.forEach((z, oe) => {
              let ye = ke[oe], Pe = typeof z.data == "number" ? [z.data] : z.data;
              if (z.type === 6)
                new Int32Array(M, ye, Pe.length).set(Pe);
              else if (z.type === 12)
                new Uint32Array(M, ye, Pe.length).set(Pe);
              else if (z.type === 10)
                new Uint16Array(M, ye, Pe.length).set(Pe);
              else if (z.type === 1)
                new Float32Array(M, ye, Pe.length).set(Pe);
              else
                throw new Error(`Unsupported uniform type: ${fi(z.type)}`);
            });
            let C = this.gpuDataManager.create(ce, GPUBufferUsage.COPY_DST | GPUBufferUsage.UNIFORM);
            this.device.queue.writeBuffer(C.buffer, 0, M, 0, ce), this.gpuDataManager.release(C.id), ee = { offset: 0, size: ce, buffer: C.buffer };
          }
          let X = this.programManager.normalizeDispatchGroupSize(k), re = X[1] === 1 && X[2] === 1, Te = Vp(s, o, re), ue = this.programManager.getArtifact(Te);
          if (ue || (ue = this.programManager.build(s, X), this.programManager.setArtifact(Te, ue), ct("info", () => `[artifact] key: ${Te}, programName: ${s.name}`)), O && ue.uniformVariablesInfo) {
            if (O.length !== ue.uniformVariablesInfo.length)
              throw new Error(`Uniform variables count mismatch: expect ${ue.uniformVariablesInfo.length}, got ${O.length} in program "${ue.programInfo.name}".`);
            for (let ce = 0; ce < O.length; ce++) {
              let ke = O[ce], Le = ke.type, M = typeof ke.data == "number" ? 1 : ke.data.length, [C, z] = ue.uniformVariablesInfo[ce];
              if (Le !== C || M !== z)
                throw new Error(`Uniform variable ${ce} mismatch: expect type ${C} with size ${z}, got type ${Le} with size ${M} in program "${ue.programInfo.name}".`);
            }
          }
          if (ct("info", () => `[ProgramManager] run "${s.name}" (key=${Te}) with ${X[0]}x${X[1]}x${X[2]}`), this.queryType !== "none" || this.sessionStatus === "capturing") {
            let ce = { kernelId: this.currentKernelId, programName: ue.programInfo.name, inputTensorViews: o, outputTensorViews: V };
            this.pendingKernels.push(ce), this.sessionStatus === "capturing" && this.capturedPendingKernels.get(this.currentSessionId).push(ce);
          }
          return this.programManager.run(ue, b, G, X, ee), Oe(s.name), V;
        }
        upload(s, o) {
          this.gpuDataManager.upload(s, o);
        }
        memcpy(s, o) {
          this.gpuDataManager.memcpy(s, o);
        }
        async download(s, o) {
          await this.gpuDataManager.download(s, o);
        }
        alloc(s) {
          return this.gpuDataManager.create(s).id;
        }
        free(s) {
          return this.gpuDataManager.release(s);
        }
        createKernel(s, o, d, g) {
          let y = mn.get(s);
          if (!y)
            throw new Error(`kernel not implemented: ${s}`);
          let x = { kernelType: s, kernelName: g, kernelEntry: y[0], attributes: [y[1], d] };
          this.kernels.set(o, x);
        }
        releaseKernel(s) {
          let o = this.kernelPersistentData.get(s);
          if (o) {
            for (let d of o)
              this.gpuDataManager.release(d.id);
            this.kernelPersistentData.delete(s);
          }
          this.kernelCustomData.delete(s), this.kernels.delete(s);
        }
        computeKernel(s, o, d) {
          let g = this.kernels.get(s);
          if (!g)
            throw new Error(`kernel not created: ${s}`);
          let y = g.kernelType, x = g.kernelName, b = g.kernelEntry, P = g.attributes;
          if (this.currentKernelId !== null)
            throw new Error(`kernel "[${y}] ${x}" is not allowed to be called recursively`);
          this.currentKernelId = s, P[0] && (P[1] = P[0](P[1]), P[0] = void 0), ct("info", () => `[WebGPU] Start to run kernel "[${y}] ${x}"...`);
          let k = this.env.debug;
          this.temporaryData = [];
          try {
            return k && this.device.pushErrorScope("validation"), b(o, P[1]), 0;
          } catch (O) {
            return d.push(Promise.resolve(`[WebGPU] Kernel "[${y}] ${x}" failed. ${O}`)), 1;
          } finally {
            k && d.push(this.device.popErrorScope().then((O) => O ? `GPU validation error for kernel "[${y}] ${x}": ${O.message}` : null));
            for (let O of this.temporaryData)
              this.gpuDataManager.release(O.id);
            this.temporaryData = [], this.currentKernelId = null;
          }
        }
        registerBuffer(s, o, d, g) {
          let y = this.sessionExternalDataMapping.get(s);
          y || (y = /* @__PURE__ */ new Map(), this.sessionExternalDataMapping.set(s, y));
          let x = y.get(o), b = this.gpuDataManager.registerExternalBuffer(d, g, x);
          return y.set(o, [b, d]), b;
        }
        unregisterBuffers(s) {
          let o = this.sessionExternalDataMapping.get(s);
          o && (o.forEach((d) => this.gpuDataManager.unregisterExternalBuffer(d[0])), this.sessionExternalDataMapping.delete(s));
        }
        getBuffer(s) {
          let o = this.gpuDataManager.get(s);
          if (!o)
            throw new Error(`no GPU data for buffer: ${s}`);
          return o.buffer;
        }
        createDownloader(s, o, d) {
          return async () => {
            let g = await si(this, s, o);
            return Ae(g.buffer, d);
          };
        }
        writeTimestamp(s) {
          this.queryType === "inside-passes" && this.computePassEncoder.writeTimestamp(this.querySet, s);
        }
        setQueryType() {
          var s;
          this.queryType = "none", (((s = this.env.webgpu.profiling) == null ? void 0 : s.mode) === "default" || (typeof this.env.trace > "u" ? this.env.wasm.trace : this.env.trace)) && (this.device.features.has("chromium-experimental-timestamp-query-inside-passes") ? this.queryType = "inside-passes" : this.device.features.has("timestamp-query") && (this.queryType = "at-passes"), this.queryType !== "none" && typeof this.querySet > "u" && (this.querySet = this.device.createQuerySet({ type: "timestamp", count: this.maxDispatchNumber * 2 }), this.queryResolveBuffer = this.device.createBuffer({ size: this.maxDispatchNumber * 2 * 8, usage: GPUBufferUsage.COPY_SRC | GPUBufferUsage.QUERY_RESOLVE })));
        }
        captureBegin() {
          ct("info", "captureBegin"), this.capturedCommandList.get(this.currentSessionId) || this.capturedCommandList.set(this.currentSessionId, []), this.capturedPendingKernels.get(this.currentSessionId) || this.capturedPendingKernels.set(this.currentSessionId, []), this.flush(), this.sessionStatus = "capturing";
        }
        captureEnd() {
          ct("info", "captureEnd"), this.flush(), this.sessionStatus = "default";
        }
        replay() {
          ct("info", "replay"), this.sessionStatus = "replaying";
          let s = this.capturedCommandList.get(this.currentSessionId), o = this.capturedPendingKernels.get(this.currentSessionId), d = s.length;
          this.pendingKernels = [];
          for (let g = 0; g < d; g++) {
            let y = this.getComputePassEncoder(), x = s[g];
            this.writeTimestamp(this.pendingDispatchNumber * 2), y.setPipeline(x.computePipeline), y.setBindGroup(0, x.bindGroup), y.dispatchWorkgroups(...x.dispatchGroup), this.writeTimestamp(this.pendingDispatchNumber * 2 + 1), this.pendingDispatchNumber++, this.queryType !== "none" && this.pendingKernels.push(o[g]), (this.pendingDispatchNumber >= this.maxDispatchNumber || this.queryType === "at-passes") && this.endComputePass(), this.pendingDispatchNumber >= this.maxDispatchNumber && this.flush();
          }
          this.flush(), this.sessionStatus = "default";
        }
        onCreateSession() {
          this.gpuDataManager.onCreateSession();
        }
        onReleaseSession(s) {
          this.unregisterBuffers(s), this.capturedCommandList.has(s) && this.capturedCommandList.delete(s), this.capturedPendingKernels.has(s) && this.capturedPendingKernels.delete(s), this.gpuDataManager.onReleaseSession(s);
        }
        onRunStart(s) {
          this.currentSessionId = s, this.setQueryType();
        }
      };
    }), pc = {};
    f(pc, { init: () => Hp });
    var qr, qg, Hp, Kg = l(() => {
      jt(), Lt(), ie(), ms(), qr = class Ab {
        constructor(o, d, g, y) {
          this.module = o, this.dataType = d, this.data = g, this.dims = y;
        }
        getFloat32Array() {
          if (this.dataType !== 1)
            throw new Error("Invalid data type");
          let o = it.size(this.dims);
          return o === 0 ? new Float32Array() : new Float32Array(this.module.HEAP8.buffer, this.data, o);
        }
        getBigInt64Array() {
          if (this.dataType !== 7)
            throw new Error("Invalid data type");
          let o = it.size(this.dims);
          return o === 0 ? new BigInt64Array() : new BigInt64Array(this.module.HEAP8.buffer, this.data, o);
        }
        getInt32Array() {
          if (this.dataType !== 6)
            throw new Error("Invalid data type");
          let o = it.size(this.dims);
          return o === 0 ? new Int32Array() : new Int32Array(this.module.HEAP8.buffer, this.data, o);
        }
        getUint16Array() {
          if (this.dataType !== 10 && this.dataType !== 4)
            throw new Error("Invalid data type");
          let o = it.size(this.dims);
          return o === 0 ? new Uint16Array() : new Uint16Array(this.module.HEAP8.buffer, this.data, o);
        }
        reshape(o) {
          if (it.size(o) !== it.size(this.dims))
            throw new Error("Invalid new shape");
          return new Ab(this.module, this.dataType, this.data, o);
        }
      }, qg = class {
        constructor(s, o, d) {
          this.module = s, this.backend = o, this.customDataOffset = 0, this.customDataSize = 0, this.adapterInfo = o.adapterInfo;
          let g = s.PTR_SIZE, y = d / s.PTR_SIZE, x = g === 4 ? "i32" : "i64";
          this.opKernelContext = Number(s.getValue(g * y++, x));
          let b = Number(s.getValue(g * y++, x));
          this.outputCount = Number(s.getValue(g * y++, x)), this.customDataOffset = Number(s.getValue(g * y++, "*")), this.customDataSize = Number(s.getValue(g * y++, x));
          let P = [];
          for (let k = 0; k < b; k++) {
            let O = Number(s.getValue(g * y++, x)), $ = Number(s.getValue(g * y++, "*")), V = Number(s.getValue(g * y++, x)), G = [];
            for (let ee = 0; ee < V; ee++)
              G.push(Number(s.getValue(g * y++, x)));
            P.push(new qr(s, O, $, G));
          }
          this.inputs = P;
        }
        get kernelCustomData() {
          return this.backend.currentKernelCustomData;
        }
        get customDataBuffer() {
          return this.module.HEAPU8.subarray(this.customDataOffset, this.customDataOffset + this.customDataSize);
        }
        compute(s, o) {
          var b;
          let d = ((b = o == null ? void 0 : o.inputs) == null ? void 0 : b.map((P) => typeof P == "number" ? this.inputs[P] : P)) ?? this.inputs, g = (o == null ? void 0 : o.outputs) ?? [], y = (P, k, O) => new qr(this.module, k, this.output(P, O), O), x = (P, k) => {
            let O = Pi(P, k);
            if (!O)
              throw new Error(`Unsupported data type: ${P}`);
            let $ = O > 0 ? this.backend.gpuDataManager.create(O).id : 0;
            return new qr(this.module, P, $, k);
          };
          return this.backend.run(s, d, g, y, x, this.outputCount);
        }
        output(s, o) {
          let d = this.module.stackSave();
          try {
            let g = this.module.PTR_SIZE, y = g === 4 ? "i32" : "i64", x = this.module.stackAlloc((1 + o.length) * g);
            this.module.setValue(x, o.length, y);
            for (let b = 0; b < o.length; b++)
              this.module.setValue(x + g * (b + 1), o[b], y);
            return this.module._JsepOutput(this.opKernelContext, s, x);
          } catch (g) {
            throw new Error(`Failed to generate kernel's output[${s}] with dims [${o}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${g}`);
          } finally {
            this.module.stackRestore(d);
          }
        }
      }, Hp = async (s, o, d, g) => {
        let y = o.jsepInit;
        if (!y)
          throw new Error("Failed to initialize JSEP. The WebAssembly module is not built with JSEP support.");
        if (s === "webgpu") {
          let x = (Hg(), h(Wg)).WebGpuBackend, b = new x();
          await b.initialize(d, g), y("webgpu", [b, (P) => b.alloc(Number(P)), (P) => b.free(P), (P, k, O, $ = !1) => {
            if ($)
              ct("verbose", () => `[WebGPU] jsepCopyGpuToGpu: src=${Number(P)}, dst=${Number(k)}, size=${Number(O)}`), b.memcpy(Number(P), Number(k));
            else {
              ct("verbose", () => `[WebGPU] jsepCopyCpuToGpu: dataOffset=${Number(P)}, gpuDataId=${Number(k)}, size=${Number(O)}`);
              let V = o.HEAPU8.subarray(Number(P >>> 0), Number(P >>> 0) + Number(O));
              b.upload(Number(k), V);
            }
          }, async (P, k, O) => {
            ct("verbose", () => `[WebGPU] jsepCopyGpuToCpu: gpuDataId=${P}, dataOffset=${k}, size=${O}`), await b.download(Number(P), () => o.HEAPU8.subarray(Number(k) >>> 0, Number(k + O) >>> 0));
          }, (P, k, O) => b.createKernel(P, Number(k), O, o.UTF8ToString(o._JsepGetNodeName(Number(k)))), (P) => b.releaseKernel(P), (P, k, O, $) => {
            ct("verbose", () => `[WebGPU] jsepRun: sessionHandle=${O}, kernel=${P}, contextDataOffset=${k}`);
            let V = new qg(o, b, Number(k));
            return b.computeKernel(Number(P), V, $);
          }, () => b.captureBegin(), () => b.captureEnd(), () => b.replay()]);
        } else {
          let x = new xi(d);
          y("webnn", [x, () => x.reserveTensorId(), (b) => x.releaseTensorId(b), async (b, P, k, O, $) => x.ensureTensor(b, P, k, O, $), (b, P) => {
            x.uploadTensor(b, P);
          }, async (b, P) => x.downloadTensor(b, P)]);
        }
      };
    }), mc, gc, _c, er, qp, yc, Qo, tr, vc, wc, xc, bc, Mc, Kp = l(() => {
      en(), ci(), jt(), ge(), Pt(), Ws(), mc = (s, o) => {
        se()._OrtInit(s, o) !== 0 && pt("Can't initialize onnxruntime.");
      }, gc = async (s) => {
        mc(s.wasm.numThreads, hs(s.logLevel));
      }, _c = async (s, o) => {
        var d, g;
        (g = (d = se()).asyncInit) == null || g.call(d);
        {
          let y = (Kg(), h(pc)).init;
          if (o === "webgpu") {
            if (typeof navigator > "u" || !navigator.gpu)
              throw new Error("WebGPU is not supported in current environment");
            let x = s.webgpu.adapter;
            if (x) {
              if (typeof x.limits != "object" || typeof x.features != "object" || typeof x.requestDevice != "function")
                throw new Error("Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.");
            } else {
              let b = s.webgpu.powerPreference;
              if (b !== void 0 && b !== "low-power" && b !== "high-performance")
                throw new Error(`Invalid powerPreference setting: "${b}"`);
              let P = s.webgpu.forceFallbackAdapter;
              if (P !== void 0 && typeof P != "boolean")
                throw new Error(`Invalid forceFallbackAdapter setting: "${P}"`);
              if (x = await navigator.gpu.requestAdapter({ powerPreference: b, forceFallbackAdapter: P }), !x)
                throw new Error('Failed to get GPU adapter. You may need to enable flag "--enable-unsafe-webgpu" if you are using Chrome.');
            }
            await y("webgpu", se(), s, x);
          }
          if (o === "webnn") {
            if (typeof navigator > "u" || !navigator.ml)
              throw new Error("WebNN is not supported in current environment");
            await y("webnn", se(), s);
          }
        }
      }, er = /* @__PURE__ */ new Map(), qp = (s) => {
        let o = se(), d = o.stackSave();
        try {
          let g = o.PTR_SIZE, y = o.stackAlloc(2 * g);
          o._OrtGetInputOutputCount(s, y, y + g) !== 0 && pt("Can't get session input/output count.");
          let x = g === 4 ? "i32" : "i64";
          return [Number(o.getValue(y, x)), Number(o.getValue(y + g, x))];
        } finally {
          o.stackRestore(d);
        }
      }, yc = (s, o) => {
        let d = se(), g = d.stackSave(), y = 0;
        try {
          let x = d.PTR_SIZE, b = d.stackAlloc(2 * x);
          d._OrtGetInputOutputMetadata(s, o, b, b + x) !== 0 && pt("Can't get session input/output metadata.");
          let P = Number(d.getValue(b, "*"));
          y = Number(d.getValue(b + x, "*"));
          let k = d.HEAP32[y / 4];
          if (k === 0)
            return [P, 0];
          let O = d.HEAPU32[y / 4 + 1], $ = [];
          for (let V = 0; V < O; V++) {
            let G = Number(d.getValue(y + 8 + V * x, "*"));
            $.push(G !== 0 ? d.UTF8ToString(G) : Number(d.getValue(y + 8 + (V + O) * x, "*")));
          }
          return [P, k, $];
        } finally {
          d.stackRestore(g), y !== 0 && d._OrtFree(y);
        }
      }, Qo = (s) => {
        let o = se(), d = o._malloc(s.byteLength);
        if (d === 0)
          throw new Error(`Can't create a session. failed to allocate a buffer of size ${s.byteLength}.`);
        return o.HEAPU8.set(s, d), [d, s.byteLength];
      }, tr = async (s, o) => {
        var V, G, ee, X;
        let d, g, y = se();
        Array.isArray(s) ? [d, g] = s : s.buffer === y.HEAPU8.buffer ? [d, g] = [s.byteOffset, s.byteLength] : [d, g] = Qo(s);
        let x = 0, b = 0, P = 0, k = [], O = [], $ = [];
        try {
          if ([b, k] = await vi(o), (o == null ? void 0 : o.externalData) && y.mountExternalData) {
            let oe = [];
            for (let ye of o.externalData) {
              let Pe = typeof ye == "string" ? ye : ye.path;
              oe.push(Ni(typeof ye == "string" ? ye : ye.data).then((Ue) => {
                y.mountExternalData(Pe, Ue);
              }));
            }
            await Promise.all(oe);
          }
          for (let oe of (o == null ? void 0 : o.executionProviders) ?? [])
            if ((typeof oe == "string" ? oe : oe.name) === "webnn") {
              if (y.shouldTransferToMLTensor = !1, typeof oe != "string") {
                let ye = oe, Pe = ye == null ? void 0 : ye.context, Ue = ye == null ? void 0 : ye.gpuDevice, Je = ye == null ? void 0 : ye.deviceType, st = ye == null ? void 0 : ye.powerPreference;
                Pe ? y.currentContext = Pe : Ue ? y.currentContext = await y.webnnCreateMLContext(Ue) : y.currentContext = await y.webnnCreateMLContext({ deviceType: Je, powerPreference: st });
              } else
                y.currentContext = await y.webnnCreateMLContext();
              break;
            }
          x = await y._OrtCreateSession(d, g, b), (V = y.webgpuOnCreateSession) == null || V.call(y, x), x === 0 && pt("Can't create a session."), (G = y.jsepOnCreateSession) == null || G.call(y), y.currentContext && (y.webnnRegisterMLContext(x, y.currentContext), y.currentContext = void 0, y.shouldTransferToMLTensor = !0);
          let [re, Te] = qp(x), ue = !!(o != null && o.enableGraphCapture), ce = [], ke = [], Le = [], M = [], C = [];
          for (let oe = 0; oe < re; oe++) {
            let [ye, Pe, Ue] = yc(x, oe);
            ye === 0 && pt("Can't get an input name."), O.push(ye);
            let Je = y.UTF8ToString(ye);
            ce.push(Je), Le.push(Pe === 0 ? { name: Je, isTensor: !1 } : { name: Je, isTensor: !0, type: fi(Pe), shape: Ue });
          }
          for (let oe = 0; oe < Te; oe++) {
            let [ye, Pe, Ue] = yc(x, oe + re);
            ye === 0 && pt("Can't get an output name."), $.push(ye);
            let Je = y.UTF8ToString(ye);
            ke.push(Je), M.push(Pe === 0 ? { name: Je, isTensor: !1 } : { name: Je, isTensor: !0, type: fi(Pe), shape: Ue });
            {
              if (ue && (o == null ? void 0 : o.preferredOutputLocation) === void 0) {
                C.push("gpu-buffer");
                continue;
              }
              let st = typeof (o == null ? void 0 : o.preferredOutputLocation) == "string" ? o.preferredOutputLocation : ((ee = o == null ? void 0 : o.preferredOutputLocation) == null ? void 0 : ee[Je]) ?? "cpu";
              if (st !== "cpu" && st !== "cpu-pinned" && st !== "gpu-buffer" && st !== "ml-tensor")
                throw new Error(`Not supported preferred output location: ${st}.`);
              if (ue && st !== "gpu-buffer")
                throw new Error(`Not supported preferred output location: ${st}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`);
              C.push(st);
            }
          }
          let z = null;
          return C.some((oe) => oe === "gpu-buffer" || oe === "ml-tensor") && (P = y._OrtCreateBinding(x), P === 0 && pt("Can't create IO binding."), z = { handle: P, outputPreferredLocations: C, outputPreferredLocationsEncoded: C.map((oe) => Oi(oe)) }), er.set(x, [x, O, $, z, ue, !1]), [x, ce, ke, Le, M];
        } catch (re) {
          throw O.forEach((Te) => y._OrtFree(Te)), $.forEach((Te) => y._OrtFree(Te)), P !== 0 && y._OrtReleaseBinding(P) !== 0 && pt("Can't release IO binding."), x !== 0 && y._OrtReleaseSession(x) !== 0 && pt("Can't release session."), re;
        } finally {
          y._free(d), b !== 0 && y._OrtReleaseSessionOptions(b) !== 0 && pt("Can't release session options."), k.forEach((re) => y._free(re)), (X = y.unmountExternalData) == null || X.call(y);
        }
      }, vc = (s) => {
        var k, O, $;
        let o = se(), d = er.get(s);
        if (!d)
          throw new Error(`cannot release session. invalid session id: ${s}`);
        let [g, y, x, b, P] = d;
        b && (P && o._OrtClearBoundOutputs(b.handle) !== 0 && pt("Can't clear bound outputs."), o._OrtReleaseBinding(b.handle) !== 0 && pt("Can't release IO binding.")), (k = o.jsepOnReleaseSession) == null || k.call(o, s), (O = o.webnnOnReleaseSession) == null || O.call(o, s), ($ = o.webgpuOnReleaseSession) == null || $.call(o, s), y.forEach((V) => o._OrtFree(V)), x.forEach((V) => o._OrtFree(V)), o._OrtReleaseSession(g) !== 0 && pt("Can't release session."), er.delete(s);
      }, wc = async (s, o, d, g, y, x, b = !1) => {
        if (!s) {
          o.push(0);
          return;
        }
        let P = se(), k = P.PTR_SIZE, O = s[0], $ = s[1], V = s[3], G = V, ee, X;
        if (O === "string" && (V === "gpu-buffer" || V === "ml-tensor"))
          throw new Error("String tensor is not supported on GPU.");
        if (b && V !== "gpu-buffer")
          throw new Error(`External buffer must be provided for input/output index ${x} when enableGraphCapture is true.`);
        if (V === "gpu-buffer") {
          let ue = s[2].gpuBuffer;
          X = Pi(ki(O), $);
          {
            let ce = P.jsepRegisterBuffer;
            if (!ce)
              throw new Error('Tensor location "gpu-buffer" is not supported without using WebGPU.');
            ee = ce(g, x, ue, X);
          }
        } else if (V === "ml-tensor") {
          let ue = s[2].mlTensor;
          X = Pi(ki(O), $);
          let ce = P.webnnRegisterMLTensor;
          if (!ce)
            throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');
          ee = ce(g, ue, ki(O), $);
        } else {
          let ue = s[2];
          if (Array.isArray(ue)) {
            X = k * ue.length, ee = P._malloc(X), d.push(ee);
            for (let ce = 0; ce < ue.length; ce++) {
              if (typeof ue[ce] != "string")
                throw new TypeError(`tensor data at index ${ce} is not a string`);
              P.setValue(ee + ce * k, Fe(ue[ce], d), "*");
            }
          } else {
            let ce = P.webnnIsGraphInput;
            if (O !== "string" && ce) {
              let ke = P.UTF8ToString(y);
              if (ce(g, ke)) {
                let Le = ki(O);
                X = Pi(Le, $), G = "ml-tensor";
                let M = P.webnnCreateTemporaryTensor, C = P.webnnUploadTensor;
                if (!M || !C)
                  throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');
                let z = await M(g, Le, $);
                C(z, new Uint8Array(ue.buffer, ue.byteOffset, ue.byteLength)), ee = z;
              } else
                X = ue.byteLength, ee = P._malloc(X), d.push(ee), P.HEAPU8.set(new Uint8Array(ue.buffer, ue.byteOffset, X), ee);
            } else
              X = ue.byteLength, ee = P._malloc(X), d.push(ee), P.HEAPU8.set(new Uint8Array(ue.buffer, ue.byteOffset, X), ee);
          }
        }
        let re = P.stackSave(), Te = P.stackAlloc(4 * $.length);
        try {
          $.forEach((ce, ke) => P.setValue(Te + ke * k, ce, k === 4 ? "i32" : "i64"));
          let ue = P._OrtCreateTensor(ki(O), ee, X, Te, $.length, Oi(G));
          ue === 0 && pt(`Can't create tensor for input/output. session=${g}, index=${x}.`), o.push(ue);
        } finally {
          P.stackRestore(re);
        }
      }, xc = async (s, o, d, g, y, x) => {
        var Ue, Je, st, gt;
        let b = se(), P = b.PTR_SIZE, k = er.get(s);
        if (!k)
          throw new Error(`cannot run inference. invalid session id: ${s}`);
        let O = k[0], $ = k[1], V = k[2], G = k[3], ee = k[4], X = k[5], re = o.length, Te = g.length, ue = 0, ce = [], ke = [], Le = [], M = [], C = b.stackSave(), z = b.stackAlloc(re * P), oe = b.stackAlloc(re * P), ye = b.stackAlloc(Te * P), Pe = b.stackAlloc(Te * P);
        try {
          [ue, ce] = Tt(x);
          for (let ht = 0; ht < re; ht++)
            await wc(d[ht], ke, M, s, $[o[ht]], o[ht], ee);
          for (let ht = 0; ht < Te; ht++)
            await wc(y[ht], Le, M, s, V[g[ht]], re + g[ht], ee);
          for (let ht = 0; ht < re; ht++)
            b.setValue(z + ht * P, ke[ht], "*"), b.setValue(oe + ht * P, $[o[ht]], "*");
          for (let ht = 0; ht < Te; ht++)
            b.setValue(ye + ht * P, Le[ht], "*"), b.setValue(Pe + ht * P, V[g[ht]], "*");
          if (G && !X) {
            let { handle: ht, outputPreferredLocations: Ot, outputPreferredLocationsEncoded: xt } = G;
            if ($.length !== re)
              throw new Error(`input count from feeds (${re}) is expected to be always equal to model's input count (${$.length}).`);
            for (let Ct = 0; Ct < re; Ct++) {
              let Ze = o[Ct];
              await b._OrtBindInput(ht, $[Ze], ke[Ct]) !== 0 && pt(`Can't bind input[${Ct}] for session=${s}.`);
            }
            for (let Ct = 0; Ct < Te; Ct++) {
              let Ze = g[Ct];
              (Ue = y[Ct]) != null && Ue[3] ? b._OrtBindOutput(ht, V[Ze], Le[Ct], 0) !== 0 && pt(`Can't bind pre-allocated output[${Ct}] for session=${s}.`) : b._OrtBindOutput(ht, V[Ze], 0, xt[Ze]) !== 0 && pt(`Can't bind output[${Ct}] to ${Ot[Ct]} for session=${s}.`);
            }
            er.set(s, [O, $, V, G, ee, !0]);
          }
          (Je = b.jsepOnRunStart) == null || Je.call(b, O), (st = b.webnnOnRunStart) == null || st.call(b, O);
          let wt;
          G ? wt = await b._OrtRunWithBinding(O, G.handle, Te, ye, ue) : wt = await b._OrtRun(O, oe, z, re, Pe, Te, ye, ue), wt !== 0 && pt("failed to call OrtRun().");
          let yt = [];
          for (let ht = 0; ht < Te; ht++) {
            let Ot = Number(b.getValue(ye + ht * P, "*"));
            if (Ot === Le[ht]) {
              yt.push(y[ht]);
              continue;
            }
            let xt = b.stackSave(), Ct = b.stackAlloc(4 * P), Ze = !1, ft, St = 0;
            try {
              b._OrtGetTensorData(Ot, Ct, Ct + P, Ct + 2 * P, Ct + 3 * P) !== 0 && pt(`Can't access output tensor data on index ${ht}.`);
              let Ht = P === 4 ? "i32" : "i64", cn = Number(b.getValue(Ct, Ht));
              St = b.getValue(Ct + P, "*");
              let Sn = b.getValue(Ct + P * 2, "*"), Hn = Number(b.getValue(Ct + P * 3, Ht)), kn = [];
              for (let Pn = 0; Pn < Hn; Pn++)
                kn.push(Number(b.getValue(Sn + Pn * P, Ht)));
              b._OrtFree(Sn) !== 0 && pt("Can't free memory for tensor dims.");
              let Zt = kn.reduce((Pn, On) => Pn * On, 1);
              ft = fi(cn);
              let $n = G == null ? void 0 : G.outputPreferredLocations[g[ht]];
              if (ft === "string") {
                if ($n === "gpu-buffer" || $n === "ml-tensor")
                  throw new Error("String tensor is not supported on GPU.");
                let Pn = [];
                for (let On = 0; On < Zt; On++) {
                  let qn = b.getValue(St + On * P, "*"), Hi = b.getValue(St + (On + 1) * P, "*"), Cc = On === Zt - 1 ? void 0 : Hi - qn;
                  Pn.push(b.UTF8ToString(qn, Cc));
                }
                yt.push([ft, kn, Pn, "cpu"]);
              } else if ($n === "gpu-buffer" && Zt > 0) {
                let Pn = b.jsepGetBuffer;
                if (!Pn)
                  throw new Error('preferredLocation "gpu-buffer" is not supported without using WebGPU.');
                let On = Pn(St), qn = Pi(cn, Zt);
                if (qn === void 0 || !fs(ft))
                  throw new Error(`Unsupported data type: ${ft}`);
                Ze = !0, yt.push([ft, kn, { gpuBuffer: On, download: b.jsepCreateDownloader(On, qn, ft), dispose: () => {
                  b._OrtReleaseTensor(Ot) !== 0 && pt("Can't release tensor.");
                } }, "gpu-buffer"]);
              } else if ($n === "ml-tensor" && Zt > 0) {
                let Pn = b.webnnEnsureTensor, On = b.webnnIsInt64Supported;
                if (!Pn || !On)
                  throw new Error('preferredLocation "ml-tensor" is not supported without using WebNN.');
                if (Pi(cn, Zt) === void 0 || !Ps(ft))
                  throw new Error(`Unsupported data type: ${ft}`);
                if (ft === "int64" && !On(s))
                  throw new Error('preferredLocation "ml-tensor" for int64 output is not supported by current WebNN Context.');
                let qn = await Pn(s, St, cn, kn, !1);
                Ze = !0, yt.push([ft, kn, { mlTensor: qn, download: b.webnnCreateMLTensorDownloader(St, ft), dispose: () => {
                  b.webnnReleaseTensorId(St), b._OrtReleaseTensor(Ot);
                } }, "ml-tensor"]);
              } else {
                let Pn = wi(ft), On = new Pn(Zt);
                new Uint8Array(On.buffer, On.byteOffset, On.byteLength).set(b.HEAPU8.subarray(St, St + On.byteLength)), yt.push([ft, kn, On, "cpu"]);
              }
            } finally {
              b.stackRestore(xt), ft === "string" && St && b._free(St), Ze || b._OrtReleaseTensor(Ot), (gt = b.webnnOnRunEnd) == null || gt.call(b, O);
            }
          }
          return G && !ee && (b._OrtClearBoundOutputs(G.handle) !== 0 && pt("Can't clear bound outputs."), er.set(s, [O, $, V, G, ee, !1])), yt;
        } finally {
          b.stackRestore(C), ke.forEach((wt) => b._OrtReleaseTensor(wt)), Le.forEach((wt) => b._OrtReleaseTensor(wt)), M.forEach((wt) => b._free(wt)), ue !== 0 && b._OrtReleaseRunOptions(ue), ce.forEach((wt) => b._free(wt));
        }
      }, bc = (s) => {
        let o = se(), d = er.get(s);
        if (!d)
          throw new Error("invalid session id");
        let g = d[0], y = o._OrtEndProfiling(g);
        y === 0 && pt("Can't get an profile file name."), o._OrtFree(y);
      }, Mc = (s) => {
        let o = [];
        for (let d of s) {
          let g = d[2];
          !Array.isArray(g) && "buffer" in g && o.push(g.buffer);
        }
        return o;
      };
    }), Os, Mi, Kr, Xr, Yr, Zo, Tc, ea, nr, br, Xp, Ec, Yp, Jp, Qp, Zp, em, tm, nm = l(() => {
      qe(), Kp(), ge(), Me(), Os = () => !!R.wasm.proxy && typeof document < "u", Kr = !1, Xr = !1, Yr = !1, ea = /* @__PURE__ */ new Map(), nr = (s, o) => {
        let d = ea.get(s);
        d ? d.push(o) : ea.set(s, [o]);
      }, br = () => {
        if (Kr || !Xr || Yr || !Mi)
          throw new Error("worker not ready");
      }, Xp = (s) => {
        switch (s.data.type) {
          case "init-wasm":
            Kr = !1, s.data.err ? (Yr = !0, Tc[1](s.data.err)) : (Xr = !0, Tc[0]()), Zo && (URL.revokeObjectURL(Zo), Zo = void 0);
            break;
          case "init-ep":
          case "copy-from":
          case "create":
          case "release":
          case "run":
          case "end-profiling": {
            let o = ea.get(s.data.type);
            s.data.err ? o.shift()[1](s.data.err) : o.shift()[0](s.data.out);
            break;
          }
        }
      }, Ec = async () => {
        if (!Xr) {
          if (Kr)
            throw new Error("multiple calls to 'initWasm()' detected.");
          if (Yr)
            throw new Error("previous call to 'initWasm()' failed.");
          if (Kr = !0, Os())
            return new Promise((s, o) => {
              Mi == null || Mi.terminate(), Si().then(([d, g]) => {
                try {
                  Mi = g, Mi.onerror = (x) => o(x), Mi.onmessage = Xp, Tc = [s, o];
                  let y = { type: "init-wasm", in: R };
                  if (!y.in.wasm.wasmPaths && d) {
                    let x = ln();
                    x && (y.in.wasm.wasmPaths = x);
                  }
                  Mi.postMessage(y), Zo = d;
                } catch (y) {
                  o(y);
                }
              }, o);
            });
          try {
            await J(R.wasm), await gc(R), Xr = !0;
          } catch (s) {
            throw Yr = !0, s;
          } finally {
            Kr = !1;
          }
        }
      }, Yp = async (s) => {
        if (Os())
          return br(), new Promise((o, d) => {
            nr("init-ep", [o, d]);
            let g = { type: "init-ep", in: { epName: s, env: R } };
            Mi.postMessage(g);
          });
        await _c(R, s);
      }, Jp = async (s) => Os() ? (br(), new Promise((o, d) => {
        nr("copy-from", [o, d]);
        let g = { type: "copy-from", in: { buffer: s } };
        Mi.postMessage(g, [s.buffer]);
      })) : Qo(s), Qp = async (s, o) => {
        if (Os()) {
          if (o != null && o.preferredOutputLocation)
            throw new Error('session option "preferredOutputLocation" is not supported for proxy.');
          return br(), new Promise((d, g) => {
            nr("create", [d, g]);
            let y = { type: "create", in: { model: s, options: { ...o } } }, x = [];
            s instanceof Uint8Array && x.push(s.buffer), Mi.postMessage(y, x);
          });
        } else
          return tr(s, o);
      }, Zp = async (s) => {
        if (Os())
          return br(), new Promise((o, d) => {
            nr("release", [o, d]);
            let g = { type: "release", in: s };
            Mi.postMessage(g);
          });
        vc(s);
      }, em = async (s, o, d, g, y, x) => {
        if (Os()) {
          if (d.some((b) => b[3] !== "cpu"))
            throw new Error("input tensor on GPU is not supported for proxy.");
          if (y.some((b) => b))
            throw new Error("pre-allocated output tensor is not supported for proxy.");
          return br(), new Promise((b, P) => {
            nr("run", [b, P]);
            let k = d, O = { type: "run", in: { sessionId: s, inputIndices: o, inputs: k, outputIndices: g, options: x } };
            Mi.postMessage(O, Mc(k));
          });
        } else
          return xc(s, o, d, g, y, x);
      }, tm = async (s) => {
        if (Os())
          return br(), new Promise((o, d) => {
            nr("end-profiling", [o, d]);
            let g = { type: "end-profiling", in: s };
            Mi.postMessage(g);
          });
        bc(s);
      };
    }), Sc, im, sm, Xg = l(() => {
      qe(), nm(), jt(), tt(), Ws(), Sc = (s, o) => {
        switch (s.location) {
          case "cpu":
            return [s.type, s.dims, s.data, "cpu"];
          case "gpu-buffer":
            return [s.type, s.dims, { gpuBuffer: s.gpuBuffer }, "gpu-buffer"];
          case "ml-tensor":
            return [s.type, s.dims, { mlTensor: s.mlTensor }, "ml-tensor"];
          default:
            throw new Error(`invalid data location: ${s.location} for ${o()}`);
        }
      }, im = (s) => {
        switch (s[3]) {
          case "cpu":
            return new Be(s[0], s[2], s[1]);
          case "gpu-buffer": {
            let o = s[0];
            if (!fs(o))
              throw new Error(`not supported data type: ${o} for deserializing GPU tensor`);
            let { gpuBuffer: d, download: g, dispose: y } = s[2];
            return Be.fromGpuBuffer(d, { dataType: o, dims: s[1], download: g, dispose: y });
          }
          case "ml-tensor": {
            let o = s[0];
            if (!Ps(o))
              throw new Error(`not supported data type: ${o} for deserializing MLTensor tensor`);
            let { mlTensor: d, download: g, dispose: y } = s[2];
            return Be.fromMLTensor(d, { dataType: o, dims: s[1], download: g, dispose: y });
          }
          default:
            throw new Error(`invalid data location: ${s[3]}`);
        }
      }, sm = class {
        async fetchModelAndCopyToWasmMemory(s) {
          return Jp(await Ni(s));
        }
        async loadModel(s, o) {
          ze();
          let d;
          typeof s == "string" ? d = await this.fetchModelAndCopyToWasmMemory(s) : d = s, [this.sessionId, this.inputNames, this.outputNames, this.inputMetadata, this.outputMetadata] = await Qp(d, o), Oe();
        }
        async dispose() {
          return Zp(this.sessionId);
        }
        async run(s, o, d) {
          ze();
          let g = [], y = [];
          Object.entries(s).forEach((V) => {
            let G = V[0], ee = V[1], X = this.inputNames.indexOf(G);
            if (X === -1)
              throw new Error(`invalid input '${G}'`);
            g.push(ee), y.push(X);
          });
          let x = [], b = [];
          Object.entries(o).forEach((V) => {
            let G = V[0], ee = V[1], X = this.outputNames.indexOf(G);
            if (X === -1)
              throw new Error(`invalid output '${G}'`);
            x.push(ee), b.push(X);
          });
          let P = g.map((V, G) => Sc(V, () => `input "${this.inputNames[y[G]]}"`)), k = x.map((V, G) => V ? Sc(V, () => `output "${this.outputNames[b[G]]}"`) : null), O = await em(this.sessionId, y, P, b, k, d), $ = {};
          for (let V = 0; V < O.length; V++)
            $[this.outputNames[b[V]]] = x[V] ?? im(O[V]);
          return Oe(), $;
        }
        startProfiling() {
        }
        endProfiling() {
          tm(this.sessionId);
        }
      };
    }), rm = {};
    f(rm, { OnnxruntimeWebAssemblyBackend: () => Ac, initializeFlags: () => Pc, wasmBackend: () => om });
    var Pc, Ac, om, Yg = l(() => {
      qe(), nm(), Xg(), Pc = () => {
        (typeof R.wasm.initTimeout != "number" || R.wasm.initTimeout < 0) && (R.wasm.initTimeout = 0);
        let s = R.wasm.simd;
        if (typeof s != "boolean" && s !== void 0 && s !== "fixed" && s !== "relaxed" && (console.warn(`Property "env.wasm.simd" is set to unknown value "${s}". Reset it to \`false\` and ignore SIMD feature checking.`), R.wasm.simd = !1), typeof R.wasm.proxy != "boolean" && (R.wasm.proxy = !1), typeof R.wasm.trace != "boolean" && (R.wasm.trace = !1), typeof R.wasm.numThreads != "number" || !Number.isInteger(R.wasm.numThreads) || R.wasm.numThreads <= 0)
          if (typeof self < "u" && !self.crossOriginIsolated)
            R.wasm.numThreads = 1;
          else {
            let o = typeof navigator > "u" ? u("node:os").cpus().length : navigator.hardwareConcurrency;
            R.wasm.numThreads = Math.min(4, Math.ceil((o || 1) / 2));
          }
      }, Ac = class {
        async init(s) {
          Pc(), await Ec(), await Yp(s);
        }
        async createInferenceSessionHandler(s, o) {
          let d = new sm();
          return await d.loadModel(s, o), d;
        }
      }, om = new Ac();
    }), am = {};
    f(am, { InferenceSession: () => $e, TRACE: () => U, TRACE_FUNC_BEGIN: () => ze, TRACE_FUNC_END: () => Oe, Tensor: () => Be, default: () => Qg, env: () => R, registerBackend: () => v }), qe(), qe(), qe();
    var Jg = "1.22.0-dev.20250409-89f8206ba4", Qg = de;
    {
      let s = (Yg(), h(rm)).wasmBackend;
      v("webgpu", s, 5), v("webnn", s, 5), v("cpu", s, 10), v("wasm", s, 10);
    }
    return Object.defineProperty(R.versions, "web", { value: Jg, enumerable: !0 }), h(am);
  })();
  /**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   */
  /**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   */
  /**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   */
  e.exports = t;
})(Sb);
var Cb = Sb.exports;
const YP = /* @__PURE__ */ XP(Cb), JP = /* @__PURE__ */ zb({
  __proto__: null,
  default: YP
}, [Cb]);
var QP = {
  /***/
  "onnxruntime-common": (
    /*!*************************************!*\
      !*** external "onnxruntime-common" ***!
      \*************************************/
    /***/
    (e) => {
      e.exports = KP;
    }
  ),
  /***/
  "onnxruntime-web": (
    /*!**********************************!*\
      !*** external "onnxruntime-web" ***!
      \**********************************/
    /***/
    (e) => {
      e.exports = JP;
    }
  ),
  /***/
  "?2ce3": (
    /*!**********************************!*\
      !*** onnxruntime-node (ignored) ***!
      \**********************************/
    /***/
    () => {
    }
  ),
  /***/
  "?7992": (
    /*!*************************!*\
      !*** node:fs (ignored) ***!
      \*************************/
    /***/
    () => {
    }
  ),
  /***/
  "?5af5": (
    /*!***************************!*\
      !*** node:path (ignored) ***!
      \***************************/
    /***/
    () => {
    }
  ),
  /***/
  "?2b25": (
    /*!***********************!*\
      !*** sharp (ignored) ***!
      \***********************/
    /***/
    () => {
    }
  ),
  /***/
  "?db59": (
    /*!*************************!*\
      !*** node:fs (ignored) ***!
      \*************************/
    /***/
    () => {
    }
  ),
  /***/
  "?383f": (
    /*!***************************!*\
      !*** node:path (ignored) ***!
      \***************************/
    /***/
    () => {
    }
  ),
  /***/
  "?fa4b": (
    /*!**************************!*\
      !*** node:url (ignored) ***!
      \**************************/
    /***/
    () => {
    }
  ),
  /***/
  "./node_modules/@huggingface/jinja/dist/index.js": (
    /*!*******************************************************!*\
      !*** ./node_modules/@huggingface/jinja/dist/index.js ***!
      \*******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Environment: () => (
          /* binding */
          lt
        ),
        /* harmony export */
        Interpreter: () => (
          /* binding */
          vn
        ),
        /* harmony export */
        Template: () => (
          /* binding */
          on
        ),
        /* harmony export */
        parse: () => (
          /* binding */
          et
        ),
        /* harmony export */
        tokenize: () => (
          /* binding */
          h
        )
        /* harmony export */
      });
      var i = Object.freeze({
        Text: "Text",
        // The text between Jinja statements or expressions
        NumericLiteral: "NumericLiteral",
        // e.g., 123, 1.0
        StringLiteral: "StringLiteral",
        // 'string'
        Identifier: "Identifier",
        // Variables, functions, statements, booleans, etc.
        Equals: "Equals",
        // =
        OpenParen: "OpenParen",
        // (
        CloseParen: "CloseParen",
        // )
        OpenStatement: "OpenStatement",
        // {%
        CloseStatement: "CloseStatement",
        // %}
        OpenExpression: "OpenExpression",
        // {{
        CloseExpression: "CloseExpression",
        // }}
        OpenSquareBracket: "OpenSquareBracket",
        // [
        CloseSquareBracket: "CloseSquareBracket",
        // ]
        OpenCurlyBracket: "OpenCurlyBracket",
        // {
        CloseCurlyBracket: "CloseCurlyBracket",
        // }
        Comma: "Comma",
        // ,
        Dot: "Dot",
        // .
        Colon: "Colon",
        // :
        Pipe: "Pipe",
        // |
        CallOperator: "CallOperator",
        // ()
        AdditiveBinaryOperator: "AdditiveBinaryOperator",
        // + - ~
        MultiplicativeBinaryOperator: "MultiplicativeBinaryOperator",
        // * / %
        ComparisonBinaryOperator: "ComparisonBinaryOperator",
        // < > <= >= == !=
        UnaryOperator: "UnaryOperator",
        // ! - +
        Comment: "Comment"
        // {# ... #}
      }), r = class {
        /**
         * Constructs a new Token.
         * @param {string} value The raw value as seen inside the source code.
         * @param {TokenType} type The type of token.
         */
        constructor(B, le) {
          this.value = B, this.type = le;
        }
      };
      function a(B) {
        return /\w/.test(B);
      }
      function c(B) {
        return /[0-9]/.test(B);
      }
      function u(B) {
        return /\s/.test(B);
      }
      var l = [
        // Control sequences
        ["{%", i.OpenStatement],
        ["%}", i.CloseStatement],
        ["{{", i.OpenExpression],
        ["}}", i.CloseExpression],
        // Single character tokens
        ["(", i.OpenParen],
        [")", i.CloseParen],
        ["{", i.OpenCurlyBracket],
        ["}", i.CloseCurlyBracket],
        ["[", i.OpenSquareBracket],
        ["]", i.CloseSquareBracket],
        [",", i.Comma],
        [".", i.Dot],
        [":", i.Colon],
        ["|", i.Pipe],
        // Comparison operators
        ["<=", i.ComparisonBinaryOperator],
        [">=", i.ComparisonBinaryOperator],
        ["==", i.ComparisonBinaryOperator],
        ["!=", i.ComparisonBinaryOperator],
        ["<", i.ComparisonBinaryOperator],
        [">", i.ComparisonBinaryOperator],
        // Arithmetic operators
        ["+", i.AdditiveBinaryOperator],
        ["-", i.AdditiveBinaryOperator],
        ["~", i.AdditiveBinaryOperator],
        ["*", i.MultiplicativeBinaryOperator],
        ["/", i.MultiplicativeBinaryOperator],
        ["%", i.MultiplicativeBinaryOperator],
        // Assignment operator
        ["=", i.Equals]
      ], f = /* @__PURE__ */ new Map([
        ["n", `
`],
        // New line
        ["t", "	"],
        // Horizontal tab
        ["r", "\r"],
        // Carriage return
        ["b", "\b"],
        // Backspace
        ["f", "\f"],
        // Form feed
        ["v", "\v"],
        // Vertical tab
        ["'", "'"],
        // Single quote
        ['"', '"'],
        // Double quote
        ["\\", "\\"]
        // Backslash
      ]);
      function m(B, le = {}) {
        return B.endsWith(`
`) && (B = B.slice(0, -1)), le.lstrip_blocks && (B = B.replace(/^[ \t]*({[#%-])/gm, "$1")), le.trim_blocks && (B = B.replace(/([#%-]})\n/g, "$1")), B.replace(/{%\s*(end)?generation\s*%}/gs, "");
      }
      function h(B, le = {}) {
        var Tt, en;
        const J = [], se = m(B, le);
        let ge = 0, Fe = 0;
        const Ke = (Dt) => {
          let tn = "";
          for (; Dt(se[ge]); ) {
            if (se[ge] === "\\") {
              if (++ge, ge >= se.length)
                throw new SyntaxError("Unexpected end of input");
              const Vt = se[ge++], nn = f.get(Vt);
              if (nn === void 0)
                throw new SyntaxError(`Unexpected escaped character: ${Vt}`);
              tn += nn;
              continue;
            }
            if (tn += se[ge++], ge >= se.length)
              throw new SyntaxError("Unexpected end of input");
          }
          return tn;
        }, pt = () => {
          const Dt = J.at(-1);
          Dt && Dt.type === i.Text && (Dt.value = Dt.value.trimEnd(), Dt.value === "" && J.pop());
        }, Pt = () => {
          for (; ge < se.length && u(se[ge]); )
            ++ge;
        };
        e:
          for (; ge < se.length; ) {
            const Dt = (Tt = J.at(-1)) == null ? void 0 : Tt.type;
            if (Dt === void 0 || Dt === i.CloseStatement || Dt === i.CloseExpression || Dt === i.Comment) {
              let Vt = "";
              for (; ge < se.length && // Keep going until we hit the next Jinja statement or expression
              !(se[ge] === "{" && (se[ge + 1] === "%" || se[ge + 1] === "{" || se[ge + 1] === "#")); )
                Vt += se[ge++];
              if (Vt.length > 0) {
                J.push(new r(Vt, i.Text));
                continue;
              }
            }
            if (se[ge] === "{" && se[ge + 1] === "#") {
              ge += 2;
              const Vt = se[ge] === "-";
              Vt && ++ge;
              let nn = "";
              for (; se[ge] !== "#" || se[ge + 1] !== "}"; ) {
                if (ge + 2 >= se.length)
                  throw new SyntaxError("Missing end of comment tag");
                nn += se[ge++];
              }
              const Mn = nn.endsWith("-");
              Mn && (nn = nn.slice(0, -1)), Vt && pt(), J.push(new r(nn, i.Comment)), ge += 2, Mn && Pt();
              continue;
            }
            if (se.slice(ge, ge + 3) === "{%-") {
              pt(), J.push(new r("{%", i.OpenStatement)), ge += 3;
              continue;
            }
            if (se.slice(ge, ge + 3) === "{{-") {
              pt(), J.push(new r("{{", i.OpenExpression)), Fe = 0, ge += 3;
              continue;
            }
            if (Ke(u), se.slice(ge, ge + 3) === "-%}") {
              J.push(new r("%}", i.CloseStatement)), ge += 3, Pt();
              continue;
            }
            if (se.slice(ge, ge + 3) === "-}}") {
              J.push(new r("}}", i.CloseExpression)), ge += 3, Pt();
              continue;
            }
            const tn = se[ge];
            if (tn === "-" || tn === "+") {
              const Vt = (en = J.at(-1)) == null ? void 0 : en.type;
              if (Vt === i.Text || Vt === void 0)
                throw new SyntaxError(`Unexpected character: ${tn}`);
              switch (Vt) {
                case i.Identifier:
                case i.NumericLiteral:
                case i.StringLiteral:
                case i.CloseParen:
                case i.CloseSquareBracket:
                  break;
                default: {
                  ++ge;
                  const nn = Ke(c);
                  J.push(
                    new r(`${tn}${nn}`, nn.length > 0 ? i.NumericLiteral : i.UnaryOperator)
                  );
                  continue;
                }
              }
            }
            for (const [Vt, nn] of l) {
              if (Vt === "}}" && Fe > 0)
                continue;
              if (se.slice(ge, ge + Vt.length) === Vt) {
                J.push(new r(Vt, nn)), nn === i.OpenExpression ? Fe = 0 : nn === i.OpenCurlyBracket ? ++Fe : nn === i.CloseCurlyBracket && --Fe, ge += Vt.length;
                continue e;
              }
            }
            if (tn === "'" || tn === '"') {
              ++ge;
              const Vt = Ke((nn) => nn !== tn);
              J.push(new r(Vt, i.StringLiteral)), ++ge;
              continue;
            }
            if (c(tn)) {
              let Vt = Ke(c);
              if (se[ge] === "." && c(se[ge + 1])) {
                ++ge;
                const nn = Ke(c);
                Vt = `${Vt}.${nn}`;
              }
              J.push(new r(Vt, i.NumericLiteral));
              continue;
            }
            if (a(tn)) {
              const Vt = Ke(a);
              J.push(new r(Vt, i.Identifier));
              continue;
            }
            throw new SyntaxError(`Unexpected character: ${tn}`);
          }
        return J;
      }
      var p = class {
        constructor() {
          Ce(this, "type", "Statement");
        }
      }, _ = class extends p {
        constructor(le) {
          super();
          Ce(this, "type", "Program");
          this.body = le;
        }
      }, v = class extends p {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "If");
          this.test = le, this.body = J, this.alternate = se;
        }
      }, S = class extends p {
        constructor(le, J, se, ge) {
          super();
          Ce(this, "type", "For");
          this.loopvar = le, this.iterable = J, this.body = se, this.defaultBlock = ge;
        }
      }, D = class extends p {
        constructor() {
          super(...arguments);
          Ce(this, "type", "Break");
        }
      }, w = class extends p {
        constructor() {
          super(...arguments);
          Ce(this, "type", "Continue");
        }
      }, T = class extends p {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "Set");
          this.assignee = le, this.value = J, this.body = se;
        }
      }, F = class extends p {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "Macro");
          this.name = le, this.args = J, this.body = se;
        }
      }, E = class extends p {
        constructor(le) {
          super();
          Ce(this, "type", "Comment");
          this.value = le;
        }
      }, A = class extends p {
        constructor() {
          super(...arguments);
          Ce(this, "type", "Expression");
        }
      }, L = class extends A {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "MemberExpression");
          this.object = le, this.property = J, this.computed = se;
        }
      }, I = class extends A {
        constructor(le, J) {
          super();
          Ce(this, "type", "CallExpression");
          this.callee = le, this.args = J;
        }
      }, R = class extends A {
        /**
         * @param {string} value The name of the identifier
         */
        constructor(le) {
          super();
          Ce(this, "type", "Identifier");
          this.value = le;
        }
      }, N = class extends A {
        constructor(le) {
          super();
          Ce(this, "type", "Literal");
          this.value = le;
        }
      }, q = class extends N {
        constructor() {
          super(...arguments);
          Ce(this, "type", "IntegerLiteral");
        }
      }, ne = class extends N {
        constructor() {
          super(...arguments);
          Ce(this, "type", "FloatLiteral");
        }
      }, Q = class extends N {
        constructor() {
          super(...arguments);
          Ce(this, "type", "StringLiteral");
        }
      }, W = class extends N {
        constructor() {
          super(...arguments);
          Ce(this, "type", "ArrayLiteral");
        }
      }, te = class extends N {
        constructor() {
          super(...arguments);
          Ce(this, "type", "TupleLiteral");
        }
      }, K = class extends N {
        constructor() {
          super(...arguments);
          Ce(this, "type", "ObjectLiteral");
        }
      }, pe = class extends A {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "BinaryExpression");
          this.operator = le, this.left = J, this.right = se;
        }
      }, be = class extends A {
        constructor(le, J) {
          super();
          Ce(this, "type", "FilterExpression");
          this.operand = le, this.filter = J;
        }
      }, Ee = class extends p {
        constructor(le, J) {
          super();
          Ce(this, "type", "FilterStatement");
          this.filter = le, this.body = J;
        }
      }, Ge = class extends A {
        constructor(le, J) {
          super();
          Ce(this, "type", "SelectExpression");
          this.lhs = le, this.test = J;
        }
      }, _e = class extends A {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "TestExpression");
          this.operand = le, this.negate = J, this.test = se;
        }
      }, De = class extends A {
        constructor(le, J) {
          super();
          Ce(this, "type", "UnaryExpression");
          this.operator = le, this.argument = J;
        }
      }, he = class extends A {
        constructor(le = void 0, J = void 0, se = void 0) {
          super();
          Ce(this, "type", "SliceExpression");
          this.start = le, this.stop = J, this.step = se;
        }
      }, Z = class extends A {
        constructor(le, J) {
          super();
          Ce(this, "type", "KeywordArgumentExpression");
          this.key = le, this.value = J;
        }
      }, me = class extends A {
        constructor(le) {
          super();
          Ce(this, "type", "SpreadExpression");
          this.argument = le;
        }
      }, we = class extends p {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "CallStatement");
          this.call = le, this.callerArgs = J, this.body = se;
        }
      }, xe = class extends A {
        constructor(le, J, se) {
          super();
          Ce(this, "type", "Ternary");
          this.condition = le, this.trueExpr = J, this.falseExpr = se;
        }
      };
      function et(B) {
        const le = new _([]);
        let J = 0;
        function se(bt, ct) {
          const Lt = B[J++];
          if (!Lt || Lt.type !== bt)
            throw new Error(`Parser Error: ${ct}. ${Lt.type} !== ${bt}.`);
          return Lt;
        }
        function ge(bt) {
          if (!Pt(bt))
            throw new SyntaxError(`Expected ${bt}`);
          ++J;
        }
        function Fe() {
          switch (B[J].type) {
            case i.Comment:
              return new E(B[J++].value);
            case i.Text:
              return Tt();
            case i.OpenStatement:
              return en();
            case i.OpenExpression:
              return Dt();
            default:
              throw new SyntaxError(`Unexpected token type: ${B[J].type}`);
          }
        }
        function Ke(...bt) {
          return J + bt.length <= B.length && bt.every((ct, Lt) => ct === B[J + Lt].type);
        }
        function pt(...bt) {
          var ct, Lt, yn;
          return ((ct = B[J]) == null ? void 0 : ct.type) === i.OpenStatement && ((Lt = B[J + 1]) == null ? void 0 : Lt.type) === i.Identifier && bt.includes((yn = B[J + 1]) == null ? void 0 : yn.value);
        }
        function Pt(...bt) {
          return J + bt.length <= B.length && bt.every((ct, Lt) => B[J + Lt].type === "Identifier" && ct === B[J + Lt].value);
        }
        function Tt() {
          return new Q(se(i.Text, "Expected text token").value);
        }
        function en() {
          if (se(i.OpenStatement, "Expected opening statement token"), B[J].type !== i.Identifier)
            throw new SyntaxError(`Unknown statement, got ${B[J].type}`);
          const bt = B[J].value;
          let ct;
          switch (bt) {
            case "set":
              ++J, ct = tn();
              break;
            case "if":
              ++J, ct = Vt(), se(i.OpenStatement, "Expected {% token"), ge("endif"), se(i.CloseStatement, "Expected %} token");
              break;
            case "macro":
              ++J, ct = nn(), se(i.OpenStatement, "Expected {% token"), ge("endmacro"), se(i.CloseStatement, "Expected %} token");
              break;
            case "for":
              ++J, ct = vi(), se(i.OpenStatement, "Expected {% token"), ge("endfor"), se(i.CloseStatement, "Expected %} token");
              break;
            case "call": {
              ++J;
              let Lt = null;
              Ke(i.OpenParen) && (Lt = jt());
              const yn = pi();
              if (yn.type !== "Identifier")
                throw new SyntaxError("Expected identifier following call statement");
              const Ui = jt();
              se(i.CloseStatement, "Expected closing statement token");
              const it = [];
              for (; !pt("endcall"); )
                it.push(Fe());
              se(i.OpenStatement, "Expected '{%'"), ge("endcall"), se(i.CloseStatement, "Expected closing statement token");
              const ps = new I(yn, Ui);
              ct = new we(ps, Lt, it);
              break;
            }
            case "break":
              ++J, se(i.CloseStatement, "Expected closing statement token"), ct = new D();
              break;
            case "continue":
              ++J, se(i.CloseStatement, "Expected closing statement token"), ct = new w();
              break;
            case "filter": {
              ++J;
              let Lt = pi();
              Lt instanceof R && Ke(i.OpenParen) && (Lt = Oi(Lt)), se(i.CloseStatement, "Expected closing statement token");
              const yn = [];
              for (; !pt("endfilter"); )
                yn.push(Fe());
              se(i.OpenStatement, "Expected '{%'"), ge("endfilter"), se(i.CloseStatement, "Expected '%}'"), ct = new Ee(Lt, yn);
              break;
            }
            default:
              throw new SyntaxError(`Unknown statement type: ${bt}`);
          }
          return ct;
        }
        function Dt() {
          se(i.OpenExpression, "Expected opening expression token");
          const bt = ci();
          return se(i.CloseExpression, "Expected closing expression token"), bt;
        }
        function tn() {
          const bt = Mn();
          let ct = null;
          const Lt = [];
          if (Ke(i.Equals))
            ++J, ct = Mn();
          else {
            for (se(i.CloseStatement, "Expected %} token"); !pt("endset"); )
              Lt.push(Fe());
            se(i.OpenStatement, "Expected {% token"), ge("endset");
          }
          return se(i.CloseStatement, "Expected closing statement token"), new T(bt, ct, Lt);
        }
        function Vt() {
          const bt = ci();
          se(i.CloseStatement, "Expected closing statement token");
          const ct = [], Lt = [];
          for (; !pt("elif", "else", "endif"); )
            ct.push(Fe());
          if (pt("elif")) {
            ++J, ++J;
            const yn = Vt();
            Lt.push(yn);
          } else if (pt("else"))
            for (++J, ++J, se(i.CloseStatement, "Expected closing statement token"); !pt("endif"); )
              Lt.push(Fe());
          return new v(bt, ct, Lt);
        }
        function nn() {
          const bt = pi();
          if (bt.type !== "Identifier")
            throw new SyntaxError("Expected identifier following macro statement");
          const ct = jt();
          se(i.CloseStatement, "Expected closing statement token");
          const Lt = [];
          for (; !pt("endmacro"); )
            Lt.push(Fe());
          return new F(bt, ct, Lt);
        }
        function Mn(bt = !1) {
          const ct = bt ? pi : ci, Lt = [ct()], yn = Ke(i.Comma);
          for (; yn && (++J, Lt.push(ct()), !!Ke(i.Comma)); )
            ;
          return yn ? new te(Lt) : Lt[0];
        }
        function vi() {
          const bt = Mn(!0);
          if (!(bt instanceof R || bt instanceof te))
            throw new SyntaxError(`Expected identifier/tuple for the loop variable, got ${bt.type} instead`);
          if (!Pt("in"))
            throw new SyntaxError("Expected `in` keyword following loop variable");
          ++J;
          const ct = ci();
          se(i.CloseStatement, "Expected closing statement token");
          const Lt = [];
          for (; !pt("endfor", "else"); )
            Lt.push(Fe());
          const yn = [];
          if (pt("else"))
            for (++J, ++J, se(i.CloseStatement, "Expected closing statement token"); !pt("endfor"); )
              yn.push(Fe());
          return new S(bt, ct, Lt, yn);
        }
        function ci() {
          return ki();
        }
        function ki() {
          const bt = fi();
          if (Pt("if")) {
            ++J;
            const ct = fi();
            if (Pt("else")) {
              ++J;
              const Lt = ki();
              return new xe(ct, bt, Lt);
            } else
              return new Ge(bt, ct);
          }
          return bt;
        }
        function fi() {
          let bt = Pi();
          for (; Pt("or"); ) {
            const ct = B[J];
            ++J;
            const Lt = Pi();
            bt = new pe(ct, bt, Lt);
          }
          return bt;
        }
        function Pi() {
          let bt = wi();
          for (; Pt("and"); ) {
            const ct = B[J];
            ++J;
            const Lt = wi();
            bt = new pe(ct, bt, Lt);
          }
          return bt;
        }
        function wi() {
          let bt;
          for (; Pt("not"); ) {
            const ct = B[J];
            ++J;
            const Lt = wi();
            bt = new De(ct, Lt);
          }
          return bt ?? hs();
        }
        function hs() {
          let bt = fs();
          for (; ; ) {
            let ct;
            if (Pt("not", "in"))
              ct = new r("not in", i.Identifier), J += 2;
            else if (Pt("in"))
              ct = B[J++];
            else if (Ke(i.ComparisonBinaryOperator))
              ct = B[J++];
            else
              break;
            const Lt = fs();
            bt = new pe(ct, bt, Lt);
          }
          return bt;
        }
        function fs() {
          let bt = Cs();
          for (; Ke(i.AdditiveBinaryOperator); ) {
            const ct = B[J];
            ++J;
            const Lt = Cs();
            bt = new pe(ct, bt, Lt);
          }
          return bt;
        }
        function Ps() {
          const bt = As(pi());
          return Ke(i.OpenParen) ? Oi(bt) : bt;
        }
        function Oi(bt) {
          let ct = new I(bt, jt());
          return ct = As(ct), Ke(i.OpenParen) && (ct = Oi(ct)), ct;
        }
        function jt() {
          se(i.OpenParen, "Expected opening parenthesis for arguments list");
          const bt = Ni();
          return se(i.CloseParen, "Expected closing parenthesis for arguments list"), bt;
        }
        function Ni() {
          const bt = [];
          for (; !Ke(i.CloseParen); ) {
            let ct;
            if (B[J].type === i.MultiplicativeBinaryOperator && B[J].value === "*") {
              ++J;
              const Lt = ci();
              ct = new me(Lt);
            } else if (ct = ci(), Ke(i.Equals)) {
              if (++J, !(ct instanceof R))
                throw new SyntaxError("Expected identifier for keyword argument");
              const Lt = ci();
              ct = new Z(ct, Lt);
            }
            bt.push(ct), Ke(i.Comma) && ++J;
          }
          return bt;
        }
        function Ws() {
          const bt = [];
          let ct = !1;
          for (; !Ke(i.CloseSquareBracket); )
            Ke(i.Colon) ? (bt.push(void 0), ++J, ct = !0) : (bt.push(ci()), Ke(i.Colon) && (++J, ct = !0));
          if (bt.length === 0)
            throw new SyntaxError("Expected at least one argument for member/slice expression");
          if (ct) {
            if (bt.length > 3)
              throw new SyntaxError("Expected 0-3 arguments for slice expression");
            return new he(...bt);
          }
          return bt[0];
        }
        function As(bt) {
          for (; Ke(i.Dot) || Ke(i.OpenSquareBracket); ) {
            const ct = B[J];
            ++J;
            let Lt;
            const yn = ct.type === i.OpenSquareBracket;
            if (yn)
              Lt = Ws(), se(i.CloseSquareBracket, "Expected closing square bracket");
            else if (Lt = pi(), Lt.type !== "Identifier")
              throw new SyntaxError("Expected identifier following dot operator");
            bt = new L(bt, Lt, yn);
          }
          return bt;
        }
        function Cs() {
          let bt = Is();
          for (; Ke(i.MultiplicativeBinaryOperator); ) {
            const ct = B[J++], Lt = Is();
            bt = new pe(ct, bt, Lt);
          }
          return bt;
        }
        function Is() {
          let bt = Ji();
          for (; Pt("is"); ) {
            ++J;
            const ct = Pt("not");
            ct && ++J;
            const Lt = pi();
            if (!(Lt instanceof R))
              throw new SyntaxError("Expected identifier for the test");
            bt = new _e(bt, ct, Lt);
          }
          return bt;
        }
        function Ji() {
          let bt = Ps();
          for (; Ke(i.Pipe); ) {
            ++J;
            let ct = pi();
            if (!(ct instanceof R))
              throw new SyntaxError("Expected identifier for the filter");
            Ke(i.OpenParen) && (ct = Oi(ct)), bt = new be(bt, ct);
          }
          return bt;
        }
        function pi() {
          const bt = B[J++];
          switch (bt.type) {
            case i.NumericLiteral: {
              const ct = bt.value;
              return ct.includes(".") ? new ne(Number(ct)) : new q(Number(ct));
            }
            case i.StringLiteral: {
              let ct = bt.value;
              for (; Ke(i.StringLiteral); )
                ct += B[J++].value;
              return new Q(ct);
            }
            case i.Identifier:
              return new R(bt.value);
            case i.OpenParen: {
              const ct = Mn();
              return se(i.CloseParen, "Expected closing parenthesis, got ${tokens[current].type} instead."), ct;
            }
            case i.OpenSquareBracket: {
              const ct = [];
              for (; !Ke(i.CloseSquareBracket); )
                ct.push(ci()), Ke(i.Comma) && ++J;
              return ++J, new W(ct);
            }
            case i.OpenCurlyBracket: {
              const ct = /* @__PURE__ */ new Map();
              for (; !Ke(i.CloseCurlyBracket); ) {
                const Lt = ci();
                se(i.Colon, "Expected colon between key and value in object literal");
                const yn = ci();
                ct.set(Lt, yn), Ke(i.Comma) && ++J;
              }
              return ++J, new K(ct);
            }
            default:
              throw new SyntaxError(`Unexpected token: ${bt.type}`);
          }
        }
        for (; J < B.length; )
          le.body.push(Fe());
        return le;
      }
      function Ve(B, le, J = 1) {
        le === void 0 && (le = B, B = 0);
        const se = [];
        for (let ge = B; ge < le; ge += J)
          se.push(ge);
        return se;
      }
      function nt(B, le, J, se = 1) {
        const ge = Math.sign(se);
        ge >= 0 ? (le = (le ?? (le = 0)) < 0 ? Math.max(B.length + le, 0) : Math.min(le, B.length), J = (J ?? (J = B.length)) < 0 ? Math.max(B.length + J, 0) : Math.min(J, B.length)) : (le = (le ?? (le = B.length - 1)) < 0 ? Math.max(B.length + le, -1) : Math.min(le, B.length - 1), J = (J ?? (J = -1)) < -1 ? Math.max(B.length + J, -1) : Math.min(J, B.length - 1));
        const Fe = [];
        for (let Ke = le; ge * Ke < ge * J; Ke += se)
          Fe.push(B[Ke]);
        return Fe;
      }
      function Be(B) {
        return B.replace(/\b\w/g, (le) => le.toUpperCase());
      }
      function ae(B) {
        return U(/* @__PURE__ */ new Date(), B);
      }
      function U(B, le) {
        const J = new Intl.DateTimeFormat(void 0, { month: "long" }), se = new Intl.DateTimeFormat(void 0, { month: "short" }), ge = (Fe) => Fe < 10 ? "0" + Fe : Fe.toString();
        return le.replace(/%[YmdbBHM%]/g, (Fe) => {
          switch (Fe) {
            case "%Y":
              return B.getFullYear().toString();
            case "%m":
              return ge(B.getMonth() + 1);
            case "%d":
              return ge(B.getDate());
            case "%b":
              return se.format(B);
            case "%B":
              return J.format(B);
            case "%H":
              return ge(B.getHours());
            case "%M":
              return ge(B.getMinutes());
            case "%%":
              return "%";
            default:
              return Fe;
          }
        });
      }
      function Se(B) {
        return B.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
      }
      function ze(B, le, J, se) {
        if (se === 0)
          return B;
        let ge = se == null || se < 0 ? 1 / 0 : se;
        const Fe = le.length === 0 ? new RegExp("(?=)", "gu") : new RegExp(Se(le), "gu");
        return B.replaceAll(Fe, (Ke) => ge > 0 ? (--ge, J) : Ke);
      }
      var Oe = class extends Error {
      }, Ye = class extends Error {
      }, H = class {
        /**
         * Creates a new RuntimeValue.
         */
        constructor(B = void 0) {
          Ce(this, "type", "RuntimeValue");
          Ce(this, "value");
          /**
           * A collection of built-in functions for this type.
           */
          Ce(this, "builtins", /* @__PURE__ */ new Map());
          this.value = B;
        }
        /**
         * Determines truthiness or falsiness of the runtime value.
         * This function should be overridden by subclasses if it has custom truthiness criteria.
         * @returns {BooleanValue} BooleanValue(true) if the value is truthy, BooleanValue(false) otherwise.
         */
        __bool__() {
          return new fe(!!this.value);
        }
        toString() {
          return String(this.value);
        }
      }, Y = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "IntegerValue");
        }
      }, $e = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "FloatValue");
        }
        toString() {
          return this.value % 1 === 0 ? this.value.toFixed(1) : this.value.toString();
        }
      }, Ie = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "StringValue");
          Ce(this, "builtins", /* @__PURE__ */ new Map([
            [
              "upper",
              new tt(() => new Ie(this.value.toUpperCase()))
            ],
            [
              "lower",
              new tt(() => new Ie(this.value.toLowerCase()))
            ],
            [
              "strip",
              new tt(() => new Ie(this.value.trim()))
            ],
            [
              "title",
              new tt(() => new Ie(Be(this.value)))
            ],
            [
              "capitalize",
              new tt(() => new Ie(this.value.charAt(0).toUpperCase() + this.value.slice(1)))
            ],
            ["length", new Y(this.value.length)],
            [
              "rstrip",
              new tt(() => new Ie(this.value.trimEnd()))
            ],
            [
              "lstrip",
              new tt(() => new Ie(this.value.trimStart()))
            ],
            [
              "startswith",
              new tt((le) => {
                if (le.length === 0)
                  throw new Error("startswith() requires at least one argument");
                const J = le[0];
                if (J instanceof Ie)
                  return new fe(this.value.startsWith(J.value));
                if (J instanceof de) {
                  for (const se of J.value) {
                    if (!(se instanceof Ie))
                      throw new Error("startswith() tuple elements must be strings");
                    if (this.value.startsWith(se.value))
                      return new fe(!0);
                  }
                  return new fe(!1);
                }
                throw new Error("startswith() argument must be a string or tuple of strings");
              })
            ],
            [
              "endswith",
              new tt((le) => {
                if (le.length === 0)
                  throw new Error("endswith() requires at least one argument");
                const J = le[0];
                if (J instanceof Ie)
                  return new fe(this.value.endsWith(J.value));
                if (J instanceof de) {
                  for (const se of J.value) {
                    if (!(se instanceof Ie))
                      throw new Error("endswith() tuple elements must be strings");
                    if (this.value.endsWith(se.value))
                      return new fe(!0);
                  }
                  return new fe(!1);
                }
                throw new Error("endswith() argument must be a string or tuple of strings");
              })
            ],
            [
              "split",
              // follows Python's `str.split(sep=None, maxsplit=-1)` function behavior
              // https://docs.python.org/3.13/library/stdtypes.html#str.split
              new tt((le) => {
                const J = le[0] ?? new He();
                if (!(J instanceof Ie || J instanceof He))
                  throw new Error("sep argument must be a string or null");
                const se = le[1] ?? new Y(-1);
                if (!(se instanceof Y))
                  throw new Error("maxsplit argument must be a number");
                let ge = [];
                if (J instanceof He) {
                  const Fe = this.value.trimStart();
                  for (const { 0: Ke, index: pt } of Fe.matchAll(/\S+/g)) {
                    if (se.value !== -1 && ge.length >= se.value && pt !== void 0) {
                      ge.push(Ke + Fe.slice(pt + Ke.length));
                      break;
                    }
                    ge.push(Ke);
                  }
                } else {
                  if (J.value === "")
                    throw new Error("empty separator");
                  ge = this.value.split(J.value), se.value !== -1 && ge.length > se.value && ge.push(ge.splice(se.value).join(J.value));
                }
                return new de(ge.map((Fe) => new Ie(Fe)));
              })
            ],
            [
              "replace",
              new tt((le) => {
                if (le.length < 2)
                  throw new Error("replace() requires at least two arguments");
                const J = le[0], se = le[1];
                if (!(J instanceof Ie && se instanceof Ie))
                  throw new Error("replace() arguments must be strings");
                let ge;
                if (le.length > 2 ? le[2].type === "KeywordArgumentsValue" ? ge = le[2].value.get("count") ?? new He() : ge = le[2] : ge = new He(), !(ge instanceof Y || ge instanceof He))
                  throw new Error("replace() count argument must be a number or null");
                return new Ie(ze(this.value, J.value, se.value, ge.value));
              })
            ]
          ]));
        }
      }, fe = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "BooleanValue");
        }
      };
      function Qe(B, le, J, se = !0) {
        const ge = J ?? 0;
        switch (B.type) {
          case "NullValue":
            return "null";
          case "UndefinedValue":
            return se ? "null" : "undefined";
          case "IntegerValue":
          case "FloatValue":
          case "StringValue":
          case "BooleanValue":
            return JSON.stringify(B.value);
          case "ArrayValue":
          case "ObjectValue": {
            const Fe = le ? " ".repeat(le) : "", Ke = `
` + Fe.repeat(ge), pt = Ke + Fe;
            if (B.type === "ArrayValue") {
              const Pt = B.value.map(
                (Tt) => Qe(Tt, le, ge + 1, se)
              );
              return le ? `[${pt}${Pt.join(`,${pt}`)}${Ke}]` : `[${Pt.join(", ")}]`;
            } else {
              const Pt = Array.from(B.value.entries()).map(([Tt, en]) => {
                const Dt = `"${Tt}": ${Qe(en, le, ge + 1, se)}`;
                return le ? `${pt}${Dt}` : Dt;
              });
              return le ? `{${Pt.join(",")}${Ke}}` : `{${Pt.join(", ")}}`;
            }
          }
          default:
            throw new Error(`Cannot convert to JSON: ${B.type}`);
        }
      }
      var Ne = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "ObjectValue");
          Ce(this, "builtins", /* @__PURE__ */ new Map([
            [
              "get",
              new tt(([le, J]) => {
                if (!(le instanceof Ie))
                  throw new Error(`Object key must be a string: got ${le.type}`);
                return this.value.get(le.value) ?? J ?? new He();
              })
            ],
            ["items", new tt(() => this.items())],
            ["keys", new tt(() => this.keys())],
            ["values", new tt(() => this.values())],
            [
              "dictsort",
              new tt((le) => {
                let J = /* @__PURE__ */ new Map();
                const se = le.filter((Pt) => Pt instanceof ut ? (J = Pt.value, !1) : !0), ge = se.at(0) ?? J.get("case_sensitive") ?? new fe(!1);
                if (!(ge instanceof fe))
                  throw new Error("case_sensitive must be a boolean");
                const Fe = se.at(1) ?? J.get("by") ?? new Ie("key");
                if (!(Fe instanceof Ie))
                  throw new Error("by must be a string");
                if (!["key", "value"].includes(Fe.value))
                  throw new Error("by must be either 'key' or 'value'");
                const Ke = se.at(2) ?? J.get("reverse") ?? new fe(!1);
                if (!(Ke instanceof fe))
                  throw new Error("reverse must be a boolean");
                const pt = Array.from(this.value.entries()).map(([Pt, Tt]) => new de([new Ie(Pt), Tt])).sort((Pt, Tt) => {
                  const en = Fe.value === "key" ? 0 : 1, Dt = Pt.value[en], tn = Tt.value[en], Vt = Kt(Dt, tn, ge.value);
                  return Ke.value ? -Vt : Vt;
                });
                return new de(pt);
              })
            ]
          ]));
        }
        /**
         * NOTE: necessary to override since all JavaScript arrays are considered truthy,
         * while only non-empty Python arrays are consider truthy.
         *
         * e.g.,
         *  - JavaScript:  {} && 5 -> 5
         *  - Python:      {} and 5 -> {}
         */
        __bool__() {
          return new fe(this.value.size > 0);
        }
        items() {
          return new de(
            Array.from(this.value.entries()).map(([le, J]) => new de([new Ie(le), J]))
          );
        }
        keys() {
          return new de(Array.from(this.value.keys()).map((le) => new Ie(le)));
        }
        values() {
          return new de(Array.from(this.value.values()));
        }
        toString() {
          return Qe(this, null, 0, !1);
        }
      }, ut = class extends Ne {
        constructor() {
          super(...arguments);
          Ce(this, "type", "KeywordArgumentsValue");
        }
      }, de = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "ArrayValue");
          Ce(this, "builtins", /* @__PURE__ */ new Map([["length", new Y(this.value.length)]]));
        }
        /**
         * NOTE: necessary to override since all JavaScript arrays are considered truthy,
         * while only non-empty Python arrays are consider truthy.
         *
         * e.g.,
         *  - JavaScript:  [] && 5 -> 5
         *  - Python:      [] and 5 -> []
         */
        __bool__() {
          return new fe(this.value.length > 0);
        }
        toString() {
          return Qe(this, null, 0, !1);
        }
      }, qe = class extends de {
        constructor() {
          super(...arguments);
          Ce(this, "type", "TupleValue");
        }
      }, tt = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "FunctionValue");
        }
      }, He = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "NullValue");
        }
      }, je = class extends H {
        constructor() {
          super(...arguments);
          Ce(this, "type", "UndefinedValue");
        }
      }, lt = class {
        constructor(B) {
          /**
           * The variables declared in this environment.
           */
          Ce(this, "variables", /* @__PURE__ */ new Map([
            [
              "namespace",
              new tt((B) => {
                if (B.length === 0)
                  return new Ne(/* @__PURE__ */ new Map());
                if (B.length !== 1 || !(B[0] instanceof Ne))
                  throw new Error("`namespace` expects either zero arguments or a single object argument");
                return B[0];
              })
            ]
          ]));
          /**
           * The tests available in this environment.
           */
          Ce(this, "tests", /* @__PURE__ */ new Map([
            ["boolean", (B) => B.type === "BooleanValue"],
            ["callable", (B) => B instanceof tt],
            [
              "odd",
              (B) => {
                if (!(B instanceof Y))
                  throw new Error(`cannot odd on ${B.type}`);
                return B.value % 2 !== 0;
              }
            ],
            [
              "even",
              (B) => {
                if (!(B instanceof Y))
                  throw new Error(`cannot even on ${B.type}`);
                return B.value % 2 === 0;
              }
            ],
            ["false", (B) => B.type === "BooleanValue" && !B.value],
            ["true", (B) => B.type === "BooleanValue" && B.value],
            ["none", (B) => B.type === "NullValue"],
            ["string", (B) => B.type === "StringValue"],
            ["number", (B) => B instanceof Y || B instanceof $e],
            ["integer", (B) => B instanceof Y],
            ["iterable", (B) => B.type === "ArrayValue" || B.type === "StringValue"],
            ["mapping", (B) => B.type === "ObjectValue"],
            [
              "lower",
              (B) => {
                const le = B.value;
                return B.type === "StringValue" && le === le.toLowerCase();
              }
            ],
            [
              "upper",
              (B) => {
                const le = B.value;
                return B.type === "StringValue" && le === le.toUpperCase();
              }
            ],
            ["none", (B) => B.type === "NullValue"],
            ["defined", (B) => B.type !== "UndefinedValue"],
            ["undefined", (B) => B.type === "UndefinedValue"],
            ["equalto", (B, le) => B.value === le.value],
            ["eq", (B, le) => B.value === le.value]
          ]));
          this.parent = B;
        }
        /**
         * Set the value of a variable in the current environment.
         */
        set(B, le) {
          return this.declareVariable(B, wn(le));
        }
        declareVariable(B, le) {
          if (this.variables.has(B))
            throw new SyntaxError(`Variable already declared: ${B}`);
          return this.variables.set(B, le), le;
        }
        // private assignVariable(name: string, value: AnyRuntimeValue): AnyRuntimeValue {
        // 	const env = this.resolve(name);
        // 	env.variables.set(name, value);
        // 	return value;
        // }
        /**
         * Set variable in the current scope.
         * See https://jinja.palletsprojects.com/en/3.0.x/templates/#assignments for more information.
         */
        setVariable(B, le) {
          return this.variables.set(B, le), le;
        }
        /**
         * Resolve the environment in which the variable is declared.
         * @param {string} name The name of the variable.
         * @returns {Environment} The environment in which the variable is declared.
         */
        resolve(B) {
          if (this.variables.has(B))
            return this;
          if (this.parent)
            return this.parent.resolve(B);
          throw new Error(`Unknown variable: ${B}`);
        }
        lookupVariable(B) {
          try {
            return this.resolve(B).variables.get(B) ?? new je();
          } catch {
            return new je();
          }
        }
      };
      function Mt(B) {
        B.set("false", !1), B.set("true", !0), B.set("none", null), B.set("raise_exception", (le) => {
          throw new Error(le);
        }), B.set("range", Ve), B.set("strftime_now", ae), B.set("True", !0), B.set("False", !1), B.set("None", null);
      }
      function Rt(B, le) {
        const J = le.split(".");
        let se = B;
        for (const ge of J)
          if (se instanceof Ne)
            se = se.value.get(ge) ?? new je();
          else if (se instanceof de) {
            const Fe = parseInt(ge, 10);
            if (!isNaN(Fe) && Fe >= 0 && Fe < se.value.length)
              se = se.value[Fe];
            else
              return new je();
          } else
            return new je();
        return se;
      }
      function Kt(B, le, J = !1) {
        if (B instanceof He && le instanceof He)
          return 0;
        if (B instanceof He || le instanceof He)
          throw new Error(`Cannot compare ${B.type} with ${le.type}`);
        if (B instanceof je && le instanceof je)
          return 0;
        if (B instanceof je || le instanceof je)
          throw new Error(`Cannot compare ${B.type} with ${le.type}`);
        const se = (Fe) => Fe instanceof Y || Fe instanceof $e || Fe instanceof fe, ge = (Fe) => Fe instanceof fe ? Fe.value ? 1 : 0 : Fe.value;
        if (se(B) && se(le)) {
          const Fe = ge(B), Ke = ge(le);
          return Fe < Ke ? -1 : Fe > Ke ? 1 : 0;
        }
        if (B.type !== le.type)
          throw new Error(`Cannot compare different types: ${B.type} and ${le.type}`);
        switch (B.type) {
          case "StringValue": {
            let Fe = B.value, Ke = le.value;
            return J || (Fe = Fe.toLowerCase(), Ke = Ke.toLowerCase()), Fe < Ke ? -1 : Fe > Ke ? 1 : 0;
          }
          default:
            throw new Error(`Cannot compare type: ${B.type}`);
        }
      }
      var vn = class {
        constructor(B) {
          Ce(this, "global");
          this.global = B ?? new lt();
        }
        /**
         * Run the program.
         */
        run(B) {
          return this.evaluate(B, this.global);
        }
        /**
         * Evaluates expressions following the binary operation type.
         */
        evaluateBinaryExpression(B, le) {
          const J = this.evaluate(B.left, le);
          switch (B.operator.value) {
            case "and":
              return J.__bool__().value ? this.evaluate(B.right, le) : J;
            case "or":
              return J.__bool__().value ? J : this.evaluate(B.right, le);
          }
          const se = this.evaluate(B.right, le);
          switch (B.operator.value) {
            case "==":
              return new fe(J.value == se.value);
            case "!=":
              return new fe(J.value != se.value);
          }
          if (J instanceof je || se instanceof je) {
            if (se instanceof je && ["in", "not in"].includes(B.operator.value))
              return new fe(B.operator.value === "not in");
            throw new Error(`Cannot perform operation ${B.operator.value} on undefined values`);
          } else {
            if (J instanceof He || se instanceof He)
              throw new Error("Cannot perform operation on null values");
            if (B.operator.value === "~")
              return new Ie(J.value.toString() + se.value.toString());
            if ((J instanceof Y || J instanceof $e) && (se instanceof Y || se instanceof $e)) {
              const ge = J.value, Fe = se.value;
              switch (B.operator.value) {
                case "+":
                case "-":
                case "*": {
                  const Ke = B.operator.value === "+" ? ge + Fe : B.operator.value === "-" ? ge - Fe : ge * Fe;
                  return J instanceof $e || se instanceof $e ? new $e(Ke) : new Y(Ke);
                }
                case "/":
                  return new $e(ge / Fe);
                case "%": {
                  const Ke = ge % Fe;
                  return J instanceof $e || se instanceof $e ? new $e(Ke) : new Y(Ke);
                }
                case "<":
                  return new fe(ge < Fe);
                case ">":
                  return new fe(ge > Fe);
                case ">=":
                  return new fe(ge >= Fe);
                case "<=":
                  return new fe(ge <= Fe);
              }
            } else if (J instanceof de && se instanceof de)
              switch (B.operator.value) {
                case "+":
                  return new de(J.value.concat(se.value));
              }
            else if (se instanceof de) {
              const ge = se.value.find((Fe) => Fe.value === J.value) !== void 0;
              switch (B.operator.value) {
                case "in":
                  return new fe(ge);
                case "not in":
                  return new fe(!ge);
              }
            }
          }
          if (J instanceof Ie || se instanceof Ie)
            switch (B.operator.value) {
              case "+":
                return new Ie(J.value.toString() + se.value.toString());
            }
          if (J instanceof Ie && se instanceof Ie)
            switch (B.operator.value) {
              case "in":
                return new fe(se.value.includes(J.value));
              case "not in":
                return new fe(!se.value.includes(J.value));
            }
          if (J instanceof Ie && se instanceof Ne)
            switch (B.operator.value) {
              case "in":
                return new fe(se.value.has(J.value));
              case "not in":
                return new fe(!se.value.has(J.value));
            }
          throw new SyntaxError(`Unknown operator "${B.operator.value}" between ${J.type} and ${se.type}`);
        }
        evaluateArguments(B, le) {
          const J = [], se = /* @__PURE__ */ new Map();
          for (const ge of B)
            if (ge.type === "SpreadExpression") {
              const Fe = ge, Ke = this.evaluate(Fe.argument, le);
              if (!(Ke instanceof de))
                throw new Error(`Cannot unpack non-iterable type: ${Ke.type}`);
              for (const pt of Ke.value)
                J.push(pt);
            } else if (ge.type === "KeywordArgumentExpression") {
              const Fe = ge;
              se.set(Fe.key.value, this.evaluate(Fe.value, le));
            } else {
              if (se.size > 0)
                throw new Error("Positional arguments must come before keyword arguments");
              J.push(this.evaluate(ge, le));
            }
          return [J, se];
        }
        applyFilter(B, le, J) {
          if (le.type === "Identifier") {
            const se = le;
            if (se.value === "tojson")
              return new Ie(Qe(B));
            if (B instanceof de)
              switch (se.value) {
                case "list":
                  return B;
                case "first":
                  return B.value[0];
                case "last":
                  return B.value[B.value.length - 1];
                case "length":
                  return new Y(B.value.length);
                case "reverse":
                  return new de(B.value.slice().reverse());
                case "sort":
                  return new de(B.value.slice().sort((ge, Fe) => Kt(ge, Fe, !1)));
                case "join":
                  return new Ie(B.value.map((ge) => ge.value).join(""));
                case "string":
                  return new Ie(Qe(B, null, 0, !1));
                case "unique": {
                  const ge = /* @__PURE__ */ new Set(), Fe = [];
                  for (const Ke of B.value)
                    ge.has(Ke.value) || (ge.add(Ke.value), Fe.push(Ke));
                  return new de(Fe);
                }
                default:
                  throw new Error(`Unknown ArrayValue filter: ${se.value}`);
              }
            else if (B instanceof Ie)
              switch (se.value) {
                case "length":
                case "upper":
                case "lower":
                case "title":
                case "capitalize": {
                  const ge = B.builtins.get(se.value);
                  if (ge instanceof tt)
                    return ge.value(
                      /* no arguments */
                      [],
                      J
                    );
                  if (ge instanceof Y)
                    return ge;
                  throw new Error(`Unknown StringValue filter: ${se.value}`);
                }
                case "trim":
                  return new Ie(B.value.trim());
                case "indent":
                  return new Ie(
                    B.value.split(`
`).map(
                      (ge, Fe) => (
                        // By default, don't indent the first line or empty lines
                        Fe === 0 || ge.length === 0 ? ge : "    " + ge
                      )
                    ).join(`
`)
                  );
                case "join":
                case "string":
                  return B;
                case "int": {
                  const ge = parseInt(B.value, 10);
                  return new Y(isNaN(ge) ? 0 : ge);
                }
                case "float": {
                  const ge = parseFloat(B.value);
                  return new $e(isNaN(ge) ? 0 : ge);
                }
                default:
                  throw new Error(`Unknown StringValue filter: ${se.value}`);
              }
            else if (B instanceof Y || B instanceof $e)
              switch (se.value) {
                case "abs":
                  return B instanceof Y ? new Y(Math.abs(B.value)) : new $e(Math.abs(B.value));
                case "int":
                  return new Y(Math.floor(B.value));
                case "float":
                  return new $e(B.value);
                default:
                  throw new Error(`Unknown NumericValue filter: ${se.value}`);
              }
            else if (B instanceof Ne)
              switch (se.value) {
                case "items":
                  return new de(
                    Array.from(B.value.entries()).map(([ge, Fe]) => new de([new Ie(ge), Fe]))
                  );
                case "length":
                  return new Y(B.value.size);
                default: {
                  const ge = B.builtins.get(se.value);
                  if (ge)
                    return ge instanceof tt ? ge.value([], J) : ge;
                  throw new Error(`Unknown ObjectValue filter: ${se.value}`);
                }
              }
            else if (B instanceof fe)
              switch (se.value) {
                case "bool":
                  return new fe(B.value);
                case "int":
                  return new Y(B.value ? 1 : 0);
                case "float":
                  return new $e(B.value ? 1 : 0);
                case "string":
                  return new Ie(B.value ? "true" : "false");
                default:
                  throw new Error(`Unknown BooleanValue filter: ${se.value}`);
              }
            throw new Error(`Cannot apply filter "${se.value}" to type: ${B.type}`);
          } else if (le.type === "CallExpression") {
            const se = le;
            if (se.callee.type !== "Identifier")
              throw new Error(`Unknown filter: ${se.callee.type}`);
            const ge = se.callee.value;
            if (ge === "tojson") {
              const [, Fe] = this.evaluateArguments(se.args, J), Ke = Fe.get("indent") ?? new He();
              if (!(Ke instanceof Y || Ke instanceof He))
                throw new Error("If set, indent must be a number");
              return new Ie(Qe(B, Ke.value));
            } else if (ge === "join") {
              let Fe;
              if (B instanceof Ie)
                Fe = Array.from(B.value);
              else if (B instanceof de)
                Fe = B.value.map((Tt) => Tt.value);
              else
                throw new Error(`Cannot apply filter "${ge}" to type: ${B.type}`);
              const [Ke, pt] = this.evaluateArguments(se.args, J), Pt = Ke.at(0) ?? pt.get("separator") ?? new Ie("");
              if (!(Pt instanceof Ie))
                throw new Error("separator must be a string");
              return new Ie(Fe.join(Pt.value));
            } else if (ge === "int" || ge === "float") {
              const [Fe, Ke] = this.evaluateArguments(se.args, J), pt = Fe.at(0) ?? Ke.get("default") ?? (ge === "int" ? new Y(0) : new $e(0));
              if (B instanceof Ie) {
                const Pt = ge === "int" ? parseInt(B.value, 10) : parseFloat(B.value);
                return isNaN(Pt) ? pt : ge === "int" ? new Y(Pt) : new $e(Pt);
              } else {
                if (B instanceof Y || B instanceof $e)
                  return B;
                if (B instanceof fe)
                  return ge === "int" ? new Y(B.value ? 1 : 0) : new $e(B.value ? 1 : 0);
                throw new Error(`Cannot apply filter "${ge}" to type: ${B.type}`);
              }
            } else if (ge === "default") {
              const [Fe, Ke] = this.evaluateArguments(se.args, J), pt = Fe[0] ?? new Ie(""), Pt = Fe[1] ?? Ke.get("boolean") ?? new fe(!1);
              if (!(Pt instanceof fe))
                throw new Error("`default` filter flag must be a boolean");
              return B instanceof je || Pt.value && !B.__bool__().value ? pt : B;
            }
            if (B instanceof de) {
              switch (ge) {
                case "sort": {
                  const [Fe, Ke] = this.evaluateArguments(se.args, J), pt = Fe.at(0) ?? Ke.get("reverse") ?? new fe(!1);
                  if (!(pt instanceof fe))
                    throw new Error("reverse must be a boolean");
                  const Pt = Fe.at(1) ?? Ke.get("case_sensitive") ?? new fe(!1);
                  if (!(Pt instanceof fe))
                    throw new Error("case_sensitive must be a boolean");
                  const Tt = Fe.at(2) ?? Ke.get("attribute") ?? new He();
                  if (!(Tt instanceof Ie || Tt instanceof Y || Tt instanceof He))
                    throw new Error("attribute must be a string, integer, or null");
                  const en = (Dt) => {
                    if (Tt instanceof He)
                      return Dt;
                    const tn = Tt instanceof Y ? String(Tt.value) : Tt.value;
                    return Rt(Dt, tn);
                  };
                  return new de(
                    B.value.slice().sort((Dt, tn) => {
                      const Vt = en(Dt), nn = en(tn), Mn = Kt(Vt, nn, Pt.value);
                      return pt.value ? -Mn : Mn;
                    })
                  );
                }
                case "selectattr":
                case "rejectattr": {
                  const Fe = ge === "selectattr";
                  if (B.value.some((Dt) => !(Dt instanceof Ne)))
                    throw new Error(`\`${ge}\` can only be applied to array of objects`);
                  if (se.args.some((Dt) => Dt.type !== "StringLiteral"))
                    throw new Error(`arguments of \`${ge}\` must be strings`);
                  const [Ke, pt, Pt] = se.args.map((Dt) => this.evaluate(Dt, J));
                  let Tt;
                  if (pt) {
                    const Dt = J.tests.get(pt.value);
                    if (!Dt)
                      throw new Error(`Unknown test: ${pt.value}`);
                    Tt = Dt;
                  } else
                    Tt = (...Dt) => Dt[0].__bool__().value;
                  const en = B.value.filter((Dt) => {
                    const tn = Dt.value.get(Ke.value), Vt = tn ? Tt(tn, Pt) : !1;
                    return Fe ? Vt : !Vt;
                  });
                  return new de(en);
                }
                case "map": {
                  const [, Fe] = this.evaluateArguments(se.args, J);
                  if (Fe.has("attribute")) {
                    const Ke = Fe.get("attribute");
                    if (!(Ke instanceof Ie))
                      throw new Error("attribute must be a string");
                    const pt = Fe.get("default"), Pt = B.value.map((Tt) => {
                      if (!(Tt instanceof Ne))
                        throw new Error("items in map must be an object");
                      const en = Rt(Tt, Ke.value);
                      return en instanceof je ? pt ?? new je() : en;
                    });
                    return new de(Pt);
                  } else
                    throw new Error("`map` expressions without `attribute` set are not currently supported.");
                }
              }
              throw new Error(`Unknown ArrayValue filter: ${ge}`);
            } else if (B instanceof Ie) {
              switch (ge) {
                case "indent": {
                  const [Fe, Ke] = this.evaluateArguments(se.args, J), pt = Fe.at(0) ?? Ke.get("width") ?? new Y(4);
                  if (!(pt instanceof Y))
                    throw new Error("width must be a number");
                  const Pt = Fe.at(1) ?? Ke.get("first") ?? new fe(!1), Tt = Fe.at(2) ?? Ke.get("blank") ?? new fe(!1), en = B.value.split(`
`), Dt = " ".repeat(pt.value), tn = en.map(
                    (Vt, nn) => !Pt.value && nn === 0 || !Tt.value && Vt.length === 0 ? Vt : Dt + Vt
                  );
                  return new Ie(tn.join(`
`));
                }
                case "replace": {
                  const Fe = B.builtins.get("replace");
                  if (!(Fe instanceof tt))
                    throw new Error("replace filter not available");
                  const [Ke, pt] = this.evaluateArguments(se.args, J);
                  return Fe.value([...Ke, new ut(pt)], J);
                }
              }
              throw new Error(`Unknown StringValue filter: ${ge}`);
            } else if (B instanceof Ne) {
              const Fe = B.builtins.get(ge);
              if (Fe && Fe instanceof tt) {
                const [Ke, pt] = this.evaluateArguments(se.args, J);
                return pt.size > 0 && Ke.push(new ut(pt)), Fe.value(Ke, J);
              }
              throw new Error(`Unknown ObjectValue filter: ${ge}`);
            } else
              throw new Error(`Cannot apply filter "${ge}" to type: ${B.type}`);
          }
          throw new Error(`Unknown filter: ${le.type}`);
        }
        /**
         * Evaluates expressions following the filter operation type.
         */
        evaluateFilterExpression(B, le) {
          const J = this.evaluate(B.operand, le);
          return this.applyFilter(J, B.filter, le);
        }
        /**
         * Evaluates expressions following the test operation type.
         */
        evaluateTestExpression(B, le) {
          const J = this.evaluate(B.operand, le), se = le.tests.get(B.test.value);
          if (!se)
            throw new Error(`Unknown test: ${B.test.value}`);
          const ge = se(J);
          return new fe(B.negate ? !ge : ge);
        }
        /**
         * Evaluates expressions following the select operation type.
         */
        evaluateSelectExpression(B, le) {
          return this.evaluate(B.test, le).__bool__().value ? this.evaluate(B.lhs, le) : new je();
        }
        /**
         * Evaluates expressions following the unary operation type.
         */
        evaluateUnaryExpression(B, le) {
          const J = this.evaluate(B.argument, le);
          switch (B.operator.value) {
            case "not":
              return new fe(!J.value);
            default:
              throw new SyntaxError(`Unknown operator: ${B.operator.value}`);
          }
        }
        evaluateTernaryExpression(B, le) {
          return this.evaluate(B.condition, le).__bool__().value ? this.evaluate(B.trueExpr, le) : this.evaluate(B.falseExpr, le);
        }
        evalProgram(B, le) {
          return this.evaluateBlock(B.body, le);
        }
        evaluateBlock(B, le) {
          let J = "";
          for (const se of B) {
            const ge = this.evaluate(se, le);
            ge.type !== "NullValue" && ge.type !== "UndefinedValue" && (J += ge.toString());
          }
          return new Ie(J);
        }
        evaluateIdentifier(B, le) {
          return le.lookupVariable(B.value);
        }
        evaluateCallExpression(B, le) {
          const [J, se] = this.evaluateArguments(B.args, le);
          se.size > 0 && J.push(new ut(se));
          const ge = this.evaluate(B.callee, le);
          if (ge.type !== "FunctionValue")
            throw new Error(`Cannot call something that is not a function: got ${ge.type}`);
          return ge.value(J, le);
        }
        evaluateSliceExpression(B, le, J) {
          if (!(B instanceof de || B instanceof Ie))
            throw new Error("Slice object must be an array or string");
          const se = this.evaluate(le.start, J), ge = this.evaluate(le.stop, J), Fe = this.evaluate(le.step, J);
          if (!(se instanceof Y || se instanceof je))
            throw new Error("Slice start must be numeric or undefined");
          if (!(ge instanceof Y || ge instanceof je))
            throw new Error("Slice stop must be numeric or undefined");
          if (!(Fe instanceof Y || Fe instanceof je))
            throw new Error("Slice step must be numeric or undefined");
          return B instanceof de ? new de(nt(B.value, se.value, ge.value, Fe.value)) : new Ie(nt(Array.from(B.value), se.value, ge.value, Fe.value).join(""));
        }
        evaluateMemberExpression(B, le) {
          const J = this.evaluate(B.object, le);
          let se;
          if (B.computed) {
            if (B.property.type === "SliceExpression")
              return this.evaluateSliceExpression(J, B.property, le);
            se = this.evaluate(B.property, le);
          } else
            se = new Ie(B.property.value);
          let ge;
          if (J instanceof Ne) {
            if (!(se instanceof Ie))
              throw new Error(`Cannot access property with non-string: got ${se.type}`);
            ge = J.value.get(se.value) ?? J.builtins.get(se.value);
          } else if (J instanceof de || J instanceof Ie)
            if (se instanceof Y)
              ge = J.value.at(se.value), J instanceof Ie && (ge = new Ie(J.value.at(se.value)));
            else if (se instanceof Ie)
              ge = J.builtins.get(se.value);
            else
              throw new Error(`Cannot access property with non-string/non-number: got ${se.type}`);
          else {
            if (!(se instanceof Ie))
              throw new Error(`Cannot access property with non-string: got ${se.type}`);
            ge = J.builtins.get(se.value);
          }
          return ge instanceof H ? ge : new je();
        }
        evaluateSet(B, le) {
          const J = B.value ? this.evaluate(B.value, le) : this.evaluateBlock(B.body, le);
          if (B.assignee.type === "Identifier") {
            const se = B.assignee.value;
            le.setVariable(se, J);
          } else if (B.assignee.type === "TupleLiteral") {
            const se = B.assignee;
            if (!(J instanceof de))
              throw new Error(`Cannot unpack non-iterable type in set: ${J.type}`);
            const ge = J.value;
            if (ge.length !== se.value.length)
              throw new Error(`Too ${se.value.length > ge.length ? "few" : "many"} items to unpack in set`);
            for (let Fe = 0; Fe < se.value.length; ++Fe) {
              const Ke = se.value[Fe];
              if (Ke.type !== "Identifier")
                throw new Error(`Cannot unpack to non-identifier in set: ${Ke.type}`);
              le.setVariable(Ke.value, ge[Fe]);
            }
          } else if (B.assignee.type === "MemberExpression") {
            const se = B.assignee, ge = this.evaluate(se.object, le);
            if (!(ge instanceof Ne))
              throw new Error("Cannot assign to member of non-object");
            if (se.property.type !== "Identifier")
              throw new Error("Cannot assign to member with non-identifier property");
            ge.value.set(se.property.value, J);
          } else
            throw new Error(`Invalid LHS inside assignment expression: ${JSON.stringify(B.assignee)}`);
          return new He();
        }
        evaluateIf(B, le) {
          const J = this.evaluate(B.test, le);
          return this.evaluateBlock(J.__bool__().value ? B.body : B.alternate, le);
        }
        evaluateFor(B, le) {
          const J = new lt(le);
          let se, ge;
          if (B.iterable.type === "SelectExpression") {
            const Tt = B.iterable;
            ge = this.evaluate(Tt.lhs, J), se = Tt.test;
          } else
            ge = this.evaluate(B.iterable, J);
          if (!(ge instanceof de || ge instanceof Ne))
            throw new Error(`Expected iterable or object type in for loop: got ${ge.type}`);
          ge instanceof Ne && (ge = ge.keys());
          const Fe = [], Ke = [];
          for (let Tt = 0; Tt < ge.value.length; ++Tt) {
            const en = new lt(J), Dt = ge.value[Tt];
            let tn;
            if (B.loopvar.type === "Identifier")
              tn = (Vt) => Vt.setVariable(B.loopvar.value, Dt);
            else if (B.loopvar.type === "TupleLiteral") {
              const Vt = B.loopvar;
              if (Dt.type !== "ArrayValue")
                throw new Error(`Cannot unpack non-iterable type: ${Dt.type}`);
              const nn = Dt;
              if (Vt.value.length !== nn.value.length)
                throw new Error(`Too ${Vt.value.length > nn.value.length ? "few" : "many"} items to unpack`);
              tn = (Mn) => {
                for (let vi = 0; vi < Vt.value.length; ++vi) {
                  if (Vt.value[vi].type !== "Identifier")
                    throw new Error(`Cannot unpack non-identifier type: ${Vt.value[vi].type}`);
                  Mn.setVariable(Vt.value[vi].value, nn.value[vi]);
                }
              };
            } else
              throw new Error(`Invalid loop variable(s): ${B.loopvar.type}`);
            se && (tn(en), !this.evaluate(se, en).__bool__().value) || (Fe.push(Dt), Ke.push(tn));
          }
          let pt = "", Pt = !0;
          for (let Tt = 0; Tt < Fe.length; ++Tt) {
            const en = /* @__PURE__ */ new Map([
              ["index", new Y(Tt + 1)],
              ["index0", new Y(Tt)],
              ["revindex", new Y(Fe.length - Tt)],
              ["revindex0", new Y(Fe.length - Tt - 1)],
              ["first", new fe(Tt === 0)],
              ["last", new fe(Tt === Fe.length - 1)],
              ["length", new Y(Fe.length)],
              ["previtem", Tt > 0 ? Fe[Tt - 1] : new je()],
              ["nextitem", Tt < Fe.length - 1 ? Fe[Tt + 1] : new je()]
            ]);
            J.setVariable("loop", new Ne(en)), Ke[Tt](J);
            try {
              const Dt = this.evaluateBlock(B.body, J);
              pt += Dt.value;
            } catch (Dt) {
              if (Dt instanceof Ye)
                continue;
              if (Dt instanceof Oe)
                break;
              throw Dt;
            }
            Pt = !1;
          }
          if (Pt) {
            const Tt = this.evaluateBlock(B.defaultBlock, J);
            pt += Tt.value;
          }
          return new Ie(pt);
        }
        /**
         * See https://jinja.palletsprojects.com/en/3.1.x/templates/#macros for more information.
         */
        evaluateMacro(B, le) {
          return le.setVariable(
            B.name.value,
            new tt((J, se) => {
              var Ke;
              const ge = new lt(se);
              J = J.slice();
              let Fe;
              ((Ke = J.at(-1)) == null ? void 0 : Ke.type) === "KeywordArgumentsValue" && (Fe = J.pop());
              for (let pt = 0; pt < B.args.length; ++pt) {
                const Pt = B.args[pt], Tt = J[pt];
                if (Pt.type === "Identifier") {
                  const en = Pt;
                  if (!Tt)
                    throw new Error(`Missing positional argument: ${en.value}`);
                  ge.setVariable(en.value, Tt);
                } else if (Pt.type === "KeywordArgumentExpression") {
                  const en = Pt, Dt = Tt ?? // Try positional arguments first
                  (Fe == null ? void 0 : Fe.value.get(en.key.value)) ?? // Look in user-passed kwargs
                  this.evaluate(en.value, ge);
                  ge.setVariable(en.key.value, Dt);
                } else
                  throw new Error(`Unknown argument type: ${Pt.type}`);
              }
              return this.evaluateBlock(B.body, ge);
            })
          ), new He();
        }
        evaluateCallStatement(B, le) {
          const J = new tt((pt, Pt) => {
            const Tt = new lt(Pt);
            if (B.callerArgs)
              for (let en = 0; en < B.callerArgs.length; ++en) {
                const Dt = B.callerArgs[en];
                if (Dt.type !== "Identifier")
                  throw new Error(`Caller parameter must be an identifier, got ${Dt.type}`);
                Tt.setVariable(Dt.value, pt[en] ?? new je());
              }
            return this.evaluateBlock(B.body, Tt);
          }), [se, ge] = this.evaluateArguments(B.call.args, le);
          se.push(new ut(ge));
          const Fe = this.evaluate(B.call.callee, le);
          if (Fe.type !== "FunctionValue")
            throw new Error(`Cannot call something that is not a function: got ${Fe.type}`);
          const Ke = new lt(le);
          return Ke.setVariable("caller", J), Fe.value(se, Ke);
        }
        evaluateFilterStatement(B, le) {
          const J = this.evaluateBlock(B.body, le);
          return this.applyFilter(J, B.filter, le);
        }
        evaluate(B, le) {
          if (!B)
            return new je();
          switch (B.type) {
            case "Program":
              return this.evalProgram(B, le);
            case "Set":
              return this.evaluateSet(B, le);
            case "If":
              return this.evaluateIf(B, le);
            case "For":
              return this.evaluateFor(B, le);
            case "Macro":
              return this.evaluateMacro(B, le);
            case "CallStatement":
              return this.evaluateCallStatement(B, le);
            case "Break":
              throw new Oe();
            case "Continue":
              throw new Ye();
            case "IntegerLiteral":
              return new Y(B.value);
            case "FloatLiteral":
              return new $e(B.value);
            case "StringLiteral":
              return new Ie(B.value);
            case "ArrayLiteral":
              return new de(B.value.map((J) => this.evaluate(J, le)));
            case "TupleLiteral":
              return new qe(B.value.map((J) => this.evaluate(J, le)));
            case "ObjectLiteral": {
              const J = /* @__PURE__ */ new Map();
              for (const [se, ge] of B.value) {
                const Fe = this.evaluate(se, le);
                if (!(Fe instanceof Ie))
                  throw new Error(`Object keys must be strings: got ${Fe.type}`);
                J.set(Fe.value, this.evaluate(ge, le));
              }
              return new Ne(J);
            }
            case "Identifier":
              return this.evaluateIdentifier(B, le);
            case "CallExpression":
              return this.evaluateCallExpression(B, le);
            case "MemberExpression":
              return this.evaluateMemberExpression(B, le);
            case "UnaryExpression":
              return this.evaluateUnaryExpression(B, le);
            case "BinaryExpression":
              return this.evaluateBinaryExpression(B, le);
            case "FilterExpression":
              return this.evaluateFilterExpression(B, le);
            case "FilterStatement":
              return this.evaluateFilterStatement(B, le);
            case "TestExpression":
              return this.evaluateTestExpression(B, le);
            case "SelectExpression":
              return this.evaluateSelectExpression(B, le);
            case "Ternary":
              return this.evaluateTernaryExpression(B, le);
            case "Comment":
              return new He();
            default:
              throw new SyntaxError(`Unknown node type: ${B.type}`);
          }
        }
      };
      function wn(B) {
        switch (typeof B) {
          case "number":
            return Number.isInteger(B) ? new Y(B) : new $e(B);
          case "string":
            return new Ie(B);
          case "boolean":
            return new fe(B);
          case "undefined":
            return new je();
          case "object":
            return B === null ? new He() : Array.isArray(B) ? new de(B.map(wn)) : new Ne(
              new Map(Object.entries(B).map(([le, J]) => [le, wn(J)]))
            );
          case "function":
            return new tt((le, J) => {
              const se = B(...le.map((ge) => ge.value)) ?? null;
              return wn(se);
            });
          default:
            throw new Error(`Cannot convert to runtime value: ${B}`);
        }
      }
      var ln = `
`, Gn = "{%- ", li = " -%}";
      function Yi(B) {
        switch (B.operator.type) {
          case "MultiplicativeBinaryOperator":
            return 4;
          case "AdditiveBinaryOperator":
            return 3;
          case "ComparisonBinaryOperator":
            return 2;
          case "Identifier":
            return B.operator.value === "and" ? 1 : B.operator.value === "in" || B.operator.value === "not in" ? 2 : 0;
        }
        return 0;
      }
      function $i(B, le = "	") {
        const J = typeof le == "number" ? " ".repeat(le) : le;
        return bn(B.body, 0, J).replace(/\n$/, "");
      }
      function An(...B) {
        return Gn + B.join(" ") + li;
      }
      function bn(B, le, J) {
        return B.map((se) => Si(se, le, J)).join(ln);
      }
      function Si(B, le, J) {
        const se = J.repeat(le);
        switch (B.type) {
          case "Program":
            return bn(B.body, le, J);
          case "If":
            return ds(B, le, J);
          case "For":
            return qt(B, le, J);
          case "Set":
            return Me(B, le, J);
          case "Macro":
            return at(B, le, J);
          case "Break":
            return se + An("break");
          case "Continue":
            return se + An("continue");
          case "CallStatement":
            return rt(B, le, J);
          case "FilterStatement":
            return mt(B, le, J);
          case "Comment":
            return se + "{# " + B.value + " #}";
          default:
            return se + "{{- " + _t(B) + " -}}";
        }
      }
      function ds(B, le, J) {
        const se = J.repeat(le), ge = [];
        let Fe = B;
        for (; Fe && (ge.push({ test: Fe.test, body: Fe.body }), Fe.alternate.length === 1 && Fe.alternate[0].type === "If"); )
          Fe = Fe.alternate[0];
        let Ke = se + An("if", _t(ge[0].test)) + ln + bn(ge[0].body, le + 1, J);
        for (let pt = 1; pt < ge.length; ++pt)
          Ke += ln + se + An("elif", _t(ge[pt].test)) + ln + bn(ge[pt].body, le + 1, J);
        return Fe && Fe.alternate.length > 0 && (Ke += ln + se + An("else") + ln + bn(Fe.alternate, le + 1, J)), Ke += ln + se + An("endif"), Ke;
      }
      function qt(B, le, J) {
        const se = J.repeat(le);
        let ge = "";
        if (B.iterable.type === "SelectExpression") {
          const Ke = B.iterable;
          ge = `${_t(Ke.lhs)} if ${_t(Ke.test)}`;
        } else
          ge = _t(B.iterable);
        let Fe = se + An("for", _t(B.loopvar), "in", ge) + ln + bn(B.body, le + 1, J);
        return B.defaultBlock.length > 0 && (Fe += ln + se + An("else") + ln + bn(B.defaultBlock, le + 1, J)), Fe += ln + se + An("endfor"), Fe;
      }
      function Me(B, le, J) {
        const se = J.repeat(le), ge = _t(B.assignee), Fe = B.value ? _t(B.value) : "", Ke = se + An("set", `${ge}${B.value ? " = " + Fe : ""}`);
        return B.body.length === 0 ? Ke : Ke + ln + bn(B.body, le + 1, J) + ln + se + An("endset");
      }
      function at(B, le, J) {
        const se = J.repeat(le), ge = B.args.map(_t).join(", ");
        return se + An("macro", `${B.name.value}(${ge})`) + ln + bn(B.body, le + 1, J) + ln + se + An("endmacro");
      }
      function rt(B, le, J) {
        const se = J.repeat(le), ge = B.callerArgs && B.callerArgs.length > 0 ? `(${B.callerArgs.map(_t).join(", ")})` : "", Fe = _t(B.call);
        let Ke = se + An(`call${ge}`, Fe) + ln;
        return Ke += bn(B.body, le + 1, J) + ln, Ke += se + An("endcall"), Ke;
      }
      function mt(B, le, J) {
        const se = J.repeat(le), ge = B.filter.type === "Identifier" ? B.filter.value : _t(B.filter);
        let Fe = se + An("filter", ge) + ln;
        return Fe += bn(B.body, le + 1, J) + ln, Fe += se + An("endfilter"), Fe;
      }
      function _t(B, le = -1) {
        switch (B.type) {
          case "SpreadExpression":
            return `*${_t(B.argument)}`;
          case "Identifier":
            return B.value;
          case "IntegerLiteral":
            return `${B.value}`;
          case "FloatLiteral":
            return `${B.value}`;
          case "StringLiteral":
            return JSON.stringify(B.value);
          case "BinaryExpression": {
            const J = B, se = Yi(J), ge = _t(J.left, se), Fe = _t(J.right, se + 1), Ke = `${ge} ${J.operator.value} ${Fe}`;
            return se < le ? `(${Ke})` : Ke;
          }
          case "UnaryExpression": {
            const J = B;
            return J.operator.value + (J.operator.value === "not" ? " " : "") + _t(J.argument, 1 / 0);
          }
          case "CallExpression": {
            const J = B, se = J.args.map(_t).join(", ");
            return `${_t(J.callee)}(${se})`;
          }
          case "MemberExpression": {
            const J = B;
            let se = _t(J.object);
            [
              "Identifier",
              "MemberExpression",
              "CallExpression",
              "StringLiteral",
              "IntegerLiteral",
              "FloatLiteral",
              "ArrayLiteral",
              "TupleLiteral",
              "ObjectLiteral"
            ].includes(J.object.type) || (se = `(${se})`);
            let ge = _t(J.property);
            return !J.computed && J.property.type !== "Identifier" && (ge = `(${ge})`), J.computed ? `${se}[${ge}]` : `${se}.${ge}`;
          }
          case "FilterExpression": {
            const J = B, se = _t(J.operand, 1 / 0);
            return J.filter.type === "CallExpression" ? `${se} | ${_t(J.filter)}` : `${se} | ${J.filter.value}`;
          }
          case "SelectExpression": {
            const J = B;
            return `${_t(J.lhs)} if ${_t(J.test)}`;
          }
          case "TestExpression": {
            const J = B;
            return `${_t(J.operand)} is${J.negate ? " not" : ""} ${J.test.value}`;
          }
          case "ArrayLiteral":
          case "TupleLiteral": {
            const J = B.value.map(_t), se = B.type === "ArrayLiteral" ? "[]" : "()";
            return `${se[0]}${J.join(", ")}${se[1]}`;
          }
          case "ObjectLiteral":
            return `{${Array.from(B.value.entries()).map(
              ([se, ge]) => `${_t(se)}: ${_t(ge)}`
            ).join(", ")}}`;
          case "SliceExpression": {
            const J = B, se = J.start ? _t(J.start) : "", ge = J.stop ? _t(J.stop) : "", Fe = J.step ? `:${_t(J.step)}` : "";
            return `${se}:${ge}${Fe}`;
          }
          case "KeywordArgumentExpression": {
            const J = B;
            return `${J.key.value}=${_t(J.value)}`;
          }
          case "Ternary": {
            const J = B, se = `${_t(J.trueExpr)} if ${_t(J.condition, 0)} else ${_t(
              J.falseExpr
            )}`;
            return le > -1 ? `(${se})` : se;
          }
          default:
            throw new Error(`Unknown expression type: ${B.type}`);
        }
      }
      var on = class {
        /**
         * @param {string} template The template string
         */
        constructor(B) {
          Ce(this, "parsed");
          const le = h(B, {
            lstrip_blocks: !0,
            trim_blocks: !0
          });
          this.parsed = et(le);
        }
        render(B) {
          const le = new lt();
          if (Mt(le), B)
            for (const [ge, Fe] of Object.entries(B))
              le.set(ge, Fe);
          return new vn(le).run(this.parsed).value;
        }
        format(B) {
          return $i(this.parsed, (B == null ? void 0 : B.indent) || "	");
        }
      };
    }
  ),
  /***/
  "./src/backends/onnx.js": (
    /*!******************************!*\
      !*** ./src/backends/onnx.js ***!
      \******************************/
    /***/
    (e, n, t) => {
      var i;
      t.r(n), t.d(n, {
        /* harmony export */
        Tensor: () => (
          /* reexport safe */
          u.Tensor
        ),
        /* harmony export */
        createInferenceSession: () => (
          /* binding */
          D
        ),
        /* harmony export */
        deviceToExecutionProviders: () => (
          /* binding */
          v
        ),
        /* harmony export */
        isONNXProxy: () => (
          /* binding */
          L
        ),
        /* harmony export */
        isONNXTensor: () => (
          /* binding */
          E
        ),
        /* harmony export */
        runInferenceSession: () => (
          /* binding */
          F
        )
        /* harmony export */
      });
      var r = t(
        /*! ../env.js */
        "./src/env.js"
      ), a = t(
        /*! onnxruntime-node */
        "?2ce3"
      ), c = t(
        /*! onnxruntime-web */
        "onnxruntime-web"
      ), u = t(
        /*! onnxruntime-common */
        "onnxruntime-common"
      );
      const l = Object.freeze({
        auto: null,
        // Auto-detect based on device and environment
        gpu: null,
        // Auto-detect GPU
        cpu: "cpu",
        // CPU
        wasm: "wasm",
        // WebAssembly
        webgpu: "webgpu",
        // WebGPU
        cuda: "cuda",
        // CUDA
        dml: "dml",
        // DirectML
        webnn: { name: "webnn", deviceType: "cpu" },
        // WebNN (default)
        "webnn-npu": { name: "webnn", deviceType: "npu" },
        // WebNN NPU
        "webnn-gpu": { name: "webnn", deviceType: "gpu" },
        // WebNN GPU
        "webnn-cpu": { name: "webnn", deviceType: "cpu" }
        // WebNN CPU
      }), f = [];
      let m, h;
      const p = Symbol.for("onnxruntime");
      if (p in globalThis)
        h = globalThis[p];
      else if (r.apis.IS_NODE_ENV) {
        switch (h = a ?? (i || (i = t.t(a, 2))), process.platform) {
          case "win32":
            f.push("dml");
            break;
          case "linux":
            process.arch === "x64" && f.push("cuda");
            break;
        }
        f.push("cpu"), m = ["cpu"];
      } else
        h = c, r.apis.IS_WEBNN_AVAILABLE && f.push("webnn-npu", "webnn-gpu", "webnn-cpu", "webnn"), r.apis.IS_WEBGPU_AVAILABLE && f.push("webgpu"), f.push("wasm"), m = ["wasm"];
      const _ = h.InferenceSession;
      function v(I = null) {
        if (!I)
          return m;
        switch (I) {
          case "auto":
            return f;
          case "gpu":
            return f.filter(
              (R) => ["webgpu", "cuda", "dml", "webnn-gpu"].includes(R)
            );
        }
        if (f.includes(I))
          return [l[I] ?? I];
        throw new Error(`Unsupported device: "${I}". Should be one of: ${f.join(", ")}.`);
      }
      let S = null;
      async function D(I, R, N) {
        S && await S;
        const q = _.create(I, R);
        S ?? (S = q);
        const ne = await q;
        return ne.config = N, ne;
      }
      let w = Promise.resolve();
      const T = r.apis.IS_BROWSER_ENV || r.apis.IS_WEBWORKER_ENV;
      async function F(I, R) {
        const N = () => I.run(R);
        return await (T ? w = w.then(N) : N());
      }
      function E(I) {
        return I instanceof h.Tensor;
      }
      const A = h == null ? void 0 : h.env;
      A != null && A.wasm && // @ts-ignore Cannot find name 'ServiceWorkerGlobalScope'.ts(2304)
      (!(typeof ServiceWorkerGlobalScope < "u" && self instanceof ServiceWorkerGlobalScope) && !A.wasm.wasmPaths && (A.wasm.wasmPaths = `https://cdn.jsdelivr.net/npm/@huggingface/transformers@${r.env.version}/dist/`), A.wasm.proxy = !1), A != null && A.webgpu && (A.webgpu.powerPreference = "high-performance");
      function L() {
        var I;
        return (I = A == null ? void 0 : A.wasm) == null ? void 0 : I.proxy;
      }
      r.env.backends.onnx = A;
    }
  ),
  /***/
  "./src/base/feature_extraction_utils.js": (
    /*!**********************************************!*\
      !*** ./src/base/feature_extraction_utils.js ***!
      \**********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        FeatureExtractor: () => (
          /* binding */
          c
        ),
        /* harmony export */
        validate_audio_inputs: () => (
          /* binding */
          u
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/constants.js */
        "./src/utils/constants.js"
      ), r = t(
        /*! ../utils/generic.js */
        "./src/utils/generic.js"
      ), a = t(
        /*! ../utils/hub.js */
        "./src/utils/hub.js"
      );
      class c extends r.Callable {
        /**
         * Constructs a new FeatureExtractor instance.
         *
         * @param {Object} config The configuration for the feature extractor.
         */
        constructor(f) {
          super(), this.config = f;
        }
        /**
         * Instantiate one of the feature extractor classes of the library from a pretrained model.
         * 
         * The feature extractor class to instantiate is selected based on the `feature_extractor_type` property of
         * the config object (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
         * 
         * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
         * - A string, the *model id* of a pretrained feature_extractor hosted inside a model repo on huggingface.co.
         *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
         *   user or organization name, like `dbmdz/bert-base-german-cased`.
         * - A path to a *directory* containing feature_extractor files, e.g., `./my_model_directory/`.
         * @param {import('../utils/hub.js').PretrainedOptions} options Additional options for loading the feature_extractor.
         * 
         * @returns {Promise<FeatureExtractor>} A new instance of the Feature Extractor class.
         */
        static async from_pretrained(f, m = {}) {
          const h = await (0, a.getModelJSON)(f, i.FEATURE_EXTRACTOR_NAME, !0, m);
          return new this(h);
        }
      }
      function u(l, f) {
        var m;
        if (!(l instanceof Float32Array || l instanceof Float64Array))
          throw new Error(
            `${f} expects input to be a Float32Array or a Float64Array, but got ${((m = l == null ? void 0 : l.constructor) == null ? void 0 : m.name) ?? typeof l} instead. If using the feature extractor directly, remember to use \`read_audio(url, sampling_rate)\` to obtain the raw audio data of the file/url.`
          );
      }
    }
  ),
  /***/
  "./src/base/image_processors_utils.js": (
    /*!********************************************!*\
      !*** ./src/base/image_processors_utils.js ***!
      \********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ImageProcessor: () => (
          /* binding */
          E
        ),
        /* harmony export */
        center_to_corners_format: () => (
          /* binding */
          h
        ),
        /* harmony export */
        post_process_instance_segmentation: () => (
          /* binding */
          F
        ),
        /* harmony export */
        post_process_object_detection: () => (
          /* binding */
          p
        ),
        /* harmony export */
        post_process_panoptic_segmentation: () => (
          /* binding */
          T
        ),
        /* harmony export */
        post_process_semantic_segmentation: () => (
          /* binding */
          _
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/generic.js */
        "./src/utils/generic.js"
      ), r = t(
        /*! ../utils/tensor.js */
        "./src/utils/tensor.js"
      ), a = t(
        /*! ../utils/maths.js */
        "./src/utils/maths.js"
      );
      t(
        /*! ../utils/image.js */
        "./src/utils/image.js"
      );
      var c = t(
        /*! ../utils/core.js */
        "./src/utils/core.js"
      ), u = t(
        /*! ../utils/hub.js */
        "./src/utils/hub.js"
      ), l = t(
        /*! ../utils/constants.js */
        "./src/utils/constants.js"
      );
      function f(A, L, I = 0, R = null) {
        const N = A / L;
        let q = (0, a.bankers_round)(N) * L;
        return R !== null && q > R && (q = Math.floor(N) * L), q < I && (q = Math.ceil(N) * L), q;
      }
      function m([A, L], I) {
        return [
          Math.max(Math.floor(A / I), 1) * I,
          Math.max(Math.floor(L / I), 1) * I
        ];
      }
      function h([A, L, I, R]) {
        return [
          A - I / 2,
          L - R / 2,
          A + I / 2,
          L + R / 2
        ];
      }
      function p(A, L = 0.5, I = null, R = !1) {
        const N = A.logits, q = A.pred_boxes, [ne, Q, W] = N.dims;
        if (I !== null && I.length !== ne)
          throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
        let te = [];
        for (let K = 0; K < ne; ++K) {
          let pe = I !== null ? I[K] : null, be = {
            boxes: [],
            classes: [],
            scores: []
          }, Ee = N[K], Ge = q[K];
          for (let _e = 0; _e < Q; ++_e) {
            let De = Ee[_e], he = [], Z;
            if (R) {
              Z = De.sigmoid().data;
              for (let me = 0; me < Z.length; ++me)
                Z[me] > L && he.push(me);
            } else {
              let me = (0, a.max)(De.data)[1];
              if (me === W - 1 || (Z = (0, a.softmax)(De.data), Z[me] < L))
                continue;
              he.push(me);
            }
            for (const me of he) {
              let we = Ge[_e].data;
              we = h(we), pe !== null && (we = we.map((xe, et) => xe * pe[(et + 1) % 2])), be.boxes.push(we), be.classes.push(me), be.scores.push(Z[me]);
            }
          }
          te.push(be);
        }
        return te;
      }
      function _(A, L = null) {
        const I = A.logits, R = I.dims[0];
        if (L !== null && L.length !== R)
          throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
        const N = [];
        for (let q = 0; q < R; ++q) {
          const ne = L !== null ? L[q] : null;
          let Q = I[q];
          ne !== null && (Q = (0, r.interpolate)(Q, ne, "bilinear", !1));
          const [W, te] = ne ?? Q.dims.slice(-2), K = new r.Tensor(
            "int32",
            new Int32Array(W * te),
            [W, te]
          ), pe = Q[0].data, be = K.data;
          for (let _e = 1; _e < Q.dims[0]; ++_e) {
            const De = Q[_e].data;
            for (let he = 0; he < De.length; ++he)
              De[he] > pe[he] && (pe[he] = De[he], be[he] = _e);
          }
          const Ee = new Array(Q.dims[0]);
          for (let _e = 0; _e < be.length; ++_e) {
            const De = be[_e];
            Ee[De] = De;
          }
          const Ge = Ee.filter((_e) => _e !== void 0);
          N.push({ segmentation: K, labels: Ge });
        }
        return N;
      }
      function v(A, L, I, R) {
        const N = [], q = [], ne = [];
        for (let Q = 0; Q < A.dims[0]; ++Q) {
          const W = A[Q], te = L[Q], K = (0, a.max)(W.data)[1];
          if (K === R)
            continue;
          const be = (0, a.softmax)(W.data)[K];
          be > I && (N.push(te), q.push(be), ne.push(K));
        }
        return [N, q, ne];
      }
      function S(A, L, I, R = 0.5, N = 0.8) {
        const q = [];
        let ne = 0, Q = 0;
        const W = L[I].data;
        for (let K = 0; K < A.length; ++K)
          A[K] === I && (q.push(K), ++ne), W[K] >= R && ++Q;
        let te = ne > 0 && Q > 0;
        return te && (te = ne / Q > N), [te, q];
      }
      function D(A, L, I, R, N, q = null, ne = null) {
        const [Q, W] = ne ?? A[0].dims, te = new r.Tensor(
          "int32",
          new Int32Array(Q * W),
          [Q, W]
        ), K = [];
        if (ne !== null)
          for (let _e = 0; _e < A.length; ++_e)
            A[_e] = (0, r.interpolate)(A[_e], ne, "bilinear", !1);
        const pe = new Int32Array(A[0].data.length), be = new Float32Array(A[0].data.length);
        for (let _e = 0; _e < A.length; ++_e) {
          let De = L[_e];
          const he = A[_e].data;
          for (let Z = 0; Z < he.length; ++Z)
            he[Z] *= De, he[Z] > be[Z] && (pe[Z] = _e, be[Z] = he[Z]);
        }
        let Ee = 0;
        const Ge = te.data;
        for (let _e = 0; _e < I.length; ++_e) {
          const De = I[_e], [he, Z] = S(
            pe,
            A,
            _e,
            R,
            N
          );
          if (he) {
            ++Ee;
            for (const me of Z)
              Ge[me] = Ee;
            K.push({
              id: Ee,
              label_id: De,
              // was_fused: should_fuse, TODO
              score: L[_e]
            });
          }
        }
        return [te, K];
      }
      function w(A, L, I = 28, R = 56 * 56, N = 14 * 14 * 4 * 1280) {
        if (A < I || L < I)
          throw new Error(`height:${A} or width:${L} must be larger than factor:${I}`);
        if (Math.max(A, L) / Math.min(A, L) > 200)
          throw new Error(
            `absolute aspect ratio must be smaller than 200, got ${Math.max(A, L) / Math.min(A, L)}`
          );
        let q = Math.round(A / I) * I, ne = Math.round(L / I) * I;
        if (q * ne > N) {
          const Q = Math.sqrt(A * L / N);
          q = Math.floor(A / Q / I) * I, ne = Math.floor(L / Q / I) * I;
        } else if (q * ne < R) {
          const Q = Math.sqrt(R / (A * L));
          q = Math.ceil(A * Q / I) * I, ne = Math.ceil(L * Q / I) * I;
        }
        return [q, ne];
      }
      function T(A, L = 0.5, I = 0.5, R = 0.8, N = null, q = null) {
        N === null && (console.warn("`label_ids_to_fuse` unset. No instance will be fused."), N = /* @__PURE__ */ new Set());
        const ne = A.class_queries_logits ?? A.logits, W = (A.masks_queries_logits ?? A.pred_masks).sigmoid();
        let [te, K, pe] = ne.dims;
        if (pe -= 1, q !== null && q.length !== te)
          throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
        let be = [];
        for (let Ee = 0; Ee < te; ++Ee) {
          let Ge = q !== null ? q[Ee] : null, _e = ne[Ee], De = W[Ee], [he, Z, me] = v(_e, De, L, pe);
          if (me.length === 0) {
            let [et, Ve] = Ge ?? De.dims.slice(-2), nt = new r.Tensor(
              "int32",
              new Int32Array(et * Ve).fill(-1),
              [et, Ve]
            );
            be.push({
              segmentation: nt,
              segments_info: []
            });
            continue;
          }
          let [we, xe] = D(
            he,
            Z,
            me,
            I,
            R,
            N,
            Ge
          );
          be.push({
            segmentation: we,
            segments_info: xe
          });
        }
        return be;
      }
      function F(A, L = 0.5, I = null) {
        throw new Error("`post_process_instance_segmentation` is not yet implemented.");
      }
      class E extends i.Callable {
        /**
         * Constructs a new `ImageProcessor`.
         * @param {ImageProcessorConfig} config The configuration object.
         */
        constructor(L) {
          super(), this.image_mean = L.image_mean ?? L.mean, this.image_std = L.image_std ?? L.std, this.resample = L.resample ?? 2, this.do_rescale = L.do_rescale ?? !0, this.rescale_factor = L.rescale_factor ?? 1 / 255, this.do_normalize = L.do_normalize, this.do_thumbnail = L.do_thumbnail, this.size = L.size ?? L.image_size, this.do_resize = L.do_resize ?? this.size !== void 0, this.size_divisibility = L.size_divisibility ?? L.size_divisor, this.do_center_crop = L.do_center_crop, this.crop_size = L.crop_size, this.do_convert_rgb = L.do_convert_rgb ?? !0, this.do_crop_margin = L.do_crop_margin, this.pad_size = L.pad_size, this.do_pad = L.do_pad, this.min_pixels = L.min_pixels, this.max_pixels = L.max_pixels, this.do_pad && !this.pad_size && this.size && this.size.width !== void 0 && this.size.height !== void 0 && (this.pad_size = this.size), this.do_flip_channel_order = L.do_flip_channel_order ?? !1, this.config = L;
        }
        /**
         * Resize the image to make a thumbnail. The image is resized so that no dimension is larger than any
         * corresponding dimension of the specified size.
         * @param {RawImage} image The image to be resized.
         * @param {{height:number, width:number}} size The size `{"height": h, "width": w}` to resize the image to.
         * @param {string | 0 | 1 | 2 | 3 | 4 | 5} [resample=2] The resampling filter to use.
         * @returns {Promise<RawImage>} The resized image.
         */
        async thumbnail(L, I, R = 2) {
          const N = L.height, q = L.width, ne = I.height, Q = I.width;
          let W = Math.min(N, ne), te = Math.min(q, Q);
          return W === N && te === q ? L : (N > q ? te = Math.floor(q * W / N) : q > N && (W = Math.floor(N * te / q)), await L.resize(te, W, { resample: R }));
        }
        /**
         * Crops the margin of the image. Gray pixels are considered margin (i.e., pixels with a value below the threshold).
         * @param {RawImage} image The image to be cropped.
         * @param {number} gray_threshold Value below which pixels are considered to be gray.
         * @returns {Promise<RawImage>} The cropped image.
         */
        async crop_margin(L, I = 200) {
          const R = L.clone().grayscale(), N = (0, a.min)(R.data)[0], ne = (0, a.max)(R.data)[0] - N;
          if (ne === 0)
            return L;
          const Q = I / 255;
          let W = R.width, te = R.height, K = 0, pe = 0;
          const be = R.data;
          for (let Ee = 0; Ee < R.height; ++Ee) {
            const Ge = Ee * R.width;
            for (let _e = 0; _e < R.width; ++_e)
              (be[Ge + _e] - N) / ne < Q && (W = Math.min(W, _e), te = Math.min(te, Ee), K = Math.max(K, _e), pe = Math.max(pe, Ee));
          }
          return L = await L.crop([W, te, K, pe]), L;
        }
        /**
         * Pad the image by a certain amount.
         * @param {Float32Array} pixelData The pixel data to pad.
         * @param {number[]} imgDims The dimensions of the image (height, width, channels).
         * @param {{width:number; height:number}|number|'square'} padSize The dimensions of the padded image.
         * @param {Object} options The options for padding.
         * @param {'constant'|'symmetric'} [options.mode='constant'] The type of padding to add.
         * @param {boolean} [options.center=false] Whether to center the image.
         * @param {number|number[]} [options.constant_values=0] The constant value to use for padding.
         * @returns {[Float32Array, number[]]} The padded pixel data and image dimensions.
         */
        pad_image(L, I, R, {
          mode: N = "constant",
          center: q = !1,
          constant_values: ne = 0
        } = {}) {
          const [Q, W, te] = I;
          let K, pe;
          if (typeof R == "number" ? (K = R, pe = R) : R === "square" ? K = pe = Math.max(Q, W) : (K = R.width, pe = R.height), K !== W || pe !== Q) {
            const be = new Float32Array(K * pe * te);
            if (Array.isArray(ne))
              for (let _e = 0; _e < be.length; ++_e)
                be[_e] = ne[_e % te];
            else
              ne !== 0 && be.fill(ne);
            const [Ee, Ge] = q ? [Math.floor((K - W) / 2), Math.floor((pe - Q) / 2)] : [0, 0];
            for (let _e = 0; _e < Q; ++_e) {
              const De = (_e + Ge) * K, he = _e * W;
              for (let Z = 0; Z < W; ++Z) {
                const me = (De + Z + Ee) * te, we = (he + Z) * te;
                for (let xe = 0; xe < te; ++xe)
                  be[me + xe] = L[we + xe];
              }
            }
            if (N === "symmetric") {
              if (q)
                throw new Error("`center` padding is not supported when `mode` is set to `symmetric`.");
              const _e = Q - 1, De = W - 1;
              for (let he = 0; he < pe; ++he) {
                const Z = he * K, me = (0, c.calculateReflectOffset)(he, _e) * W;
                for (let we = 0; we < K; ++we) {
                  if (he < Q && we < W)
                    continue;
                  const xe = (Z + we) * te, et = (me + (0, c.calculateReflectOffset)(we, De)) * te;
                  for (let Ve = 0; Ve < te; ++Ve)
                    be[xe + Ve] = L[et + Ve];
                }
              }
            }
            L = be, I = [pe, K, te];
          }
          return [L, I];
        }
        /**
         * Rescale the image' pixel values by `this.rescale_factor`.
         * @param {Float32Array} pixelData The pixel data to rescale.
         * @returns {void}
         */
        rescale(L) {
          for (let I = 0; I < L.length; ++I)
            L[I] = this.rescale_factor * L[I];
        }
        /**
         * Find the target (width, height) dimension of the output image after
         * resizing given the input image and the desired size.
         * @param {RawImage} image The image to resize.
         * @param {any} size The size to use for resizing the image. 
         * @returns {[number, number]} The target (width, height) dimension of the output image after resizing.
         */
        get_resize_output_image_size(L, I) {
          const [R, N] = L.size;
          let q, ne;
          if (this.do_thumbnail) {
            const { height: Q, width: W } = I;
            q = Math.min(Q, W);
          } else
            Number.isInteger(I) ? (q = I, ne = this.config.max_size ?? q) : I !== void 0 && (q = I.shortest_edge, ne = I.longest_edge);
          if (q !== void 0 || ne !== void 0) {
            const Q = q === void 0 ? 1 : Math.max(q / R, q / N), W = R * Q, te = N * Q, K = ne === void 0 ? 1 : Math.min(ne / W, ne / te);
            let pe = Math.floor(Number((W * K).toFixed(2))), be = Math.floor(Number((te * K).toFixed(2)));
            return this.size_divisibility !== void 0 && ([pe, be] = m([pe, be], this.size_divisibility)), [pe, be];
          } else if (I !== void 0 && I.width !== void 0 && I.height !== void 0) {
            let Q = I.width, W = I.height;
            if (this.config.keep_aspect_ratio && this.config.ensure_multiple_of) {
              let te = W / N, K = Q / R;
              Math.abs(1 - K) < Math.abs(1 - te) ? te = K : K = te, W = f(te * N, this.config.ensure_multiple_of), Q = f(K * R, this.config.ensure_multiple_of);
            }
            return [Q, W];
          } else {
            if (this.size_divisibility !== void 0)
              return m([R, N], this.size_divisibility);
            if (this.min_pixels !== void 0 && this.max_pixels !== void 0) {
              const Q = this.config.patch_size * this.config.merge_size;
              return w(N, R, Q, this.min_pixels, this.max_pixels);
            } else
              throw new Error(`Could not resize image due to unsupported \`this.size\` option in config: ${JSON.stringify(I)}`);
          }
        }
        /**
         * Resizes the image.
         * @param {RawImage} image The image to resize.
         * @returns {Promise<RawImage>} The resized image.
         */
        async resize(L) {
          const [I, R] = this.get_resize_output_image_size(L, this.size);
          return await L.resize(I, R, {
            // @ts-expect-error TS2322
            resample: this.resample
          });
        }
        /**
         * @typedef {object} PreprocessedImage
         * @property {HeightWidth} original_size The original size of the image.
         * @property {HeightWidth} reshaped_input_size The reshaped input size of the image.
         * @property {Tensor} pixel_values The pixel values of the preprocessed image.
         */
        /**
         * Preprocesses the given image.
         *
         * @param {RawImage} image The image to preprocess.
         * @param {Object} overrides The overrides for the preprocessing options.
         * @returns {Promise<PreprocessedImage>} The preprocessed image.
         */
        async preprocess(L, {
          do_normalize: I = null,
          do_pad: R = null,
          do_convert_rgb: N = null,
          do_convert_grayscale: q = null,
          do_flip_channel_order: ne = null
        } = {}) {
          this.do_crop_margin && (L = await this.crop_margin(L));
          const [Q, W] = L.size;
          if (N ?? this.do_convert_rgb ? L = L.rgb() : q && (L = L.grayscale()), this.do_resize && (L = await this.resize(L)), this.do_thumbnail && (L = await this.thumbnail(L, this.size, this.resample)), this.do_center_crop) {
            let Ee, Ge;
            Number.isInteger(this.crop_size) ? (Ee = this.crop_size, Ge = this.crop_size) : (Ee = this.crop_size.width, Ge = this.crop_size.height), L = await L.center_crop(Ee, Ge);
          }
          const te = [L.height, L.width];
          let K = Float32Array.from(L.data), pe = [L.height, L.width, L.channels];
          if (this.do_rescale && this.rescale(K), I ?? this.do_normalize) {
            let Ee = this.image_mean;
            Array.isArray(this.image_mean) || (Ee = new Array(L.channels).fill(Ee));
            let Ge = this.image_std;
            if (Array.isArray(this.image_std) || (Ge = new Array(L.channels).fill(Ge)), Ee.length !== L.channels || Ge.length !== L.channels)
              throw new Error(`When set to arrays, the length of \`image_mean\` (${Ee.length}) and \`image_std\` (${Ge.length}) must match the number of channels in the image (${L.channels}).`);
            for (let _e = 0; _e < K.length; _e += L.channels)
              for (let De = 0; De < L.channels; ++De)
                K[_e + De] = (K[_e + De] - Ee[De]) / Ge[De];
          }
          if (R ?? this.do_pad) {
            if (this.pad_size)
              [K, pe] = this.pad_image(K, [L.height, L.width, L.channels], this.pad_size);
            else if (this.size_divisibility) {
              const [Ee, Ge] = m([pe[1], pe[0]], this.size_divisibility);
              [K, pe] = this.pad_image(K, pe, { width: Ee, height: Ge });
            }
          }
          if (ne ?? this.do_flip_channel_order) {
            if (pe[2] !== 3)
              throw new Error("Flipping channel order is only supported for RGB images.");
            for (let Ee = 0; Ee < K.length; Ee += 3) {
              const Ge = K[Ee];
              K[Ee] = K[Ee + 2], K[Ee + 2] = Ge;
            }
          }
          const be = new r.Tensor("float32", K, pe).permute(2, 0, 1);
          return {
            original_size: [W, Q],
            reshaped_input_size: te,
            pixel_values: be
          };
        }
        /**
         * Calls the feature extraction process on an array of images,
         * preprocesses each image, and concatenates the resulting
         * features into a single Tensor.
         * @param {RawImage[]} images The image(s) to extract features from.
         * @param {...any} args Additional arguments.
         * @returns {Promise<ImageProcessorResult>} An object containing the concatenated pixel values (and other metadata) of the preprocessed images.
         */
        async _call(L, ...I) {
          Array.isArray(L) || (L = [L]);
          const R = await Promise.all(L.map((q) => this.preprocess(q)));
          return {
            pixel_values: (0, r.stack)(R.map((q) => q.pixel_values), 0),
            // Original sizes of images
            original_sizes: R.map((q) => q.original_size),
            // Reshaped sizes of images, before padding or cropping
            reshaped_input_sizes: R.map((q) => q.reshaped_input_size)
          };
        }
        /**
         * Instantiate one of the processor classes of the library from a pretrained model.
         * 
         * The processor class to instantiate is selected based on the `image_processor_type` (or `feature_extractor_type`; legacy)
         * property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
         * 
         * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
         * - A string, the *model id* of a pretrained processor hosted inside a model repo on huggingface.co.
         *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
         *   user or organization name, like `dbmdz/bert-base-german-cased`.
         * - A path to a *directory* containing processor files, e.g., `./my_model_directory/`.
         * @param {import('../utils/hub.js').PretrainedOptions} options Additional options for loading the processor.
         * 
         * @returns {Promise<ImageProcessor>} A new instance of the Processor class.
         */
        static async from_pretrained(L, I = {}) {
          const R = await (0, u.getModelJSON)(L, l.IMAGE_PROCESSOR_NAME, !0, I);
          return new this(R);
        }
      }
    }
  ),
  /***/
  "./src/base/processing_utils.js": (
    /*!**************************************!*\
      !*** ./src/base/processing_utils.js ***!
      \**************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Processor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/constants.js */
        "./src/utils/constants.js"
      ), r = t(
        /*! ../utils/generic.js */
        "./src/utils/generic.js"
      ), a = t(
        /*! ../utils/hub.js */
        "./src/utils/hub.js"
      );
      class c extends r.Callable {
        /**
         * Creates a new Processor with the given components
         * @param {Object} config 
         * @param {Record<string, Object>} components 
         * @param {string} chat_template
         */
        constructor(l, f, m) {
          super(), this.config = l, this.components = f, this.chat_template = m;
        }
        /**
         * @returns {import('./image_processors_utils.js').ImageProcessor|undefined} The image processor of the processor, if it exists.
         */
        get image_processor() {
          return this.components.image_processor;
        }
        /**
         * @returns {PreTrainedTokenizer|undefined} The tokenizer of the processor, if it exists.
         */
        get tokenizer() {
          return this.components.tokenizer;
        }
        /**
         * @returns {import('./feature_extraction_utils.js').FeatureExtractor|undefined} The feature extractor of the processor, if it exists.
         */
        get feature_extractor() {
          return this.components.feature_extractor;
        }
        /**
         * @param {Parameters<PreTrainedTokenizer['apply_chat_template']>[0]} messages
         * @param {Parameters<PreTrainedTokenizer['apply_chat_template']>[1]} options
         * @returns {ReturnType<PreTrainedTokenizer['apply_chat_template']>}
         */
        apply_chat_template(l, f = {}) {
          if (!this.tokenizer)
            throw new Error("Unable to apply chat template without a tokenizer.");
          return this.tokenizer.apply_chat_template(l, {
            tokenize: !1,
            // default to false
            chat_template: this.chat_template ?? void 0,
            ...f
          });
        }
        /**
         * @param {Parameters<PreTrainedTokenizer['batch_decode']>} args
         * @returns {ReturnType<PreTrainedTokenizer['batch_decode']>}
         */
        batch_decode(...l) {
          if (!this.tokenizer)
            throw new Error("Unable to decode without a tokenizer.");
          return this.tokenizer.batch_decode(...l);
        }
        /**
         * @param {Parameters<PreTrainedTokenizer['decode']>} args
         * @returns {ReturnType<PreTrainedTokenizer['decode']>}
         */
        decode(...l) {
          if (!this.tokenizer)
            throw new Error("Unable to decode without a tokenizer.");
          return this.tokenizer.decode(...l);
        }
        /**
         * Calls the feature_extractor function with the given input.
         * @param {any} input The input to extract features from.
         * @param {...any} args Additional arguments.
         * @returns {Promise<any>} A Promise that resolves with the extracted features.
         */
        async _call(l, ...f) {
          for (const m of [this.image_processor, this.feature_extractor, this.tokenizer])
            if (m)
              return m(l, ...f);
          throw new Error("No image processor, feature extractor, or tokenizer found.");
        }
        /**
         * Instantiate one of the processor classes of the library from a pretrained model.
         * 
         * The processor class to instantiate is selected based on the `image_processor_type` (or `feature_extractor_type`; legacy)
         * property of the config object (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
         * 
         * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
         * - A string, the *model id* of a pretrained processor hosted inside a model repo on huggingface.co.
         *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
         *   user or organization name, like `dbmdz/bert-base-german-cased`.
         * - A path to a *directory* containing processor files, e.g., `./my_model_directory/`.
         * @param {PretrainedProcessorOptions} options Additional options for loading the processor.
         * 
         * @returns {Promise<Processor>} A new instance of the Processor class.
         */
        static async from_pretrained(l, f = {}) {
          const [m, h, p] = await Promise.all([
            // TODO:
            this.uses_processor_config ? (0, a.getModelJSON)(l, i.PROCESSOR_NAME, !0, f) : {},
            Promise.all(
              this.classes.filter((_) => _ in this).map(async (_) => {
                const v = await this[_].from_pretrained(l, f);
                return [_.replace(/_class$/, ""), v];
              })
            ).then(Object.fromEntries),
            this.uses_chat_template_file ? (0, a.getModelText)(l, i.CHAT_TEMPLATE_NAME, !0, f) : null
          ]);
          return new this(m, h, p);
        }
      }
      Ce(c, "classes", [
        "image_processor_class",
        "tokenizer_class",
        "feature_extractor_class"
      ]), Ce(c, "uses_processor_config", !1), Ce(c, "uses_chat_template_file", !1);
    }
  ),
  /***/
  "./src/configs.js": (
    /*!************************!*\
      !*** ./src/configs.js ***!
      \************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        AutoConfig: () => (
          /* binding */
          m
        ),
        /* harmony export */
        PretrainedConfig: () => (
          /* binding */
          f
        ),
        /* harmony export */
        getCacheShapes: () => (
          /* binding */
          u
        )
        /* harmony export */
      });
      var i = t(
        /*! ./utils/core.js */
        "./src/utils/core.js"
      ), r = t(
        /*! ./utils/hub.js */
        "./src/utils/hub.js"
      );
      async function a(h, p) {
        return await (0, r.getModelJSON)(h, "config.json", !0, p);
      }
      function c(h) {
        const p = {};
        let _ = {};
        switch (h.model_type) {
          case "llava":
          case "paligemma":
          case "gemma3":
          case "florence2":
          case "llava_onevision":
          case "idefics3":
          case "ultravox":
          case "voxtral":
          case "smolvlm":
          case "gemma3n":
          case "mistral3":
            _ = c(h.text_config);
            break;
          case "moondream1":
            _ = c(h.phi_config);
            break;
          case "musicgen":
            _ = c(h.decoder);
            break;
          case "multi_modality":
            _ = c(h.language_config);
            break;
          case "gpt2":
          case "gptj":
          case "jais":
          case "codegen":
          case "gpt_bigcode":
            p.num_heads = "n_head", p.num_layers = "n_layer", p.hidden_size = "n_embd";
            break;
          case "gpt_neox":
          case "stablelm":
          case "opt":
          case "falcon":
          case "modernbert-decoder":
            p.num_heads = "num_attention_heads", p.num_layers = "num_hidden_layers", p.hidden_size = "hidden_size";
            break;
          case "llama":
          case "llama4_text":
          case "nanochat":
          case "arcee":
          case "lfm2":
          case "smollm3":
          case "olmo":
          case "olmo2":
          case "mobilellm":
          case "granite":
          case "granitemoehybrid":
          case "cohere":
          case "mistral":
          case "starcoder2":
          case "qwen2":
          case "qwen2_vl":
          case "phi":
          case "phi3":
          case "phi3_v":
          case "llava_qwen2":
            p.num_heads = "num_key_value_heads", p.num_layers = "num_hidden_layers", p.hidden_size = "hidden_size", p.num_attention_heads = "num_attention_heads", p.dim_kv = "head_dim";
            break;
          case "qwen3":
          case "gemma":
          case "gemma2":
          case "vaultgemma":
          case "gemma3_text":
          case "gemma3n_text":
          case "glm":
          case "helium":
          case "ernie4_5":
          case "ministral":
          case "ministral3":
            p.num_heads = "num_key_value_heads", p.num_layers = "num_hidden_layers", p.dim_kv = "head_dim";
            break;
          case "openelm":
            p.num_heads = "num_kv_heads", p.num_layers = "num_transformer_layers", p.dim_kv = "head_dim";
            break;
          case "gpt_neo":
          case "donut-swin":
            p.num_heads = "num_heads", p.num_layers = "num_layers", p.hidden_size = "hidden_size";
            break;
          case "bloom":
            p.num_heads = "n_head", p.num_layers = "n_layer", p.hidden_size = "hidden_size";
            break;
          case "mpt":
            p.num_heads = "n_heads", p.num_layers = "n_layers", p.hidden_size = "d_model";
            break;
          case "exaone":
            p.num_heads = "num_key_value_heads", p.num_layers = "num_layers", p.dim_kv = "head_dim", p.num_attention_heads = "num_attention_heads";
            break;
          case "t5":
          case "mt5":
          case "longt5":
            p.num_decoder_layers = "num_decoder_layers", p.num_decoder_heads = "num_heads", p.decoder_dim_kv = "d_kv", p.num_encoder_layers = "num_layers", p.num_encoder_heads = "num_heads", p.encoder_dim_kv = "d_kv";
            break;
          case "bart":
          case "mbart":
          case "marian":
          case "whisper":
          case "lite-whisper":
          case "m2m_100":
          case "blenderbot":
          case "blenderbot-small":
          case "florence2_language":
            p.num_decoder_layers = "decoder_layers", p.num_decoder_heads = "decoder_attention_heads", p.decoder_hidden_size = "d_model", p.num_encoder_layers = "encoder_layers", p.num_encoder_heads = "encoder_attention_heads", p.encoder_hidden_size = "d_model";
            break;
          case "speecht5":
            p.num_decoder_layers = "decoder_layers", p.num_decoder_heads = "decoder_attention_heads", p.decoder_hidden_size = "hidden_size", p.num_encoder_layers = "encoder_layers", p.num_encoder_heads = "encoder_attention_heads", p.encoder_hidden_size = "hidden_size";
            break;
          case "trocr":
            p.num_encoder_layers = p.num_decoder_layers = "decoder_layers", p.num_encoder_heads = p.num_decoder_heads = "decoder_attention_heads", p.encoder_hidden_size = p.decoder_hidden_size = "d_model";
            break;
          case "musicgen_decoder":
            p.num_encoder_layers = p.num_decoder_layers = "num_hidden_layers", p.num_encoder_heads = p.num_decoder_heads = "num_attention_heads", p.encoder_hidden_size = p.decoder_hidden_size = "hidden_size";
            break;
          case "moonshine":
            p.num_decoder_layers = "decoder_num_hidden_layers", p.num_decoder_heads = "decoder_num_key_value_heads", p.num_encoder_layers = "encoder_num_hidden_layers", p.num_encoder_heads = "encoder_num_key_value_heads", p.encoder_hidden_size = p.decoder_hidden_size = "hidden_size";
            break;
          case "vision-encoder-decoder":
            const S = c(h.decoder), D = "num_decoder_layers" in S, w = (0, i.pick)(h, ["model_type", "is_encoder_decoder"]);
            return D ? (w.num_decoder_layers = S.num_decoder_layers, w.num_decoder_heads = S.num_decoder_heads, w.decoder_hidden_size = S.decoder_hidden_size, w.num_encoder_layers = S.num_encoder_layers, w.num_encoder_heads = S.num_encoder_heads, w.encoder_hidden_size = S.encoder_hidden_size) : (w.num_layers = S.num_layers, w.num_heads = S.num_heads, w.hidden_size = S.hidden_size), w;
        }
        const v = {
          ..._,
          ...(0, i.pick)(h, ["model_type", "multi_query", "is_encoder_decoder"])
        };
        for (const S in p)
          v[S] = h[p[S]];
        return v;
      }
      function u(h, p) {
        if (h.model_type === "lfm2") {
          const _ = (p == null ? void 0 : p.prefix) ?? "past_key_values", v = _ === "present" ? "present" : "past", S = {}, { layer_types: D, num_attention_heads: w, num_key_value_heads: T, hidden_size: F, conv_L_cache: E } = h, A = F / w, L = (p == null ? void 0 : p.batch_size) ?? 1;
          for (let I = 0; I < D.length; ++I)
            if (D[I] === "full_attention")
              for (const R of ["key", "value"])
                S[`${_}.${I}.${R}`] = [L, T, 0, A];
            else if (D[I] === "conv")
              S[`${v}_conv.${I}`] = [L, F, E];
            else
              throw new Error(`Unsupported layer type: ${D[I]}`);
          return S;
        }
        return l(h, p);
      }
      function l(h, {
        prefix: p = "past_key_values",
        batch_size: _ = 1
      } = {}) {
        const v = {}, S = h.normalized_config;
        if (S.is_encoder_decoder && "num_encoder_heads" in S && "num_decoder_heads" in S) {
          const D = S.encoder_dim_kv ?? S.encoder_hidden_size / S.num_encoder_heads, w = S.decoder_dim_kv ?? S.decoder_hidden_size / S.num_decoder_heads, T = [_, S.num_encoder_heads, 0, D], F = [_, S.num_decoder_heads, 0, w];
          for (let E = 0; E < S.num_decoder_layers; ++E)
            v[`${p}.${E}.encoder.key`] = T, v[`${p}.${E}.encoder.value`] = T, v[`${p}.${E}.decoder.key`] = F, v[`${p}.${E}.decoder.value`] = F;
        } else {
          const D = S.num_heads, w = S.num_layers, T = S.dim_kv ?? S.hidden_size / (S.num_attention_heads ?? D);
          if (S.model_type === "falcon") {
            const F = [_ * D, 0, T];
            for (let E = 0; E < w; ++E)
              v[`${p}.${E}.key`] = F, v[`${p}.${E}.value`] = F;
          } else if (S.multi_query) {
            const F = [_ * D, 0, 2 * T];
            for (let E = 0; E < w; ++E)
              v[`${p}.${E}.key_value`] = F;
          } else if (S.model_type === "bloom") {
            const F = [_ * D, T, 0], E = [_ * D, 0, T];
            for (let A = 0; A < w; ++A)
              v[`${p}.${A}.key`] = F, v[`${p}.${A}.value`] = E;
          } else if (S.model_type === "openelm")
            for (let F = 0; F < w; ++F) {
              const E = [_, D[F], 0, T];
              v[`${p}.${F}.key`] = E, v[`${p}.${F}.value`] = E;
            }
          else {
            const F = [_, D, 0, T];
            for (let E = 0; E < w; ++E)
              v[`${p}.${E}.key`] = F, v[`${p}.${E}.value`] = F;
          }
        }
        return v;
      }
      class f {
        /**
         * Create a new PreTrainedTokenizer instance.
         * @param {Object} configJSON The JSON of the config.
         */
        constructor(p) {
          // NOTE: Typo in original
          /** @type {string|null} */
          Ce(this, "model_type", null);
          /** @type {boolean} */
          Ce(this, "is_encoder_decoder", !1);
          /** @type {number} */
          Ce(this, "max_position_embeddings");
          /** @type {TransformersJSConfig} */
          Ce(this, "transformers.js_config");
          Object.assign(this, p), this.normalized_config = c(this);
        }
        /**
         * Loads a pre-trained config from the given `pretrained_model_name_or_path`. 
         * 
         * @param {string} pretrained_model_name_or_path The path to the pre-trained config.
         * @param {PretrainedOptions} options Additional options for loading the config.
         * @throws {Error} Throws an error if the config.json is not found in the `pretrained_model_name_or_path`.
         * 
         * @returns {Promise<PretrainedConfig>} A new instance of the `PretrainedConfig` class.
         */
        static async from_pretrained(p, {
          progress_callback: _ = null,
          config: v = null,
          cache_dir: S = null,
          local_files_only: D = !1,
          revision: w = "main"
        } = {}) {
          v && !(v instanceof f) && (v = new f(v));
          const T = v ?? await a(p, {
            progress_callback: _,
            config: v,
            cache_dir: S,
            local_files_only: D,
            revision: w
          });
          return new this(T);
        }
      }
      class m {
        /** @type {typeof PretrainedConfig.from_pretrained} */
        static async from_pretrained(...p) {
          return f.from_pretrained(...p);
        }
      }
    }
  ),
  /***/
  "./src/env.js": (
    /*!********************!*\
      !*** ./src/env.js ***!
      \********************/
    /***/
    (e, n, t) => {
      var N, q;
      t.r(n), t.d(n, {
        /* harmony export */
        apis: () => (
          /* binding */
          w
        ),
        /* harmony export */
        env: () => (
          /* binding */
          I
        )
        /* harmony export */
      });
      var i = t(
        /*! node:fs */
        "?db59"
      ), r = t(
        /*! node:path */
        "?383f"
      ), a = t(
        /*! node:url */
        "?fa4b"
      );
      const c = "3.8.1", u = typeof window < "u" && typeof window.document < "u", l = typeof self < "u" && ["DedicatedWorkerGlobalScope", "ServiceWorkerGlobalScope", "SharedWorkerGlobalScope"].includes((N = self.constructor) == null ? void 0 : N.name), f = typeof self < "u" && "caches" in self, m = typeof navigator < "u" && "gpu" in navigator, h = typeof navigator < "u" && "ml" in navigator, p = typeof process < "u", _ = p && ((q = process == null ? void 0 : process.release) == null ? void 0 : q.name) === "node", v = !R(i), S = !R(r), D = typeof globalThis.Deno < "u", w = Object.freeze({
        /** Whether we are running in a browser environment (and not a web worker) */
        IS_BROWSER_ENV: u,
        /** Whether we are running in a web worker environment */
        IS_WEBWORKER_ENV: l,
        /** Whether the Cache API is available */
        IS_WEB_CACHE_AVAILABLE: f,
        /** Whether the WebGPU API is available */
        IS_WEBGPU_AVAILABLE: m,
        /** Whether the WebNN API is available */
        IS_WEBNN_AVAILABLE: h,
        /** Whether the Node.js process API is available */
        IS_PROCESS_AVAILABLE: p,
        /** Whether we are running in a Node.js-like environment (node, deno, bun) */
        IS_NODE_ENV: _,
        /** Whether the filesystem API is available */
        IS_FS_AVAILABLE: v,
        /** Whether the path API is available */
        IS_PATH_AVAILABLE: S
      }), T = v && S;
      let F = "./";
      if (T) {
        const ne = Object(import.meta).url;
        ne ? F = r.dirname(r.dirname(a.fileURLToPath(ne))) : typeof __dirname < "u" && (F = r.dirname(__dirname));
      }
      const E = T ? r.join(F, "/.cache/") : null, A = "/models/", L = T ? r.join(F, A) : A, I = {
        version: c,
        /////////////////// Backends settings ///////////////////
        // NOTE: These will be populated later by the backends themselves.
        backends: {
          // onnxruntime-web/onnxruntime-node
          onnx: {}
        },
        /////////////////// Model settings ///////////////////
        allowRemoteModels: !0,
        remoteHost: "https://huggingface.co/",
        remotePathTemplate: "{model}/resolve/{revision}/",
        allowLocalModels: !(u || l),
        localModelPath: L,
        useFS: v,
        /////////////////// Cache settings ///////////////////
        useBrowserCache: f && !D,
        useFSCache: v,
        cacheDir: E,
        useCustomCache: !1,
        customCache: null
        //////////////////////////////////////////////////////
      };
      function R(ne) {
        return Object.keys(ne).length === 0;
      }
    }
  ),
  /***/
  "./src/generation/configuration_utils.js": (
    /*!***********************************************!*\
      !*** ./src/generation/configuration_utils.js ***!
      \***********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        GenerationConfig: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/core.js */
        "./src/utils/core.js"
      );
      class r {
        /**
         * 
         * @param {GenerationConfig|import('../configs.js').PretrainedConfig} config 
         */
        constructor(c) {
          // Parameters that control the length of the output
          /**
           * The maximum length the generated tokens can have.
           * Corresponds to the length of the input prompt + `max_new_tokens`.
           * Its effect is overridden by `max_new_tokens`, if also set.
           * @type {number}
           * @default 20
           */
          Ce(this, "max_length", 20);
          /**
           * The maximum numbers of tokens to generate, ignoring the number of tokens in the prompt.
           * @type {number}
           * @default null
           */
          Ce(this, "max_new_tokens", null);
          /**
           * The minimum length of the sequence to be generated.
           * Corresponds to the length of the input prompt + `min_new_tokens`.
           * Its effect is overridden by `min_new_tokens`, if also set.
           * @type {number}
           * @default 0
           */
          Ce(this, "min_length", 0);
          /**
           * The minimum numbers of tokens to generate, ignoring the number of tokens in the prompt.
           * @type {number}
           * @default null
           */
          Ce(this, "min_new_tokens", null);
          /**
           * Controls the stopping condition for beam-based methods, like beam-search. It accepts the following values:
           * - `true`, where the generation stops as soon as there are `num_beams` complete candidates;
           * - `false`, where an heuristic is applied and the generation stops when is it very unlikely to find better candidates;
           * - `"never"`, where the beam search procedure only stops when there cannot be better candidates (canonical beam search algorithm).
           * @type {boolean|"never"}
           * @default false
           */
          Ce(this, "early_stopping", !1);
          /**
           * The maximum amount of time you allow the computation to run for in seconds.
           * Generation will still finish the current pass after allocated time has been passed.
           * @type {number}
           * @default null
           */
          Ce(this, "max_time", null);
          // Parameters that control the generation strategy used
          /**
           * Whether or not to use sampling; use greedy decoding otherwise.
           * @type {boolean}
           * @default false
           */
          Ce(this, "do_sample", !1);
          /**
           * Number of beams for beam search. 1 means no beam search.
           * @type {number}
           * @default 1
           */
          Ce(this, "num_beams", 1);
          /**
           * Number of groups to divide `num_beams` into in order to ensure diversity among different groups of beams.
           * See [this paper](https://huggingface.co/papers/1610.02424) for more details.
           * @type {number}
           * @default 1
           */
          Ce(this, "num_beam_groups", 1);
          /**
           * The values balance the model confidence and the degeneration penalty in contrastive search decoding.
           * @type {number}
           * @default null
           */
          Ce(this, "penalty_alpha", null);
          /**
           * Whether or not the model should use the past last key/values attentions (if applicable to the model) to speed up decoding.
           * @type {boolean}
           * @default true
           */
          Ce(this, "use_cache", !0);
          // Parameters for manipulation of the model output logits
          /**
           * The value used to modulate the next token probabilities.
           * @type {number}
           * @default 1.0
           */
          Ce(this, "temperature", 1);
          /**
           * The number of highest probability vocabulary tokens to keep for top-k-filtering.
           * @type {number}
           * @default 50
           */
          Ce(this, "top_k", 50);
          /**
           * If set to float < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation.
           * @type {number}
           * @default 1.0
           */
          Ce(this, "top_p", 1);
          /**
           * Local typicality measures how similar the conditional probability of predicting a target token next is to the expected conditional probability of predicting a random token next, given the partial text already generated.
           * If set to float < 1, the smallest set of the most locally typical tokens with probabilities that add up to `typical_p` or higher are kept for generation.
           * See [this paper](https://huggingface.co/papers/2202.00666) for more details.
           * @type {number}
           * @default 1.0
           */
          Ce(this, "typical_p", 1);
          /**
           * If set to float strictly between 0 and 1, only tokens with a conditional probability greater than `epsilon_cutoff` will be sampled.
           * In the paper, suggested values range from 3e-4 to 9e-4, depending on the size of the model.
           * See [Truncation Sampling as Language Model Desmoothing](https://huggingface.co/papers/2210.15191) for more details.
           * @type {number}
           * @default 0.0
           */
          Ce(this, "epsilon_cutoff", 0);
          /**
           * Eta sampling is a hybrid of locally typical sampling and epsilon sampling.
           * If set to float strictly between 0 and 1, a token is only considered if it is greater than either `eta_cutoff` or `sqrt(eta_cutoff) * exp(-entropy(softmax(next_token_logits)))`.
           * The latter term is intuitively the expected next token probability, scaled by `sqrt(eta_cutoff)`. In the paper, suggested values range from 3e-4 to 2e-3, depending on the size of the model.
           * See [Truncation Sampling as Language Model Desmoothing](https://huggingface.co/papers/2210.15191) for more details.
           * @type {number}
           * @default 0.0
           */
          Ce(this, "eta_cutoff", 0);
          /**
           * This value is subtracted from a beam's score if it generates a token same as any beam from other group at a particular time.
           * Note that `diversity_penalty` is only effective if `group beam search` is enabled.
           * @type {number}
           * @default 0.0
           */
          Ce(this, "diversity_penalty", 0);
          /**
           * The parameter for repetition penalty. 1.0 means no penalty.
           * See [this paper](https://huggingface.co/papers/1909.05858) for more details.
           * @type {number}
           * @default 1.0
           */
          Ce(this, "repetition_penalty", 1);
          /**
           * The paramater for encoder_repetition_penalty.
           * An exponential penalty on sequences that are not in the original input.
           * 1.0 means no penalty.
           * @type {number}
           * @default 1.0
           */
          Ce(this, "encoder_repetition_penalty", 1);
          /**
           * Exponential penalty to the length that is used with beam-based generation.
           * It is applied as an exponent to the sequence length, which in turn is used to divide the score of the sequence.
           * Since the score is the log likelihood of the sequence (i.e. negative), `length_penalty` > 0.0 promotes longer sequences, while `length_penalty` < 0.0 encourages shorter sequences.
           * @type {number}
           * @default 1.0
           */
          Ce(this, "length_penalty", 1);
          /**
           * If set to int > 0, all ngrams of that size can only occur once.
           * @type {number}
           * @default 0
           */
          Ce(this, "no_repeat_ngram_size", 0);
          /**
           * List of token ids that are not allowed to be generated.
           * In order to get the token ids of the words that should not appear in the generated text, use
           * `tokenizer(bad_words, { add_prefix_space: true, add_special_tokens: false }).input_ids`.
           * @type {number[][]}
           * @default null
           */
          Ce(this, "bad_words_ids", null);
          /**
           * List of token ids that must be generated.
           * If given a `number[][]`, this is treated as a simple list of words that must be included, the opposite to `bad_words_ids`.
           * If given `number[][][]`, this triggers a [disjunctive constraint](https://github.com/huggingface/transformers/issues/14081), where one can allow different forms of each word.
           * @type {number[][]|number[][][]}
           * @default null
           */
          Ce(this, "force_words_ids", null);
          /**
           * Whether to renormalize the logits after applying all the logits processors or warpers (including the custom ones).
           * It's highly recommended to set this flag to `true` as the search algorithms suppose the score logits are normalized but some logit processors or warpers break the normalization.
           * @type {boolean}
           * @default false
           */
          Ce(this, "renormalize_logits", !1);
          /**
           * Custom constraints that can be added to the generation to ensure that the output will contain the use of certain tokens as defined by `Constraint` objects, in the most sensible way possible.
           * @type {Object[]}
           * @default null
           */
          Ce(this, "constraints", null);
          /**
           * The id of the token to force as the first generated token after the `decoder_start_token_id`.
           * Useful for multilingual models like mBART where the first generated token needs to be the target language token.
           * @type {number}
           * @default null
           */
          Ce(this, "forced_bos_token_id", null);
          /**
           * The id of the token to force as the last generated token when `max_length` is reached.
           * Optionally, use a list to set multiple *end-of-sequence* tokens.
           * @type {number|number[]}
           * @default null
           */
          Ce(this, "forced_eos_token_id", null);
          /**
           * Whether to remove possible *nan* and *inf* outputs of the model to prevent the generation method to crash. Note that using `remove_invalid_values` can slow down generation.
           * @type {boolean}
           */
          Ce(this, "remove_invalid_values", !1);
          /**
           * This Tuple adds an exponentially increasing length penalty, after a certain amount of tokens have been generated.
           * The tuple shall consist of: `(start_index, decay_factor)` where `start_index` indicates where penalty starts and `decay_factor` represents the factor of exponential decay.
           * @type {[number, number]}
           * @default null
           */
          Ce(this, "exponential_decay_length_penalty", null);
          /**
           * A list of tokens that will be suppressed at generation.
           * The `SuppressTokens` logit processor will set their log probs to `-inf` so that they are not sampled.
           * @type {number[]}
           * @default null
           */
          Ce(this, "suppress_tokens", null);
          /**
           * A streamer that will be used to stream the generation.
           * @type {import('./streamers.js').TextStreamer}
           * @default null
           */
          Ce(this, "streamer", null);
          /**
           * A list of tokens that will be suppressed at the beginning of the generation.
           * The `SuppressBeginTokens` logit processor will set their log probs to `-inf` so that they are not sampled.
           * @type {number[]}
           * @default null
           */
          Ce(this, "begin_suppress_tokens", null);
          /**
           * A list of pairs of integers which indicates a mapping from generation indices to token indices that will be forced before sampling.
           * For example, `[[1, 123]]` means the second generated token will always be a token of index 123.
           * @type {[number, number][]}
           * @default null
           */
          Ce(this, "forced_decoder_ids", null);
          /**
           * The guidance scale for classifier free guidance (CFG). CFG is enabled by setting `guidance_scale > 1`.
           * Higher guidance scale encourages the model to generate samples that are more closely linked to the input
           * prompt, usually at the expense of poorer quality.
           * @type {number}
           * @default null
           */
          Ce(this, "guidance_scale", null);
          // Parameters that define the output variables of `generate`
          /**
           * The number of independently computed returned sequences for each element in the batch.
           * @type {number}
           * @default 1
           */
          Ce(this, "num_return_sequences", 1);
          /**
           * Whether or not to return the attentions tensors of all attention layers.
           * See `attentions` under returned tensors for more details.
           * @type {boolean}
           * @default false
           */
          Ce(this, "output_attentions", !1);
          /**
           * Whether or not to return the hidden states of all layers.
           * See `hidden_states` under returned tensors for more details.
           * @type {boolean}
           * @default false
           */
          Ce(this, "output_hidden_states", !1);
          /**
           * Whether or not to return the prediction scores.
           * See `scores` under returned tensors for more details.
           * @type {boolean}
           * @default false
           */
          Ce(this, "output_scores", !1);
          /**
           * Whether or not to return a `ModelOutput` instead of a plain tuple.
           * @type {boolean}
           * @default false
           */
          Ce(this, "return_dict_in_generate", !1);
          // Special tokens that can be used at generation time
          /**
           * The id of the *padding* token.
           * @type {number}
           * @default null
           */
          Ce(this, "pad_token_id", null);
          /**
           * The id of the *beginning-of-sequence* token.
           * @type {number}
           * @default null
           */
          Ce(this, "bos_token_id", null);
          /**
           * The id of the *end-of-sequence* token.
           * Optionally, use a list to set multiple *end-of-sequence* tokens.
           * @type {number|number[]}
           * @default null
           */
          Ce(this, "eos_token_id", null);
          // Generation parameters exclusive to encoder-decoder models
          /**
           * If set to int > 0, all ngrams of that size that occur in the `encoder_input_ids` cannot occur in the `decoder_input_ids`.
           * @type {number}
           * @default 0
           */
          Ce(this, "encoder_no_repeat_ngram_size", 0);
          /**
           * If an encoder-decoder model starts decoding with a different token than *bos*, the id of that token.
           * @type {number}
           * @default null
           */
          Ce(this, "decoder_start_token_id", null);
          // Wild card
          /**
           * Additional generation kwargs will be forwarded to the `generate` function of the model.
           * Kwargs that are not present in `generate`'s signature will be used in the model forward pass.
           * @type {Object}
           * @default {}
           */
          Ce(this, "generation_kwargs", {});
          Object.assign(this, (0, i.pick)(c, Object.getOwnPropertyNames(this)));
        }
      }
    }
  ),
  /***/
  "./src/generation/logits_process.js": (
    /*!******************************************!*\
      !*** ./src/generation/logits_process.js ***!
      \******************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ClassifierFreeGuidanceLogitsProcessor: () => (
          /* binding */
          w
        ),
        /* harmony export */
        ForcedBOSTokenLogitsProcessor: () => (
          /* binding */
          l
        ),
        /* harmony export */
        ForcedEOSTokenLogitsProcessor: () => (
          /* binding */
          f
        ),
        /* harmony export */
        LogitsProcessor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        LogitsProcessorList: () => (
          /* binding */
          u
        ),
        /* harmony export */
        LogitsWarper: () => (
          /* binding */
          c
        ),
        /* harmony export */
        MinLengthLogitsProcessor: () => (
          /* binding */
          v
        ),
        /* harmony export */
        MinNewTokensLengthLogitsProcessor: () => (
          /* binding */
          S
        ),
        /* harmony export */
        NoBadWordsLogitsProcessor: () => (
          /* binding */
          D
        ),
        /* harmony export */
        NoRepeatNGramLogitsProcessor: () => (
          /* binding */
          p
        ),
        /* harmony export */
        RepetitionPenaltyLogitsProcessor: () => (
          /* binding */
          _
        ),
        /* harmony export */
        SuppressTokensAtBeginLogitsProcessor: () => (
          /* binding */
          m
        ),
        /* harmony export */
        TemperatureLogitsWarper: () => (
          /* binding */
          T
        ),
        /* harmony export */
        TopKLogitsWarper: () => (
          /* binding */
          E
        ),
        /* harmony export */
        TopPLogitsWarper: () => (
          /* binding */
          F
        ),
        /* harmony export */
        WhisperTimeStampLogitsProcessor: () => (
          /* binding */
          h
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/generic.js */
        "./src/utils/generic.js"
      );
      t(
        /*! ../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      var r = t(
        /*! ../utils/maths.js */
        "./src/utils/maths.js"
      );
      class a extends i.Callable {
        /**
         * Apply the processor to the input logits.
         *
         * @abstract
         * @param {bigint[][]} input_ids The input ids.
         * @param {Tensor} logits The logits to process.
         * @throws {Error} Throws an error if `_call` is not implemented in the subclass.
         */
        _call(L, I) {
          throw Error("`_call` should be implemented in a subclass");
        }
      }
      class c extends i.Callable {
        /**
         * Apply the processor to the input logits.
         *
         * @abstract
         * @param {bigint[][]} input_ids The input ids.
         * @param {Tensor} logits The logits to process.
         * @throws {Error} Throws an error if `_call` is not implemented in the subclass.
         */
        _call(L, I) {
          throw Error("`_call` should be implemented in a subclass");
        }
      }
      class u extends i.Callable {
        /**
         * Constructs a new instance of `LogitsProcessorList`.
         */
        constructor() {
          super(), this.processors = [];
        }
        /**
         * Adds a new logits processor to the list.
         *
         * @param {LogitsProcessor} item The logits processor function to add.
         */
        push(L) {
          this.processors.push(L);
        }
        /**
         * Adds multiple logits processors to the list.
         *
         * @param {LogitsProcessor[]} items The logits processor functions to add.
         */
        extend(L) {
          this.processors.push(...L);
        }
        /**
         * Applies all logits processors in the list to a batch of logits, modifying them in-place.
         *
         * @param {bigint[][]} input_ids The input IDs for the language model.
         * @param {Tensor} logits
         */
        _call(L, I) {
          let R = I;
          for (const N of this.processors)
            R = N(L, R);
          return R;
        }
        [Symbol.iterator]() {
          return this.processors.values();
        }
      }
      class l extends a {
        /**
         * Create a ForcedBOSTokenLogitsProcessor.
         * @param {number} bos_token_id The ID of the beginning-of-sequence token to be forced.
         */
        constructor(L) {
          super(), this.bos_token_id = L;
        }
        /**
         * Apply the BOS token forcing to the logits.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The logits with BOS token forcing.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R)
            if (L[R].length === 1) {
              const N = (
                /** @type {Float32Array} */
                I[R].data
              );
              N.fill(-1 / 0), N[this.bos_token_id] = 0;
            }
          return I;
        }
      }
      class f extends a {
        /**
         * Create a ForcedEOSTokenLogitsProcessor.
         * @param {number} max_length The maximum length of the sequence to be generated.
         * @param {number|number[]} eos_token_id The id(s) of the *end-of-sequence* token.
         */
        constructor(L, I) {
          super(), this.max_length = L, this.eos_token_id = Array.isArray(I) ? I : [I];
        }
        /**
         * Apply the processor to input_ids and logits.
         * 
         * @param {bigint[][]} input_ids The input ids.
         * @param {Tensor} logits The logits tensor.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R)
            if (L[R].length === this.max_length - 1) {
              const N = (
                /** @type {Float32Array} */
                I[R].data
              );
              N.fill(-1 / 0);
              for (const q of this.eos_token_id)
                N[q] = 0;
            }
          return I;
        }
      }
      class m extends a {
        /**
         * Create a SuppressTokensAtBeginLogitsProcessor.
         * @param {number[]} begin_suppress_tokens The IDs of the tokens to suppress.
         * @param {number} begin_index The number of tokens to generate before suppressing tokens.
         */
        constructor(L, I) {
          super(), this.begin_suppress_tokens = L, this.begin_index = I;
        }
        /**
         * Apply the BOS token forcing to the logits.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The logits with BOS token forcing.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R)
            if (L[R].length === this.begin_index) {
              const N = (
                /** @type {Float32Array} */
                I[R].data
              );
              for (const q of this.begin_suppress_tokens)
                N[q] = -1 / 0;
            }
          return I;
        }
      }
      class h extends a {
        /**
         * Constructs a new WhisperTimeStampLogitsProcessor.
         * @param {import('../models/whisper/generation_whisper.js').WhisperGenerationConfig} generate_config The config object passed to the `generate()` method of a transformer model.
         * @param {number[]} init_tokens The initial tokens of the input sequence.
         */
        constructor(L, I) {
          super(), this.eos_token_id = Array.isArray(L.eos_token_id) ? L.eos_token_id[0] : L.eos_token_id, this.no_timestamps_token_id = L.no_timestamps_token_id, this.timestamp_begin = this.no_timestamps_token_id + 1, this.begin_index = I.length, I.at(-1) === this.no_timestamps_token_id && (this.begin_index -= 1), this.max_initial_timestamp_index = L.max_initial_timestamp_index;
        }
        /**
         * Modify the logits to handle timestamp tokens.
         * @param {bigint[][]} input_ids The input sequence of tokens.
         * @param {Tensor} logits The logits output by the model.
         * @returns {Tensor} The modified logits.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R) {
            const N = (
              /** @type {Float32Array} */
              I[R].data
            );
            if (N[this.no_timestamps_token_id] = -1 / 0, L[R].length === this.begin_index - 1) {
              N.fill(-1 / 0), N[this.timestamp_begin] = 0;
              continue;
            }
            const q = L[R].slice(this.begin_index), ne = q.length >= 1 && q[q.length - 1] >= this.timestamp_begin, Q = q.length < 2 || q[q.length - 2] >= this.timestamp_begin;
            if (ne && (Q ? N.subarray(this.timestamp_begin).fill(-1 / 0) : N.subarray(0, this.eos_token_id).fill(-1 / 0)), L[R].length === this.begin_index && this.max_initial_timestamp_index !== null) {
              const pe = this.timestamp_begin + this.max_initial_timestamp_index;
              N.subarray(pe + 1).fill(-1 / 0);
            }
            const W = (0, r.log_softmax)(N), te = Math.log(W.subarray(this.timestamp_begin).map(Math.exp).reduce((pe, be) => pe + be)), K = (0, r.max)(W.subarray(0, this.timestamp_begin))[0];
            te > K && N.subarray(0, this.timestamp_begin).fill(-1 / 0);
          }
          return I;
        }
      }
      class p extends a {
        /**
         * Create a NoRepeatNGramLogitsProcessor.
         * @param {number} no_repeat_ngram_size The no-repeat-ngram size. All ngrams of this size can only occur once.
         */
        constructor(L) {
          super(), this.no_repeat_ngram_size = L;
        }
        /**
         * Generate n-grams from a sequence of token ids.
         * @param {bigint[]} prevInputIds List of previous input ids
         * @returns {Map<string, number[]>} Map of generated n-grams
         */
        getNgrams(L) {
          const I = L.length, R = [];
          for (let q = 0; q < I + 1 - this.no_repeat_ngram_size; ++q) {
            const ne = [];
            for (let Q = 0; Q < this.no_repeat_ngram_size; ++Q)
              ne.push(L[q + Q]);
            R.push(ne.map(Number));
          }
          const N = /* @__PURE__ */ new Map();
          for (const q of R) {
            const ne = q.slice(0, q.length - 1), Q = JSON.stringify(ne), W = N.get(Q) ?? [];
            W.push(q[q.length - 1]), N.set(Q, W);
          }
          return N;
        }
        /**
         * Generate n-grams from a sequence of token ids.
         * @param {Map<string, number[]>} bannedNgrams Map of banned n-grams
         * @param {bigint[]} prevInputIds List of previous input ids
         * @returns {number[]} Map of generated n-grams
         */
        getGeneratedNgrams(L, I) {
          const R = I.slice(I.length + 1 - this.no_repeat_ngram_size, I.length);
          return L.get(JSON.stringify(R.map(Number))) ?? [];
        }
        /**
         * Calculate banned n-gram tokens
         * @param {bigint[]} prevInputIds List of previous input ids
         * @returns {number[]} Map of generated n-grams
         */
        calcBannedNgramTokens(L) {
          const I = [];
          if (L.length + 1 < this.no_repeat_ngram_size)
            return I;
          {
            const R = this.getNgrams(L);
            return this.getGeneratedNgrams(R, L);
          }
        }
        /**
         * Apply the no-repeat-ngram processor to the logits.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The logits with no-repeat-ngram processing.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R) {
            const N = (
              /** @type {Float32Array} */
              I[R].data
            ), q = this.calcBannedNgramTokens(L[R]);
            for (const ne of q)
              N[ne] = -1 / 0;
          }
          return I;
        }
      }
      class _ extends a {
        /**
         * Create a RepetitionPenaltyLogitsProcessor.
         * @param {number} penalty The parameter for repetition penalty.
         * - 1.0 means no penalty. Above 1.0 penalizes previously generated tokens.
         * - Between 0.0 and 1.0 rewards previously generated tokens.
         */
        constructor(L) {
          super(), this.penalty = L;
        }
        /**
         * Apply the repetition penalty to the logits.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The logits with repetition penalty processing.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R) {
            const N = (
              /** @type {Float32Array} */
              I[R].data
            );
            for (const q of new Set(L[R])) {
              const ne = Number(q);
              N[ne] < 0 ? N[ne] *= this.penalty : N[ne] /= this.penalty;
            }
          }
          return I;
        }
      }
      class v extends a {
        /**
         * Create a MinLengthLogitsProcessor.
         * @param {number} min_length The minimum length below which the score of `eos_token_id` is set to negative infinity.
         * @param {number|number[]} eos_token_id The ID/IDs of the end-of-sequence token.
         */
        constructor(L, I) {
          super(), this.min_length = L, this.eos_token_id = Array.isArray(I) ? I : [I];
        }
        /**
         * Apply logit processor.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The processed logits.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R)
            if (L[R].length < this.min_length) {
              const N = (
                /** @type {Float32Array} */
                I[R].data
              );
              for (const q of this.eos_token_id)
                N[q] = -1 / 0;
            }
          return I;
        }
      }
      class S extends a {
        /**
         * Create a MinNewTokensLengthLogitsProcessor.
         * @param {number} prompt_length_to_skip The input tokens length.
         * @param {number} min_new_tokens The minimum *new* tokens length below which the score of `eos_token_id` is set to negative infinity.
         * @param {number|number[]} eos_token_id The ID/IDs of the end-of-sequence token.
         */
        constructor(L, I, R) {
          super(), this.prompt_length_to_skip = L, this.min_new_tokens = I, this.eos_token_id = Array.isArray(R) ? R : [R];
        }
        /**
         * Apply logit processor.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The processed logits.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R)
            if (L[R].length - this.prompt_length_to_skip < this.min_new_tokens) {
              const q = (
                /** @type {Float32Array} */
                I[R].data
              );
              for (const ne of this.eos_token_id)
                q[ne] = -1 / 0;
            }
          return I;
        }
      }
      class D extends a {
        /**
         * Create a `NoBadWordsLogitsProcessor`.
         * @param {number[][]} bad_words_ids List of list of token ids that are not allowed to be generated.
         * @param {number|number[]} eos_token_id The id of the *end-of-sequence* token. Optionally, use a list to set multiple *end-of-sequence* tokens.
         */
        constructor(L, I) {
          super(), this.bad_words_ids = L, this.eos_token_id = Array.isArray(I) ? I : [I];
        }
        /**
         * Apply logit processor.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The processed logits.
         */
        _call(L, I) {
          for (let R = 0; R < L.length; ++R) {
            const N = (
              /** @type {Float32Array} */
              I[R].data
            ), q = L[R];
            for (const ne of this.bad_words_ids) {
              if (q.length < ne.length - 1)
                continue;
              let Q = !0;
              for (let W = 1; W <= ne.length - 1; ++W)
                if (ne.at(-W - 1) != q.at(-W)) {
                  Q = !1;
                  break;
                }
              Q && (N[ne.at(-1)] = -1 / 0);
            }
          }
          return I;
        }
      }
      class w extends a {
        /**
         * Create a `ClassifierFreeGuidanceLogitsProcessor`.
         * @param {number} guidance_scale The guidance scale for classifier free guidance (CFG). CFG is enabled by setting `guidance_scale > 1`.
         * Higher guidance scale encourages the model to generate samples that are more closely linked to the input
         * prompt, usually at the expense of poorer quality.
         */
        constructor(L) {
          if (super(), L <= 1)
            throw new Error(
              `Require guidance scale >1 to use the classifier free guidance processor, got guidance scale ${L}.`
            );
          this.guidance_scale = L;
        }
        /**
         * Apply logit processor.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The processed logits.
         */
        _call(L, I) {
          if (I.dims[0] !== 2 * L.length)
            throw new Error(
              `Logits should have twice the batch size of the input ids, the first half of batches corresponding to the conditional inputs, and the second half of batches corresponding to the unconditional inputs. Got batch size ${I.dims[0]} for the logits and ${L.length} for the input ids.`
            );
          const R = L.length, N = I.slice([0, R], null), q = I.slice([R, I.dims[0]], null);
          for (let ne = 0; ne < q.data.length; ++ne)
            q.data[ne] += (N.data[ne] - q.data[ne]) * this.guidance_scale;
          return q;
        }
      }
      class T extends c {
        /**
         * Create a `TemperatureLogitsWarper`.
         * @param {number} temperature Strictly positive float value used to modulate the logits distribution.
         * A value smaller than `1` decreases randomness (and vice versa), with `0` being equivalent to shifting
         * all probability mass to the most likely token.
         */
        constructor(L) {
          super(), this.temperature = L;
        }
        /**
         * Apply logit warper.
         * @param {bigint[][]} input_ids The input IDs.
         * @param {Tensor} logits The logits.
         * @returns {Tensor} The processed logits.
         */
        _call(L, I) {
          const R = (
            /** @type {Float32Array} */
            I.data
          );
          for (let N = 0; N < R.length; ++N)
            R[N] /= this.temperature;
          return I;
        }
      }
      class F extends c {
        /**
         * Create a `TopPLogitsWarper`.
         * @param {number} top_p If set to < 1, only the smallest set of most probable tokens with
         * probabilities that add up to `top_p` or higher are kept for generation.
         * @param {Object} options Additional options for the top-p sampling.
         * @param {number} [options.filter_value=-Infinity] All filtered values will be set to this float value.
         * @param {number} [options.min_tokens_to_keep=1] Minimum number of tokens that cannot be filtered.
         */
        constructor(L, {
          filter_value: I = -1 / 0,
          min_tokens_to_keep: R = 1
        } = {}) {
          if (super(), L < 0 || L > 1)
            throw new Error(`\`top_p\` must be a float > 0 and < 1, but is ${L}`);
          if (!Number.isInteger(R) || R < 1)
            throw new Error(`\`min_tokens_to_keep\` must be a positive integer, but is ${R}`);
          this.top_p = L, this.filter_value = I, this.min_tokens_to_keep = R;
        }
      }
      class E extends c {
        /**
         * Create a `TopKLogitsWarper`.
         * @param {number} top_k If set to > 0, only the top `top_k` tokens are kept for generation.
         * @param {Object} options Additional options for the top-k sampling.
         * @param {number} [options.filter_value=-Infinity] All filtered values will be set to this float value.
         * @param {number} [options.min_tokens_to_keep=1] Minimum number of tokens that cannot be filtered.
         */
        constructor(L, {
          filter_value: I = -1 / 0,
          min_tokens_to_keep: R = 1
        } = {}) {
          if (super(), !Number.isInteger(L) || L < 0)
            throw new Error(`\`top_k\` must be a positive integer, but is ${L}`);
          this.top_k = Math.max(L, R), this.filter_value = I;
        }
      }
    }
  ),
  /***/
  "./src/generation/logits_sampler.js": (
    /*!******************************************!*\
      !*** ./src/generation/logits_sampler.js ***!
      \******************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        LogitsSampler: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/generic.js */
        "./src/utils/generic.js"
      ), r = t(
        /*! ../utils/tensor.js */
        "./src/utils/tensor.js"
      ), a = t(
        /*! ../utils/maths.js */
        "./src/utils/maths.js"
      );
      t(
        /*! ../generation/configuration_utils.js */
        "./src/generation/configuration_utils.js"
      );
      class c extends i.Callable {
        /**
         * Creates a new Sampler object with the specified generation config.
         * @param {GenerationConfig} generation_config The generation config.
         */
        constructor(h) {
          super(), this.generation_config = h;
        }
        /**
         * Executes the sampler, using the specified logits.
         * @param {Tensor} logits
         * @returns {Promise<[bigint, number][]>}
         */
        async _call(h) {
          return this.sample(h);
        }
        /**
         * Abstract method for sampling the logits.
         * @param {Tensor} logits
         * @throws {Error} If not implemented in subclass.
         * @returns {Promise<[bigint, number][]>}
         */
        async sample(h) {
          throw Error("sample should be implemented in subclasses.");
        }
        /**
         * Returns the specified logits as an array, with temperature applied.
         * @param {Tensor} logits
         * @param {number} index
         * @returns {Float32Array}
         */
        getLogits(h, p) {
          let _ = h.dims.at(-1), v = (
            /** @type {Float32Array} */
            h.data
          );
          if (p === -1)
            v = v.slice(-_);
          else {
            let S = p * _;
            v = v.slice(S, S + _);
          }
          return v;
        }
        /**
         * Selects an item randomly based on the specified probabilities.
         * @param {import("../transformers.js").DataArray} probabilities An array of probabilities to use for selection.
         * @returns {number} The index of the selected item.
         */
        randomSelect(h) {
          let p = 0;
          for (let v = 0; v < h.length; ++v)
            p += h[v];
          let _ = Math.random() * p;
          for (let v = 0; v < h.length; ++v)
            if (_ -= h[v], _ <= 0)
              return v;
          return 0;
        }
        /**
         * Returns a Sampler object based on the specified options.
         * @param {GenerationConfig} generation_config An object containing options for the sampler.
         * @returns {LogitsSampler} A Sampler object.
         */
        static getSampler(h) {
          if (h.do_sample)
            return new l(h);
          if (h.num_beams > 1)
            return new f(h);
          if (h.num_return_sequences > 1)
            throw Error(`num_return_sequences has to be 1 when doing greedy search, but is ${h.num_return_sequences}.`);
          return new u(h);
        }
      }
      class u extends c {
        /**
         * Sample the maximum probability of a given logits tensor.
         * @param {Tensor} logits
         * @returns {Promise<[bigint, number][]>} An array with a single tuple, containing the index of the maximum value and a meaningless score (since this is a greedy search).
         */
        async sample(h) {
          const p = (0, a.max)(h.data)[1];
          return [
            [BigInt(p), 0]
          ];
        }
      }
      class l extends c {
        /**
         * Sample from the logits.
         * @param {Tensor} logits
         * @returns {Promise<[bigint, number][]>}
         */
        async sample(h) {
          let p = h.dims.at(-1);
          this.generation_config.top_k > 0 && (p = Math.min(this.generation_config.top_k, p));
          const [_, v] = await (0, r.topk)(h, p), S = (0, a.softmax)(
            /** @type {Float32Array} */
            _.data
          );
          return Array.from({ length: this.generation_config.num_beams }, () => {
            const D = this.randomSelect(S);
            return [
              v.data[D],
              // token id
              Math.log(S[D])
              // score
            ];
          });
        }
      }
      class f extends c {
        /**
         * Sample from the logits.
         * @param {Tensor} logits
         * @returns {Promise<[bigint, number][]>}
         */
        async sample(h) {
          let p = h.dims.at(-1);
          this.generation_config.top_k > 0 && (p = Math.min(this.generation_config.top_k, p));
          const [_, v] = await (0, r.topk)(h, p), S = (0, a.softmax)(
            /** @type {Float32Array} */
            _.data
          );
          return Array.from({ length: this.generation_config.num_beams }, (D, w) => [
            v.data[w],
            // token id
            Math.log(S[w])
            // score
          ]);
        }
      }
    }
  ),
  /***/
  "./src/generation/stopping_criteria.js": (
    /*!*********************************************!*\
      !*** ./src/generation/stopping_criteria.js ***!
      \*********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        EosTokenCriteria: () => (
          /* binding */
          u
        ),
        /* harmony export */
        InterruptableStoppingCriteria: () => (
          /* binding */
          l
        ),
        /* harmony export */
        MaxLengthCriteria: () => (
          /* binding */
          c
        ),
        /* harmony export */
        StoppingCriteria: () => (
          /* binding */
          r
        ),
        /* harmony export */
        StoppingCriteriaList: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/generic.js */
        "./src/utils/generic.js"
      );
      class r extends i.Callable {
        /**
         * 
         * @param {number[][]} input_ids (`number[][]` of shape `(batch_size, sequence_length)`):
         * Indices of input sequence tokens in the vocabulary.
         * @param {number[][]} scores scores (`number[][]` of shape `(batch_size, config.vocab_size)`):
         * Prediction scores of a language modeling head. These can be scores for each vocabulary token before SoftMax
         * or scores for each vocabulary token after SoftMax.
         * @returns {boolean[]} A list of booleans indicating whether each sequence should be stopped.
         */
        _call(m, h) {
          throw Error("StoppingCriteria needs to be subclassed");
        }
      }
      class a extends i.Callable {
        /**
         * Constructs a new instance of `StoppingCriteriaList`.
         */
        constructor() {
          super(), this.criteria = [];
        }
        /**
         * Adds a new stopping criterion to the list.
         *
         * @param {StoppingCriteria} item The stopping criterion to add.
         */
        push(m) {
          this.criteria.push(m);
        }
        /**
         * Adds multiple stopping criteria to the list.
         *
         * @param {StoppingCriteria|StoppingCriteriaList|StoppingCriteria[]} items The stopping criteria to add.
         */
        extend(m) {
          m instanceof a ? m = m.criteria : m instanceof r && (m = [m]), this.criteria.push(...m);
        }
        _call(m, h) {
          const p = new Array(m.length).fill(!1);
          for (const _ of this.criteria) {
            const v = _(m, h);
            for (let S = 0; S < p.length; ++S)
              p[S] || (p[S] = v[S]);
          }
          return p;
        }
        [Symbol.iterator]() {
          return this.criteria.values();
        }
      }
      class c extends r {
        /**
         * 
         * @param {number} max_length The maximum length that the output sequence can have in number of tokens.
         * @param {number} [max_position_embeddings=null] The maximum model length, as defined by the model's `config.max_position_embeddings` attribute.
         */
        constructor(m, h = null) {
          super(), this.max_length = m, this.max_position_embeddings = h;
        }
        _call(m) {
          return m.map((h) => h.length >= this.max_length);
        }
      }
      class u extends r {
        /**
         * 
         * @param {number|number[]} eos_token_id The id of the *end-of-sequence* token.
         * Optionally, use a list to set multiple *end-of-sequence* tokens.
         */
        constructor(m) {
          super(), Array.isArray(m) || (m = [m]), this.eos_token_id = m;
        }
        /**
         * 
         * @param {number[][]} input_ids 
         * @param {number[][]} scores 
         * @returns {boolean[]}
         */
        _call(m, h) {
          return m.map((p) => {
            const _ = p.at(-1);
            return this.eos_token_id.some((v) => _ == v);
          });
        }
      }
      class l extends r {
        constructor() {
          super(), this.interrupted = !1;
        }
        interrupt() {
          this.interrupted = !0;
        }
        reset() {
          this.interrupted = !1;
        }
        _call(m, h) {
          return new Array(m.length).fill(this.interrupted);
        }
      }
    }
  ),
  /***/
  "./src/generation/streamers.js": (
    /*!*************************************!*\
      !*** ./src/generation/streamers.js ***!
      \*************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        BaseStreamer: () => (
          /* binding */
          c
        ),
        /* harmony export */
        TextStreamer: () => (
          /* binding */
          l
        ),
        /* harmony export */
        WhisperTextStreamer: () => (
          /* binding */
          f
        )
        /* harmony export */
      });
      var i = t(
        /*! ../utils/core.js */
        "./src/utils/core.js"
      ), r = t(
        /*! ../tokenizers.js */
        "./src/tokenizers.js"
      ), a = t(
        /*! ../env.js */
        "./src/env.js"
      );
      class c {
        /**
         * Function that is called by `.generate()` to push new tokens
         * @param {bigint[][]} value 
         */
        put(h) {
          throw Error("Not implemented");
        }
        /**
         * Function that is called by `.generate()` to signal the end of generation
         */
        end() {
          throw Error("Not implemented");
        }
      }
      const u = a.apis.IS_PROCESS_AVAILABLE ? (m) => process.stdout.write(m) : (m) => console.log(m);
      class l extends c {
        /**
         * 
         * @param {import('../tokenizers.js').PreTrainedTokenizer} tokenizer
         * @param {Object} options
         * @param {boolean} [options.skip_prompt=false] Whether to skip the prompt tokens
         * @param {boolean} [options.skip_special_tokens=true] Whether to skip special tokens when decoding
         * @param {function(string): void} [options.callback_function=null] Function to call when a piece of text is ready to display
         * @param {function(bigint[]): void} [options.token_callback_function=null] Function to call when a new token is generated
         * @param {Object} [options.decode_kwargs={}] Additional keyword arguments to pass to the tokenizer's decode method
         */
        constructor(h, {
          skip_prompt: p = !1,
          callback_function: _ = null,
          token_callback_function: v = null,
          skip_special_tokens: S = !0,
          decode_kwargs: D = {},
          ...w
        } = {}) {
          super(), this.tokenizer = h, this.skip_prompt = p, this.callback_function = _ ?? u, this.token_callback_function = v, this.decode_kwargs = { skip_special_tokens: S, ...D, ...w }, this.token_cache = [], this.print_len = 0, this.next_tokens_are_prompt = !0;
        }
        /**
         * Receives tokens, decodes them, and prints them to stdout as soon as they form entire words.
         * @param {bigint[][]} value 
         */
        put(h) {
          var D;
          if (h.length > 1)
            throw Error("TextStreamer only supports batch size of 1");
          const p = this.next_tokens_are_prompt;
          if (p && (this.next_tokens_are_prompt = !1, this.skip_prompt))
            return;
          const _ = h[0];
          (D = this.token_callback_function) == null || D.call(this, _), this.token_cache = (0, i.mergeArrays)(this.token_cache, _);
          const v = this.tokenizer.decode(this.token_cache, this.decode_kwargs);
          let S;
          p || v.endsWith(`
`) ? (S = v.slice(this.print_len), this.token_cache = [], this.print_len = 0) : v.length > 0 && (0, r.is_chinese_char)(v.charCodeAt(v.length - 1)) ? (S = v.slice(this.print_len), this.print_len += S.length) : (S = v.slice(this.print_len, v.lastIndexOf(" ") + 1), this.print_len += S.length), this.on_finalized_text(S, !1);
        }
        /**
         * Flushes any remaining cache and prints a newline to stdout.
         */
        end() {
          let h;
          this.token_cache.length > 0 ? (h = this.tokenizer.decode(this.token_cache, this.decode_kwargs).slice(this.print_len), this.token_cache = [], this.print_len = 0) : h = "", this.next_tokens_are_prompt = !0, this.on_finalized_text(h, !0);
        }
        /**
         * Prints the new text to stdout. If the stream is ending, also prints a newline.
         * @param {string} text 
         * @param {boolean} stream_end 
         */
        on_finalized_text(h, p) {
          var _, v;
          h.length > 0 && ((_ = this.callback_function) == null || _.call(this, h)), p && this.callback_function === u && a.apis.IS_PROCESS_AVAILABLE && ((v = this.callback_function) == null || v.call(this, `
`));
        }
      }
      class f extends l {
        /**
         * @param {import('../tokenizers.js').WhisperTokenizer} tokenizer
         * @param {Object} options
         * @param {boolean} [options.skip_prompt=false] Whether to skip the prompt tokens
         * @param {function(string): void} [options.callback_function=null] Function to call when a piece of text is ready to display
         * @param {function(bigint[]): void} [options.token_callback_function=null] Function to call when a new token is generated
         * @param {function(number): void} [options.on_chunk_start=null] Function to call when a new chunk starts
         * @param {function(number): void} [options.on_chunk_end=null] Function to call when a chunk ends
         * @param {function(): void} [options.on_finalize=null] Function to call when the stream is finalized
         * @param {number} [options.time_precision=0.02] Precision of the timestamps
         * @param {boolean} [options.skip_special_tokens=true] Whether to skip special tokens when decoding
         * @param {Object} [options.decode_kwargs={}] Additional keyword arguments to pass to the tokenizer's decode method
         */
        constructor(h, {
          skip_prompt: p = !1,
          callback_function: _ = null,
          token_callback_function: v = null,
          on_chunk_start: S = null,
          on_chunk_end: D = null,
          on_finalize: w = null,
          time_precision: T = 0.02,
          skip_special_tokens: F = !0,
          decode_kwargs: E = {}
        } = {}) {
          super(h, {
            skip_prompt: p,
            skip_special_tokens: F,
            callback_function: _,
            token_callback_function: v,
            decode_kwargs: E
          }), this.timestamp_begin = h.timestamp_begin, this.on_chunk_start = S, this.on_chunk_end = D, this.on_finalize = w, this.time_precision = T, this.waiting_for_timestamp = !1;
        }
        /**
         * @param {bigint[][]} value 
         */
        put(h) {
          var _, v, S;
          if (h.length > 1)
            throw Error("WhisperTextStreamer only supports batch size of 1");
          const p = h[0];
          if (p.length === 1) {
            const D = Number(p[0]) - this.timestamp_begin;
            if (D >= 0) {
              const w = D * this.time_precision;
              this.waiting_for_timestamp ? (_ = this.on_chunk_end) == null || _.call(this, w) : (v = this.on_chunk_start) == null || v.call(this, w), this.waiting_for_timestamp = !this.waiting_for_timestamp, (S = this.token_callback_function) == null || S.call(this, p);
              return;
            }
          }
          return super.put(h);
        }
        end() {
          var h;
          super.end(), (h = this.on_finalize) == null || h.call(this);
        }
      }
    }
  ),
  /***/
  "./src/models.js": (
    /*!***********************!*\
      !*** ./src/models.js ***!
      \***********************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ASTForAudioClassification: () => (
          /* binding */
          Ou
        ),
        /* harmony export */
        ASTModel: () => (
          /* binding */
          ku
        ),
        /* harmony export */
        ASTPreTrainedModel: () => (
          /* binding */
          vo
        ),
        /* harmony export */
        AlbertForMaskedLM: () => (
          /* binding */
          kt
        ),
        /* harmony export */
        AlbertForQuestionAnswering: () => (
          /* binding */
          At
        ),
        /* harmony export */
        AlbertForSequenceClassification: () => (
          /* binding */
          It
        ),
        /* harmony export */
        AlbertModel: () => (
          /* binding */
          Et
        ),
        /* harmony export */
        AlbertPreTrainedModel: () => (
          /* binding */
          ot
        ),
        /* harmony export */
        ArceeForCausalLM: () => (
          /* binding */
          xd
        ),
        /* harmony export */
        ArceeModel: () => (
          /* binding */
          wd
        ),
        /* harmony export */
        ArceePreTrainedModel: () => (
          /* binding */
          vd
        ),
        /* harmony export */
        AutoModel: () => (
          /* binding */
          Ec
        ),
        /* harmony export */
        AutoModelForAudioClassification: () => (
          /* binding */
          Qg
        ),
        /* harmony export */
        AutoModelForAudioFrameClassification: () => (
          /* binding */
          o
        ),
        /* harmony export */
        AutoModelForAudioTextToText: () => (
          /* binding */
          $
        ),
        /* harmony export */
        AutoModelForCTC: () => (
          /* binding */
          Jg
        ),
        /* harmony export */
        AutoModelForCausalLM: () => (
          /* binding */
          nm
        ),
        /* harmony export */
        AutoModelForDepthEstimation: () => (
          /* binding */
          x
        ),
        /* harmony export */
        AutoModelForDocumentQuestionAnswering: () => (
          /* binding */
          d
        ),
        /* harmony export */
        AutoModelForImageClassification: () => (
          /* binding */
          Xg
        ),
        /* harmony export */
        AutoModelForImageFeatureExtraction: () => (
          /* binding */
          k
        ),
        /* harmony export */
        AutoModelForImageMatting: () => (
          /* binding */
          g
        ),
        /* harmony export */
        AutoModelForImageSegmentation: () => (
          /* binding */
          rm
        ),
        /* harmony export */
        AutoModelForImageTextToText: () => (
          /* binding */
          O
        ),
        /* harmony export */
        AutoModelForImageToImage: () => (
          /* binding */
          y
        ),
        /* harmony export */
        AutoModelForMaskGeneration: () => (
          /* binding */
          am
        ),
        /* harmony export */
        AutoModelForMaskedLM: () => (
          /* binding */
          Sc
        ),
        /* harmony export */
        AutoModelForNormalEstimation: () => (
          /* binding */
          b
        ),
        /* harmony export */
        AutoModelForObjectDetection: () => (
          /* binding */
          om
        ),
        /* harmony export */
        AutoModelForPoseEstimation: () => (
          /* binding */
          P
        ),
        /* harmony export */
        AutoModelForQuestionAnswering: () => (
          /* binding */
          im
        ),
        /* harmony export */
        AutoModelForSemanticSegmentation: () => (
          /* binding */
          Pc
        ),
        /* harmony export */
        AutoModelForSeq2SeqLM: () => (
          /* binding */
          Qp
        ),
        /* harmony export */
        AutoModelForSequenceClassification: () => (
          /* binding */
          Yp
        ),
        /* harmony export */
        AutoModelForSpeechSeq2Seq: () => (
          /* binding */
          Zp
        ),
        /* harmony export */
        AutoModelForTextToSpectrogram: () => (
          /* binding */
          em
        ),
        /* harmony export */
        AutoModelForTextToWaveform: () => (
          /* binding */
          tm
        ),
        /* harmony export */
        AutoModelForTokenClassification: () => (
          /* binding */
          Jp
        ),
        /* harmony export */
        AutoModelForUniversalSegmentation: () => (
          /* binding */
          Ac
        ),
        /* harmony export */
        AutoModelForVision2Seq: () => (
          /* binding */
          sm
        ),
        /* harmony export */
        AutoModelForXVector: () => (
          /* binding */
          s
        ),
        /* harmony export */
        AutoModelForZeroShotObjectDetection: () => (
          /* binding */
          Yg
        ),
        /* harmony export */
        BartForConditionalGeneration: () => (
          /* binding */
          Cn
        ),
        /* harmony export */
        BartForSequenceClassification: () => (
          /* binding */
          Vn
        ),
        /* harmony export */
        BartModel: () => (
          /* binding */
          gs
        ),
        /* harmony export */
        BartPretrainedModel: () => (
          /* binding */
          ei
        ),
        /* harmony export */
        BaseModelOutput: () => (
          /* binding */
          ze
        ),
        /* harmony export */
        BeitForImageClassification: () => (
          /* binding */
          Sh
        ),
        /* harmony export */
        BeitModel: () => (
          /* binding */
          Eh
        ),
        /* harmony export */
        BeitPreTrainedModel: () => (
          /* binding */
          Th
        ),
        /* harmony export */
        BertForMaskedLM: () => (
          /* binding */
          H
        ),
        /* harmony export */
        BertForQuestionAnswering: () => (
          /* binding */
          Ie
        ),
        /* harmony export */
        BertForSequenceClassification: () => (
          /* binding */
          Y
        ),
        /* harmony export */
        BertForTokenClassification: () => (
          /* binding */
          $e
        ),
        /* harmony export */
        BertModel: () => (
          /* binding */
          Ye
        ),
        /* harmony export */
        BertPreTrainedModel: () => (
          /* binding */
          Oe
        ),
        /* harmony export */
        BlenderbotForConditionalGeneration: () => (
          /* binding */
          Wn
        ),
        /* harmony export */
        BlenderbotModel: () => (
          /* binding */
          jn
        ),
        /* harmony export */
        BlenderbotPreTrainedModel: () => (
          /* binding */
          Yn
        ),
        /* harmony export */
        BlenderbotSmallForConditionalGeneration: () => (
          /* binding */
          ts
        ),
        /* harmony export */
        BlenderbotSmallModel: () => (
          /* binding */
          pn
        ),
        /* harmony export */
        BlenderbotSmallPreTrainedModel: () => (
          /* binding */
          Yt
        ),
        /* harmony export */
        BloomForCausalLM: () => (
          /* binding */
          oh
        ),
        /* harmony export */
        BloomModel: () => (
          /* binding */
          rh
        ),
        /* harmony export */
        BloomPreTrainedModel: () => (
          /* binding */
          ul
        ),
        /* harmony export */
        CLIPModel: () => (
          /* binding */
          Ku
        ),
        /* harmony export */
        CLIPPreTrainedModel: () => (
          /* binding */
          qs
        ),
        /* harmony export */
        CLIPSegForImageSegmentation: () => (
          /* binding */
          ji
        ),
        /* harmony export */
        CLIPSegModel: () => (
          /* binding */
          nd
        ),
        /* harmony export */
        CLIPSegPreTrainedModel: () => (
          /* binding */
          ka
        ),
        /* harmony export */
        CLIPTextModel: () => (
          /* binding */
          Vy
        ),
        /* harmony export */
        CLIPTextModelWithProjection: () => (
          /* binding */
          Gi
        ),
        /* harmony export */
        CLIPVisionModel: () => (
          /* binding */
          pg
        ),
        /* harmony export */
        CLIPVisionModelWithProjection: () => (
          /* binding */
          bo
        ),
        /* harmony export */
        CamembertForMaskedLM: () => (
          /* binding */
          Fe
        ),
        /* harmony export */
        CamembertForQuestionAnswering: () => (
          /* binding */
          Pt
        ),
        /* harmony export */
        CamembertForSequenceClassification: () => (
          /* binding */
          Ke
        ),
        /* harmony export */
        CamembertForTokenClassification: () => (
          /* binding */
          pt
        ),
        /* harmony export */
        CamembertModel: () => (
          /* binding */
          ge
        ),
        /* harmony export */
        CamembertPreTrainedModel: () => (
          /* binding */
          se
        ),
        /* harmony export */
        CausalLMOutput: () => (
          /* binding */
          ue
        ),
        /* harmony export */
        CausalLMOutputWithPast: () => (
          /* binding */
          ce
        ),
        /* harmony export */
        ChineseCLIPModel: () => (
          /* binding */
          Qu
        ),
        /* harmony export */
        ChineseCLIPPreTrainedModel: () => (
          /* binding */
          Ju
        ),
        /* harmony export */
        ClapAudioModelWithProjection: () => (
          /* binding */
          op
        ),
        /* harmony export */
        ClapModel: () => (
          /* binding */
          rp
        ),
        /* harmony export */
        ClapPreTrainedModel: () => (
          /* binding */
          jo
        ),
        /* harmony export */
        ClapTextModelWithProjection: () => (
          /* binding */
          Bg
        ),
        /* harmony export */
        CodeGenForCausalLM: () => (
          /* binding */
          fd
        ),
        /* harmony export */
        CodeGenModel: () => (
          /* binding */
          hd
        ),
        /* harmony export */
        CodeGenPreTrainedModel: () => (
          /* binding */
          Ga
        ),
        /* harmony export */
        CohereForCausalLM: () => (
          /* binding */
          Ud
        ),
        /* harmony export */
        CohereModel: () => (
          /* binding */
          Nd
        ),
        /* harmony export */
        CoherePreTrainedModel: () => (
          /* binding */
          Za
        ),
        /* harmony export */
        ConvBertForMaskedLM: () => (
          /* binding */
          qt
        ),
        /* harmony export */
        ConvBertForQuestionAnswering: () => (
          /* binding */
          rt
        ),
        /* harmony export */
        ConvBertForSequenceClassification: () => (
          /* binding */
          Me
        ),
        /* harmony export */
        ConvBertForTokenClassification: () => (
          /* binding */
          at
        ),
        /* harmony export */
        ConvBertModel: () => (
          /* binding */
          ds
        ),
        /* harmony export */
        ConvBertPreTrainedModel: () => (
          /* binding */
          Si
        ),
        /* harmony export */
        ConvNextForImageClassification: () => (
          /* binding */
          of
        ),
        /* harmony export */
        ConvNextModel: () => (
          /* binding */
          rf
        ),
        /* harmony export */
        ConvNextPreTrainedModel: () => (
          /* binding */
          $l
        ),
        /* harmony export */
        ConvNextV2ForImageClassification: () => (
          /* binding */
          cf
        ),
        /* harmony export */
        ConvNextV2Model: () => (
          /* binding */
          lf
        ),
        /* harmony export */
        ConvNextV2PreTrainedModel: () => (
          /* binding */
          af
        ),
        /* harmony export */
        DFineForObjectDetection: () => (
          /* binding */
          Fh
        ),
        /* harmony export */
        DFineModel: () => (
          /* binding */
          Al
        ),
        /* harmony export */
        DFinePreTrainedModel: () => (
          /* binding */
          Pl
        ),
        /* harmony export */
        DINOv3ConvNextModel: () => (
          /* binding */
          _s
        ),
        /* harmony export */
        DINOv3ConvNextPreTrainedModel: () => (
          /* binding */
          ss
        ),
        /* harmony export */
        DINOv3ViTModel: () => (
          /* binding */
          Ag
        ),
        /* harmony export */
        DINOv3ViTPreTrainedModel: () => (
          /* binding */
          ff
        ),
        /* harmony export */
        DPTForDepthEstimation: () => (
          /* binding */
          Wh
        ),
        /* harmony export */
        DPTModel: () => (
          /* binding */
          jh
        ),
        /* harmony export */
        DPTPreTrainedModel: () => (
          /* binding */
          Rl
        ),
        /* harmony export */
        DacDecoderModel: () => (
          /* binding */
          Gg
        ),
        /* harmony export */
        DacDecoderOutput: () => (
          /* binding */
          zp
        ),
        /* harmony export */
        DacEncoderModel: () => (
          /* binding */
          Np
        ),
        /* harmony export */
        DacEncoderOutput: () => (
          /* binding */
          Bp
        ),
        /* harmony export */
        DacModel: () => (
          /* binding */
          $p
        ),
        /* harmony export */
        DacPreTrainedModel: () => (
          /* binding */
          Hr
        ),
        /* harmony export */
        DebertaForMaskedLM: () => (
          /* binding */
          Dt
        ),
        /* harmony export */
        DebertaForQuestionAnswering: () => (
          /* binding */
          nn
        ),
        /* harmony export */
        DebertaForSequenceClassification: () => (
          /* binding */
          tn
        ),
        /* harmony export */
        DebertaForTokenClassification: () => (
          /* binding */
          Vt
        ),
        /* harmony export */
        DebertaModel: () => (
          /* binding */
          en
        ),
        /* harmony export */
        DebertaPreTrainedModel: () => (
          /* binding */
          Tt
        ),
        /* harmony export */
        DebertaV2ForMaskedLM: () => (
          /* binding */
          ci
        ),
        /* harmony export */
        DebertaV2ForQuestionAnswering: () => (
          /* binding */
          Pi
        ),
        /* harmony export */
        DebertaV2ForSequenceClassification: () => (
          /* binding */
          ki
        ),
        /* harmony export */
        DebertaV2ForTokenClassification: () => (
          /* binding */
          fi
        ),
        /* harmony export */
        DebertaV2Model: () => (
          /* binding */
          vi
        ),
        /* harmony export */
        DebertaV2PreTrainedModel: () => (
          /* binding */
          Mn
        ),
        /* harmony export */
        DecisionTransformerModel: () => (
          /* binding */
          Mp
        ),
        /* harmony export */
        DecisionTransformerPreTrainedModel: () => (
          /* binding */
          bp
        ),
        /* harmony export */
        DeiTForImageClassification: () => (
          /* binding */
          zh
        ),
        /* harmony export */
        DeiTModel: () => (
          /* binding */
          wg
        ),
        /* harmony export */
        DeiTPreTrainedModel: () => (
          /* binding */
          Il
        ),
        /* harmony export */
        DepthAnythingForDepthEstimation: () => (
          /* binding */
          Hh
        ),
        /* harmony export */
        DepthAnythingPreTrainedModel: () => (
          /* binding */
          bg
        ),
        /* harmony export */
        DepthProForDepthEstimation: () => (
          /* binding */
          Yh
        ),
        /* harmony export */
        DepthProPreTrainedModel: () => (
          /* binding */
          Mg
        ),
        /* harmony export */
        DetrForObjectDetection: () => (
          /* binding */
          Do
        ),
        /* harmony export */
        DetrForSegmentation: () => (
          /* binding */
          Ml
        ),
        /* harmony export */
        DetrModel: () => (
          /* binding */
          Ph
        ),
        /* harmony export */
        DetrObjectDetectionOutput: () => (
          /* binding */
          Nr
        ),
        /* harmony export */
        DetrPreTrainedModel: () => (
          /* binding */
          bl
        ),
        /* harmony export */
        DetrSegmentationOutput: () => (
          /* binding */
          Tl
        ),
        /* harmony export */
        Dinov2ForImageClassification: () => (
          /* binding */
          Pg
        ),
        /* harmony export */
        Dinov2Model: () => (
          /* binding */
          uf
        ),
        /* harmony export */
        Dinov2PreTrainedModel: () => (
          /* binding */
          Nl
        ),
        /* harmony export */
        Dinov2WithRegistersForImageClassification: () => (
          /* binding */
          hf
        ),
        /* harmony export */
        Dinov2WithRegistersModel: () => (
          /* binding */
          df
        ),
        /* harmony export */
        Dinov2WithRegistersPreTrainedModel: () => (
          /* binding */
          Ul
        ),
        /* harmony export */
        DistilBertForMaskedLM: () => (
          /* binding */
          jt
        ),
        /* harmony export */
        DistilBertForQuestionAnswering: () => (
          /* binding */
          Oi
        ),
        /* harmony export */
        DistilBertForSequenceClassification: () => (
          /* binding */
          fs
        ),
        /* harmony export */
        DistilBertForTokenClassification: () => (
          /* binding */
          Ps
        ),
        /* harmony export */
        DistilBertModel: () => (
          /* binding */
          hs
        ),
        /* harmony export */
        DistilBertPreTrainedModel: () => (
          /* binding */
          wi
        ),
        /* harmony export */
        DonutSwinModel: () => (
          /* binding */
          sf
        ),
        /* harmony export */
        DonutSwinPreTrainedModel: () => (
          /* binding */
          Sg
        ),
        /* harmony export */
        EdgeTamModel: () => (
          /* binding */
          Cg
        ),
        /* harmony export */
        EfficientNetForImageClassification: () => (
          /* binding */
          dp
        ),
        /* harmony export */
        EfficientNetModel: () => (
          /* binding */
          sc
        ),
        /* harmony export */
        EfficientNetPreTrainedModel: () => (
          /* binding */
          Ho
        ),
        /* harmony export */
        ElectraForMaskedLM: () => (
          /* binding */
          on
        ),
        /* harmony export */
        ElectraForQuestionAnswering: () => (
          /* binding */
          J
        ),
        /* harmony export */
        ElectraForSequenceClassification: () => (
          /* binding */
          B
        ),
        /* harmony export */
        ElectraForTokenClassification: () => (
          /* binding */
          le
        ),
        /* harmony export */
        ElectraModel: () => (
          /* binding */
          _t
        ),
        /* harmony export */
        ElectraPreTrainedModel: () => (
          /* binding */
          mt
        ),
        /* harmony export */
        Ernie4_5ForCausalLM: () => (
          /* binding */
          ep
        ),
        /* harmony export */
        Ernie4_5Model: () => (
          /* binding */
          Zf
        ),
        /* harmony export */
        Ernie4_5PreTrainedModel: () => (
          /* binding */
          Uo
        ),
        /* harmony export */
        EsmForMaskedLM: () => (
          /* binding */
          As
        ),
        /* harmony export */
        EsmForSequenceClassification: () => (
          /* binding */
          Cs
        ),
        /* harmony export */
        EsmForTokenClassification: () => (
          /* binding */
          Is
        ),
        /* harmony export */
        EsmModel: () => (
          /* binding */
          Ws
        ),
        /* harmony export */
        EsmPreTrainedModel: () => (
          /* binding */
          Ni
        ),
        /* harmony export */
        ExaoneForCausalLM: () => (
          /* binding */
          Id
        ),
        /* harmony export */
        ExaoneModel: () => (
          /* binding */
          Cd
        ),
        /* harmony export */
        ExaonePreTrainedModel: () => (
          /* binding */
          Ka
        ),
        /* harmony export */
        FalconForCausalLM: () => (
          /* binding */
          sp
        ),
        /* harmony export */
        FalconModel: () => (
          /* binding */
          ip
        ),
        /* harmony export */
        FalconPreTrainedModel: () => (
          /* binding */
          Vo
        ),
        /* harmony export */
        FastViTForImageClassification: () => (
          /* binding */
          yl
        ),
        /* harmony export */
        FastViTModel: () => (
          /* binding */
          mh
        ),
        /* harmony export */
        FastViTPreTrainedModel: () => (
          /* binding */
          Co
        ),
        /* harmony export */
        Florence2ForConditionalGeneration: () => (
          /* binding */
          Uu
        ),
        /* harmony export */
        Florence2PreTrainedModel: () => (
          /* binding */
          Nu
        ),
        /* harmony export */
        GLPNForDepthEstimation: () => (
          /* binding */
          nf
        ),
        /* harmony export */
        GLPNModel: () => (
          /* binding */
          tf
        ),
        /* harmony export */
        GLPNPreTrainedModel: () => (
          /* binding */
          zl
        ),
        /* harmony export */
        GPT2LMHeadModel: () => (
          /* binding */
          sd
        ),
        /* harmony export */
        GPT2Model: () => (
          /* binding */
          id
        ),
        /* harmony export */
        GPT2PreTrainedModel: () => (
          /* binding */
          Oa
        ),
        /* harmony export */
        GPTBigCodeForCausalLM: () => (
          /* binding */
          Eo
        ),
        /* harmony export */
        GPTBigCodeModel: () => (
          /* binding */
          dd
        ),
        /* harmony export */
        GPTBigCodePreTrainedModel: () => (
          /* binding */
          ud
        ),
        /* harmony export */
        GPTJForCausalLM: () => (
          /* binding */
          Ua
        ),
        /* harmony export */
        GPTJModel: () => (
          /* binding */
          cd
        ),
        /* harmony export */
        GPTJPreTrainedModel: () => (
          /* binding */
          Na
        ),
        /* harmony export */
        GPTNeoForCausalLM: () => (
          /* binding */
          ld
        ),
        /* harmony export */
        GPTNeoModel: () => (
          /* binding */
          ad
        ),
        /* harmony export */
        GPTNeoPreTrainedModel: () => (
          /* binding */
          Ra
        ),
        /* harmony export */
        GPTNeoXForCausalLM: () => (
          /* binding */
          $a
        ),
        /* harmony export */
        GPTNeoXModel: () => (
          /* binding */
          za
        ),
        /* harmony export */
        GPTNeoXPreTrainedModel: () => (
          /* binding */
          Ba
        ),
        /* harmony export */
        Gemma2ForCausalLM: () => (
          /* binding */
          jd
        ),
        /* harmony export */
        Gemma2Model: () => (
          /* binding */
          nl
        ),
        /* harmony export */
        Gemma2PreTrainedModel: () => (
          /* binding */
          tl
        ),
        /* harmony export */
        Gemma3ForCausalLM: () => (
          /* binding */
          qd
        ),
        /* harmony export */
        Gemma3Model: () => (
          /* binding */
          Hd
        ),
        /* harmony export */
        Gemma3PreTrainedModel: () => (
          /* binding */
          sl
        ),
        /* harmony export */
        Gemma3nForConditionalGeneration: () => (
          /* binding */
          Ia
        ),
        /* harmony export */
        Gemma3nPreTrainedModel: () => (
          /* binding */
          Wu
        ),
        /* harmony export */
        GemmaForCausalLM: () => (
          /* binding */
          Vd
        ),
        /* harmony export */
        GemmaModel: () => (
          /* binding */
          Gd
        ),
        /* harmony export */
        GemmaPreTrainedModel: () => (
          /* binding */
          el
        ),
        /* harmony export */
        GlmForCausalLM: () => (
          /* binding */
          Ad
        ),
        /* harmony export */
        GlmModel: () => (
          /* binding */
          Pd
        ),
        /* harmony export */
        GlmPreTrainedModel: () => (
          /* binding */
          qa
        ),
        /* harmony export */
        GraniteForCausalLM: () => (
          /* binding */
          Bd
        ),
        /* harmony export */
        GraniteModel: () => (
          /* binding */
          Rd
        ),
        /* harmony export */
        GraniteMoeHybridForCausalLM: () => (
          /* binding */
          $d
        ),
        /* harmony export */
        GraniteMoeHybridModel: () => (
          /* binding */
          zd
        ),
        /* harmony export */
        GraniteMoeHybridPreTrainedModel: () => (
          /* binding */
          Qa
        ),
        /* harmony export */
        GranitePreTrainedModel: () => (
          /* binding */
          Ja
        ),
        /* harmony export */
        GroundingDinoForObjectDetection: () => (
          /* binding */
          Zs
        ),
        /* harmony export */
        GroundingDinoPreTrainedModel: () => (
          /* binding */
          Qs
        ),
        /* harmony export */
        GroupViTModel: () => (
          /* binding */
          _l
        ),
        /* harmony export */
        GroupViTPreTrainedModel: () => (
          /* binding */
          ph
        ),
        /* harmony export */
        HeliumForCausalLM: () => (
          /* binding */
          Sd
        ),
        /* harmony export */
        HeliumModel: () => (
          /* binding */
          Ed
        ),
        /* harmony export */
        HeliumPreTrainedModel: () => (
          /* binding */
          Ha
        ),
        /* harmony export */
        HieraForImageClassification: () => (
          /* binding */
          Nh
        ),
        /* harmony export */
        HieraModel: () => (
          /* binding */
          $h
        ),
        /* harmony export */
        HieraPreTrainedModel: () => (
          /* binding */
          Ll
        ),
        /* harmony export */
        HubertForCTC: () => (
          /* binding */
          kg
        ),
        /* harmony export */
        HubertForSequenceClassification: () => (
          /* binding */
          $f
        ),
        /* harmony export */
        HubertModel: () => (
          /* binding */
          zf
        ),
        /* harmony export */
        HubertPreTrainedModel: () => (
          /* binding */
          Dg
        ),
        /* harmony export */
        IJepaForImageClassification: () => (
          /* binding */
          fl
        ),
        /* harmony export */
        IJepaModel: () => (
          /* binding */
          Xs
        ),
        /* harmony export */
        IJepaPreTrainedModel: () => (
          /* binding */
          Ds
        ),
        /* harmony export */
        Idefics3ForConditionalGeneration: () => (
          /* binding */
          xo
        ),
        /* harmony export */
        Idefics3PreTrainedModel: () => (
          /* binding */
          Hu
        ),
        /* harmony export */
        ImageMattingOutput: () => (
          /* binding */
          ke
        ),
        /* harmony export */
        JAISLMHeadModel: () => (
          /* binding */
          od
        ),
        /* harmony export */
        JAISModel: () => (
          /* binding */
          rd
        ),
        /* harmony export */
        JAISPreTrainedModel: () => (
          /* binding */
          Fa
        ),
        /* harmony export */
        JinaCLIPModel: () => (
          /* binding */
          Zu
        ),
        /* harmony export */
        JinaCLIPPreTrainedModel: () => (
          /* binding */
          To
        ),
        /* harmony export */
        JinaCLIPTextModel: () => (
          /* binding */
          ed
        ),
        /* harmony export */
        JinaCLIPVisionModel: () => (
          /* binding */
          td
        ),
        /* harmony export */
        Lfm2ForCausalLM: () => (
          /* binding */
          bd
        ),
        /* harmony export */
        Lfm2Model: () => (
          /* binding */
          mg
        ),
        /* harmony export */
        Lfm2PreTrainedModel: () => (
          /* binding */
          Wa
        ),
        /* harmony export */
        LiteWhisperForConditionalGeneration: () => (
          /* binding */
          Ru
        ),
        /* harmony export */
        Llama4ForCausalLM: () => (
          /* binding */
          gd
        ),
        /* harmony export */
        Llama4PreTrainedModel: () => (
          /* binding */
          Va
        ),
        /* harmony export */
        LlamaForCausalLM: () => (
          /* binding */
          md
        ),
        /* harmony export */
        LlamaModel: () => (
          /* binding */
          pd
        ),
        /* harmony export */
        LlamaPreTrainedModel: () => (
          /* binding */
          _r
        ),
        /* harmony export */
        LlavaForConditionalGeneration: () => (
          /* binding */
          wo
        ),
        /* harmony export */
        LlavaOnevisionForConditionalGeneration: () => (
          /* binding */
          zu
        ),
        /* harmony export */
        LlavaPreTrainedModel: () => (
          /* binding */
          Ca
        ),
        /* harmony export */
        LlavaQwen2ForCausalLM: () => (
          /* binding */
          Fi
        ),
        /* harmony export */
        LongT5ForConditionalGeneration: () => (
          /* binding */
          Un
        ),
        /* harmony export */
        LongT5Model: () => (
          /* binding */
          En
        ),
        /* harmony export */
        LongT5PreTrainedModel: () => (
          /* binding */
          Rn
        ),
        /* harmony export */
        M2M100ForConditionalGeneration: () => (
          /* binding */
          Mf
        ),
        /* harmony export */
        M2M100Model: () => (
          /* binding */
          Gr
        ),
        /* harmony export */
        M2M100PreTrainedModel: () => (
          /* binding */
          Wl
        ),
        /* harmony export */
        MBartForCausalLM: () => (
          /* binding */
          es
        ),
        /* harmony export */
        MBartForConditionalGeneration: () => (
          /* binding */
          Zi
        ),
        /* harmony export */
        MBartForSequenceClassification: () => (
          /* binding */
          si
        ),
        /* harmony export */
        MBartModel: () => (
          /* binding */
          Qi
        ),
        /* harmony export */
        MBartPreTrainedModel: () => (
          /* binding */
          ii
        ),
        /* harmony export */
        MPNetForMaskedLM: () => (
          /* binding */
          it
        ),
        /* harmony export */
        MPNetForQuestionAnswering: () => (
          /* binding */
          Xe
        ),
        /* harmony export */
        MPNetForSequenceClassification: () => (
          /* binding */
          ps
        ),
        /* harmony export */
        MPNetForTokenClassification: () => (
          /* binding */
          Br
        ),
        /* harmony export */
        MPNetModel: () => (
          /* binding */
          Ui
        ),
        /* harmony export */
        MPNetPreTrainedModel: () => (
          /* binding */
          yn
        ),
        /* harmony export */
        MT5ForConditionalGeneration: () => (
          /* binding */
          ms
        ),
        /* harmony export */
        MT5Model: () => (
          /* binding */
          xi
        ),
        /* harmony export */
        MT5PreTrainedModel: () => (
          /* binding */
          ui
        ),
        /* harmony export */
        MarianMTModel: () => (
          /* binding */
          jl
        ),
        /* harmony export */
        MarianModel: () => (
          /* binding */
          bf
        ),
        /* harmony export */
        MarianPreTrainedModel: () => (
          /* binding */
          Vl
        ),
        /* harmony export */
        MaskFormerForInstanceSegmentation: () => (
          /* binding */
          Eg
        ),
        /* harmony export */
        MaskFormerModel: () => (
          /* binding */
          ef
        ),
        /* harmony export */
        MaskFormerPreTrainedModel: () => (
          /* binding */
          Bl
        ),
        /* harmony export */
        MaskedLMOutput: () => (
          /* binding */
          re
        ),
        /* harmony export */
        Metric3DForDepthEstimation: () => (
          /* binding */
          Tg
        ),
        /* harmony export */
        Metric3DPreTrainedModel: () => (
          /* binding */
          Jh
        ),
        /* harmony export */
        Metric3Dv2ForDepthEstimation: () => (
          /* binding */
          Zh
        ),
        /* harmony export */
        Metric3Dv2PreTrainedModel: () => (
          /* binding */
          Qh
        ),
        /* harmony export */
        MgpstrForSceneTextRecognition: () => (
          /* binding */
          Pp
        ),
        /* harmony export */
        MgpstrModelOutput: () => (
          /* binding */
          Ep
        ),
        /* harmony export */
        MgpstrPreTrainedModel: () => (
          /* binding */
          Sp
        ),
        /* harmony export */
        MimiDecoderModel: () => (
          /* binding */
          Ug
        ),
        /* harmony export */
        MimiDecoderOutput: () => (
          /* binding */
          Op
        ),
        /* harmony export */
        MimiEncoderModel: () => (
          /* binding */
          Rp
        ),
        /* harmony export */
        MimiEncoderOutput: () => (
          /* binding */
          kp
        ),
        /* harmony export */
        MimiModel: () => (
          /* binding */
          Fp
        ),
        /* harmony export */
        MimiPreTrainedModel: () => (
          /* binding */
          hc
        ),
        /* harmony export */
        Ministral3ForCausalLM: () => (
          /* binding */
          tc
        ),
        /* harmony export */
        Ministral3Model: () => (
          /* binding */
          Qf
        ),
        /* harmony export */
        Ministral3PreTrainedModel: () => (
          /* binding */
          ec
        ),
        /* harmony export */
        MinistralForCausalLM: () => (
          /* binding */
          Zl
        ),
        /* harmony export */
        MinistralModel: () => (
          /* binding */
          Ql
        ),
        /* harmony export */
        MinistralPreTrainedModel: () => (
          /* binding */
          No
        ),
        /* harmony export */
        Mistral3ForConditionalGeneration: () => (
          /* binding */
          ju
        ),
        /* harmony export */
        MistralForCausalLM: () => (
          /* binding */
          Jl
        ),
        /* harmony export */
        MistralModel: () => (
          /* binding */
          jr
        ),
        /* harmony export */
        MistralPreTrainedModel: () => (
          /* binding */
          Jf
        ),
        /* harmony export */
        MobileBertForMaskedLM: () => (
          /* binding */
          bt
        ),
        /* harmony export */
        MobileBertForQuestionAnswering: () => (
          /* binding */
          Lt
        ),
        /* harmony export */
        MobileBertForSequenceClassification: () => (
          /* binding */
          ct
        ),
        /* harmony export */
        MobileBertModel: () => (
          /* binding */
          pi
        ),
        /* harmony export */
        MobileBertPreTrainedModel: () => (
          /* binding */
          Ji
        ),
        /* harmony export */
        MobileLLMForCausalLM: () => (
          /* binding */
          Dd
        ),
        /* harmony export */
        MobileLLMModel: () => (
          /* binding */
          Ld
        ),
        /* harmony export */
        MobileLLMPreTrainedModel: () => (
          /* binding */
          Xa
        ),
        /* harmony export */
        MobileNetV1ForImageClassification: () => (
          /* binding */
          ac
        ),
        /* harmony export */
        MobileNetV1ForSemanticSegmentation: () => (
          /* binding */
          fp
        ),
        /* harmony export */
        MobileNetV1Model: () => (
          /* binding */
          hp
        ),
        /* harmony export */
        MobileNetV1PreTrainedModel: () => (
          /* binding */
          qo
        ),
        /* harmony export */
        MobileNetV2ForImageClassification: () => (
          /* binding */
          mp
        ),
        /* harmony export */
        MobileNetV2ForSemanticSegmentation: () => (
          /* binding */
          gp
        ),
        /* harmony export */
        MobileNetV2Model: () => (
          /* binding */
          pp
        ),
        /* harmony export */
        MobileNetV2PreTrainedModel: () => (
          /* binding */
          Ko
        ),
        /* harmony export */
        MobileNetV3ForImageClassification: () => (
          /* binding */
          yp
        ),
        /* harmony export */
        MobileNetV3ForSemanticSegmentation: () => (
          /* binding */
          lc
        ),
        /* harmony export */
        MobileNetV3Model: () => (
          /* binding */
          _p
        ),
        /* harmony export */
        MobileNetV3PreTrainedModel: () => (
          /* binding */
          Xo
        ),
        /* harmony export */
        MobileNetV4ForImageClassification: () => (
          /* binding */
          wp
        ),
        /* harmony export */
        MobileNetV4ForSemanticSegmentation: () => (
          /* binding */
          xp
        ),
        /* harmony export */
        MobileNetV4Model: () => (
          /* binding */
          vp
        ),
        /* harmony export */
        MobileNetV4PreTrainedModel: () => (
          /* binding */
          Yo
        ),
        /* harmony export */
        MobileViTForImageClassification: () => (
          /* binding */
          yh
        ),
        /* harmony export */
        MobileViTModel: () => (
          /* binding */
          _h
        ),
        /* harmony export */
        MobileViTPreTrainedModel: () => (
          /* binding */
          Lo
        ),
        /* harmony export */
        MobileViTV2ForImageClassification: () => (
          /* binding */
          vl
        ),
        /* harmony export */
        MobileViTV2Model: () => (
          /* binding */
          wh
        ),
        /* harmony export */
        MobileViTV2PreTrainedModel: () => (
          /* binding */
          vh
        ),
        /* harmony export */
        ModelOutput: () => (
          /* binding */
          Se
        ),
        /* harmony export */
        ModernBertDecoderForCausalLM: () => (
          /* binding */
          vn
        ),
        /* harmony export */
        ModernBertDecoderModel: () => (
          /* binding */
          Kt
        ),
        /* harmony export */
        ModernBertDecoderPreTrainedModel: () => (
          /* binding */
          Rt
        ),
        /* harmony export */
        ModernBertForMaskedLM: () => (
          /* binding */
          je
        ),
        /* harmony export */
        ModernBertForSequenceClassification: () => (
          /* binding */
          lt
        ),
        /* harmony export */
        ModernBertForTokenClassification: () => (
          /* binding */
          Mt
        ),
        /* harmony export */
        ModernBertModel: () => (
          /* binding */
          He
        ),
        /* harmony export */
        ModernBertPreTrainedModel: () => (
          /* binding */
          tt
        ),
        /* harmony export */
        Moondream1ForConditionalGeneration: () => (
          /* binding */
          $u
        ),
        /* harmony export */
        MoonshineForConditionalGeneration: () => (
          /* binding */
          Bu
        ),
        /* harmony export */
        MoonshineModel: () => (
          /* binding */
          Hs
        ),
        /* harmony export */
        MoonshinePreTrainedModel: () => (
          /* binding */
          Pa
        ),
        /* harmony export */
        MptForCausalLM: () => (
          /* binding */
          ch
        ),
        /* harmony export */
        MptModel: () => (
          /* binding */
          lh
        ),
        /* harmony export */
        MptPreTrainedModel: () => (
          /* binding */
          ah
        ),
        /* harmony export */
        MultiModalityCausalLM: () => (
          /* binding */
          Ng
        ),
        /* harmony export */
        MultiModalityPreTrainedModel: () => (
          /* binding */
          Tp
        ),
        /* harmony export */
        MusicgenForCausalLM: () => (
          /* binding */
          Wy
        ),
        /* harmony export */
        MusicgenForConditionalGeneration: () => (
          /* binding */
          oc
        ),
        /* harmony export */
        MusicgenModel: () => (
          /* binding */
          $g
        ),
        /* harmony export */
        MusicgenPreTrainedModel: () => (
          /* binding */
          rc
        ),
        /* harmony export */
        NanoChatForCausalLM: () => (
          /* binding */
          yd
        ),
        /* harmony export */
        NanoChatModel: () => (
          /* binding */
          _d
        ),
        /* harmony export */
        NanoChatPreTrainedModel: () => (
          /* binding */
          ja
        ),
        /* harmony export */
        NeoBertForMaskedLM: () => (
          /* binding */
          Ne
        ),
        /* harmony export */
        NeoBertForQuestionAnswering: () => (
          /* binding */
          qe
        ),
        /* harmony export */
        NeoBertForSequenceClassification: () => (
          /* binding */
          ut
        ),
        /* harmony export */
        NeoBertForTokenClassification: () => (
          /* binding */
          de
        ),
        /* harmony export */
        NeoBertModel: () => (
          /* binding */
          Qe
        ),
        /* harmony export */
        NeoBertPreTrainedModel: () => (
          /* binding */
          fe
        ),
        /* harmony export */
        NomicBertModel: () => (
          /* binding */
          ln
        ),
        /* harmony export */
        NomicBertPreTrainedModel: () => (
          /* binding */
          wn
        ),
        /* harmony export */
        OPTForCausalLM: () => (
          /* binding */
          dh
        ),
        /* harmony export */
        OPTModel: () => (
          /* binding */
          uh
        ),
        /* harmony export */
        OPTPreTrainedModel: () => (
          /* binding */
          dl
        ),
        /* harmony export */
        Olmo2ForCausalLM: () => (
          /* binding */
          Fd
        ),
        /* harmony export */
        Olmo2Model: () => (
          /* binding */
          Od
        ),
        /* harmony export */
        Olmo2PreTrainedModel: () => (
          /* binding */
          Ya
        ),
        /* harmony export */
        OlmoForCausalLM: () => (
          /* binding */
          So
        ),
        /* harmony export */
        OlmoModel: () => (
          /* binding */
          kd
        ),
        /* harmony export */
        OlmoPreTrainedModel: () => (
          /* binding */
          yr
        ),
        /* harmony export */
        OpenELMForCausalLM: () => (
          /* binding */
          ol
        ),
        /* harmony export */
        OpenELMModel: () => (
          /* binding */
          Kd
        ),
        /* harmony export */
        OpenELMPreTrainedModel: () => (
          /* binding */
          rl
        ),
        /* harmony export */
        OwlViTForObjectDetection: () => (
          /* binding */
          wl
        ),
        /* harmony export */
        OwlViTModel: () => (
          /* binding */
          xh
        ),
        /* harmony export */
        OwlViTPreTrainedModel: () => (
          /* binding */
          vr
        ),
        /* harmony export */
        Owlv2ForObjectDetection: () => (
          /* binding */
          Mh
        ),
        /* harmony export */
        Owlv2Model: () => (
          /* binding */
          bh
        ),
        /* harmony export */
        Owlv2PreTrainedModel: () => (
          /* binding */
          xl
        ),
        /* harmony export */
        PaliGemmaForConditionalGeneration: () => (
          /* binding */
          Vu
        ),
        /* harmony export */
        PaliGemmaPreTrainedModel: () => (
          /* binding */
          Gu
        ),
        /* harmony export */
        ParakeetForCTC: () => (
          /* binding */
          Af
        ),
        /* harmony export */
        ParakeetPreTrainedModel: () => (
          /* binding */
          Hl
        ),
        /* harmony export */
        PatchTSMixerForPrediction: () => (
          /* binding */
          Ip
        ),
        /* harmony export */
        PatchTSMixerModel: () => (
          /* binding */
          uc
        ),
        /* harmony export */
        PatchTSMixerPreTrainedModel: () => (
          /* binding */
          cc
        ),
        /* harmony export */
        PatchTSTForPrediction: () => (
          /* binding */
          Wr
        ),
        /* harmony export */
        PatchTSTModel: () => (
          /* binding */
          Cp
        ),
        /* harmony export */
        PatchTSTPreTrainedModel: () => (
          /* binding */
          Ap
        ),
        /* harmony export */
        Phi3ForCausalLM: () => (
          /* binding */
          sh
        ),
        /* harmony export */
        Phi3Model: () => (
          /* binding */
          ih
        ),
        /* harmony export */
        Phi3PreTrainedModel: () => (
          /* binding */
          cl
        ),
        /* harmony export */
        Phi3VForCausalLM: () => (
          /* binding */
          Da
        ),
        /* harmony export */
        Phi3VPreTrainedModel: () => (
          /* binding */
          qu
        ),
        /* harmony export */
        PhiForCausalLM: () => (
          /* binding */
          nh
        ),
        /* harmony export */
        PhiModel: () => (
          /* binding */
          th
        ),
        /* harmony export */
        PhiPreTrainedModel: () => (
          /* binding */
          ll
        ),
        /* harmony export */
        PreTrainedModel: () => (
          /* binding */
          U
        ),
        /* harmony export */
        PretrainedMixin: () => (
          /* binding */
          mn
        ),
        /* harmony export */
        PvtForImageClassification: () => (
          /* binding */
          hh
        ),
        /* harmony export */
        PvtModel: () => (
          /* binding */
          ml
        ),
        /* harmony export */
        PvtPreTrainedModel: () => (
          /* binding */
          pl
        ),
        /* harmony export */
        PyAnnoteForAudioFrameClassification: () => (
          /* binding */
          If
        ),
        /* harmony export */
        PyAnnoteModel: () => (
          /* binding */
          Cf
        ),
        /* harmony export */
        PyAnnotePreTrainedModel: () => (
          /* binding */
          ql
        ),
        /* harmony export */
        QuestionAnsweringModelOutput: () => (
          /* binding */
          Te
        ),
        /* harmony export */
        Qwen2ForCausalLM: () => (
          /* binding */
          Yd
        ),
        /* harmony export */
        Qwen2Model: () => (
          /* binding */
          Xd
        ),
        /* harmony export */
        Qwen2PreTrainedModel: () => (
          /* binding */
          al
        ),
        /* harmony export */
        Qwen2VLForConditionalGeneration: () => (
          /* binding */
          eh
        ),
        /* harmony export */
        Qwen2VLPreTrainedModel: () => (
          /* binding */
          Wi
        ),
        /* harmony export */
        Qwen3ForCausalLM: () => (
          /* binding */
          Zd
        ),
        /* harmony export */
        Qwen3Model: () => (
          /* binding */
          Qd
        ),
        /* harmony export */
        Qwen3PreTrainedModel: () => (
          /* binding */
          Jd
        ),
        /* harmony export */
        RFDetrForObjectDetection: () => (
          /* binding */
          Sl
        ),
        /* harmony export */
        RFDetrModel: () => (
          /* binding */
          kh
        ),
        /* harmony export */
        RFDetrObjectDetectionOutput: () => (
          /* binding */
          Oh
        ),
        /* harmony export */
        RFDetrPreTrainedModel: () => (
          /* binding */
          El
        ),
        /* harmony export */
        RTDetrForObjectDetection: () => (
          /* binding */
          Ch
        ),
        /* harmony export */
        RTDetrModel: () => (
          /* binding */
          Ah
        ),
        /* harmony export */
        RTDetrObjectDetectionOutput: () => (
          /* binding */
          wr
        ),
        /* harmony export */
        RTDetrPreTrainedModel: () => (
          /* binding */
          ko
        ),
        /* harmony export */
        RTDetrV2ForObjectDetection: () => (
          /* binding */
          yg
        ),
        /* harmony export */
        RTDetrV2Model: () => (
          /* binding */
          Lh
        ),
        /* harmony export */
        RTDetrV2ObjectDetectionOutput: () => (
          /* binding */
          Dh
        ),
        /* harmony export */
        RTDetrV2PreTrainedModel: () => (
          /* binding */
          Ih
        ),
        /* harmony export */
        ResNetForImageClassification: () => (
          /* binding */
          Oo
        ),
        /* harmony export */
        ResNetModel: () => (
          /* binding */
          xg
        ),
        /* harmony export */
        ResNetPreTrainedModel: () => (
          /* binding */
          Dl
        ),
        /* harmony export */
        RoFormerForMaskedLM: () => (
          /* binding */
          Yi
        ),
        /* harmony export */
        RoFormerForQuestionAnswering: () => (
          /* binding */
          bn
        ),
        /* harmony export */
        RoFormerForSequenceClassification: () => (
          /* binding */
          $i
        ),
        /* harmony export */
        RoFormerForTokenClassification: () => (
          /* binding */
          An
        ),
        /* harmony export */
        RoFormerModel: () => (
          /* binding */
          li
        ),
        /* harmony export */
        RoFormerPreTrainedModel: () => (
          /* binding */
          Gn
        ),
        /* harmony export */
        RobertaForMaskedLM: () => (
          /* binding */
          di
        ),
        /* harmony export */
        RobertaForQuestionAnswering: () => (
          /* binding */
          Ta
        ),
        /* harmony export */
        RobertaForSequenceClassification: () => (
          /* binding */
          Ut
        ),
        /* harmony export */
        RobertaForTokenClassification: () => (
          /* binding */
          Dn
        ),
        /* harmony export */
        RobertaModel: () => (
          /* binding */
          Jn
        ),
        /* harmony export */
        RobertaPreTrainedModel: () => (
          /* binding */
          ns
        ),
        /* harmony export */
        Sam2ImageSegmentationOutput: () => (
          /* binding */
          wf
        ),
        /* harmony export */
        Sam2Model: () => (
          /* binding */
          Fo
        ),
        /* harmony export */
        Sam2PreTrainedModel: () => (
          /* binding */
          xf
        ),
        /* harmony export */
        Sam3TrackerModel: () => (
          /* binding */
          mi
        ),
        /* harmony export */
        SamImageSegmentationOutput: () => (
          /* binding */
          vf
        ),
        /* harmony export */
        SamModel: () => (
          /* binding */
          yf
        ),
        /* harmony export */
        SamPreTrainedModel: () => (
          /* binding */
          _f
        ),
        /* harmony export */
        SapiensForDepthEstimation: () => (
          /* binding */
          Kh
        ),
        /* harmony export */
        SapiensForNormalEstimation: () => (
          /* binding */
          Xh
        ),
        /* harmony export */
        SapiensForSemanticSegmentation: () => (
          /* binding */
          qh
        ),
        /* harmony export */
        SapiensPreTrainedModel: () => (
          /* binding */
          Ur
        ),
        /* harmony export */
        SegformerForImageClassification: () => (
          /* binding */
          lp
        ),
        /* harmony export */
        SegformerForSemanticSegmentation: () => (
          /* binding */
          cp
        ),
        /* harmony export */
        SegformerModel: () => (
          /* binding */
          jy
        ),
        /* harmony export */
        SegformerPreTrainedModel: () => (
          /* binding */
          Wo
        ),
        /* harmony export */
        Seq2SeqLMOutput: () => (
          /* binding */
          V
        ),
        /* harmony export */
        SequenceClassifierOutput: () => (
          /* binding */
          G
        ),
        /* harmony export */
        SiglipModel: () => (
          /* binding */
          Vi
        ),
        /* harmony export */
        SiglipPreTrainedModel: () => (
          /* binding */
          Mo
        ),
        /* harmony export */
        SiglipTextModel: () => (
          /* binding */
          Xu
        ),
        /* harmony export */
        SiglipVisionModel: () => (
          /* binding */
          Yu
        ),
        /* harmony export */
        SmolLM3ForCausalLM: () => (
          /* binding */
          Td
        ),
        /* harmony export */
        SmolLM3Model: () => (
          /* binding */
          Md
        ),
        /* harmony export */
        SmolLM3PreTrainedModel: () => (
          /* binding */
          hn
        ),
        /* harmony export */
        SmolVLMForConditionalGeneration: () => (
          /* binding */
          La
        ),
        /* harmony export */
        SnacDecoderModel: () => (
          /* binding */
          Vg
        ),
        /* harmony export */
        SnacEncoderModel: () => (
          /* binding */
          Gp
        ),
        /* harmony export */
        SnacModel: () => (
          /* binding */
          Up
        ),
        /* harmony export */
        SnacPreTrainedModel: () => (
          /* binding */
          Jo
        ),
        /* harmony export */
        SpeechT5ForSpeechToText: () => (
          /* binding */
          Wf
        ),
        /* harmony export */
        SpeechT5ForTextToSpeech: () => (
          /* binding */
          Hf
        ),
        /* harmony export */
        SpeechT5HifiGan: () => (
          /* binding */
          qf
        ),
        /* harmony export */
        SpeechT5Model: () => (
          /* binding */
          Rg
        ),
        /* harmony export */
        SpeechT5PreTrainedModel: () => (
          /* binding */
          $o
        ),
        /* harmony export */
        SqueezeBertForMaskedLM: () => (
          /* binding */
          Ae
        ),
        /* harmony export */
        SqueezeBertForQuestionAnswering: () => (
          /* binding */
          We
        ),
        /* harmony export */
        SqueezeBertForSequenceClassification: () => (
          /* binding */
          Re
        ),
        /* harmony export */
        SqueezeBertModel: () => (
          /* binding */
          ie
        ),
        /* harmony export */
        SqueezeBertPreTrainedModel: () => (
          /* binding */
          j
        ),
        /* harmony export */
        StableLmForCausalLM: () => (
          /* binding */
          up
        ),
        /* harmony export */
        StableLmModel: () => (
          /* binding */
          zg
        ),
        /* harmony export */
        StableLmPreTrainedModel: () => (
          /* binding */
          ic
        ),
        /* harmony export */
        Starcoder2ForCausalLM: () => (
          /* binding */
          np
        ),
        /* harmony export */
        Starcoder2Model: () => (
          /* binding */
          tp
        ),
        /* harmony export */
        Starcoder2PreTrainedModel: () => (
          /* binding */
          Go
        ),
        /* harmony export */
        StyleTextToSpeech2Model: () => (
          /* binding */
          Fg
        ),
        /* harmony export */
        StyleTextToSpeech2PreTrainedModel: () => (
          /* binding */
          jf
        ),
        /* harmony export */
        SupertonicForConditionalGeneration: () => (
          /* binding */
          Yl
        ),
        /* harmony export */
        SupertonicPreTrainedModel: () => (
          /* binding */
          Kf
        ),
        /* harmony export */
        Swin2SRForImageSuperResolution: () => (
          /* binding */
          Fl
        ),
        /* harmony export */
        Swin2SRModel: () => (
          /* binding */
          Vh
        ),
        /* harmony export */
        Swin2SRPreTrainedModel: () => (
          /* binding */
          Ol
        ),
        /* harmony export */
        SwinForImageClassification: () => (
          /* binding */
          Uh
        ),
        /* harmony export */
        SwinForSemanticSegmentation: () => (
          /* binding */
          Gh
        ),
        /* harmony export */
        SwinModel: () => (
          /* binding */
          kl
        ),
        /* harmony export */
        SwinPreTrainedModel: () => (
          /* binding */
          Js
        ),
        /* harmony export */
        T5ForConditionalGeneration: () => (
          /* binding */
          _n
        ),
        /* harmony export */
        T5Model: () => (
          /* binding */
          fn
        ),
        /* harmony export */
        T5PreTrainedModel: () => (
          /* binding */
          Xt
        ),
        /* harmony export */
        TableTransformerForObjectDetection: () => (
          /* binding */
          Rh
        ),
        /* harmony export */
        TableTransformerModel: () => (
          /* binding */
          vg
        ),
        /* harmony export */
        TableTransformerObjectDetectionOutput: () => (
          /* binding */
          Bh
        ),
        /* harmony export */
        TableTransformerPreTrainedModel: () => (
          /* binding */
          Cl
        ),
        /* harmony export */
        TokenClassifierOutput: () => (
          /* binding */
          X
        ),
        /* harmony export */
        TrOCRForCausalLM: () => (
          /* binding */
          Yf
        ),
        /* harmony export */
        TrOCRPreTrainedModel: () => (
          /* binding */
          Xf
        ),
        /* harmony export */
        UltravoxModel: () => (
          /* binding */
          dc
        ),
        /* harmony export */
        UltravoxPreTrainedModel: () => (
          /* binding */
          Lp
        ),
        /* harmony export */
        UniSpeechForCTC: () => (
          /* binding */
          kf
        ),
        /* harmony export */
        UniSpeechForSequenceClassification: () => (
          /* binding */
          Kl
        ),
        /* harmony export */
        UniSpeechModel: () => (
          /* binding */
          Df
        ),
        /* harmony export */
        UniSpeechPreTrainedModel: () => (
          /* binding */
          Bo
        ),
        /* harmony export */
        UniSpeechSatForAudioFrameClassification: () => (
          /* binding */
          Ff
        ),
        /* harmony export */
        UniSpeechSatForCTC: () => (
          /* binding */
          Ig
        ),
        /* harmony export */
        UniSpeechSatForSequenceClassification: () => (
          /* binding */
          Xl
        ),
        /* harmony export */
        UniSpeechSatModel: () => (
          /* binding */
          Of
        ),
        /* harmony export */
        UniSpeechSatPreTrainedModel: () => (
          /* binding */
          Vr
        ),
        /* harmony export */
        VaultGemmaForCausalLM: () => (
          /* binding */
          Wd
        ),
        /* harmony export */
        VaultGemmaModel: () => (
          /* binding */
          il
        ),
        /* harmony export */
        VaultGemmaPreTrainedModel: () => (
          /* binding */
          Po
        ),
        /* harmony export */
        ViTForImageClassification: () => (
          /* binding */
          Ks
        ),
        /* harmony export */
        ViTMAEModel: () => (
          /* binding */
          $r
        ),
        /* harmony export */
        ViTMAEPreTrainedModel: () => (
          /* binding */
          _g
        ),
        /* harmony export */
        ViTMSNForImageClassification: () => (
          /* binding */
          fh
        ),
        /* harmony export */
        ViTMSNModel: () => (
          /* binding */
          gl
        ),
        /* harmony export */
        ViTMSNPreTrainedModel: () => (
          /* binding */
          Ao
        ),
        /* harmony export */
        ViTModel: () => (
          /* binding */
          gg
        ),
        /* harmony export */
        ViTPreTrainedModel: () => (
          /* binding */
          hl
        ),
        /* harmony export */
        VisionEncoderDecoderModel: () => (
          /* binding */
          Aa
        ),
        /* harmony export */
        VitMatteForImageMatting: () => (
          /* binding */
          Io
        ),
        /* harmony export */
        VitMattePreTrainedModel: () => (
          /* binding */
          gh
        ),
        /* harmony export */
        VitPoseForPoseEstimation: () => (
          /* binding */
          ti
        ),
        /* harmony export */
        VitPosePreTrainedModel: () => (
          /* binding */
          Ys
        ),
        /* harmony export */
        VitsModel: () => (
          /* binding */
          nc
        ),
        /* harmony export */
        VitsModelOutput: () => (
          /* binding */
          Le
        ),
        /* harmony export */
        VitsPreTrainedModel: () => (
          /* binding */
          ap
        ),
        /* harmony export */
        VoxtralForConditionalGeneration: () => (
          /* binding */
          Dp
        ),
        /* harmony export */
        Wav2Vec2BertForCTC: () => (
          /* binding */
          Lg
        ),
        /* harmony export */
        Wav2Vec2BertForSequenceClassification: () => (
          /* binding */
          Bf
        ),
        /* harmony export */
        Wav2Vec2BertModel: () => (
          /* binding */
          Rf
        ),
        /* harmony export */
        Wav2Vec2BertPreTrainedModel: () => (
          /* binding */
          zo
        ),
        /* harmony export */
        Wav2Vec2ForAudioFrameClassification: () => (
          /* binding */
          Pf
        ),
        /* harmony export */
        Wav2Vec2ForCTC: () => (
          /* binding */
          Ef
        ),
        /* harmony export */
        Wav2Vec2ForSequenceClassification: () => (
          /* binding */
          Sf
        ),
        /* harmony export */
        Wav2Vec2Model: () => (
          /* binding */
          Tf
        ),
        /* harmony export */
        Wav2Vec2PreTrainedModel: () => (
          /* binding */
          ks
        ),
        /* harmony export */
        WavLMForAudioFrameClassification: () => (
          /* binding */
          Vf
        ),
        /* harmony export */
        WavLMForCTC: () => (
          /* binding */
          Nf
        ),
        /* harmony export */
        WavLMForSequenceClassification: () => (
          /* binding */
          Uf
        ),
        /* harmony export */
        WavLMForXVector: () => (
          /* binding */
          Gf
        ),
        /* harmony export */
        WavLMModel: () => (
          /* binding */
          Og
        ),
        /* harmony export */
        WavLMPreTrainedModel: () => (
          /* binding */
          xr
        ),
        /* harmony export */
        WeSpeakerResNetModel: () => (
          /* binding */
          Lf
        ),
        /* harmony export */
        WeSpeakerResNetPreTrainedModel: () => (
          /* binding */
          Ro
        ),
        /* harmony export */
        WhisperForConditionalGeneration: () => (
          /* binding */
          bi
        ),
        /* harmony export */
        WhisperModel: () => (
          /* binding */
          Fu
        ),
        /* harmony export */
        WhisperPreTrainedModel: () => (
          /* binding */
          Sa
        ),
        /* harmony export */
        XLMForQuestionAnswering: () => (
          /* binding */
          $t
        ),
        /* harmony export */
        XLMForSequenceClassification: () => (
          /* binding */
          zr
        ),
        /* harmony export */
        XLMForTokenClassification: () => (
          /* binding */
          dt
        ),
        /* harmony export */
        XLMModel: () => (
          /* binding */
          Ls
        ),
        /* harmony export */
        XLMPreTrainedModel: () => (
          /* binding */
          is
        ),
        /* harmony export */
        XLMRobertaForMaskedLM: () => (
          /* binding */
          Iu
        ),
        /* harmony export */
        XLMRobertaForQuestionAnswering: () => (
          /* binding */
          Du
        ),
        /* harmony export */
        XLMRobertaForSequenceClassification: () => (
          /* binding */
          Lu
        ),
        /* harmony export */
        XLMRobertaForTokenClassification: () => (
          /* binding */
          sn
        ),
        /* harmony export */
        XLMRobertaModel: () => (
          /* binding */
          Ea
        ),
        /* harmony export */
        XLMRobertaPreTrainedModel: () => (
          /* binding */
          gr
        ),
        /* harmony export */
        XLMWithLMHeadModel: () => (
          /* binding */
          Nt
        ),
        /* harmony export */
        XVectorOutput: () => (
          /* binding */
          ee
        ),
        /* harmony export */
        YolosForObjectDetection: () => (
          /* binding */
          mf
        ),
        /* harmony export */
        YolosModel: () => (
          /* binding */
          pf
        ),
        /* harmony export */
        YolosObjectDetectionOutput: () => (
          /* binding */
          gf
        ),
        /* harmony export */
        YolosPreTrainedModel: () => (
          /* binding */
          Gl
        )
        /* harmony export */
      });
      var i = t(
        /*! ./configs.js */
        "./src/configs.js"
      ), r = t(
        /*! ./backends/onnx.js */
        "./src/backends/onnx.js"
      ), a = t(
        /*! ./utils/dtypes.js */
        "./src/utils/dtypes.js"
      ), c = t(
        /*! ./utils/generic.js */
        "./src/utils/generic.js"
      ), u = t(
        /*! ./utils/core.js */
        "./src/utils/core.js"
      ), l = t(
        /*! ./utils/hub.js */
        "./src/utils/hub.js"
      ), f = t(
        /*! ./utils/constants.js */
        "./src/utils/constants.js"
      ), m = t(
        /*! ./generation/logits_process.js */
        "./src/generation/logits_process.js"
      ), h = t(
        /*! ./generation/configuration_utils.js */
        "./src/generation/configuration_utils.js"
      ), p = t(
        /*! ./utils/tensor.js */
        "./src/utils/tensor.js"
      ), _ = t(
        /*! ./utils/image.js */
        "./src/utils/image.js"
      ), v = t(
        /*! ./utils/maths.js */
        "./src/utils/maths.js"
      ), S = t(
        /*! ./generation/stopping_criteria.js */
        "./src/generation/stopping_criteria.js"
      ), D = t(
        /*! ./generation/logits_sampler.js */
        "./src/generation/logits_sampler.js"
      ), w = t(
        /*! ./env.js */
        "./src/env.js"
      ), T = t(
        /*! ./models/whisper/generation_whisper.js */
        "./src/models/whisper/generation_whisper.js"
      ), F = t(
        /*! ./models/whisper/common_whisper.js */
        "./src/models/whisper/common_whisper.js"
      );
      const E = {
        EncoderOnly: 0,
        EncoderDecoder: 1,
        Seq2Seq: 2,
        Vision2Seq: 3,
        DecoderOnly: 4,
        MaskGeneration: 5,
        ImageTextToText: 6,
        Musicgen: 7,
        MultiModality: 8,
        Phi3V: 9,
        AudioTextToText: 10,
        AutoEncoder: 11,
        ImageAudioTextToText: 12,
        Supertonic: 13
      }, A = /* @__PURE__ */ new Map(), L = /* @__PURE__ */ new Map(), I = /* @__PURE__ */ new Map();
      async function R(M, C, z) {
        var kn;
        let oe = ((kn = z.config) == null ? void 0 : kn["transformers.js_config"]) ?? {}, ye = z.device ?? oe.device;
        ye && typeof ye != "string" && (ye.hasOwnProperty(C) ? ye = ye[C] : (console.warn(`device not specified for "${C}". Using the default device.`), ye = null));
        const Pe = (
          /** @type {import("./utils/devices.js").DeviceType} */
          ye ?? (w.apis.IS_NODE_ENV ? "cpu" : "wasm")
        ), Ue = (0, r.deviceToExecutionProviders)(Pe), Je = oe.device_config ?? {};
        Je.hasOwnProperty(Pe) && (oe = {
          ...oe,
          ...Je[Pe]
        });
        let st = z.dtype ?? oe.dtype;
        if (typeof st != "string" && (st && st.hasOwnProperty(C) ? st = st[C] : (st = a.DEFAULT_DEVICE_DTYPE_MAPPING[Pe] ?? a.DATA_TYPES.fp32, console.warn(`dtype not specified for "${C}". Using the default dtype (${st}) for this device (${Pe}).`))), st === a.DATA_TYPES.auto) {
          let Zt = oe.dtype;
          typeof Zt != "string" && (Zt = Zt == null ? void 0 : Zt[C]), Zt && Zt !== a.DATA_TYPES.auto && a.DATA_TYPES.hasOwnProperty(Zt) ? st = Zt : st = a.DEFAULT_DEVICE_DTYPE_MAPPING[Pe] ?? a.DATA_TYPES.fp32;
        }
        const gt = (
          /** @type {import("./utils/dtypes.js").DataType} */
          st
        );
        if (a.DEFAULT_DTYPE_SUFFIX_MAPPING.hasOwnProperty(gt)) {
          if (gt === a.DATA_TYPES.fp16 && Pe === "webgpu" && !await (0, a.isWebGpuFp16Supported)())
            throw new Error(`The device (${Pe}) does not support fp16.`);
        } else
          throw new Error(`Invalid dtype: ${gt}. Should be one of: ${Object.keys(a.DATA_TYPES).join(", ")}`);
        const wt = oe.kv_cache_dtype, yt = wt ? typeof wt == "string" ? wt : wt[gt] ?? "float32" : void 0;
        if (yt && !["float32", "float16"].includes(yt))
          throw new Error(`Invalid kv_cache_dtype: ${yt}. Should be one of: float32, float16`);
        const ht = {
          dtype: gt,
          kv_cache_dtype: yt,
          device: Pe
        }, Ot = a.DEFAULT_DTYPE_SUFFIX_MAPPING[gt], xt = `${C}${Ot}.onnx`, Ct = `${z.subfolder ?? ""}/${xt}`, Ze = { ...z.session_options };
        Ze.executionProviders ?? (Ze.executionProviders = Ue);
        const ft = oe.free_dimension_overrides;
        ft ? Ze.freeDimensionOverrides ?? (Ze.freeDimensionOverrides = ft) : Pe.startsWith("webnn") && !Ze.freeDimensionOverrides && console.warn(
          `WebNN does not currently support dynamic shapes and requires 'free_dimension_overrides' to be set in config.json, preferably as a field within config["transformers.js_config"]["device_config"]["${Pe}"]. When 'free_dimension_overrides' is not set, you may experience significant performance degradation.`
        );
        const St = w.apis.IS_NODE_ENV && w.env.useFSCache, Ht = (0, l.getModelFile)(M, Ct, !0, z, St), cn = z.use_external_data_format ?? oe.use_external_data_format;
        let Sn = [];
        if (cn) {
          let Zt;
          typeof cn == "object" ? cn.hasOwnProperty(xt) ? Zt = cn[xt] : cn.hasOwnProperty(C) ? Zt = cn[C] : Zt = !1 : Zt = cn;
          const $n = +Zt;
          if ($n > l.MAX_EXTERNAL_DATA_CHUNKS)
            throw new Error(`The number of external data chunks (${$n}) exceeds the maximum allowed value (${l.MAX_EXTERNAL_DATA_CHUNKS}).`);
          for (let Pn = 0; Pn < $n; ++Pn) {
            const On = `${xt}_data${Pn === 0 ? "" : "_" + Pn}`, qn = `${z.subfolder ?? ""}/${On}`;
            Sn.push(new Promise(async (Hi, Cc) => {
              const ta = await (0, l.getModelFile)(M, qn, !0, z, St);
              Hi(ta instanceof Uint8Array ? { path: On, data: ta } : On);
            }));
          }
        } else
          Ze.externalData !== void 0 && (Sn = Ze.externalData.map(async (Zt) => {
            if (typeof Zt.data == "string") {
              const $n = await (0, l.getModelFile)(M, Zt.data, !0, z);
              return { ...Zt, data: $n };
            }
            return Zt;
          }));
        if (Sn.length > 0) {
          const Zt = await Promise.all(Sn);
          w.apis.IS_NODE_ENV || (Ze.externalData = Zt);
        }
        if (Pe === "webgpu") {
          const Zt = (0, i.getCacheShapes)(z.config, {
            prefix: "present"
          });
          if (Object.keys(Zt).length > 0 && !(0, r.isONNXProxy)()) {
            const $n = {};
            for (const Pn in Zt)
              $n[Pn] = "gpu-buffer";
            Ze.preferredOutputLocation = $n;
          }
        }
        return { buffer_or_path: await Ht, session_options: Ze, session_config: ht };
      }
      async function N(M, C, z) {
        return Object.fromEntries(await Promise.all(
          Object.keys(C).map(async (oe) => {
            const { buffer_or_path: ye, session_options: Pe, session_config: Ue } = await R(M, C[oe], z), Je = await (0, r.createInferenceSession)(ye, Pe, Ue);
            return [oe, Je];
          })
        ));
      }
      async function q(M, C, z) {
        return Object.fromEntries(await Promise.all(
          Object.keys(C).map(async (oe) => {
            const ye = await (0, l.getModelJSON)(M, C[oe], !1, z);
            return [oe, ye];
          })
        ));
      }
      function ne(M, C) {
        const z = /* @__PURE__ */ Object.create(null), oe = [];
        for (const Ue of M.inputNames) {
          const Je = C[Ue];
          if (!(Je instanceof p.Tensor)) {
            oe.push(Ue);
            continue;
          }
          z[Ue] = (0, r.isONNXProxy)() ? Je.clone() : Je;
        }
        if (oe.length > 0)
          throw new Error(
            `An error occurred during model execution: "Missing the following inputs: ${oe.join(", ")}.`
          );
        const ye = Object.keys(C).length, Pe = M.inputNames.length;
        if (ye > Pe) {
          let Ue = Object.keys(C).filter((Je) => !M.inputNames.includes(Je));
          console.warn(`WARNING: Too many inputs were provided (${ye} > ${Pe}). The following inputs will be ignored: "${Ue.join(", ")}".`);
        }
        return z;
      }
      async function Q(M, C) {
        const z = ne(M, C);
        try {
          const oe = Object.fromEntries(Object.entries(z).map(([Pe, Ue]) => [Pe, Ue.ort_tensor])), ye = await (0, r.runInferenceSession)(M, oe);
          return W(ye);
        } catch (oe) {
          const ye = Object.fromEntries(Object.entries(z).map(([Pe, Ue]) => {
            const Je = {
              type: Ue.type,
              dims: Ue.dims,
              location: Ue.location
            };
            return Je.location !== "gpu-buffer" && (Je.data = Ue.data), [Pe, Je];
          }));
          throw console.error(`An error occurred during model execution: "${oe}".`), console.error("Inputs given to model:", ye), oe;
        }
      }
      function W(M) {
        for (let C in M)
          (0, r.isONNXTensor)(M[C]) ? M[C] = new p.Tensor(M[C]) : typeof M[C] == "object" && W(M[C]);
        return M;
      }
      function te(M) {
        if (M instanceof p.Tensor)
          return M;
        if (M.length === 0)
          throw Error("items must be non-empty");
        if (Array.isArray(M[0])) {
          if (M.some((C) => C.length !== M[0].length))
            throw Error("Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' and/or 'truncation=True' to have batched tensors with the same length.");
          return new p.Tensor(
            "int64",
            BigInt64Array.from(M.flat().map((C) => BigInt(C))),
            [M.length, M[0].length]
          );
        } else
          return new p.Tensor(
            "int64",
            BigInt64Array.from(M.map((C) => BigInt(C))),
            [1, M.length]
          );
      }
      function K(M) {
        return new p.Tensor("bool", [M], [1]);
      }
      async function pe(M, C) {
        let { encoder_outputs: z, input_ids: oe, decoder_input_ids: ye, ...Pe } = C;
        if (!z) {
          const Je = (0, u.pick)(C, M.sessions.model.inputNames);
          z = (await be(M, Je)).last_hidden_state;
        }
        return Pe.input_ids = ye, Pe.encoder_hidden_states = z, M.sessions.decoder_model_merged.inputNames.includes("encoder_attention_mask") && (Pe.encoder_attention_mask = C.attention_mask), await Ge(M, Pe, !0);
      }
      async function be(M, C) {
        const z = M.sessions.model, oe = (0, u.pick)(C, z.inputNames);
        if (z.inputNames.includes("inputs_embeds") && !oe.inputs_embeds) {
          if (!C.input_ids)
            throw new Error("Both `input_ids` and `inputs_embeds` are missing in the model inputs.");
          oe.inputs_embeds = await M.encode_text({ input_ids: C.input_ids });
        }
        if (z.inputNames.includes("token_type_ids") && !oe.token_type_ids) {
          if (!oe.input_ids)
            throw new Error("Both `input_ids` and `token_type_ids` are missing in the model inputs.");
          oe.token_type_ids = (0, p.zeros_like)(oe.input_ids);
        }
        if (z.inputNames.includes("pixel_mask") && !oe.pixel_mask) {
          if (!oe.pixel_values)
            throw new Error("Both `pixel_values` and `pixel_mask` are missing in the model inputs.");
          const ye = oe.pixel_values.dims;
          oe.pixel_mask = (0, p.ones)([ye[0], ye[2], ye[3]]);
        }
        return await Q(z, oe);
      }
      async function Ee(M, C) {
        const z = await M.encode(C);
        return await M.decode(z);
      }
      async function Ge(M, C, z = !1) {
        const oe = M.sessions[z ? "decoder_model_merged" : "model"], { past_key_values: ye, ...Pe } = C;
        if (oe.inputNames.includes("use_cache_branch") && (Pe.use_cache_branch = K(!!ye)), oe.inputNames.includes("position_ids") && Pe.attention_mask && !Pe.position_ids) {
          const Je = ["paligemma", "gemma3_text", "gemma3"].includes(M.config.model_type) ? 1 : 0;
          Pe.position_ids = et(Pe, ye, Je);
        }
        M.addPastKeyValues(Pe, ye);
        const Ue = (0, u.pick)(Pe, oe.inputNames);
        return await Q(oe, Ue);
      }
      function _e({
        modality_token_id: M,
        inputs_embeds: C,
        modality_features: z,
        input_ids: oe,
        attention_mask: ye
      }) {
        const Pe = oe.tolist().map(
          (gt) => gt.reduce((wt, yt, ht) => (yt == M && wt.push(ht), wt), [])
        ), Ue = Pe.reduce((gt, wt) => gt + wt.length, 0), Je = z.dims[0];
        if (Ue !== Je)
          throw new Error(`Number of tokens and features do not match: tokens: ${Ue}, features ${Je}`);
        let st = 0;
        for (let gt = 0; gt < Pe.length; ++gt) {
          const wt = Pe[gt], yt = C[gt];
          for (let ht = 0; ht < wt.length; ++ht)
            yt[wt[ht]].data.set(z[st++].data);
        }
        return { inputs_embeds: C, attention_mask: ye };
      }
      function De({
        image_token_id: M,
        inputs_embeds: C,
        image_features: z,
        input_ids: oe,
        attention_mask: ye
      }) {
        return _e({
          modality_token_id: M,
          inputs_embeds: C,
          modality_features: z,
          input_ids: oe,
          attention_mask: ye
        });
      }
      function he({
        audio_token_id: M,
        inputs_embeds: C,
        audio_features: z,
        input_ids: oe,
        attention_mask: ye
      }) {
        return _e({
          modality_token_id: M,
          inputs_embeds: C,
          modality_features: z,
          input_ids: oe,
          attention_mask: ye
        });
      }
      async function Z(M, {
        // Generic parameters:
        encode_function: C,
        merge_function: z,
        modality_input_name: oe,
        modality_output_name: ye,
        // Produced by the tokenizer/processor:
        input_ids: Pe = null,
        attention_mask: Ue = null,
        // Used during generation:
        position_ids: Je = null,
        inputs_embeds: st = null,
        past_key_values: gt = null,
        // Generic generation parameters
        generation_config: wt = null,
        logits_processor: yt = null,
        // Additional parameters
        ...ht
      }) {
        const Ot = ht[oe];
        if (!st) {
          if (st = await M.encode_text({ input_ids: Pe, ...ht }), Ot && Pe.dims[1] !== 1) {
            const Ct = await C({
              // Pass the modality values under its expected key.
              // The caller knows whether this is audio or image.
              [oe]: Ot,
              ...ht
            });
            ({ inputs_embeds: st, attention_mask: Ue } = z({
              [ye]: Ct,
              inputs_embeds: st,
              input_ids: Pe,
              attention_mask: Ue
            }));
          } else if (gt && Ot && Pe.dims[1] === 1) {
            const Ct = Pe.dims[1], Ze = Object.values(gt)[0].dims.at(-2);
            Ue = (0, p.cat)([
              (0, p.ones)([Pe.dims[0], Ze]),
              Ue.slice(null, [Ue.dims[1] - Ct, Ue.dims[1]])
            ], 1);
          }
        }
        if (!Je && M.config.model_type === "qwen2_vl") {
          const { image_grid_thw: Ct, video_grid_thw: Ze } = ht;
          [Je] = M.get_rope_index(Pe, Ct, Ze, Ue);
        }
        return await Ge(M, {
          inputs_embeds: st,
          past_key_values: gt,
          attention_mask: Ue,
          position_ids: Je,
          generation_config: wt,
          logits_processor: yt
        }, !0);
      }
      async function me(M, C) {
        return await Z(M, {
          ...C,
          modality_input_name: "audio_values",
          modality_output_name: "audio_features",
          encode_function: M.encode_audio.bind(M),
          merge_function: M._merge_input_ids_with_audio_features.bind(M)
        });
      }
      async function we(M, C) {
        return await Z(M, {
          ...C,
          modality_input_name: "pixel_values",
          modality_output_name: "image_features",
          encode_function: M.encode_image.bind(M),
          merge_function: M._merge_input_ids_with_image_features.bind(M)
        });
      }
      function xe(M, C = 0) {
        const [z, oe] = M.dims, ye = M.data, Pe = new BigInt64Array(ye.length);
        for (let Ue = 0; Ue < z; ++Ue) {
          const Je = Ue * oe;
          let st = BigInt(C);
          for (let gt = 0; gt < oe; ++gt) {
            const wt = Je + gt;
            ye[wt] === 0n ? Pe[wt] = BigInt(1) : (Pe[wt] = st, st += ye[wt]);
          }
        }
        return { data: Pe, dims: M.dims };
      }
      function et(M, C = null, z = 0) {
        const { input_ids: oe, inputs_embeds: ye, attention_mask: Pe } = M, { data: Ue, dims: Je } = xe(Pe, z);
        let st = new p.Tensor("int64", Ue, Je);
        if (C) {
          const gt = -(oe ?? ye).dims.at(1);
          st = st.slice(null, [gt, null]);
        }
        return st;
      }
      function Ve(M, C, z, oe) {
        const ye = z.past_key_values ? Object.values(z.past_key_values)[0].dims.at(-2) : 0;
        if (!z.attention_mask) {
          let Pe;
          for (const Ue of ["input_ids", "inputs_embeds", "position_ids"])
            if (z[Ue]) {
              Pe = z[Ue].dims;
              break;
            }
          if (!Pe)
            throw new Error("attention_mask is not provided, and unable to infer its shape from model inputs.");
          z.attention_mask = (0, p.ones)([Pe[0], ye + Pe[1]]);
        }
        if (z.past_key_values) {
          const { input_ids: Pe, attention_mask: Ue } = z;
          Ue && Ue.dims[1] > Pe.dims[1] || ye < Pe.dims[1] && (z.input_ids = Pe.slice(null, [ye, null]));
        }
        return z;
      }
      function nt(M, C, z, oe) {
        return z.past_key_values && (C = C.map((ye) => [ye.at(-1)])), {
          ...z,
          decoder_input_ids: te(C)
        };
      }
      function Be(M, ...C) {
        return M.config.is_encoder_decoder ? nt(M, ...C) : Ve(M, ...C);
      }
      function ae(M, C, z, oe) {
        const ye = !!z.past_key_values;
        return oe.guidance_scale !== null && oe.guidance_scale > 1 && (ye ? z.input_ids = (0, p.cat)([
          z.input_ids,
          z.input_ids
        ], 0) : (z.input_ids = (0, p.cat)([
          z.input_ids,
          (0, p.full_like)(z.input_ids, BigInt(oe.pad_token_id))
        ], 0), z.attention_mask = (0, p.cat)([
          z.attention_mask,
          (0, p.full_like)(z.attention_mask, 0n)
        ], 0))), (ye || !z.pixel_values) && (z.pixel_values = (0, p.full)([0, 0, 3, 384, 384], 1)), ye && (z.images_seq_mask = new p.Tensor(
          "bool",
          new Array(0 + 1).fill(!0).fill(!1, 0, 1),
          [1, 0 + 1]
        ), z.images_emb_mask = new p.Tensor(
          "bool",
          new Array(0).fill(!1),
          [1, 1, 0]
        )), z;
      }
      class U extends c.Callable {
        /**
         * Creates a new instance of the `PreTrainedModel` class.
         * @param {import('./configs.js').PretrainedConfig} config The model configuration.
         * @param {Record<string, any>} sessions The inference sessions for the model.
         * @param {Record<string, Object>} configs Additional configuration files (e.g., generation_config.json).
         */
        constructor(z, oe, ye) {
          super();
          Ce(this, "main_input_name", "input_ids");
          Ce(this, "forward_params", ["input_ids", "attention_mask"]);
          this.config = z, this.sessions = oe, this.configs = ye;
          const Pe = I.get(this.constructor), Ue = A.get(Pe);
          switch (this.can_generate = !1, this._forward = null, this._prepare_inputs_for_generation = null, Ue) {
            case E.DecoderOnly:
              this.can_generate = !0, this._forward = Ge, this._prepare_inputs_for_generation = Ve;
              break;
            case E.Seq2Seq:
            case E.Vision2Seq:
            case E.Musicgen:
              this.can_generate = !0, this._forward = pe, this._prepare_inputs_for_generation = nt;
              break;
            case E.EncoderDecoder:
              this._forward = pe;
              break;
            case E.ImageTextToText:
              this.can_generate = !0, this._forward = we, this._prepare_inputs_for_generation = Be;
              break;
            case E.AudioTextToText:
              this.can_generate = !0, this._forward = me, this._prepare_inputs_for_generation = Be;
              break;
            case E.Phi3V:
            case E.ImageAudioTextToText:
              this.can_generate = !0, this._prepare_inputs_for_generation = Be;
              break;
            case E.MultiModality:
              this.can_generate = !0, this._prepare_inputs_for_generation = ae;
              break;
            case E.AutoEncoder:
              this._forward = Ee;
              break;
            default:
              this._forward = be;
              break;
          }
          this.can_generate && this.forward_params.push("past_key_values"), this.custom_config = this.config["transformers.js_config"] ?? {};
        }
        /**
        * Disposes of all the ONNX sessions that were created during inference.
        * @returns {Promise<unknown[]>} An array of promises, one for each ONNX session that is being disposed.
        * @todo Use https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry
        */
        async dispose() {
          var oe;
          const z = [];
          for (const ye of Object.values(this.sessions))
            (oe = ye == null ? void 0 : ye.handler) != null && oe.dispose && z.push(ye.handler.dispose());
          return await Promise.all(z);
        }
        /**
         * Instantiate one of the model classes of the library from a pretrained model.
         * 
         * The model class to instantiate is selected based on the `model_type` property of the config object
         * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
         * 
         * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
         * - A string, the *model id* of a pretrained model hosted inside a model repo on huggingface.co.
         *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
         *   user or organization name, like `dbmdz/bert-base-german-cased`.
         * - A path to a *directory* containing model weights, e.g., `./my_model_directory/`.
         * @param {import('./utils/hub.js').PretrainedModelOptions} options Additional options for loading the model.
         * 
         * @returns {Promise<PreTrainedModel>} A new instance of the `PreTrainedModel` class.
         */
        static async from_pretrained(z, {
          progress_callback: oe = null,
          config: ye = null,
          cache_dir: Pe = null,
          local_files_only: Ue = !1,
          revision: Je = "main",
          model_file_name: st = null,
          subfolder: gt = "onnx",
          device: wt = null,
          dtype: yt = null,
          use_external_data_format: ht = null,
          session_options: Ot = {}
        } = {}) {
          let xt = {
            progress_callback: oe,
            config: ye,
            cache_dir: Pe,
            local_files_only: Ue,
            revision: Je,
            model_file_name: st,
            subfolder: gt,
            device: wt,
            dtype: yt,
            use_external_data_format: ht,
            session_options: Ot
          };
          const Ct = I.get(this), Ze = A.get(Ct);
          ye = xt.config = await i.AutoConfig.from_pretrained(z, xt);
          let ft;
          if (Ze === E.DecoderOnly)
            ft = await Promise.all([
              N(z, {
                model: xt.model_file_name ?? "model"
              }, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          else if (Ze === E.Seq2Seq || Ze === E.Vision2Seq)
            ft = await Promise.all([
              N(z, {
                model: "encoder_model",
                decoder_model_merged: "decoder_model_merged"
              }, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          else if (Ze === E.MaskGeneration)
            ft = await Promise.all([
              N(z, {
                model: "vision_encoder",
                prompt_encoder_mask_decoder: "prompt_encoder_mask_decoder"
              }, xt)
            ]);
          else if (Ze === E.EncoderDecoder)
            ft = await Promise.all([
              N(z, {
                model: "encoder_model",
                decoder_model_merged: "decoder_model_merged"
              }, xt)
            ]);
          else if (Ze === E.ImageTextToText) {
            const St = {
              embed_tokens: "embed_tokens",
              vision_encoder: "vision_encoder",
              decoder_model_merged: "decoder_model_merged"
            };
            ye.is_encoder_decoder && (St.model = "encoder_model"), ft = await Promise.all([
              N(z, St, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          } else if (Ze === E.AudioTextToText) {
            const St = {
              embed_tokens: "embed_tokens",
              audio_encoder: "audio_encoder",
              decoder_model_merged: "decoder_model_merged"
            };
            ft = await Promise.all([
              N(z, St, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          } else if (Ze === E.ImageAudioTextToText) {
            const St = {
              embed_tokens: "embed_tokens",
              audio_encoder: "audio_encoder",
              vision_encoder: "vision_encoder",
              decoder_model_merged: "decoder_model_merged"
            };
            ft = await Promise.all([
              N(z, St, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          } else if (Ze === E.Musicgen)
            ft = await Promise.all([
              N(z, {
                model: "text_encoder",
                decoder_model_merged: "decoder_model_merged",
                encodec_decode: "encodec_decode"
              }, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          else if (Ze === E.MultiModality)
            ft = await Promise.all([
              N(z, {
                prepare_inputs_embeds: "prepare_inputs_embeds",
                model: "language_model",
                lm_head: "lm_head",
                gen_head: "gen_head",
                gen_img_embeds: "gen_img_embeds",
                image_decode: "image_decode"
              }, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          else if (Ze === E.Phi3V)
            ft = await Promise.all([
              N(z, {
                prepare_inputs_embeds: "prepare_inputs_embeds",
                model: "model",
                vision_encoder: "vision_encoder"
              }, xt),
              q(z, {
                generation_config: "generation_config.json"
              }, xt)
            ]);
          else if (Ze === E.AutoEncoder)
            ft = await Promise.all([
              N(z, {
                encoder_model: "encoder_model",
                decoder_model: "decoder_model"
              }, xt)
            ]);
          else if (Ze === E.Supertonic)
            ft = await Promise.all([
              N(z, {
                text_encoder: "text_encoder",
                latent_denoiser: "latent_denoiser",
                voice_decoder: "voice_decoder"
              }, xt)
            ]);
          else {
            if (Ze !== E.EncoderOnly) {
              const St = Ct ?? (ye == null ? void 0 : ye.model_type);
              St !== "custom" && console.warn(`Model type for '${St}' not found, assuming encoder-only architecture. Please report this at ${f.GITHUB_ISSUE_URL}.`);
            }
            ft = await Promise.all([
              N(z, {
                model: xt.model_file_name ?? "model"
              }, xt)
            ]);
          }
          return new this(ye, ...ft);
        }
        /**
         * Runs the model with the provided inputs
         * @param {Object} model_inputs Object containing input tensors
         * @returns {Promise<Object>} Object containing output tensors
         */
        async _call(z) {
          return await this.forward(z);
        }
        /**
         * Forward method for a pretrained model. If not overridden by a subclass, the correct forward method
         * will be chosen based on the model type.
         * @param {Object} model_inputs The input data to the model in the format specified in the ONNX model.
         * @returns {Promise<Object>} The output data from the model in the format specified in the ONNX model.
         * @throws {Error} This method must be implemented in subclasses.
         */
        async forward(z) {
          return await this._forward(this, z);
        }
        /**
         * Get the model's generation config, if it exists.
         * @returns {GenerationConfig|null} The model's generation config if it exists, otherwise `null`.
         */
        get generation_config() {
          var z;
          return ((z = this.configs) == null ? void 0 : z.generation_config) ?? null;
        }
        /**
         * @param {GenerationConfig} generation_config 
         * @param {number} input_ids_seq_length The starting sequence length for the input ids.
         * @returns {LogitsProcessorList}
         * @private
         */
        _get_logits_processor(z, oe, ye = null) {
          const Pe = new m.LogitsProcessorList();
          if (z.repetition_penalty !== null && z.repetition_penalty !== 1 && Pe.push(new m.RepetitionPenaltyLogitsProcessor(z.repetition_penalty)), z.no_repeat_ngram_size !== null && z.no_repeat_ngram_size > 0 && Pe.push(new m.NoRepeatNGramLogitsProcessor(z.no_repeat_ngram_size)), z.bad_words_ids !== null && Pe.push(new m.NoBadWordsLogitsProcessor(z.bad_words_ids, z.eos_token_id)), z.min_length !== null && z.eos_token_id !== null && z.min_length > 0 && Pe.push(new m.MinLengthLogitsProcessor(z.min_length, z.eos_token_id)), z.min_new_tokens !== null && z.eos_token_id !== null && z.min_new_tokens > 0 && Pe.push(new m.MinNewTokensLengthLogitsProcessor(
            oe,
            z.min_new_tokens,
            z.eos_token_id
          )), z.forced_bos_token_id !== null && Pe.push(new m.ForcedBOSTokenLogitsProcessor(z.forced_bos_token_id)), z.forced_eos_token_id !== null && Pe.push(new m.ForcedEOSTokenLogitsProcessor(
            z.max_length,
            z.forced_eos_token_id
          )), z.begin_suppress_tokens !== null) {
            const Ue = oe > 1 || z.forced_bos_token_id === null ? oe : oe + 1;
            Pe.push(new m.SuppressTokensAtBeginLogitsProcessor(z.begin_suppress_tokens, Ue));
          }
          return z.guidance_scale !== null && z.guidance_scale > 1 && Pe.push(new m.ClassifierFreeGuidanceLogitsProcessor(z.guidance_scale)), z.temperature === 0 && z.do_sample && (console.warn("`do_sample` changed to false because `temperature: 0` implies greedy sampling (always selecting the most likely token), which is incompatible with `do_sample: true`."), z.do_sample = !1), z.do_sample && z.temperature !== null && z.temperature !== 1 && Pe.push(new m.TemperatureLogitsWarper(z.temperature)), ye !== null && Pe.extend(ye), Pe;
        }
        /**
         * This function merges multiple generation configs together to form a final generation config to be used by the model for text generation.
         * It first creates an empty `GenerationConfig` object, then it applies the model's own `generation_config` property to it. Finally, if a `generation_config` object was passed in the arguments, it overwrites the corresponding properties in the final config with those of the passed config object.
         * @param {GenerationConfig|null} generation_config A `GenerationConfig` object containing generation parameters.
         * @param {Object} kwargs Additional generation parameters to be used in place of those in the `generation_config` object.
         * @returns {GenerationConfig} The final generation config object to be used by the model for text generation.
         */
        _prepare_generation_config(z, oe, ye = h.GenerationConfig) {
          const Pe = { ...this.config };
          for (const Je of ["decoder", "generator", "text_config"])
            Je in Pe && Object.assign(Pe, Pe[Je]);
          const Ue = new ye(Pe);
          return Object.assign(Ue, this.generation_config ?? {}), z && Object.assign(Ue, z), oe && Object.assign(Ue, (0, u.pick)(oe, Object.getOwnPropertyNames(Ue))), Ue;
        }
        /**
         * 
         * @param {GenerationConfig} generation_config 
         * @param {StoppingCriteriaList} [stopping_criteria=null] 
         */
        _get_stopping_criteria(z, oe = null) {
          const ye = new S.StoppingCriteriaList();
          return z.max_length !== null && ye.push(new S.MaxLengthCriteria(
            z.max_length,
            this.config.max_position_embeddings ?? null
          )), z.eos_token_id !== null && ye.push(new S.EosTokenCriteria(z.eos_token_id)), oe && ye.extend(oe), ye;
        }
        /**
         * Confirms that the model class is compatible with generation.
         * If not, raises an exception that points to the right class to use.
         */
        _validate_model_class() {
          if (!this.can_generate) {
            const z = [
              qr,
              // MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING, // TODO
              mc,
              pc,
              fc
            ], oe = I.get(this.constructor), ye = /* @__PURE__ */ new Set(), Pe = this.config.model_type;
            for (const Je of z) {
              const st = Je.get(Pe);
              st && ye.add(st[0]);
            }
            let Ue = `The current model class (${oe}) is not compatible with \`.generate()\`, as it doesn't have a language model head.`;
            throw ye.size > 0 && (Ue += ` Please use the following class instead: ${[...ye].join(", ")}`), Error(Ue);
          }
        }
        prepare_inputs_for_generation(...z) {
          return this._prepare_inputs_for_generation(this, ...z);
        }
        /**
         * 
         * @param {Object} inputs
         * @param {bigint[][]} inputs.generated_input_ids
         * @param {Object} inputs.outputs
         * @param {Object} inputs.model_inputs
         * @param {boolean} inputs.is_encoder_decoder
         * @returns {Object} The updated model inputs for the next generation iteration.
         */
        _update_model_kwargs_for_generation({ generated_input_ids: z, outputs: oe, model_inputs: ye, is_encoder_decoder: Pe }) {
          return ye.past_key_values = this.getPastKeyValues(oe, ye.past_key_values), ye.input_ids = new p.Tensor("int64", z.flat(), [z.length, 1]), Pe || (ye.attention_mask = (0, p.cat)(
            [
              ye.attention_mask,
              (0, p.ones)([ye.attention_mask.dims[0], 1])
            ],
            1
          )), ye.position_ids = null, ye;
        }
        /**
         * This function extracts the model-specific `inputs` for generation.
         * @param {Object} params
         * @param {Tensor} [params.inputs=null]
         * @param {number} [params.bos_token_id=null]
         * @param {Record<string, Tensor|number[]>} [params.model_kwargs]
         * @returns {{inputs_tensor: Tensor, model_inputs: Record<string, Tensor>, model_input_name: string}} The model-specific inputs for generation.
         */
        _prepare_model_inputs({ inputs: z, bos_token_id: oe, model_kwargs: ye }) {
          const Pe = (0, u.pick)(ye, this.forward_params), Ue = this.main_input_name;
          if (Ue in Pe) {
            if (z)
              throw new Error(
                "`inputs`: {inputs}` were passed alongside {input_name} which is not allowed. Make sure to either pass {inputs} or {input_name}=..."
              );
          } else
            Pe[Ue] = z;
          return { inputs_tensor: Pe[Ue], model_inputs: Pe, model_input_name: Ue };
        }
        async _prepare_encoder_decoder_kwargs_for_generation({ inputs_tensor: z, model_inputs: oe, model_input_name: ye, generation_config: Pe }) {
          if (this.sessions.model.inputNames.includes("inputs_embeds") && !oe.inputs_embeds && "_prepare_inputs_embeds" in this) {
            const { input_ids: Je, pixel_values: st, attention_mask: gt, ...wt } = oe, yt = await this._prepare_inputs_embeds(oe);
            oe = {
              ...wt,
              ...(0, u.pick)(yt, ["inputs_embeds", "attention_mask"])
            };
          }
          let { last_hidden_state: Ue } = await be(this, oe);
          if (Pe.guidance_scale !== null && Pe.guidance_scale > 1)
            Ue = (0, p.cat)([
              Ue,
              (0, p.full_like)(Ue, 0)
            ], 0), "attention_mask" in oe && (oe.attention_mask = (0, p.cat)([
              oe.attention_mask,
              (0, p.zeros_like)(oe.attention_mask)
            ], 0));
          else if (oe.decoder_input_ids) {
            const Je = te(oe.decoder_input_ids).dims[0];
            if (Je !== Ue.dims[0]) {
              if (Ue.dims[0] !== 1)
                throw new Error(
                  `The encoder outputs have a different batch size (${Ue.dims[0]}) than the decoder inputs (${Je}).`
                );
              Ue = (0, p.cat)(Array.from({ length: Je }, () => Ue), 0);
            }
          }
          return oe.encoder_outputs = Ue, oe;
        }
        /**
         * Prepares `decoder_input_ids` for generation with encoder-decoder models
         * @param {*} param0 
         */
        _prepare_decoder_input_ids_for_generation({ batch_size: z, model_input_name: oe, model_kwargs: ye, decoder_start_token_id: Pe, bos_token_id: Ue, generation_config: Je }) {
          let { decoder_input_ids: st, ...gt } = ye;
          if (!(st instanceof p.Tensor)) {
            if (st)
              Array.isArray(st[0]) || (st = Array.from({
                length: z
              }, () => st));
            else if (Pe ?? (Pe = Ue), this.config.model_type === "musicgen")
              st = Array.from({
                // @ts-expect-error TS2339
                length: z * this.config.decoder.num_codebooks
              }, () => [Pe]);
            else if (Array.isArray(Pe)) {
              if (Pe.length !== z)
                throw new Error(
                  `\`decoder_start_token_id\` expcted to have length ${z} but got ${Pe.length}`
                );
              st = Pe;
            } else
              st = Array.from({
                length: z
              }, () => [Pe]);
            st = te(st);
          }
          return ye.decoder_attention_mask = (0, p.ones_like)(st), { input_ids: st, model_inputs: gt };
        }
        /**
         * Generates sequences of token ids for models with a language modeling head.
         * @param {import('./generation/parameters.js').GenerationFunctionParameters} options
         * @returns {Promise<ModelOutput|Tensor>} The output of the model, which can contain the generated token ids, attentions, and scores.
         */
        async generate({
          inputs: z = null,
          generation_config: oe = null,
          logits_processor: ye = null,
          stopping_criteria: Pe = null,
          streamer: Ue = null,
          // inputs_attention_mask = null,
          ...Je
        }) {
          this._validate_model_class(), oe = this._prepare_generation_config(oe, Je);
          let { inputs_tensor: st, model_inputs: gt, model_input_name: wt } = this._prepare_model_inputs({
            inputs: z,
            model_kwargs: Je
          });
          const yt = this.config.is_encoder_decoder;
          yt && ("encoder_outputs" in gt || (gt = await this._prepare_encoder_decoder_kwargs_for_generation(
            { inputs_tensor: st, model_inputs: gt, model_input_name: wt, generation_config: oe }
          )));
          let ht;
          yt ? { input_ids: ht, model_inputs: gt } = this._prepare_decoder_input_ids_for_generation({
            batch_size: gt[wt].dims.at(0),
            model_input_name: wt,
            model_kwargs: gt,
            decoder_start_token_id: oe.decoder_start_token_id,
            bos_token_id: oe.bos_token_id,
            generation_config: oe
          }) : ht = gt[wt];
          let Ot = ht.dims.at(-1);
          oe.max_new_tokens !== null && (oe.max_length = Ot + oe.max_new_tokens);
          const xt = this._get_logits_processor(
            oe,
            Ot,
            ye
          ), Ct = this._get_stopping_criteria(
            oe,
            Pe
          ), Ze = gt[wt].dims.at(0), ft = D.LogitsSampler.getSampler(oe), St = new Array(Ze).fill(0), Ht = ht.tolist();
          Ue && Ue.put(Ht);
          let cn, Sn = {};
          for (; ; ) {
            if (gt = this.prepare_inputs_for_generation(Ht, gt, oe), cn = await this.forward(gt), oe.output_attentions && oe.return_dict_in_generate) {
              const qn = this.getAttentions(cn);
              for (const Hi in qn)
                Hi in Sn || (Sn[Hi] = []), Sn[Hi].push(qn[Hi]);
            }
            const Zt = cn.logits.slice(null, -1, null), $n = xt(Ht, Zt), Pn = [];
            for (let qn = 0; qn < $n.dims.at(0); ++qn) {
              const Hi = $n[qn], Cc = await ft(Hi);
              for (const [ta, Zg] of Cc) {
                const e_ = BigInt(ta);
                St[qn] += Zg, Ht[qn].push(e_), Pn.push([e_]);
                break;
              }
            }
            if (Ue && Ue.put(Pn), Ct(Ht).every((qn) => qn))
              break;
            gt = this._update_model_kwargs_for_generation({
              generated_input_ids: Pn,
              outputs: cn,
              model_inputs: gt,
              is_encoder_decoder: yt
            });
          }
          Ue && Ue.end();
          const Hn = this.getPastKeyValues(cn, gt.past_key_values, !0), kn = new p.Tensor("int64", Ht.flat(), [Ht.length, Ht[0].length]);
          if (oe.return_dict_in_generate)
            return {
              sequences: kn,
              past_key_values: Hn,
              ...Sn
              // TODO:
              // scores,
              // logits,
            };
          for (const Zt of Object.values(cn))
            Zt.location === "gpu-buffer" && Zt.dispose();
          return kn;
        }
        /**
         * Returns an object containing past key values from the given decoder results object.
         *
         * @param {Object} decoderResults The decoder results object.
         * @param {Object} pastKeyValues The previous past key values.
         * @returns {Object} An object containing past key values.
         */
        getPastKeyValues(z, oe, ye = !1) {
          const Pe = /* @__PURE__ */ Object.create(null);
          for (const Ue in z)
            if (Ue.startsWith("present")) {
              const Je = Ue.replace("present_conv", "past_conv").replace("present", "past_key_values"), st = Ue.includes("encoder");
              if (st && oe ? Pe[Je] = oe[Je] : Pe[Je] = z[Ue], oe && (!st || ye)) {
                const gt = oe[Je];
                gt.location === "gpu-buffer" && gt.dispose();
              }
            }
          return Pe;
        }
        /**
         * Returns an object containing attentions from the given model output object.
         *
         * @param {Object} model_output The output of the model.
         * @returns {{cross_attentions?: Tensor[]}} An object containing attentions.
         */
        getAttentions(z) {
          const oe = {};
          for (const ye of ["cross_attentions", "encoder_attentions", "decoder_attentions"])
            for (const Pe in z)
              Pe.startsWith(ye) && (ye in oe || (oe[ye] = []), oe[ye].push(z[Pe]));
          return oe;
        }
        /**
         * Adds past key values to the decoder feeds object. If pastKeyValues is null, creates new tensors for past key values.
         *
         * @param {Object} decoderFeeds The decoder feeds object to add past key values to.
         * @param {Object} pastKeyValues An object containing past key values.
         */
        addPastKeyValues(z, oe) {
          var ye, Pe, Ue;
          if (oe)
            Object.assign(z, oe);
          else {
            const Je = this.sessions.decoder_model_merged ?? this.sessions.model, st = ((Pe = (ye = z[this.main_input_name] ?? z.attention_mask) == null ? void 0 : ye.dims) == null ? void 0 : Pe[0]) ?? 1, gt = ((Ue = Je == null ? void 0 : Je.config) == null ? void 0 : Ue.kv_cache_dtype) ?? "float32", wt = gt === "float16" ? p.DataTypeMap.float16 : p.DataTypeMap.float32, yt = (0, i.getCacheShapes)(this.config, { batch_size: st });
            for (const ht in yt) {
              const Ot = yt[ht].reduce((xt, Ct) => xt * Ct, 1);
              z[ht] = new p.Tensor(gt, new wt(Ot), yt[ht]);
            }
          }
        }
        async encode_image({ pixel_values: z }) {
          return (await Q(this.sessions.vision_encoder, { pixel_values: z })).image_features;
        }
        async encode_text({ input_ids: z }) {
          return (await Q(this.sessions.embed_tokens, { input_ids: z })).inputs_embeds;
        }
        async encode_audio({ audio_values: z }) {
          return (await Q(this.sessions.audio_encoder, { audio_values: z })).audio_features;
        }
      }
      class Se {
      }
      class ze extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.last_hidden_state Sequence of hidden-states at the output of the last layer of the model.
         * @param {Tensor} [output.hidden_states] Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.
         * @param {Tensor} [output.attentions] Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.
         */
        constructor({ last_hidden_state: C, hidden_states: z = null, attentions: oe = null }) {
          super(), this.last_hidden_state = C, this.hidden_states = z, this.attentions = oe;
        }
      }
      class Oe extends U {
      }
      class Ye extends Oe {
      }
      class H extends Oe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Y extends Oe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class $e extends Oe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Ie extends Oe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class fe extends U {
      }
      class Qe extends fe {
      }
      class Ne extends fe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class ut extends fe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class de extends fe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class qe extends fe {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class tt extends U {
      }
      class He extends tt {
      }
      class je extends tt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class lt extends tt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Mt extends tt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Rt extends U {
      }
      class Kt extends Rt {
      }
      class vn extends Rt {
      }
      class wn extends U {
      }
      class ln extends wn {
      }
      class Gn extends U {
      }
      class li extends Gn {
      }
      class Yi extends Gn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class $i extends Gn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class An extends Gn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class bn extends Gn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class Si extends U {
      }
      class ds extends Si {
      }
      class qt extends Si {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Me extends Si {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class at extends Si {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class rt extends Si {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class mt extends U {
      }
      class _t extends mt {
      }
      class on extends mt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class B extends mt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class le extends mt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class J extends mt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class se extends U {
      }
      class ge extends se {
      }
      class Fe extends se {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Ke extends se {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class pt extends se {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Pt extends se {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class Tt extends U {
      }
      class en extends Tt {
      }
      class Dt extends Tt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class tn extends Tt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Vt extends Tt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class nn extends Tt {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class Mn extends U {
      }
      class vi extends Mn {
      }
      class ci extends Mn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class ki extends Mn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class fi extends Mn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Pi extends Mn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class wi extends U {
      }
      class hs extends wi {
      }
      class fs extends wi {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Ps extends wi {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Oi extends wi {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class jt extends wi {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} returned object
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Ni extends U {
      }
      class Ws extends Ni {
      }
      class As extends Ni {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Cs extends Ni {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Is extends Ni {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Ji extends U {
      }
      class pi extends Ji {
      }
      class bt extends Ji {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} returned object
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class ct extends Ji {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} returned object
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Lt extends Ji {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} returned object
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class yn extends U {
      }
      class Ui extends yn {
      }
      class it extends yn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} An object containing the model's output logits for masked language modeling.
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class ps extends yn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Br extends yn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Xe extends yn {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} An object containing the model's output logits for question answering.
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class j extends U {
      }
      class ie extends j {
      }
      class Ae extends j {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} returned object
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Re extends j {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} returned object
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class We extends j {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} returned object
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class ot extends U {
      }
      class Et extends ot {
      }
      class It extends ot {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} returned object
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class At extends ot {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} returned object
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class kt extends ot {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} returned object
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Xt extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            "input_ids",
            "attention_mask",
            "encoder_outputs",
            "decoder_input_ids",
            "decoder_attention_mask",
            "past_key_values"
          ]);
        }
      }
      class fn extends Xt {
      }
      class _n extends Xt {
      }
      class Rn extends U {
      }
      class En extends Rn {
      }
      class Un extends Rn {
      }
      class ui extends U {
      }
      class xi extends ui {
      }
      class ms extends ui {
      }
      class ei extends U {
      }
      class gs extends ei {
      }
      class Cn extends ei {
      }
      class Vn extends ei {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class ii extends U {
      }
      class Qi extends ii {
      }
      class Zi extends ii {
      }
      class si extends ii {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class es extends ii {
      }
      class Yn extends U {
      }
      class jn extends Yn {
      }
      class Wn extends Yn {
      }
      class Yt extends U {
      }
      class pn extends Yt {
      }
      class ts extends Yt {
      }
      class ns extends U {
      }
      class Jn extends ns {
      }
      class di extends ns {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} returned object
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Ut extends ns {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} returned object
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Dn extends ns {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Ta extends ns {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} returned object
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class is extends U {
      }
      class Ls extends is {
      }
      class Nt extends is {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} returned object
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class zr extends is {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} returned object
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class dt extends is {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class $t extends is {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} returned object
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class gr extends U {
      }
      class Ea extends gr {
      }
      class Iu extends gr {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<MaskedLMOutput>} returned object
         */
        async _call(C) {
          return new re(await super._call(C));
        }
      }
      class Lu extends gr {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} returned object
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class sn extends gr {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for token classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Du extends gr {
        /**
         * Calls the model on new inputs.
         *
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<QuestionAnsweringModelOutput>} returned object
         */
        async _call(C) {
          return new Te(await super._call(C));
        }
      }
      class vo extends U {
      }
      class ku extends vo {
      }
      class Ou extends vo {
      }
      class Sa extends U {
        constructor() {
          super(...arguments);
          Ce(this, "requires_attention_mask", !1);
          Ce(this, "main_input_name", "input_features");
          Ce(this, "forward_params", [
            "input_features",
            "attention_mask",
            "decoder_input_ids",
            "decoder_attention_mask",
            "past_key_values"
          ]);
        }
      }
      class Fu extends Sa {
      }
      class bi extends Sa {
        _prepare_generation_config(C, z) {
          return (
            /** @type {WhisperGenerationConfig} */
            super._prepare_generation_config(C, z, T.WhisperGenerationConfig)
          );
        }
        /**
         * 
         * @param {WhisperGenerationConfig} generation_config 
         */
        _retrieve_init_tokens(C) {
          const z = [C.decoder_start_token_id];
          let oe = C.language;
          const ye = C.task;
          if (C.is_multilingual) {
            oe || (console.warn("No language specified - defaulting to English (en)."), oe = "en");
            const Ue = `<|${(0, F.whisper_language_to_code)(oe)}|>`;
            z.push(C.lang_to_id[Ue]), z.push(C.task_to_id[ye ?? "transcribe"]);
          } else if (oe || ye)
            throw new Error(
              "Cannot specify `task` or `language` for an English-only model. If the model is intended to be multilingual, pass `is_multilingual=true` to generate, or update the generation config."
            );
          return !C.return_timestamps && C.no_timestamps_token_id && z.at(-1) !== C.no_timestamps_token_id ? z.push(C.no_timestamps_token_id) : C.return_timestamps && z.at(-1) === C.no_timestamps_token_id && (console.warn("<|notimestamps|> prompt token is removed from generation_config since `return_timestamps` is set to `true`."), z.pop()), z.filter((Pe) => Pe != null);
        }
        /**
         * Transcribes or translates log-mel input features to a sequence of auto-regressively generated token ids.
         * @param {import('./models/whisper/generation_whisper.js').WhisperGenerationFunctionParameters} options
         * @returns {Promise<ModelOutput|Tensor>} The output of the model, which can contain the generated token ids, attentions, and scores.
         */
        async generate({
          inputs: C = null,
          generation_config: z = null,
          logits_processor: oe = null,
          stopping_criteria: ye = null,
          // Whisper-specific options (passed to kwargs)
          // prompt_ids = null,
          // language = null,
          // task = null,
          ...Pe
        }) {
          z = this._prepare_generation_config(z, Pe);
          const Ue = Pe.decoder_input_ids ?? this._retrieve_init_tokens(z);
          if (z.return_timestamps && (oe ?? (oe = new m.LogitsProcessorList()), oe.push(
            new m.WhisperTimeStampLogitsProcessor(z, Ue)
          )), z.begin_suppress_tokens && (oe ?? (oe = new m.LogitsProcessorList()), oe.push(
            new m.SuppressTokensAtBeginLogitsProcessor(z.begin_suppress_tokens, Ue.length)
          )), z.return_token_timestamps) {
            if (!z.alignment_heads)
              throw new Error(
                "Model generation config has no `alignment_heads`, token-level timestamps not available. See https://gist.github.com/hollance/42e32852f24243b748ae6bc1f985b13a on how to add this property to the generation config."
              );
            z.task === "translate" && console.warn("Token-level timestamps may not be reliable for task 'translate'."), z.output_attentions = !0, z.return_dict_in_generate = !0;
          }
          const Je = await super.generate({
            inputs: C,
            generation_config: z,
            logits_processor: oe,
            decoder_input_ids: Ue,
            ...Pe
          });
          return z.return_token_timestamps && (Je.token_timestamps = this._extract_token_timestamps(
            // @ts-expect-error TS2345
            Je,
            z.alignment_heads,
            z.num_frames
          )), Je;
        }
        /**
         * Calculates token-level timestamps using the encoder-decoder cross-attentions and
         * dynamic time-warping (DTW) to map each output token to a position in the input audio.
         * If `num_frames` is specified, the encoder-decoder cross-attentions will be cropped before applying DTW.
         * @param {Object} generate_outputs Outputs generated by the model
         * @param {Tensor[][]} generate_outputs.cross_attentions The cross attentions output by the model
         * @param {Tensor} generate_outputs.sequences The sequences output by the model
         * @param {number[][]} alignment_heads Alignment heads of the model
         * @param {number} [num_frames=null] Number of frames in the input audio.
         * @param {number} [time_precision=0.02] Precision of the timestamps in seconds
         * @returns {Tensor} tensor containing the timestamps in seconds for each predicted token
         */
        _extract_token_timestamps(C, z, oe = null, ye = 0.02) {
          if (!C.cross_attentions)
            throw new Error(
              "Model outputs must contain cross attentions to extract timestamps. This is most likely because the model was not exported with `output_attentions=True`."
            );
          oe == null && console.warn(
            "`num_frames` has not been set, meaning the entire audio will be analyzed. This may lead to inaccurate token-level timestamps for short audios (< 30 seconds)."
          );
          let Pe = this.config.median_filter_width;
          Pe === void 0 && (console.warn("Model config has no `median_filter_width`, using default value of 7."), Pe = 7);
          const Ue = C.cross_attentions, Je = Array.from(
            { length: this.config.decoder_layers },
            // Concatenate the cross attentions for each layer across sequence length dimension.
            (Ct, Ze) => (0, p.cat)(Ue.map((ft) => ft[Ze]), 2)
          ), st = (0, p.stack)(z.map(([Ct, Ze]) => {
            if (Ct >= Je.length)
              throw new Error(`Layer index ${Ct} is out of bounds for cross attentions (length ${Je.length}).`);
            return oe ? Je[Ct].slice(null, Ze, null, [0, oe]) : Je[Ct].slice(null, Ze);
          })).transpose(1, 0, 2, 3), [gt, wt] = (0, p.std_mean)(st, -2, 0, !0), yt = st.clone();
          for (let Ct = 0; Ct < yt.dims[0]; ++Ct) {
            const Ze = yt[Ct];
            for (let ft = 0; ft < Ze.dims[0]; ++ft) {
              const St = Ze[ft], Ht = gt[Ct][ft][0].data, cn = wt[Ct][ft][0].data;
              for (let Sn = 0; Sn < St.dims[0]; ++Sn) {
                let Hn = St[Sn].data;
                for (let kn = 0; kn < Hn.length; ++kn)
                  Hn[kn] = (Hn[kn] - cn[kn]) / Ht[kn];
                Hn.set((0, v.medianFilter)(Hn, Pe));
              }
            }
          }
          const ht = [(0, p.mean)(yt, 1)], Ot = C.sequences.dims, xt = new p.Tensor(
            "float32",
            new Float32Array(Ot[0] * Ot[1]),
            Ot
          );
          for (let Ct = 0; Ct < Ot[0]; ++Ct) {
            const Ze = ht[Ct].neg().squeeze_(0), [ft, St] = (0, v.dynamic_time_warping)(Ze.tolist()), Ht = Array.from({ length: ft.length - 1 }, (Hn, kn) => ft[kn + 1] - ft[kn]), cn = (0, u.mergeArrays)([1], Ht).map((Hn) => !!Hn), Sn = [];
            for (let Hn = 0; Hn < cn.length; ++Hn)
              cn[Hn] && Sn.push(St[Hn] * ye);
            xt[Ct].data.set(Sn, 1);
          }
          return xt;
        }
      }
      class Ru extends bi {
      }
      class Pa extends U {
        constructor() {
          super(...arguments);
          Ce(this, "requires_attention_mask", !1);
          Ce(this, "main_input_name", "input_values");
          Ce(this, "forward_params", [
            "input_values",
            "decoder_input_ids",
            "past_key_values"
          ]);
        }
      }
      class Hs extends Pa {
      }
      class Bu extends Pa {
      }
      class Aa extends U {
        constructor() {
          super(...arguments);
          Ce(this, "main_input_name", "pixel_values");
          Ce(this, "forward_params", [
            // Encoder inputs
            "pixel_values",
            // Decoder inpputs
            "decoder_input_ids",
            "encoder_hidden_states",
            "past_key_values"
          ]);
        }
      }
      class Ca extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            "input_ids",
            "attention_mask",
            "pixel_values",
            "position_ids",
            "past_key_values"
          ]);
        }
      }
      class wo extends Ca {
        _merge_input_ids_with_image_features(C) {
          const z = C.image_features.dims.at(-1), oe = C.image_features.view(-1, z);
          return De({
            // @ts-ignore
            image_token_id: this.config.image_token_index,
            ...C,
            image_features: oe
          });
        }
      }
      class zu extends wo {
      }
      class $u extends wo {
      }
      class Nu extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            // Encoder inputs
            "input_ids",
            "inputs_embeds",
            "attention_mask",
            "pixel_values",
            // Decoder inputs
            "encoder_outputs",
            "decoder_input_ids",
            "decoder_inputs_embeds",
            "decoder_attention_mask",
            "past_key_values"
          ]);
          Ce(this, "main_input_name", "inputs_embeds");
        }
      }
      class Uu extends Nu {
        _merge_input_ids_with_image_features({
          inputs_embeds: C,
          image_features: z,
          input_ids: oe,
          attention_mask: ye
        }) {
          return {
            inputs_embeds: (0, p.cat)([
              z,
              // image embeds
              C
              // task prefix embeds
            ], 1),
            attention_mask: (0, p.cat)([
              (0, p.ones)(z.dims.slice(0, 2)),
              // image attention mask
              ye
              // task prefix attention mask
            ], 1)
          };
        }
        async _prepare_inputs_embeds({ input_ids: C, pixel_values: z, inputs_embeds: oe, attention_mask: ye }) {
          if (!C && !z)
            throw new Error("Either `input_ids` or `pixel_values` should be provided.");
          let Pe, Ue;
          return C && (Pe = await this.encode_text({ input_ids: C })), z && (Ue = await this.encode_image({ pixel_values: z })), Pe && Ue ? { inputs_embeds: oe, attention_mask: ye } = this._merge_input_ids_with_image_features({
            inputs_embeds: Pe,
            image_features: Ue,
            input_ids: C,
            attention_mask: ye
          }) : oe = Pe || Ue, { inputs_embeds: oe, attention_mask: ye };
        }
        async forward({
          input_ids: C,
          pixel_values: z,
          attention_mask: oe,
          decoder_input_ids: ye,
          decoder_attention_mask: Pe,
          encoder_outputs: Ue,
          past_key_values: Je,
          inputs_embeds: st,
          decoder_inputs_embeds: gt
        }) {
          if (st || ({ inputs_embeds: st, attention_mask: oe } = await this._prepare_inputs_embeds({ input_ids: C, pixel_values: z, inputs_embeds: st, attention_mask: oe })), !Ue) {
            let { last_hidden_state: ht } = await be(this, { inputs_embeds: st, attention_mask: oe });
            Ue = ht;
          }
          if (!gt) {
            if (!ye)
              throw new Error("Either `decoder_input_ids` or `decoder_inputs_embeds` should be provided.");
            gt = await this.encode_text({ input_ids: ye });
          }
          return await Ge(this, {
            inputs_embeds: gt,
            attention_mask: Pe,
            encoder_attention_mask: oe,
            encoder_hidden_states: Ue,
            past_key_values: Je
          }, !0);
        }
      }
      class Gu extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            "input_ids",
            // 'inputs_embeds',
            "attention_mask",
            "pixel_values",
            "position_ids",
            "past_key_values"
          ]);
        }
      }
      class Vu extends Gu {
        _merge_input_ids_with_image_features(C) {
          const z = C.image_features.dims.at(-1), oe = C.image_features.view(-1, z);
          return De({
            // @ts-ignore
            image_token_id: this.config.image_token_index,
            ...C,
            image_features: oe
          });
        }
      }
      class Fi extends Ca {
        _merge_input_ids_with_image_features(C) {
          const z = C.image_features.dims.at(-1), oe = C.image_features.view(-1, z);
          return De({
            // @ts-ignore
            image_token_id: this.config.image_token_index,
            ...C,
            image_features: oe
          });
        }
      }
      class ju extends Fi {
      }
      class Wu extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            "input_ids",
            "attention_mask",
            "inputs_embeds",
            "per_layer_inputs",
            "position_ids",
            "pixel_values",
            "input_features",
            "input_features_mask",
            "past_key_values"
          ]);
        }
      }
      class Ia extends Wu {
        async forward({
          // Produced by the tokenizer/processor:
          input_ids: C = null,
          attention_mask: z = null,
          pixel_values: oe = null,
          input_features: ye = null,
          input_features_mask: Pe = null,
          // Used during generation:
          position_ids: Ue = null,
          inputs_embeds: Je = null,
          per_layer_inputs: st = null,
          past_key_values: gt = null,
          // Generic generation parameters
          generation_config: wt = null,
          logits_processor: yt = null,
          // TODO: needed?
          ...ht
        }) {
          if ((!Je || !st) && ({ inputs_embeds: Je, per_layer_inputs: st } = await Q(this.sessions.embed_tokens, {
            input_ids: C
          }), C.dims[1] !== 1)) {
            if (oe) {
              const { image_features: xt } = await Q(this.sessions.vision_encoder, {
                pixel_values: oe
              });
              ({ inputs_embeds: Je, attention_mask: z } = this._merge_input_ids_with_image_features({
                image_features: xt,
                inputs_embeds: Je,
                input_ids: C,
                attention_mask: z
              }));
            }
            if (ye) {
              const { audio_features: xt } = await Q(this.sessions.audio_encoder, {
                input_features: ye,
                input_features_mask: Pe
              });
              ({ inputs_embeds: Je, attention_mask: z } = this._merge_input_ids_with_audio_features({
                audio_features: xt,
                inputs_embeds: Je,
                input_ids: C,
                attention_mask: z
              }));
            }
          }
          return await Ge(this, {
            inputs_embeds: Je,
            per_layer_inputs: st,
            past_key_values: gt,
            attention_mask: z,
            position_ids: Ue,
            generation_config: wt,
            logits_processor: yt
          }, !0);
        }
        _merge_input_ids_with_image_features(C) {
          const z = C.image_features.dims.at(-1), oe = C.image_features.view(-1, z);
          return De({
            // @ts-ignore
            image_token_id: this.config.image_token_id,
            ...C,
            image_features: oe
          });
        }
        _merge_input_ids_with_audio_features(C) {
          const z = C.audio_features.dims.at(-1), oe = C.audio_features.view(-1, z);
          return he({
            // @ts-ignore
            audio_token_id: this.config.audio_token_id,
            ...C,
            audio_features: oe
          });
        }
      }
      class Hu extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            "input_ids",
            "attention_mask",
            "pixel_values",
            "pixel_attention_mask",
            "position_ids",
            "past_key_values"
          ]);
        }
      }
      class xo extends Hu {
        async encode_image({ pixel_values: C, pixel_attention_mask: z }) {
          return (await Q(this.sessions.vision_encoder, { pixel_values: C, pixel_attention_mask: z })).image_features;
        }
        _merge_input_ids_with_image_features(C) {
          const z = C.image_features.dims.at(-1), oe = C.image_features.view(-1, z);
          return De({
            // @ts-ignore
            image_token_id: this.config.image_token_id,
            ...C,
            image_features: oe
          });
        }
      }
      class La extends xo {
      }
      class qu extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            "input_ids",
            "inputs_embeds",
            "attention_mask",
            "position_ids",
            "pixel_values",
            "image_sizes",
            "past_key_values"
          ]);
        }
      }
      class Da extends qu {
        async forward({
          // Produced by the tokenizer/processor:
          input_ids: C = null,
          attention_mask: z = null,
          pixel_values: oe = null,
          image_sizes: ye = null,
          // Used during generation:
          position_ids: Pe = null,
          inputs_embeds: Ue = null,
          past_key_values: Je = null,
          // Generic generation parameters
          generation_config: st = null,
          logits_processor: gt = null,
          // TODO: needed?
          ...wt
        }) {
          if (!Ue) {
            let ht;
            if (oe && C.dims[1] !== 1) {
              if (!ye)
                throw new Error("`image_sizes` must be provided when `pixel_values` is provided.");
              ({ image_features: ht } = await Q(this.sessions.vision_encoder, {
                pixel_values: oe,
                image_sizes: ye
              }));
            } else {
              const Ot = this.config.normalized_config.hidden_size;
              ht = new p.Tensor(
                "float32",
                [],
                [0, Ot]
              );
            }
            ({ inputs_embeds: Ue } = await Q(this.sessions.prepare_inputs_embeds, {
              input_ids: C,
              image_features: ht
            }));
          }
          return await Ge(this, {
            inputs_embeds: Ue,
            past_key_values: Je,
            attention_mask: z,
            position_ids: Pe,
            generation_config: st,
            logits_processor: gt
          }, !1);
        }
      }
      class qs extends U {
      }
      class Ku extends qs {
      }
      class Vy extends qs {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "text_model"
          });
        }
      }
      class Gi extends qs {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "text_model"
          });
        }
      }
      class pg extends qs {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "vision_model"
          });
        }
      }
      class bo extends qs {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "vision_model"
          });
        }
      }
      class Mo extends U {
      }
      class Vi extends Mo {
      }
      class Xu extends Mo {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "text_model"
          });
        }
      }
      class Yu extends qs {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "vision_model"
          });
        }
      }
      class Ju extends U {
      }
      class Qu extends Ju {
      }
      class To extends U {
      }
      class Zu extends To {
        async forward(C) {
          const z = !C.input_ids, oe = !C.pixel_values;
          if (z && oe)
            throw new Error("Either `input_ids` or `pixel_values` should be provided.");
          if (z && (C.input_ids = (0, p.ones)([C.pixel_values.dims[0], 1])), oe) {
            const { image_size: gt } = this.config.vision_config;
            C.pixel_values = (0, p.full)([0, 3, gt, gt], 0);
          }
          const { text_embeddings: ye, image_embeddings: Pe, l2norm_text_embeddings: Ue, l2norm_image_embeddings: Je } = await super.forward(C), st = {};
          return z || (st.text_embeddings = ye, st.l2norm_text_embeddings = Ue), oe || (st.image_embeddings = Pe, st.l2norm_image_embeddings = Je), st;
        }
      }
      class ed extends To {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "text_model"
          });
        }
      }
      class td extends To {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "vision_model"
          });
        }
      }
      class ka extends U {
      }
      class nd extends ka {
      }
      class ji extends ka {
      }
      class Oa extends U {
      }
      class id extends Oa {
      }
      class sd extends Oa {
      }
      class Fa extends U {
      }
      class rd extends Fa {
      }
      class od extends Fa {
      }
      class Ra extends U {
      }
      class ad extends Ra {
      }
      class ld extends Ra {
      }
      class Ba extends U {
      }
      class za extends Ba {
      }
      class $a extends Ba {
      }
      class Na extends U {
      }
      class cd extends Na {
      }
      class Ua extends Na {
      }
      class ud extends U {
      }
      class dd extends ud {
      }
      class Eo extends ud {
      }
      class Ga extends U {
      }
      class hd extends Ga {
      }
      class fd extends Ga {
      }
      class _r extends U {
      }
      class pd extends _r {
      }
      class md extends _r {
      }
      class Va extends U {
      }
      class gd extends Va {
      }
      class ja extends U {
      }
      class _d extends ja {
      }
      class yd extends ja {
      }
      class vd extends U {
      }
      class wd extends vd {
      }
      class xd extends vd {
      }
      class Wa extends U {
      }
      class mg extends Wa {
      }
      class bd extends Wa {
      }
      class hn extends U {
      }
      class Md extends hn {
      }
      class Td extends hn {
      }
      class Ha extends U {
      }
      class Ed extends Ha {
      }
      class Sd extends Ha {
      }
      class qa extends U {
      }
      class Pd extends qa {
      }
      class Ad extends qa {
      }
      class Ka extends U {
      }
      class Cd extends Ka {
      }
      class Id extends Ka {
      }
      class Xa extends U {
      }
      class Ld extends Xa {
      }
      class Dd extends Xa {
      }
      class yr extends U {
      }
      class kd extends yr {
      }
      class So extends yr {
      }
      class Ya extends U {
      }
      class Od extends Ya {
      }
      class Fd extends Ya {
      }
      class Ja extends U {
      }
      class Rd extends Ja {
      }
      class Bd extends Ja {
      }
      class Qa extends U {
      }
      class zd extends Qa {
      }
      class $d extends Qa {
      }
      class Za extends U {
      }
      class Nd extends Za {
      }
      class Ud extends Za {
      }
      class el extends U {
      }
      class Gd extends el {
      }
      class Vd extends el {
      }
      class tl extends U {
      }
      class nl extends tl {
      }
      class jd extends tl {
      }
      class Po extends U {
      }
      class il extends Po {
      }
      class Wd extends Po {
      }
      class sl extends U {
      }
      class Hd extends sl {
      }
      class qd extends sl {
      }
      class rl extends U {
      }
      class Kd extends rl {
      }
      class ol extends rl {
      }
      class al extends U {
      }
      class Xd extends al {
      }
      class Yd extends al {
      }
      class Jd extends U {
      }
      class Qd extends Jd {
      }
      class Zd extends Jd {
      }
      class Wi extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            // Text inputs
            "input_ids",
            "attention_mask",
            "position_ids",
            "past_key_values",
            // Vision inputs
            "pixel_values",
            "image_grid_thw"
          ]);
        }
      }
      class eh extends Wi {
        /**
         * Calculate the 3D rope index based on image and video's temporal, height and width in LLM.
         *
         * Explanation:
         *     Each embedding sequence contains vision embedding and text embedding or just contains text embedding.
         *
         *     For pure text embedding sequence, the rotary position embedding has no difference with mordern LLMs.
         *     Examples:
         *         input_ids: [T T T T T], here T is for text.
         *         temporal position_ids: [0, 1, 2, 3, 4]
         *         height position_ids: [0, 1, 2, 3, 4]
         *         width position_ids: [0, 1, 2, 3, 4]
         *
         *     For vision and text embedding sequence, we calculate 3D rotary position embedding for vision part
         *     and 1D rotary position embeddin for text part.
         *     Examples:
         *         Assume we have a video input with 3 temporal patches, 2 height patches and 2 width patches.
         *         input_ids: [V V V V V V V V V V V V T T T T T], here V is for vision.
         *         vision temporal position_ids: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]
         *         vision height position_ids: [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]
         *         vision width position_ids: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
         *         text temporal position_ids: [3, 4, 5, 6, 7]
         *         text height position_ids: [3, 4, 5, 6, 7]
         *         text width position_ids: [3, 4, 5, 6, 7]
         *         Here we calculate the text start position_ids as the max vision position_ids plus 1.
         * 
         * @param {Tensor} input_ids Indices of input sequence tokens in the vocabulary. Tensor of shape `(batch_size, sequence_length)`.
         * @param {Tensor} image_grid_thw (Optional) The temporal, height and width of feature shape of each image in LLM. Tensor of shape `(num_images, 3)`.
         * @param {Tensor} video_grid_thw (Optional) The temporal, height and width of feature shape of each video in LLM. Tensor of shape `(num_videos, 3)`.
         * @param {Tensor} attention_mask (Optional) Mask to avoid performing attention on padding token indices. Tensor of shape `(batch_size, sequence_length)`. Mask values selected in `[0, 1]`:
         * - 1 for tokens that are **not masked**,
         * - 0 for tokens that are **masked**.
         * @returns {[Tensor, Tensor]} [position_ids, mrope_position_deltas] with:
         * - position_ids: Tensor of shape `(3, batch_size, sequence_length)`.
         * - mrope_position_deltas: Tensor of shape `(batch_size)`.
         */
        get_rope_index(C, z, oe, ye) {
          const { vision_config: Pe, image_token_id: Ue, video_token_id: Je, vision_start_token_id: st } = this.config, gt = Pe.spatial_merge_size ?? 2, wt = [];
          if (z || oe) {
            let yt = C.tolist();
            ye || (ye = (0, p.ones_like)(C));
            const ht = ye.tolist(), Ot = Array.from({ length: 3 }, (St) => Array.from({ length: C.dims[0] }, (Ht) => Array.from({ length: C.dims[1] }, (cn) => 1))), xt = z ? z.tolist() : [], Ct = oe ? oe.tolist() : [];
            let Ze = 0, ft = 0;
            for (let St = 0; St < yt.length; ++St) {
              const Ht = yt[St].filter((Bn, ri) => ht[St][ri] == 1), Sn = Ht.reduce((Bn, ri, Jr) => (ri == st && Bn.push(Jr), Bn), []).map((Bn) => Ht[Bn + 1]), Hn = Sn.filter((Bn) => Bn == Ue).length, kn = Sn.filter((Bn) => Bn == Je).length;
              let Zt = [], $n = 0, Pn = Hn, On = kn;
              for (let Bn = 0; Bn < Sn.length; ++Bn) {
                const ri = Ht.findIndex((ia, Fs) => Fs > $n && ia == Ue), Jr = Ht.findIndex((ia, Fs) => Fs > $n && ia == Je), na = Pn > 0 && ri !== -1 ? ri : Ht.length + 1, Ic = On > 0 && Jr !== -1 ? Jr : Ht.length + 1;
                let t_, Ky, Xy, Yy;
                na < Ic ? ([Ky, Xy, Yy] = xt[Ze], ++Ze, --Pn, t_ = na) : ([Ky, Xy, Yy] = Ct[ft], ++ft, --On, t_ = Ic);
                const [Db, Jy, n_] = [
                  Number(Ky),
                  Math.floor(Number(Xy) / gt),
                  Math.floor(Number(Yy) / gt)
                ], Qy = t_ - $n, W0 = Zt.length > 0 ? (0, v.max)(Zt.at(-1))[0] + 1 : 0;
                Zt.push(
                  Array.from({ length: 3 * Qy }, (ia, Fs) => W0 + Fs % Qy)
                );
                const Zy = Qy + W0, i_ = Db * Jy * n_, kb = Array.from({ length: i_ }, (ia, Fs) => Zy + Math.floor(Fs / (Jy * n_))), Ob = Array.from({ length: i_ }, (ia, Fs) => Zy + Math.floor(Fs / n_) % Jy), Fb = Array.from({ length: i_ }, (ia, Fs) => Zy + Fs % n_);
                Zt.push([kb, Ob, Fb].flat()), $n = t_ + i_;
              }
              if ($n < Ht.length) {
                const Bn = Zt.length > 0 ? (0, v.max)(Zt.at(-1))[0] + 1 : 0, ri = Ht.length - $n;
                Zt.push(
                  Array.from({ length: 3 * ri }, (Jr, na) => Bn + na % ri)
                );
              }
              const qn = Zt.reduce((Bn, ri) => Bn + ri.length, 0), Hi = new Array(qn);
              let Cc = 0;
              for (let Bn = 0; Bn < 3; ++Bn)
                for (let ri = 0; ri < Zt.length; ++ri) {
                  const Jr = Zt[ri], na = Jr.length / 3;
                  for (let Ic = Bn * na; Ic < (Bn + 1) * na; ++Ic)
                    Hi[Cc++] = Jr[Ic];
                }
              let ta = 0;
              const Zg = ht[St];
              for (let Bn = 0; Bn < Zg.length; ++Bn)
                if (Zg[Bn] == 1) {
                  for (let ri = 0; ri < 3; ++ri)
                    Ot[ri][St][Bn] = Hi[ri * qn / 3 + ta];
                  ++ta;
                }
              const e_ = (0, v.max)(Hi)[0];
              wt.push(e_ + 1 - yt[St].length);
            }
            return [
              new p.Tensor("int64", Ot.flat(1 / 0), [3, C.dims[0], C.dims[1]]),
              new p.Tensor("int64", wt, [wt.length, 1])
            ];
          } else if (ye) {
            const { data: yt, dims: ht } = xe(ye), Ot = BigInt64Array.from(
              { length: 3 * yt.length },
              (Ct, Ze) => yt[Ze % yt.length]
            ), xt = Array.from(
              { length: ht[0] },
              (Ct, Ze) => (0, v.max)(yt.subarray(ht[1] * Ze, ht[1] * (Ze + 1)))[0] + 1n + BigInt(ht[1])
            );
            return [
              new p.Tensor("int64", Ot, [3, ...ht]),
              new p.Tensor("int64", xt, [xt.length, 1])
            ];
          } else {
            const [yt, ht] = C.dims, Ot = BigInt64Array.from(
              { length: 3 * yt * ht },
              (xt, Ct) => BigInt(Math.floor(Ct % ht / yt))
            );
            return [
              new p.Tensor("int64", Ot, [3, ...C.dims]),
              (0, p.zeros)([yt, 1])
            ];
          }
        }
        async encode_image({ pixel_values: C, image_grid_thw: z }) {
          return (await Q(this.sessions.vision_encoder, { pixel_values: C, grid_thw: z })).image_features;
        }
        _merge_input_ids_with_image_features(C) {
          return De({
            // @ts-ignore
            image_token_id: this.config.image_token_id,
            ...C
          });
        }
        prepare_inputs_for_generation(C, z, oe) {
          if (z.attention_mask && !z.position_ids)
            if (!z.past_key_values)
              [z.position_ids, z.rope_deltas] = this.get_rope_index(
                z.input_ids,
                z.image_grid_thw,
                z.video_grid_thw,
                z.attention_mask
              );
            else {
              z.pixel_values = null;
              const ye = BigInt(Object.values(z.past_key_values)[0].dims.at(-2)), Pe = z.rope_deltas.map((Ue) => ye + Ue);
              z.position_ids = (0, p.stack)([Pe, Pe, Pe], 0);
            }
          return z;
        }
      }
      class ll extends U {
      }
      class th extends ll {
      }
      class nh extends ll {
      }
      class cl extends U {
      }
      class ih extends cl {
      }
      class sh extends cl {
      }
      class ul extends U {
      }
      class rh extends ul {
      }
      class oh extends ul {
      }
      class ah extends U {
      }
      class lh extends ah {
      }
      class ch extends ah {
      }
      class dl extends U {
      }
      class uh extends dl {
      }
      class dh extends dl {
      }
      class hl extends U {
      }
      class gg extends hl {
      }
      class Ks extends hl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Ds extends U {
      }
      class Xs extends Ds {
      }
      class fl extends Ds {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Ys extends U {
      }
      class ti extends Ys {
      }
      class pl extends U {
      }
      class ml extends pl {
      }
      class hh extends pl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class _g extends U {
      }
      class $r extends _g {
      }
      class Ao extends U {
      }
      class gl extends Ao {
      }
      class fh extends Ao {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class ph extends U {
      }
      class _l extends ph {
      }
      class Co extends U {
      }
      class mh extends Co {
      }
      class yl extends Co {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class gh extends U {
      }
      class Io extends gh {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new ke(await super._call(C));
        }
      }
      class Lo extends U {
      }
      class _h extends Lo {
      }
      class yh extends Lo {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class vh extends U {
      }
      class wh extends vh {
      }
      class vl extends vh {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class vr extends U {
      }
      class xh extends vr {
      }
      class wl extends vr {
      }
      class xl extends U {
      }
      class bh extends xl {
      }
      class Mh extends xl {
      }
      class Th extends U {
      }
      class Eh extends Th {
      }
      class Sh extends Th {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class bl extends U {
      }
      class Ph extends bl {
      }
      class Do extends bl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new Nr(await super._call(C));
        }
      }
      class Ml extends bl {
        /**
         * Runs the model with the provided inputs
         * @param {Object} model_inputs Model inputs
         * @returns {Promise<DetrSegmentationOutput>} Object containing segmentation outputs
         */
        async _call(C) {
          return new Tl(await super._call(C));
        }
      }
      class Nr extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Classification logits (including no-object) for all queries.
         * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).
         * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).
         */
        constructor({ logits: C, pred_boxes: z }) {
          super(), this.logits = C, this.pred_boxes = z;
        }
      }
      class Tl extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits The output logits of the model.
         * @param {Tensor} output.pred_boxes Predicted boxes.
         * @param {Tensor} output.pred_masks Predicted masks.
         */
        constructor({ logits: C, pred_boxes: z, pred_masks: oe }) {
          super(), this.logits = C, this.pred_boxes = z, this.pred_masks = oe;
        }
      }
      class ko extends U {
      }
      class Ah extends ko {
      }
      class Ch extends ko {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new wr(await super._call(C));
        }
      }
      class wr extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Classification logits (including no-object) for all queries.
         * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).
         * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).
         */
        constructor({ logits: C, pred_boxes: z }) {
          super(), this.logits = C, this.pred_boxes = z;
        }
      }
      class Ih extends U {
      }
      class Lh extends Ih {
      }
      class yg extends Ih {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new Dh(await super._call(C));
        }
      }
      class Dh extends wr {
      }
      class El extends U {
      }
      class kh extends El {
      }
      class Sl extends El {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new Oh(await super._call(C));
        }
      }
      class Oh extends wr {
      }
      class Pl extends U {
      }
      class Al extends Pl {
      }
      class Fh extends Pl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new wr(await super._call(C));
        }
      }
      class Cl extends U {
      }
      class vg extends Cl {
      }
      class Rh extends Cl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new Bh(await super._call(C));
        }
      }
      class Bh extends Nr {
      }
      class Il extends U {
      }
      class wg extends Il {
      }
      class zh extends Il {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Ll extends U {
      }
      class $h extends Ll {
      }
      class Nh extends Ll {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Dl extends U {
      }
      class xg extends Dl {
      }
      class Oo extends Dl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Js extends U {
      }
      class kl extends Js {
      }
      class Uh extends Js {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Gh extends Js {
      }
      class Ol extends U {
      }
      class Vh extends Ol {
      }
      class Fl extends Ol {
      }
      class Rl extends U {
      }
      class jh extends Rl {
      }
      class Wh extends Rl {
      }
      class bg extends U {
      }
      class Hh extends bg {
      }
      class Ur extends U {
      }
      class qh extends Ur {
      }
      class Kh extends Ur {
      }
      class Xh extends Ur {
      }
      class Mg extends U {
      }
      class Yh extends Mg {
      }
      class Jh extends U {
      }
      class Tg extends Jh {
      }
      class Qh extends U {
      }
      class Zh extends Qh {
      }
      class Bl extends U {
      }
      class ef extends Bl {
      }
      class Eg extends Bl {
      }
      class zl extends U {
      }
      class tf extends zl {
      }
      class nf extends zl {
      }
      class Sg extends U {
      }
      class sf extends Sg {
      }
      class $l extends U {
      }
      class rf extends $l {
      }
      class of extends $l {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class af extends U {
      }
      class lf extends af {
      }
      class cf extends af {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Nl extends U {
      }
      class uf extends Nl {
      }
      class Pg extends Nl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Ul extends U {
      }
      class df extends Ul {
      }
      class hf extends Ul {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class ff extends U {
      }
      class Ag extends ff {
      }
      class ss extends U {
      }
      class _s extends ss {
      }
      class Qs extends U {
      }
      class Zs extends Qs {
      }
      class Gl extends U {
      }
      class pf extends Gl {
      }
      class mf extends Gl {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new gf(await super._call(C));
        }
      }
      class gf extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Classification logits (including no-object) for all queries.
         * @param {Tensor} output.pred_boxes Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height).
         * These values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding possible padding).
         */
        constructor({ logits: C, pred_boxes: z }) {
          super(), this.logits = C, this.pred_boxes = z;
        }
      }
      class _f extends U {
      }
      class yf extends _f {
        /**
         * Compute image embeddings and positional image embeddings, given the pixel values of an image.
         * @param {Object} model_inputs Object containing the model inputs.
         * @param {Tensor} model_inputs.pixel_values Pixel values obtained using a `SamProcessor`.
         * @returns {Promise<{ image_embeddings: Tensor, image_positional_embeddings: Tensor }>} The image embeddings and positional image embeddings.
         */
        async get_image_embeddings({ pixel_values: C }) {
          return await be(this, { pixel_values: C });
        }
        /**
         * @typedef {Object} SamModelInputs Object containing the model inputs.
         * @property {Tensor} pixel_values Pixel values as a Tensor with shape `(batch_size, num_channels, height, width)`.
         * These can be obtained using a `SamProcessor`.
         * @property {Tensor} [input_points] Input 2D spatial points with shape `(batch_size, num_points, 2)`.
         * This is used by the prompt encoder to encode the prompt.
         * @property {Tensor} [input_labels] Input labels for the points, as a Tensor of shape `(batch_size, point_batch_size, num_points)`.
         * This is used by the prompt encoder to encode the prompt. There are 4 types of labels:
         *  - `1`: the point is a point that contains the object of interest
         *  - `0`: the point is a point that does not contain the object of interest
         *  - `-1`: the point corresponds to the background
         *  - `-10`: the point is a padding point, thus should be ignored by the prompt encoder
         * @property {Tensor} [input_boxes] Input bounding boxes with shape `(batch_size, num_boxes, 4)`.
         * @property {Tensor} [image_embeddings] Image embeddings used by the mask decoder.
         * @property {Tensor} [image_positional_embeddings] Image positional embeddings used by the mask decoder.
         */
        /**
         * @param {SamModelInputs} model_inputs Object containing the model inputs.
         * @returns {Promise<Object>} The output of the model.
         */
        async forward(C) {
          !C.image_embeddings || !C.image_positional_embeddings ? C = {
            ...C,
            ...await this.get_image_embeddings(C)
          } : C = { ...C }, C.input_labels ?? (C.input_labels = (0, p.ones)(C.input_points.dims.slice(0, -1)));
          const z = {
            image_embeddings: C.image_embeddings,
            image_positional_embeddings: C.image_positional_embeddings
          };
          return C.input_points && (z.input_points = C.input_points), C.input_labels && (z.input_labels = C.input_labels), C.input_boxes && (z.input_boxes = C.input_boxes), await Q(this.sessions.prompt_encoder_mask_decoder, z);
        }
        /**
         * Runs the model with the provided inputs
         * @param {Object} model_inputs Model inputs
         * @returns {Promise<SamImageSegmentationOutput>} Object containing segmentation outputs
         */
        async _call(C) {
          return new vf(await super._call(C));
        }
      }
      class vf extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.iou_scores The output logits of the model.
         * @param {Tensor} output.pred_masks Predicted boxes.
         */
        constructor({ iou_scores: C, pred_masks: z }) {
          super(), this.iou_scores = C, this.pred_masks = z;
        }
      }
      class wf extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.iou_scores The output logits of the model.
         * @param {Tensor} output.pred_masks Predicted boxes.
         * @param {Tensor} output.object_score_logits Logits for the object score, indicating if an object is present.
         */
        constructor({ iou_scores: C, pred_masks: z, object_score_logits: oe }) {
          super(), this.iou_scores = C, this.pred_masks = z, this.object_score_logits = oe;
        }
      }
      class xf extends U {
      }
      class Fo extends xf {
        /**
         * Compute image embeddings and positional image embeddings, given the pixel values of an image.
         * @param {Object} model_inputs Object containing the model inputs.
         * @param {Tensor} model_inputs.pixel_values Pixel values obtained using a `Sam2Processor`.
         * @returns {Promise<Record<String, Tensor>>} The image embeddings.
         */
        async get_image_embeddings({ pixel_values: C }) {
          return await be(this, { pixel_values: C });
        }
        async forward(C) {
          const { num_feature_levels: z } = this.config.vision_config;
          if (Array.from({ length: z }, (Ue, Je) => `image_embeddings.${Je}`).some((Ue) => !C[Ue]) ? C = {
            ...C,
            ...await this.get_image_embeddings(C)
          } : C = { ...C }, C.input_points) {
            if (C.input_boxes && C.input_boxes.dims[1] !== 1)
              throw new Error("When both `input_points` and `input_boxes` are provided, the number of boxes per image must be 1.");
            const Ue = C.input_points.dims;
            C.input_labels ?? (C.input_labels = (0, p.ones)(Ue.slice(0, -1))), C.input_boxes ?? (C.input_boxes = (0, p.full)([Ue[0], 0, 4], 0));
          } else if (C.input_boxes) {
            const Ue = C.input_boxes.dims;
            C.input_labels = (0, p.full)([Ue[0], Ue[1], 0], -1n), C.input_points = (0, p.full)([Ue[0], 1, 0, 2], 0);
          } else
            throw new Error("At least one of `input_points` or `input_boxes` must be provided.");
          const ye = this.sessions.prompt_encoder_mask_decoder, Pe = (0, u.pick)(C, ye.inputNames);
          return await Q(ye, Pe);
        }
        /**
         * Runs the model with the provided inputs
         * @param {Object} model_inputs Model inputs
         * @returns {Promise<Sam2ImageSegmentationOutput>} Object containing segmentation outputs
         */
        async _call(C) {
          return new wf(await super._call(C));
        }
      }
      class Cg extends Fo {
      }
      class mi extends Fo {
      }
      class Vl extends U {
      }
      class bf extends Vl {
      }
      class jl extends Vl {
      }
      class Wl extends U {
      }
      class Gr extends Wl {
      }
      class Mf extends Wl {
      }
      class ks extends U {
      }
      class Tf extends ks {
      }
      class Ef extends ks {
        /**
         * @param {Object} model_inputs
         * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
         * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
         */
        async _call(C) {
          return new ue(await super._call(C));
        }
      }
      class Sf extends ks {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Pf extends ks {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Hl extends U {
      }
      class Af extends Hl {
        /**
         * @param {Object} model_inputs
         * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
         * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
         */
        async _call(C) {
          return new ue(await super._call(C));
        }
      }
      class ql extends U {
      }
      class Cf extends ql {
      }
      class If extends ql {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class Ro extends U {
      }
      class Lf extends Ro {
      }
      class Bo extends U {
      }
      class Df extends Bo {
      }
      class kf extends Bo {
        /**
         * @param {Object} model_inputs
         * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
         * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
         */
        async _call(C) {
          return new ue(await super._call(C));
        }
      }
      class Kl extends Bo {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Vr extends U {
      }
      class Of extends Vr {
      }
      class Ig extends Vr {
        /**
         * @param {Object} model_inputs
         * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
         * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
         */
        async _call(C) {
          return new ue(await super._call(C));
        }
      }
      class Xl extends Vr {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Ff extends Vr {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class zo extends U {
      }
      class Rf extends zo {
      }
      class Lg extends zo {
        /**
         * @param {Object} model_inputs
         * @param {Tensor} model_inputs.input_features Float values of input mel-spectrogram.
         * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
         */
        async _call(C) {
          return new ue(await super._call(C));
        }
      }
      class Bf extends zo {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Dg extends U {
      }
      class zf extends ks {
      }
      class kg extends ks {
        /**
         * @param {Object} model_inputs
         * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
         * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
         */
        async _call(C) {
          return new ue(await super._call(C));
        }
      }
      class $f extends ks {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class xr extends U {
      }
      class Og extends xr {
      }
      class Nf extends xr {
        /**
         * @param {Object} model_inputs
         * @param {Tensor} model_inputs.input_values Float values of input raw speech waveform.
         * @param {Tensor} model_inputs.attention_mask Mask to avoid performing convolution and attention on padding token indices. Mask values selected in [0, 1]
         */
        async _call(C) {
          return new ue(await super._call(C));
        }
      }
      class Uf extends xr {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<SequenceClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class Gf extends xr {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<XVectorOutput>} An object containing the model's output logits and speaker embeddings.
         */
        async _call(C) {
          return new ee(await super._call(C));
        }
      }
      class Vf extends xr {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<TokenClassifierOutput>} An object containing the model's output logits for sequence classification.
         */
        async _call(C) {
          return new X(await super._call(C));
        }
      }
      class jf extends U {
      }
      class Fg extends jf {
      }
      class $o extends U {
      }
      class Rg extends $o {
      }
      class Wf extends $o {
      }
      class Hf extends $o {
        /**
         * @typedef {Object} SpeechOutput
         * @property {Tensor} [spectrogram] The predicted log-mel spectrogram of shape
         * `(output_sequence_length, config.num_mel_bins)`. Returned when no `vocoder` is provided
         * @property {Tensor} [waveform] The predicted waveform of shape `(num_frames,)`. Returned when a `vocoder` is provided.
         * @property {Tensor} [cross_attentions] The outputs of the decoder's cross-attention layers of shape
         * `(config.decoder_layers, config.decoder_attention_heads, output_sequence_length, input_sequence_length)`. returned when `output_cross_attentions` is `true`.
         */
        /**
         * Converts a sequence of input tokens into a sequence of mel spectrograms, which are subsequently turned into a speech waveform using a vocoder.
         * @param {Tensor} input_values Indices of input sequence tokens in the vocabulary.
         * @param {Tensor} speaker_embeddings Tensor containing the speaker embeddings.
         * @param {Object} options Optional parameters for generating speech.
         * @param {number} [options.threshold=0.5] The generated sequence ends when the predicted stop token probability exceeds this value.
         * @param {number} [options.minlenratio=0.0] Used to calculate the minimum required length for the output sequence.
         * @param {number} [options.maxlenratio=20.0] Used to calculate the maximum allowed length for the output sequence.
         * @param {Object} [options.vocoder=null] The vocoder that converts the mel spectrogram into a speech waveform. If `null`, the output is the mel spectrogram.
         * @param {boolean} [options.output_cross_attentions=false] Whether or not to return the attentions tensors of the decoder's cross-attention layers.
         * @returns {Promise<SpeechOutput>} A promise which resolves to an object containing the spectrogram, waveform, and cross-attention tensors.
         */
        async generate_speech(C, z, {
          threshold: oe = 0.5,
          minlenratio: ye = 0,
          maxlenratio: Pe = 20,
          vocoder: Ue = null
          // output_cross_attentions = false, // TODO add
        } = {}) {
          const Je = {
            input_ids: C
          }, { encoder_outputs: st, encoder_attention_mask: gt } = await be(this, Je), wt = st.dims[1] / this.config.reduction_factor, yt = Math.floor(wt * Pe), ht = Math.floor(wt * ye), Ot = this.config.num_mel_bins;
          let xt = [], Ct = null, Ze = null, ft = 0;
          for (; ; ) {
            ++ft;
            const cn = K(!!Ze);
            let Sn;
            Ze ? Sn = Ze.output_sequence_out : Sn = new p.Tensor(
              "float32",
              new Float32Array(Ot),
              [1, 1, Ot]
            );
            let Hn = {
              use_cache_branch: cn,
              output_sequence: Sn,
              encoder_attention_mask: gt,
              speaker_embeddings: z,
              encoder_hidden_states: st
            };
            this.addPastKeyValues(Hn, Ct), Ze = await Q(this.sessions.decoder_model_merged, Hn), Ct = this.getPastKeyValues(Ze, Ct);
            const { prob: kn, spectrum: Zt } = Ze;
            if (xt.push(Zt), ft >= ht && // Finished when stop token or maximum length is reached.
            (Array.from(kn.data).filter(($n) => $n >= oe).length > 0 || ft >= yt))
              break;
          }
          const St = (0, p.cat)(xt), { waveform: Ht } = await Q(Ue.sessions.model, { spectrogram: St });
          return {
            spectrogram: St,
            waveform: Ht
            // cross_attentions: null, // TODO add
          };
        }
      }
      class qf extends U {
        constructor() {
          super(...arguments);
          Ce(this, "main_input_name", "spectrogram");
        }
      }
      class Kf extends U {
      }
      class Yl extends Kf {
        async generate_speech({
          // Required inputs
          input_ids: C,
          attention_mask: z,
          style: oe,
          // Optional inputs
          num_inference_steps: ye = 5,
          speed: Pe = 1.05
        }) {
          const { sampling_rate: Ue, chunk_compress_factor: Je, base_chunk_size: st, latent_dim: gt } = this.config, { last_hidden_state: wt, durations: yt } = await Q(this.sessions.text_encoder, {
            input_ids: C,
            attention_mask: z,
            style: oe
          });
          yt.div_(Pe);
          const ht = yt.max().item() * Ue, Ot = st * Je, xt = Math.floor((ht + Ot - 1) / Ot), Ct = C.dims[0], Ze = (0, p.ones)([Ct, xt]), ft = (0, p.full)([Ct], ye);
          let St = (0, p.randn)([Ct, gt * Je, xt]);
          for (let cn = 0; cn < ye; ++cn) {
            const Sn = (0, p.full)([Ct], cn);
            ({ denoised_latents: St } = await Q(this.sessions.latent_denoiser, {
              style: oe,
              noisy_latents: St,
              latent_mask: Ze,
              encoder_outputs: wt,
              attention_mask: z,
              timestep: Sn,
              num_inference_steps: ft
            }));
          }
          const { waveform: Ht } = await Q(this.sessions.voice_decoder, {
            latents: St
          });
          return {
            waveform: Ht,
            durations: yt
          };
        }
      }
      class Xf extends U {
      }
      class Yf extends Xf {
      }
      class Jf extends U {
      }
      class jr extends Jf {
      }
      class Jl extends Jf {
      }
      class No extends U {
      }
      class Ql extends No {
      }
      class Zl extends No {
      }
      class ec extends U {
      }
      class Qf extends ec {
      }
      class tc extends ec {
      }
      class Uo extends U {
      }
      class Zf extends Uo {
      }
      class ep extends Uo {
      }
      class Go extends U {
      }
      class tp extends Go {
      }
      class np extends Go {
      }
      class Vo extends U {
      }
      class ip extends Vo {
      }
      class sp extends Vo {
      }
      class jo extends U {
      }
      class rp extends jo {
      }
      class Bg extends jo {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "text_model"
          });
        }
      }
      class op extends jo {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "audio_model"
          });
        }
      }
      class ap extends U {
      }
      class nc extends ap {
        /**
         * Calls the model on new inputs.
         * @param {Object} model_inputs The inputs to the model.
         * @returns {Promise<VitsModelOutput>} The outputs for the VITS model.
         */
        async _call(C) {
          return new Le(await super._call(C));
        }
      }
      class Wo extends U {
      }
      class jy extends Wo {
      }
      class lp extends Wo {
      }
      class cp extends Wo {
      }
      class ic extends U {
      }
      class zg extends ic {
      }
      class up extends ic {
      }
      class Ho extends U {
      }
      class sc extends Ho {
      }
      class dp extends Ho {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class rc extends U {
      }
      class $g extends rc {
      }
      class Wy extends rc {
      }
      class oc extends U {
        constructor() {
          super(...arguments);
          // NOTE: not MusicgenPreTrainedModel
          Ce(this, "forward_params", [
            "input_ids",
            "attention_mask",
            "encoder_outputs",
            "decoder_input_ids",
            "decoder_attention_mask",
            "past_key_values"
          ]);
        }
        /**
         * Apply the pattern mask to the final ids,
         * then revert the pattern delay mask by filtering the pad token id in a single step.
         * @param {Tensor} outputs The output tensor from the model.
         * @returns {Tensor} The filtered output tensor.
         */
        _apply_and_filter_by_delay_pattern_mask(z) {
          const [oe, ye] = z.dims, Pe = this.config.decoder.num_codebooks, Ue = ye - Pe;
          let Je = 0;
          for (let wt = 0; wt < z.size; ++wt) {
            if (z.data[wt] === this.config.decoder.pad_token_id)
              continue;
            const yt = wt % ye, ht = Math.floor(wt / ye) % Pe, Ot = yt - ht;
            Ot > 0 && Ot <= Ue && (z.data[Je++] = z.data[wt]);
          }
          const st = Math.floor(oe / Pe), gt = Je / (st * Pe);
          return new p.Tensor(
            z.type,
            z.data.slice(0, Je),
            [st, Pe, gt]
          );
        }
        prepare_inputs_for_generation(z, oe, ye) {
          let Pe = structuredClone(z);
          for (let Je = 0; Je < Pe.length; ++Je)
            for (let st = 0; st < Pe[Je].length; ++st)
              Je % this.config.decoder.num_codebooks >= st && (Pe[Je][st] = BigInt(this.config.decoder.pad_token_id));
          return ye.guidance_scale !== null && ye.guidance_scale > 1 && (Pe = Pe.concat(Pe)), super.prepare_inputs_for_generation(Pe, oe, ye);
        }
        /**
         * Generates sequences of token ids for models with a language modeling head.
         * @param {import('./generation/parameters.js').GenerationFunctionParameters} options
         * @returns {Promise<ModelOutput|Tensor>} The output of the model, which can contain the generated token ids, attentions, and scores.
         */
        async generate(z) {
          const oe = await super.generate(z), ye = this._apply_and_filter_by_delay_pattern_mask(
            /** @type {Tensor} */
            oe
          ).unsqueeze_(0), { audio_values: Pe } = await Q(this.sessions.encodec_decode, { audio_codes: ye });
          return Pe;
        }
      }
      class qo extends U {
      }
      class hp extends qo {
      }
      class ac extends qo {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class fp extends qo {
      }
      class Ko extends U {
      }
      class pp extends Ko {
      }
      class mp extends Ko {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class gp extends Ko {
      }
      class Xo extends U {
      }
      class _p extends Xo {
      }
      class yp extends Xo {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class lc extends Xo {
      }
      class Yo extends U {
      }
      class vp extends Yo {
      }
      class wp extends Yo {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new G(await super._call(C));
        }
      }
      class xp extends Yo {
      }
      class bp extends U {
      }
      class Mp extends bp {
      }
      class Tp extends U {
      }
      class Ng extends Tp {
        /**
         * @param {ConstructorParameters<typeof MultiModalityPreTrainedModel>} args
         */
        constructor(...z) {
          super(...z);
          Ce(this, "forward_params", [
            // prepare_inputs_embeds
            "input_ids",
            "pixel_values",
            "images_seq_mask",
            "images_emb_mask",
            // language_model
            "attention_mask",
            "position_ids",
            "past_key_values"
          ]);
          this._generation_mode = "text";
        }
        async forward(z) {
          const oe = this._generation_mode ?? "text";
          let ye;
          if (oe === "text" || !z.past_key_values) {
            const gt = this.sessions.prepare_inputs_embeds, wt = (0, u.pick)(z, gt.inputNames);
            ye = await Q(gt, wt);
          } else {
            const gt = this.sessions.gen_img_embeds, wt = (0, u.pick)({
              image_ids: z.input_ids
            }, gt.inputNames);
            ye = await Q(gt, wt);
          }
          const Pe = { ...z, ...ye }, Ue = await Ge(this, Pe), Je = this.sessions[oe === "text" ? "lm_head" : "gen_head"];
          if (!Je)
            throw new Error(`Unable to find "${Je}" generation head`);
          const st = await Q(Je, (0, u.pick)(Ue, Je.inputNames));
          return {
            ...ye,
            ...Ue,
            ...st
          };
        }
        /**
         * @param {import('./generation/parameters.js').GenerationFunctionParameters} options
         */
        async generate(z) {
          return this._generation_mode = "text", super.generate(z);
        }
        /**
         * @param {import('./generation/parameters.js').GenerationFunctionParameters} options
         */
        async generate_images(z) {
          this._generation_mode = "image";
          const oe = (z.inputs ?? z[this.main_input_name]).dims[1], Pe = (
            /** @type {Tensor} */
            (await super.generate(z)).slice(null, [oe, null])
          ), Ue = this.sessions.image_decode, { decoded_image: Je } = await Q(Ue, {
            generated_tokens: Pe
          }), st = Je.add_(1).mul_(255 / 2).clamp_(0, 255).to("uint8"), gt = [];
          for (const wt of st) {
            const yt = _.RawImage.fromTensor(wt);
            gt.push(yt);
          }
          return gt;
        }
      }
      class Ep extends Se {
        constructor({ char_logits: C, bpe_logits: z, wp_logits: oe }) {
          super(), this.char_logits = C, this.bpe_logits = z, this.wp_logits = oe;
        }
        get logits() {
          return [this.char_logits, this.bpe_logits, this.wp_logits];
        }
      }
      class Sp extends U {
      }
      class Pp extends Sp {
        /**
         * @param {any} model_inputs
         */
        async _call(C) {
          return new Ep(await super._call(C));
        }
      }
      class Ap extends U {
      }
      class Cp extends Ap {
      }
      class Wr extends Ap {
      }
      class cc extends U {
      }
      class uc extends cc {
      }
      class Ip extends cc {
      }
      class Lp extends U {
        constructor() {
          super(...arguments);
          Ce(this, "forward_params", [
            "input_ids",
            "attention_mask",
            "position_ids",
            "audio_values",
            "past_key_values"
          ]);
        }
      }
      class dc extends Lp {
        _merge_input_ids_with_audio_features(C) {
          const z = C.audio_features.dims.at(-1), oe = C.audio_features.view(-1, z);
          return he({
            // @ts-ignore
            audio_token_id: this.config.ignore_index ?? this.config.audio_token_id,
            ...C,
            audio_features: oe
          });
        }
      }
      class Dp extends dc {
      }
      class hc extends U {
        constructor() {
          super(...arguments);
          Ce(this, "main_input_name", "input_values");
          Ce(this, "forward_params", ["input_values"]);
        }
      }
      class kp extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.audio_codes Discrete code embeddings, of shape `(batch_size, num_quantizers, codes_length)`.
         */
        constructor({ audio_codes: C }) {
          super(), this.audio_codes = C;
        }
      }
      class Op extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.audio_values Decoded audio values, of shape `(batch_size, num_channels, sequence_length)`.
         */
        constructor({ audio_values: C }) {
          super(), this.audio_values = C;
        }
      }
      class Fp extends hc {
        /**
         * Encodes the input audio waveform into discrete codes.
         * @param {Object} inputs Model inputs
         * @param {Tensor} [inputs.input_values] Float values of the input audio waveform, of shape `(batch_size, channels, sequence_length)`).
         * @returns {Promise<MimiEncoderOutput>} The output tensor of shape `(batch_size, num_codebooks, sequence_length)`.
         */
        async encode(C) {
          return new kp(await Q(this.sessions.encoder_model, C));
        }
        /**
         * Decodes the given frames into an output audio waveform.
         * @param {MimiEncoderOutput} inputs The encoded audio codes.
         * @returns {Promise<MimiDecoderOutput>} The output tensor of shape `(batch_size, num_channels, sequence_length)`.
         */
        async decode(C) {
          return new Op(await Q(this.sessions.decoder_model, C));
        }
      }
      class Rp extends hc {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "encoder_model"
          });
        }
      }
      class Ug extends hc {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "decoder_model"
          });
        }
      }
      class Hr extends U {
        constructor() {
          super(...arguments);
          Ce(this, "main_input_name", "input_values");
          Ce(this, "forward_params", ["input_values"]);
        }
      }
      class Bp extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.audio_codes Discrete code embeddings, of shape `(batch_size, num_quantizers, codes_length)`.
         */
        constructor({ audio_codes: C }) {
          super(), this.audio_codes = C;
        }
      }
      class zp extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.audio_values Decoded audio values, of shape `(batch_size, num_channels, sequence_length)`.
         */
        constructor({ audio_values: C }) {
          super(), this.audio_values = C;
        }
      }
      class $p extends Hr {
        /**
         * Encodes the input audio waveform into discrete codes.
         * @param {Object} inputs Model inputs
         * @param {Tensor} [inputs.input_values] Float values of the input audio waveform, of shape `(batch_size, channels, sequence_length)`).
         * @returns {Promise<DacEncoderOutput>} The output tensor of shape `(batch_size, num_codebooks, sequence_length)`.
         */
        async encode(C) {
          return new Bp(await Q(this.sessions.encoder_model, C));
        }
        /**
         * Decodes the given frames into an output audio waveform.
         * @param {DacEncoderOutput} inputs The encoded audio codes.
         * @returns {Promise<DacDecoderOutput>} The output tensor of shape `(batch_size, num_channels, sequence_length)`.
         */
        async decode(C) {
          return new zp(await Q(this.sessions.decoder_model, C));
        }
      }
      class Np extends Hr {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "encoder_model"
          });
        }
      }
      class Gg extends Hr {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "decoder_model"
          });
        }
      }
      class Jo extends U {
        constructor() {
          super(...arguments);
          Ce(this, "main_input_name", "input_values");
          Ce(this, "forward_params", ["input_values"]);
        }
      }
      class Up extends Jo {
        /**
         * Encodes the input audio waveform into discrete codes.
         * @param {Object} inputs Model inputs
         * @param {Tensor} [inputs.input_values] Float values of the input audio waveform, of shape `(batch_size, channels, sequence_length)`).
         * @returns {Promise<Record<string, Tensor>>} The output tensors of shape `(batch_size, num_codebooks, sequence_length)`.
         */
        async encode(C) {
          return await Q(this.sessions.encoder_model, C);
        }
        /**
         * Decodes the given frames into an output audio waveform.
         * @param {Record<string, Tensor>} inputs The encoded audio codes.
         * @returns {Promise<{audio_values: Tensor}>} The output tensor of shape `(batch_size, num_channels, sequence_length)`.
         */
        async decode(C) {
          return await Q(this.sessions.decoder_model, C);
        }
      }
      class Gp extends Jo {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "encoder_model"
          });
        }
      }
      class Vg extends Jo {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, z = {}) {
          return super.from_pretrained(C, {
            ...z,
            // Update default model file name if not provided
            model_file_name: z.model_file_name ?? "decoder_model"
          });
        }
      }
      class mn {
        /** @type {typeof PreTrainedModel.from_pretrained} */
        static async from_pretrained(C, {
          progress_callback: z = null,
          config: oe = null,
          cache_dir: ye = null,
          local_files_only: Pe = !1,
          revision: Ue = "main",
          model_file_name: Je = null,
          subfolder: st = "onnx",
          device: gt = null,
          dtype: wt = null,
          use_external_data_format: yt = null,
          session_options: ht = {}
        } = {}) {
          const Ot = {
            progress_callback: z,
            config: oe,
            cache_dir: ye,
            local_files_only: Pe,
            revision: Ue,
            model_file_name: Je,
            subfolder: st,
            device: gt,
            dtype: wt,
            use_external_data_format: yt,
            session_options: ht
          };
          if (Ot.config = await i.AutoConfig.from_pretrained(C, Ot), !this.MODEL_CLASS_MAPPINGS)
            throw new Error("`MODEL_CLASS_MAPPINGS` not implemented for this type of `AutoClass`: " + this.name);
          const xt = Ot.config.model_type;
          for (const Ct of this.MODEL_CLASS_MAPPINGS) {
            let Ze = Ct.get(xt);
            if (!Ze) {
              for (const ft of Ct.values())
                if (ft[0] === xt) {
                  Ze = ft;
                  break;
                }
              if (!Ze)
                continue;
            }
            return await Ze[1].from_pretrained(C, Ot);
          }
          if (this.BASE_IF_FAIL)
            return Xp.has(xt) || console.warn(`Unknown model class "${xt}", attempting to construct from base class.`), await U.from_pretrained(C, Ot);
          throw Error(`Unsupported model type: ${xt}`);
        }
      }
      /**
       * Mapping from model type to model class.
       * @type {Map<string, Object>[]}
       */
      Ce(mn, "MODEL_CLASS_MAPPINGS", null), /**
       * Whether to attempt to instantiate the base class (`PretrainedModel`) if 
       * the model type is not found in the mapping.
       */
      Ce(mn, "BASE_IF_FAIL", !1);
      const Hy = /* @__PURE__ */ new Map([
        ["bert", ["BertModel", Ye]],
        ["neobert", ["NeoBertModel", Qe]],
        ["modernbert", ["ModernBertModel", He]],
        ["nomic_bert", ["NomicBertModel", ln]],
        ["roformer", ["RoFormerModel", li]],
        ["electra", ["ElectraModel", _t]],
        ["esm", ["EsmModel", Ws]],
        ["convbert", ["ConvBertModel", ds]],
        ["camembert", ["CamembertModel", ge]],
        ["deberta", ["DebertaModel", en]],
        ["deberta-v2", ["DebertaV2Model", vi]],
        ["mpnet", ["MPNetModel", Ui]],
        ["albert", ["AlbertModel", Et]],
        ["distilbert", ["DistilBertModel", hs]],
        ["roberta", ["RobertaModel", Jn]],
        ["xlm", ["XLMModel", Ls]],
        ["xlm-roberta", ["XLMRobertaModel", Ea]],
        ["clap", ["ClapModel", rp]],
        ["clip", ["CLIPModel", Ku]],
        ["clipseg", ["CLIPSegModel", nd]],
        ["chinese_clip", ["ChineseCLIPModel", Qu]],
        ["siglip", ["SiglipModel", Vi]],
        ["jina_clip", ["JinaCLIPModel", Zu]],
        ["mobilebert", ["MobileBertModel", pi]],
        ["squeezebert", ["SqueezeBertModel", ie]],
        ["wav2vec2", ["Wav2Vec2Model", Tf]],
        ["wav2vec2-bert", ["Wav2Vec2BertModel", Rf]],
        ["unispeech", ["UniSpeechModel", Df]],
        ["unispeech-sat", ["UniSpeechSatModel", Of]],
        ["hubert", ["HubertModel", zf]],
        ["wavlm", ["WavLMModel", Og]],
        ["audio-spectrogram-transformer", ["ASTModel", ku]],
        ["vits", ["VitsModel", nc]],
        ["pyannote", ["PyAnnoteModel", Cf]],
        ["wespeaker-resnet", ["WeSpeakerResNetModel", Lf]],
        ["detr", ["DetrModel", Ph]],
        ["rt_detr", ["RTDetrModel", Ah]],
        ["rt_detr_v2", ["RTDetrV2Model", Lh]],
        ["rf_detr", ["RFDetrModel", kh]],
        ["d_fine", ["DFineModel", Al]],
        ["table-transformer", ["TableTransformerModel", vg]],
        ["vit", ["ViTModel", gg]],
        ["ijepa", ["IJepaModel", Xs]],
        ["pvt", ["PvtModel", ml]],
        ["vit_msn", ["ViTMSNModel", gl]],
        ["vit_mae", ["ViTMAEModel", $r]],
        ["groupvit", ["GroupViTModel", _l]],
        ["fastvit", ["FastViTModel", mh]],
        ["mobilevit", ["MobileViTModel", _h]],
        ["mobilevitv2", ["MobileViTV2Model", wh]],
        ["owlvit", ["OwlViTModel", xh]],
        ["owlv2", ["Owlv2Model", bh]],
        ["beit", ["BeitModel", Eh]],
        ["deit", ["DeiTModel", wg]],
        ["hiera", ["HieraModel", $h]],
        ["convnext", ["ConvNextModel", rf]],
        ["convnextv2", ["ConvNextV2Model", lf]],
        ["dinov2", ["Dinov2Model", uf]],
        ["dinov2_with_registers", ["Dinov2WithRegistersModel", df]],
        ["dinov3_vit", ["DINOv3ViTModel", Ag]],
        ["dinov3_convnext", ["DINOv3ConvNextModel", _s]],
        ["resnet", ["ResNetModel", xg]],
        ["swin", ["SwinModel", kl]],
        ["swin2sr", ["Swin2SRModel", Vh]],
        ["donut-swin", ["DonutSwinModel", sf]],
        ["yolos", ["YolosModel", pf]],
        ["dpt", ["DPTModel", jh]],
        ["glpn", ["GLPNModel", tf]],
        ["hifigan", ["SpeechT5HifiGan", qf]],
        ["efficientnet", ["EfficientNetModel", sc]],
        ["decision_transformer", ["DecisionTransformerModel", Mp]],
        ["patchtst", ["PatchTSTForPrediction", Cp]],
        ["patchtsmixer", ["PatchTSMixerForPrediction", uc]],
        ["mobilenet_v1", ["MobileNetV1Model", hp]],
        ["mobilenet_v2", ["MobileNetV2Model", pp]],
        ["mobilenet_v3", ["MobileNetV3Model", _p]],
        ["mobilenet_v4", ["MobileNetV4Model", vp]],
        ["maskformer", ["MaskFormerModel", ef]],
        ["mgp-str", ["MgpstrForSceneTextRecognition", Pp]],
        ["style_text_to_speech_2", ["StyleTextToSpeech2Model", Fg]]
      ]), jg = /* @__PURE__ */ new Map([
        ["t5", ["T5Model", fn]],
        ["longt5", ["LongT5Model", En]],
        ["mt5", ["MT5Model", xi]],
        ["bart", ["BartModel", gs]],
        ["mbart", ["MBartModel", Qi]],
        ["marian", ["MarianModel", bf]],
        ["whisper", ["WhisperModel", Fu]],
        ["m2m_100", ["M2M100Model", Gr]],
        ["blenderbot", ["BlenderbotModel", jn]],
        ["blenderbot-small", ["BlenderbotSmallModel", pn]]
      ]), qy = /* @__PURE__ */ new Map([
        ["mimi", ["MimiModel", Fp]],
        ["dac", ["DacModel", $p]],
        ["snac", ["SnacModel", Up]]
      ]), Wg = /* @__PURE__ */ new Map([
        ["bloom", ["BloomModel", rh]],
        ["jais", ["JAISModel", rd]],
        ["gpt2", ["GPT2Model", id]],
        ["gptj", ["GPTJModel", cd]],
        ["gpt_bigcode", ["GPTBigCodeModel", dd]],
        ["gpt_neo", ["GPTNeoModel", ad]],
        ["gpt_neox", ["GPTNeoXModel", za]],
        ["codegen", ["CodeGenModel", hd]],
        ["llama", ["LlamaModel", pd]],
        ["nanochat", ["NanoChatModel", _d]],
        ["arcee", ["ArceeModel", wd]],
        ["lfm2", ["Lfm2Model", mg]],
        ["smollm3", ["SmolLM3Model", Md]],
        ["exaone", ["ExaoneModel", Cd]],
        ["olmo", ["OlmoModel", kd]],
        ["olmo2", ["Olmo2Model", Od]],
        ["mobilellm", ["MobileLLMModel", Ld]],
        ["granite", ["GraniteModel", Rd]],
        ["granitemoehybrid", ["GraniteMoeHybridModel", zd]],
        ["cohere", ["CohereModel", Nd]],
        ["gemma", ["GemmaModel", Gd]],
        ["gemma2", ["Gemma2Model", nl]],
        ["vaultgemma", ["VaultGemmaModel", il]],
        ["gemma3_text", ["Gemma3Model", Hd]],
        ["helium", ["HeliumModel", Ed]],
        ["glm", ["GlmModel", Pd]],
        ["openelm", ["OpenELMModel", Kd]],
        ["qwen2", ["Qwen2Model", Xd]],
        ["qwen3", ["Qwen3Model", Qd]],
        ["phi", ["PhiModel", th]],
        ["phi3", ["Phi3Model", ih]],
        ["mpt", ["MptModel", lh]],
        ["opt", ["OPTModel", uh]],
        ["mistral", ["MistralModel", jr]],
        ["ministral", ["MinistralModel", Ql]],
        ["ministral3", ["Ministral3Model", Qf]],
        ["ernie4_5", ["Ernie4_5Model", Zf]],
        ["starcoder2", ["Starcoder2Model", tp]],
        ["falcon", ["FalconModel", ip]],
        ["stablelm", ["StableLmModel", zg]],
        ["modernbert-decoder", ["ModernBertDecoderModel", Kt]]
      ]), fc = /* @__PURE__ */ new Map([
        ["speecht5", ["SpeechT5ForSpeechToText", Wf]],
        ["whisper", ["WhisperForConditionalGeneration", bi]],
        ["lite-whisper", ["LiteWhisperForConditionalGeneration", Ru]],
        ["moonshine", ["MoonshineForConditionalGeneration", Bu]]
      ]), Vp = /* @__PURE__ */ new Map([
        ["speecht5", ["SpeechT5ForTextToSpeech", Hf]]
      ]), jp = /* @__PURE__ */ new Map([
        ["vits", ["VitsModel", nc]],
        ["musicgen", ["MusicgenForConditionalGeneration", oc]],
        ["supertonic", ["SupertonicForConditionalGeneration", Yl]]
      ]), Wp = /* @__PURE__ */ new Map([
        ["bert", ["BertForSequenceClassification", Y]],
        ["neobert", ["NeoBertForSequenceClassification", ut]],
        ["modernbert", ["ModernBertForSequenceClassification", lt]],
        ["roformer", ["RoFormerForSequenceClassification", $i]],
        ["electra", ["ElectraForSequenceClassification", B]],
        ["esm", ["EsmForSequenceClassification", Cs]],
        ["convbert", ["ConvBertForSequenceClassification", Me]],
        ["camembert", ["CamembertForSequenceClassification", Ke]],
        ["deberta", ["DebertaForSequenceClassification", tn]],
        ["deberta-v2", ["DebertaV2ForSequenceClassification", ki]],
        ["mpnet", ["MPNetForSequenceClassification", ps]],
        ["albert", ["AlbertForSequenceClassification", It]],
        ["distilbert", ["DistilBertForSequenceClassification", fs]],
        ["roberta", ["RobertaForSequenceClassification", Ut]],
        ["xlm", ["XLMForSequenceClassification", zr]],
        ["xlm-roberta", ["XLMRobertaForSequenceClassification", Lu]],
        ["bart", ["BartForSequenceClassification", Vn]],
        ["mbart", ["MBartForSequenceClassification", si]],
        ["mobilebert", ["MobileBertForSequenceClassification", ct]],
        ["squeezebert", ["SqueezeBertForSequenceClassification", Re]]
      ]), Hg = /* @__PURE__ */ new Map([
        ["bert", ["BertForTokenClassification", $e]],
        ["neobert", ["NeoBertForTokenClassification", de]],
        ["modernbert", ["ModernBertForTokenClassification", Mt]],
        ["roformer", ["RoFormerForTokenClassification", An]],
        ["electra", ["ElectraForTokenClassification", le]],
        ["esm", ["EsmForTokenClassification", Is]],
        ["convbert", ["ConvBertForTokenClassification", at]],
        ["camembert", ["CamembertForTokenClassification", pt]],
        ["deberta", ["DebertaForTokenClassification", Vt]],
        ["deberta-v2", ["DebertaV2ForTokenClassification", fi]],
        ["mpnet", ["MPNetForTokenClassification", Br]],
        ["distilbert", ["DistilBertForTokenClassification", Ps]],
        ["roberta", ["RobertaForTokenClassification", Dn]],
        ["xlm", ["XLMForTokenClassification", dt]],
        ["xlm-roberta", ["XLMRobertaForTokenClassification", sn]]
      ]), pc = /* @__PURE__ */ new Map([
        ["t5", ["T5ForConditionalGeneration", _n]],
        ["longt5", ["LongT5ForConditionalGeneration", Un]],
        ["mt5", ["MT5ForConditionalGeneration", ms]],
        ["bart", ["BartForConditionalGeneration", Cn]],
        ["mbart", ["MBartForConditionalGeneration", Zi]],
        ["marian", ["MarianMTModel", jl]],
        ["m2m_100", ["M2M100ForConditionalGeneration", Mf]],
        ["blenderbot", ["BlenderbotForConditionalGeneration", Wn]],
        ["blenderbot-small", ["BlenderbotSmallForConditionalGeneration", ts]]
      ]), qr = /* @__PURE__ */ new Map([
        ["bloom", ["BloomForCausalLM", oh]],
        ["gpt2", ["GPT2LMHeadModel", sd]],
        ["jais", ["JAISLMHeadModel", od]],
        ["gptj", ["GPTJForCausalLM", Ua]],
        ["gpt_bigcode", ["GPTBigCodeForCausalLM", Eo]],
        ["gpt_neo", ["GPTNeoForCausalLM", ld]],
        ["gpt_neox", ["GPTNeoXForCausalLM", $a]],
        ["codegen", ["CodeGenForCausalLM", fd]],
        ["llama", ["LlamaForCausalLM", md]],
        ["nanochat", ["NanoChatForCausalLM", yd]],
        ["llama4_text", ["Llama4ForCausalLM", gd]],
        ["arcee", ["ArceeForCausalLM", xd]],
        ["lfm2", ["Lfm2ForCausalLM", bd]],
        ["smollm3", ["SmolLM3ForCausalLM", Td]],
        ["exaone", ["ExaoneForCausalLM", Id]],
        ["olmo", ["OlmoForCausalLM", So]],
        ["olmo2", ["Olmo2ForCausalLM", Fd]],
        ["mobilellm", ["MobileLLMForCausalLM", Dd]],
        ["granite", ["GraniteForCausalLM", Bd]],
        ["granitemoehybrid", ["GraniteMoeHybridForCausalLM", $d]],
        ["cohere", ["CohereForCausalLM", Ud]],
        ["gemma", ["GemmaForCausalLM", Vd]],
        ["gemma2", ["Gemma2ForCausalLM", jd]],
        ["vaultgemma", ["VaultGemmaForCausalLM", Wd]],
        ["gemma3_text", ["Gemma3ForCausalLM", qd]],
        ["helium", ["HeliumForCausalLM", Sd]],
        ["glm", ["GlmForCausalLM", Ad]],
        ["openelm", ["OpenELMForCausalLM", ol]],
        ["qwen2", ["Qwen2ForCausalLM", Yd]],
        ["qwen3", ["Qwen3ForCausalLM", Zd]],
        ["phi", ["PhiForCausalLM", nh]],
        ["phi3", ["Phi3ForCausalLM", sh]],
        ["mpt", ["MptForCausalLM", ch]],
        ["opt", ["OPTForCausalLM", dh]],
        ["mbart", ["MBartForCausalLM", es]],
        ["mistral", ["MistralForCausalLM", Jl]],
        ["ministral", ["MinistralForCausalLM", Zl]],
        ["ministral3", ["Ministral3ForCausalLM", tc]],
        ["ernie4_5", ["Ernie4_5ForCausalLM", ep]],
        ["starcoder2", ["Starcoder2ForCausalLM", np]],
        ["falcon", ["FalconForCausalLM", sp]],
        ["trocr", ["TrOCRForCausalLM", Yf]],
        ["stablelm", ["StableLmForCausalLM", up]],
        ["modernbert-decoder", ["ModernBertDecoderForCausalLM", vn]],
        // Also image-text-to-text
        ["phi3_v", ["Phi3VForCausalLM", Da]]
      ]), qg = /* @__PURE__ */ new Map([
        ["multi_modality", ["MultiModalityCausalLM", Ng]]
      ]), Hp = /* @__PURE__ */ new Map([
        ["bert", ["BertForMaskedLM", H]],
        ["neobert", ["NeoBertForMaskedLM", Ne]],
        ["modernbert", ["ModernBertForMaskedLM", je]],
        ["roformer", ["RoFormerForMaskedLM", Yi]],
        ["electra", ["ElectraForMaskedLM", on]],
        ["esm", ["EsmForMaskedLM", As]],
        ["convbert", ["ConvBertForMaskedLM", qt]],
        ["camembert", ["CamembertForMaskedLM", Fe]],
        ["deberta", ["DebertaForMaskedLM", Dt]],
        ["deberta-v2", ["DebertaV2ForMaskedLM", ci]],
        ["mpnet", ["MPNetForMaskedLM", it]],
        ["albert", ["AlbertForMaskedLM", kt]],
        ["distilbert", ["DistilBertForMaskedLM", jt]],
        ["roberta", ["RobertaForMaskedLM", di]],
        ["xlm", ["XLMWithLMHeadModel", Nt]],
        ["xlm-roberta", ["XLMRobertaForMaskedLM", Iu]],
        ["mobilebert", ["MobileBertForMaskedLM", bt]],
        ["squeezebert", ["SqueezeBertForMaskedLM", Ae]]
      ]), Kg = /* @__PURE__ */ new Map([
        ["bert", ["BertForQuestionAnswering", Ie]],
        ["neobert", ["NeoBertForQuestionAnswering", qe]],
        ["roformer", ["RoFormerForQuestionAnswering", bn]],
        ["electra", ["ElectraForQuestionAnswering", J]],
        ["convbert", ["ConvBertForQuestionAnswering", rt]],
        ["camembert", ["CamembertForQuestionAnswering", Pt]],
        ["deberta", ["DebertaForQuestionAnswering", nn]],
        ["deberta-v2", ["DebertaV2ForQuestionAnswering", Pi]],
        ["mpnet", ["MPNetForQuestionAnswering", Xe]],
        ["albert", ["AlbertForQuestionAnswering", At]],
        ["distilbert", ["DistilBertForQuestionAnswering", Oi]],
        ["roberta", ["RobertaForQuestionAnswering", Ta]],
        ["xlm", ["XLMForQuestionAnswering", $t]],
        ["xlm-roberta", ["XLMRobertaForQuestionAnswering", Du]],
        ["mobilebert", ["MobileBertForQuestionAnswering", Lt]],
        ["squeezebert", ["SqueezeBertForQuestionAnswering", We]]
      ]), mc = /* @__PURE__ */ new Map([
        ["vision-encoder-decoder", ["VisionEncoderDecoderModel", Aa]],
        ["idefics3", ["Idefics3ForConditionalGeneration", xo]],
        ["smolvlm", ["SmolVLMForConditionalGeneration", La]]
      ]), gc = /* @__PURE__ */ new Map([
        ["llava", ["LlavaForConditionalGeneration", wo]],
        ["llava_onevision", ["LlavaOnevisionForConditionalGeneration", zu]],
        ["moondream1", ["Moondream1ForConditionalGeneration", $u]],
        ["florence2", ["Florence2ForConditionalGeneration", Uu]],
        ["qwen2-vl", ["Qwen2VLForConditionalGeneration", eh]],
        ["idefics3", ["Idefics3ForConditionalGeneration", xo]],
        ["smolvlm", ["SmolVLMForConditionalGeneration", La]],
        ["paligemma", ["PaliGemmaForConditionalGeneration", Vu]],
        ["llava_qwen2", ["LlavaQwen2ForCausalLM", Fi]],
        ["gemma3n", ["Gemma3nForConditionalGeneration", Ia]],
        ["mistral3", ["Mistral3ForConditionalGeneration", ju]]
      ]), _c = /* @__PURE__ */ new Map([
        ["ultravox", ["UltravoxModel", dc]],
        ["voxtral", ["VoxtralForConditionalGeneration", Dp]]
      ]), er = /* @__PURE__ */ new Map([
        ["vision-encoder-decoder", ["VisionEncoderDecoderModel", Aa]]
      ]), qp = /* @__PURE__ */ new Map([
        ["vit", ["ViTForImageClassification", Ks]],
        ["ijepa", ["IJepaForImageClassification", fl]],
        ["pvt", ["PvtForImageClassification", hh]],
        ["vit_msn", ["ViTMSNForImageClassification", fh]],
        ["fastvit", ["FastViTForImageClassification", yl]],
        ["mobilevit", ["MobileViTForImageClassification", yh]],
        ["mobilevitv2", ["MobileViTV2ForImageClassification", vl]],
        ["beit", ["BeitForImageClassification", Sh]],
        ["deit", ["DeiTForImageClassification", zh]],
        ["hiera", ["HieraForImageClassification", Nh]],
        ["convnext", ["ConvNextForImageClassification", of]],
        ["convnextv2", ["ConvNextV2ForImageClassification", cf]],
        ["dinov2", ["Dinov2ForImageClassification", Pg]],
        ["dinov2_with_registers", ["Dinov2WithRegistersForImageClassification", hf]],
        ["resnet", ["ResNetForImageClassification", Oo]],
        ["swin", ["SwinForImageClassification", Uh]],
        ["segformer", ["SegformerForImageClassification", lp]],
        ["efficientnet", ["EfficientNetForImageClassification", dp]],
        ["mobilenet_v1", ["MobileNetV1ForImageClassification", ac]],
        ["mobilenet_v2", ["MobileNetV2ForImageClassification", mp]],
        ["mobilenet_v3", ["MobileNetV3ForImageClassification", yp]],
        ["mobilenet_v4", ["MobileNetV4ForImageClassification", wp]]
      ]), yc = /* @__PURE__ */ new Map([
        ["detr", ["DetrForObjectDetection", Do]],
        ["rt_detr", ["RTDetrForObjectDetection", Ch]],
        ["rt_detr_v2", ["RTDetrV2ForObjectDetection", yg]],
        ["rf_detr", ["RFDetrForObjectDetection", Sl]],
        ["d_fine", ["DFineForObjectDetection", Fh]],
        ["table-transformer", ["TableTransformerForObjectDetection", Rh]],
        ["yolos", ["YolosForObjectDetection", mf]]
      ]), Qo = /* @__PURE__ */ new Map([
        ["owlvit", ["OwlViTForObjectDetection", wl]],
        ["owlv2", ["Owlv2ForObjectDetection", Mh]],
        ["grounding-dino", ["GroundingDinoForObjectDetection", Zs]]
      ]), tr = /* @__PURE__ */ new Map([
        // TODO: Do not add new models here
        ["detr", ["DetrForSegmentation", Ml]],
        ["clipseg", ["CLIPSegForImageSegmentation", ji]]
      ]), vc = /* @__PURE__ */ new Map([
        ["segformer", ["SegformerForSemanticSegmentation", cp]],
        ["sapiens", ["SapiensForSemanticSegmentation", qh]],
        ["swin", ["SwinForSemanticSegmentation", Gh]],
        ["mobilenet_v1", ["MobileNetV1ForSemanticSegmentation", fp]],
        ["mobilenet_v2", ["MobileNetV2ForSemanticSegmentation", gp]],
        ["mobilenet_v3", ["MobileNetV3ForSemanticSegmentation", lc]],
        ["mobilenet_v4", ["MobileNetV4ForSemanticSegmentation", xp]]
      ]), wc = /* @__PURE__ */ new Map([
        ["detr", ["DetrForSegmentation", Ml]],
        ["maskformer", ["MaskFormerForInstanceSegmentation", Eg]]
      ]), xc = /* @__PURE__ */ new Map([
        ["sam", ["SamModel", yf]],
        ["sam2", ["Sam2Model", Fo]],
        ["edgetam", ["EdgeTamModel", Cg]],
        ["sam3_tracker", ["Sam3TrackerModel", mi]]
      ]), bc = /* @__PURE__ */ new Map([
        ["wav2vec2", ["Wav2Vec2ForCTC", Ef]],
        ["wav2vec2-bert", ["Wav2Vec2BertForCTC", Lg]],
        ["unispeech", ["UniSpeechForCTC", kf]],
        ["unispeech-sat", ["UniSpeechSatForCTC", Ig]],
        ["wavlm", ["WavLMForCTC", Nf]],
        ["hubert", ["HubertForCTC", kg]],
        ["parakeet_ctc", ["ParakeetForCTC", Af]]
      ]), Mc = /* @__PURE__ */ new Map([
        ["wav2vec2", ["Wav2Vec2ForSequenceClassification", Sf]],
        ["wav2vec2-bert", ["Wav2Vec2BertForSequenceClassification", Bf]],
        ["unispeech", ["UniSpeechForSequenceClassification", Kl]],
        ["unispeech-sat", ["UniSpeechSatForSequenceClassification", Xl]],
        ["wavlm", ["WavLMForSequenceClassification", Uf]],
        ["hubert", ["HubertForSequenceClassification", $f]],
        ["audio-spectrogram-transformer", ["ASTForAudioClassification", Ou]]
      ]), Kp = /* @__PURE__ */ new Map([
        ["wavlm", ["WavLMForXVector", Gf]]
      ]), Os = /* @__PURE__ */ new Map([
        ["unispeech-sat", ["UniSpeechSatForAudioFrameClassification", Ff]],
        ["wavlm", ["WavLMForAudioFrameClassification", Vf]],
        ["wav2vec2", ["Wav2Vec2ForAudioFrameClassification", Pf]],
        ["pyannote", ["PyAnnoteForAudioFrameClassification", If]]
      ]), Mi = /* @__PURE__ */ new Map([
        ["vitmatte", ["VitMatteForImageMatting", Io]]
      ]), Kr = /* @__PURE__ */ new Map([
        ["patchtst", ["PatchTSTForPrediction", Wr]],
        ["patchtsmixer", ["PatchTSMixerForPrediction", Ip]]
      ]), Xr = /* @__PURE__ */ new Map([
        ["swin2sr", ["Swin2SRForImageSuperResolution", Fl]]
      ]), Yr = /* @__PURE__ */ new Map([
        ["dpt", ["DPTForDepthEstimation", Wh]],
        ["depth_anything", ["DepthAnythingForDepthEstimation", Hh]],
        ["glpn", ["GLPNForDepthEstimation", nf]],
        ["sapiens", ["SapiensForDepthEstimation", Kh]],
        ["depth_pro", ["DepthProForDepthEstimation", Yh]],
        ["metric3d", ["Metric3DForDepthEstimation", Tg]],
        ["metric3dv2", ["Metric3Dv2ForDepthEstimation", Zh]]
      ]), Zo = /* @__PURE__ */ new Map([
        ["sapiens", ["SapiensForNormalEstimation", Xh]]
      ]), Tc = /* @__PURE__ */ new Map([
        ["vitpose", ["VitPoseForPoseEstimation", ti]]
      ]), ea = /* @__PURE__ */ new Map([
        ["clip", ["CLIPVisionModelWithProjection", bo]],
        ["siglip", ["SiglipVisionModel", Yu]],
        ["jina_clip", ["JinaCLIPVisionModel", td]]
      ]), nr = [
        // MODEL_MAPPING_NAMES:
        [Hy, E.EncoderOnly],
        [jg, E.EncoderDecoder],
        [Wg, E.DecoderOnly],
        [qy, E.AutoEncoder],
        [Wp, E.EncoderOnly],
        [Hg, E.EncoderOnly],
        [pc, E.Seq2Seq],
        [fc, E.Seq2Seq],
        [qr, E.DecoderOnly],
        [qg, E.MultiModality],
        [Hp, E.EncoderOnly],
        [Kg, E.EncoderOnly],
        [mc, E.Vision2Seq],
        [gc, E.ImageTextToText],
        [_c, E.AudioTextToText],
        [qp, E.EncoderOnly],
        [tr, E.EncoderOnly],
        [wc, E.EncoderOnly],
        [vc, E.EncoderOnly],
        [Mi, E.EncoderOnly],
        [Kr, E.EncoderOnly],
        [Xr, E.EncoderOnly],
        [Yr, E.EncoderOnly],
        [Zo, E.EncoderOnly],
        [Tc, E.EncoderOnly],
        [yc, E.EncoderOnly],
        [Qo, E.EncoderOnly],
        [xc, E.MaskGeneration],
        [bc, E.EncoderOnly],
        [Mc, E.EncoderOnly],
        [Vp, E.Seq2Seq],
        [jp, E.EncoderOnly],
        [Kp, E.EncoderOnly],
        [Os, E.EncoderOnly],
        // Custom:
        [ea, E.EncoderOnly]
      ];
      for (const [M, C] of nr)
        for (const [z, oe] of M.values())
          A.set(z, C), I.set(oe, z), L.set(z, oe);
      const br = [
        // OVERRIDE:
        // TODO: Refactor to allow class to specify model
        ["MusicgenForConditionalGeneration", oc, E.Musicgen],
        ["Phi3VForCausalLM", Da, E.Phi3V],
        ["CLIPTextModelWithProjection", Gi, E.EncoderOnly],
        ["SiglipTextModel", Xu, E.EncoderOnly],
        ["JinaCLIPTextModel", ed, E.EncoderOnly],
        ["ClapTextModelWithProjection", Bg, E.EncoderOnly],
        ["ClapAudioModelWithProjection", op, E.EncoderOnly],
        ["DacEncoderModel", Np, E.EncoderOnly],
        ["DacDecoderModel", Gg, E.EncoderOnly],
        ["MimiEncoderModel", Rp, E.EncoderOnly],
        ["MimiDecoderModel", Ug, E.EncoderOnly],
        ["SnacEncoderModel", Gp, E.EncoderOnly],
        ["SnacDecoderModel", Vg, E.EncoderOnly],
        ["Gemma3nForConditionalGeneration", Ia, E.ImageAudioTextToText],
        ["SupertonicForConditionalGeneration", Yl, E.Supertonic]
      ];
      for (const [M, C, z] of br)
        A.set(M, z), I.set(C, M), L.set(M, C);
      const Xp = /* @__PURE__ */ new Map([
        ["modnet", tr],
        ["birefnet", tr],
        ["isnet", tr],
        ["ben", tr]
      ]);
      for (const [M, C] of Xp.entries())
        C.set(M, ["PreTrainedModel", U]), A.set(M, E.EncoderOnly), I.set(U, M), L.set(M, U);
      class Ec extends mn {
      }
      /** @type {Map<string, Object>[]} */
      // @ts-ignore
      Ce(Ec, "MODEL_CLASS_MAPPINGS", nr.map((C) => C[0])), Ce(Ec, "BASE_IF_FAIL", !0);
      class Yp extends mn {
      }
      Ce(Yp, "MODEL_CLASS_MAPPINGS", [Wp]);
      class Jp extends mn {
      }
      Ce(Jp, "MODEL_CLASS_MAPPINGS", [Hg]);
      class Qp extends mn {
      }
      Ce(Qp, "MODEL_CLASS_MAPPINGS", [pc]);
      class Zp extends mn {
      }
      Ce(Zp, "MODEL_CLASS_MAPPINGS", [fc]);
      class em extends mn {
      }
      Ce(em, "MODEL_CLASS_MAPPINGS", [Vp]);
      class tm extends mn {
      }
      Ce(tm, "MODEL_CLASS_MAPPINGS", [jp]);
      class nm extends mn {
      }
      Ce(nm, "MODEL_CLASS_MAPPINGS", [qr]);
      class Sc extends mn {
      }
      Ce(Sc, "MODEL_CLASS_MAPPINGS", [Hp]);
      class im extends mn {
      }
      Ce(im, "MODEL_CLASS_MAPPINGS", [Kg]);
      class sm extends mn {
      }
      Ce(sm, "MODEL_CLASS_MAPPINGS", [mc]);
      class Xg extends mn {
      }
      Ce(Xg, "MODEL_CLASS_MAPPINGS", [qp]);
      class rm extends mn {
      }
      Ce(rm, "MODEL_CLASS_MAPPINGS", [tr]);
      class Pc extends mn {
      }
      Ce(Pc, "MODEL_CLASS_MAPPINGS", [vc]);
      class Ac extends mn {
      }
      Ce(Ac, "MODEL_CLASS_MAPPINGS", [wc]);
      class om extends mn {
      }
      Ce(om, "MODEL_CLASS_MAPPINGS", [yc]);
      class Yg extends mn {
      }
      Ce(Yg, "MODEL_CLASS_MAPPINGS", [Qo]);
      class am extends mn {
      }
      Ce(am, "MODEL_CLASS_MAPPINGS", [xc]);
      class Jg extends mn {
      }
      Ce(Jg, "MODEL_CLASS_MAPPINGS", [bc]);
      class Qg extends mn {
      }
      Ce(Qg, "MODEL_CLASS_MAPPINGS", [Mc]);
      class s extends mn {
      }
      Ce(s, "MODEL_CLASS_MAPPINGS", [Kp]);
      class o extends mn {
      }
      Ce(o, "MODEL_CLASS_MAPPINGS", [Os]);
      class d extends mn {
      }
      Ce(d, "MODEL_CLASS_MAPPINGS", [er]);
      class g extends mn {
      }
      Ce(g, "MODEL_CLASS_MAPPINGS", [Mi]);
      class y extends mn {
      }
      Ce(y, "MODEL_CLASS_MAPPINGS", [Xr]);
      class x extends mn {
      }
      Ce(x, "MODEL_CLASS_MAPPINGS", [Yr]);
      class b extends mn {
      }
      Ce(b, "MODEL_CLASS_MAPPINGS", [Zo]);
      class P extends mn {
      }
      Ce(P, "MODEL_CLASS_MAPPINGS", [Tc]);
      class k extends mn {
      }
      Ce(k, "MODEL_CLASS_MAPPINGS", [ea]);
      class O extends mn {
      }
      Ce(O, "MODEL_CLASS_MAPPINGS", [gc]);
      class $ extends mn {
      }
      Ce($, "MODEL_CLASS_MAPPINGS", [_c]);
      class V extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits The output logits of the model.
         * @param {Tensor} output.past_key_values An tensor of key/value pairs that represent the previous state of the model.
         * @param {Tensor} output.encoder_outputs The output of the encoder in a sequence-to-sequence model.
         * @param {Tensor} [output.decoder_attentions] Attentions weights of the decoder, after the attention softmax, used to compute the weighted average in the self-attention heads.
         * @param {Tensor} [output.cross_attentions] Attentions weights of the decoder's cross-attention layer, after the attention softmax, used to compute the weighted average in the cross-attention heads.
         */
        constructor({ logits: C, past_key_values: z, encoder_outputs: oe, decoder_attentions: ye = null, cross_attentions: Pe = null }) {
          super(), this.logits = C, this.past_key_values = z, this.encoder_outputs = oe, this.decoder_attentions = ye, this.cross_attentions = Pe;
        }
      }
      class G extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits classification (or regression if config.num_labels==1) scores (before SoftMax).
         * @param {Record<string, Tensor>} [output.attentions] Object of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length, sequence_length)`.
         * Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.
         */
        constructor({ logits: C, ...z }) {
          super(), this.logits = C;
          const oe = Object.values(z);
          oe.length > 0 && (this.attentions = oe);
        }
      }
      class ee extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Classification hidden states before AMSoftmax, of shape `(batch_size, config.xvector_output_dim)`.
         * @param {Tensor} output.embeddings Utterance embeddings used for vector similarity-based retrieval, of shape `(batch_size, config.xvector_output_dim)`.
         */
        constructor({ logits: C, embeddings: z }) {
          super(), this.logits = C, this.embeddings = z;
        }
      }
      class X extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Classification scores (before SoftMax).
         */
        constructor({ logits: C }) {
          super(), this.logits = C;
        }
      }
      class re extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).
         */
        constructor({ logits: C }) {
          super(), this.logits = C;
        }
      }
      class Te extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.start_logits Span-start scores (before SoftMax).
         * @param {Tensor} output.end_logits Span-end scores (before SoftMax).
         */
        constructor({ start_logits: C, end_logits: z }) {
          super(), this.start_logits = C, this.end_logits = z;
        }
      }
      class ue extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before softmax).
         */
        constructor({ logits: C }) {
          super(), this.logits = C;
        }
      }
      class ce extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.logits Prediction scores of the language modeling head (scores for each vocabulary token before softmax).
         * @param {Tensor} output.past_key_values Contains pre-computed hidden-states (key and values in the self-attention blocks)
         * that can be used (see `past_key_values` input) to speed up sequential decoding.
         */
        constructor({ logits: C, past_key_values: z }) {
          super(), this.logits = C, this.past_key_values = z;
        }
      }
      class ke extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.alphas Estimated alpha values, of shape `(batch_size, num_channels, height, width)`.
         */
        constructor({ alphas: C }) {
          super(), this.alphas = C;
        }
      }
      class Le extends Se {
        /**
         * @param {Object} output The output of the model.
         * @param {Tensor} output.waveform The final audio waveform predicted by the model, of shape `(batch_size, sequence_length)`.
         * @param {Tensor} output.spectrogram The log-mel spectrogram predicted at the output of the flow model.
         * This spectrogram is passed to the Hi-Fi GAN decoder model to obtain the final audio waveform.
         */
        constructor({ waveform: C, spectrogram: z }) {
          super(), this.waveform = C, this.spectrogram = z;
        }
      }
    }
  ),
  /***/
  "./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js": (
    /*!******************************************************************************************************!*\
      !*** ./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js ***!
      \******************************************************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ASTFeatureExtractor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      );
      t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      var r = t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      );
      class a extends i.FeatureExtractor {
        constructor(u) {
          super(u);
          const l = this.config.sampling_rate, f = (0, r.mel_filter_bank)(
            257,
            // num_frequency_bins
            this.config.num_mel_bins,
            // num_mel_filters
            20,
            // min_frequency
            Math.floor(l / 2),
            // max_frequency
            l,
            // sampling_rate
            null,
            // norm
            "kaldi",
            // mel_scale
            !0
            // triangularize_in_mel_space
          );
          this.mel_filters = f, this.window = (0, r.window_function)(400, "hann", {
            periodic: !1
          }), this.mean = this.config.mean, this.std = this.config.std;
        }
        /**
         * Computes the log-Mel spectrogram of the provided audio waveform.
         * @param {Float32Array|Float64Array} waveform The audio waveform to process.
         * @param {number} max_length The maximum number of frames to return.
         * @returns {Promise<Tensor>} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
         */
        async _extract_fbank_features(u, l) {
          return (0, r.spectrogram)(
            u,
            this.window,
            // window
            400,
            // frame_length
            160,
            // hop_length
            {
              fft_length: 512,
              power: 2,
              center: !1,
              preemphasis: 0.97,
              mel_filters: this.mel_filters,
              log_mel: "log",
              mel_floor: 1192092955078125e-22,
              remove_dc_offset: !0,
              // Custom
              max_num_frames: l,
              transpose: !0
            }
          );
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_values: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.
         */
        async _call(u) {
          (0, i.validate_audio_inputs)(u, "ASTFeatureExtractor");
          const l = await this._extract_fbank_features(u, this.config.max_length);
          if (this.config.do_normalize) {
            const f = this.std * 2, m = l.data;
            for (let h = 0; h < m.length; ++h)
              m[h] = (m[h] - this.mean) / f;
          }
          return {
            input_values: l.unsqueeze_(0)
          };
        }
      }
    }
  ),
  /***/
  "./src/models/auto/feature_extraction_auto.js": (
    /*!****************************************************!*\
      !*** ./src/models/auto/feature_extraction_auto.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        AutoFeatureExtractor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../utils/constants.js */
        "./src/utils/constants.js"
      ), r = t(
        /*! ../../utils/hub.js */
        "./src/utils/hub.js"
      );
      t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      );
      var a = t(
        /*! ../feature_extractors.js */
        "./src/models/feature_extractors.js"
      );
      class c {
        /** @type {typeof FeatureExtractor.from_pretrained} */
        static async from_pretrained(l, f = {}) {
          const m = await (0, r.getModelJSON)(l, i.FEATURE_EXTRACTOR_NAME, !0, f), h = m.feature_extractor_type, p = a[h];
          if (!p)
            throw new Error(`Unknown feature_extractor_type: '${h}'. Please report this at ${i.GITHUB_ISSUE_URL}.`);
          return new p(m);
        }
      }
    }
  ),
  /***/
  "./src/models/auto/image_processing_auto.js": (
    /*!**************************************************!*\
      !*** ./src/models/auto/image_processing_auto.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        AutoImageProcessor: () => (
          /* binding */
          u
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../utils/constants.js */
        "./src/utils/constants.js"
      ), r = t(
        /*! ../../utils/hub.js */
        "./src/utils/hub.js"
      ), a = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), c = t(
        /*! ../image_processors.js */
        "./src/models/image_processors.js"
      );
      class u {
        /** @type {typeof ImageProcessor.from_pretrained} */
        static async from_pretrained(f, m = {}) {
          const h = await (0, r.getModelJSON)(f, i.IMAGE_PROCESSOR_NAME, !0, m), p = h.image_processor_type ?? h.feature_extractor_type;
          let _ = c[p == null ? void 0 : p.replace(/Fast$/, "")];
          return _ || (p !== void 0 && console.warn(`Image processor type '${p}' not found, assuming base ImageProcessor. Please report this at ${i.GITHUB_ISSUE_URL}.`), _ = a.ImageProcessor), new _(h);
        }
      }
    }
  ),
  /***/
  "./src/models/auto/processing_auto.js": (
    /*!********************************************!*\
      !*** ./src/models/auto/processing_auto.js ***!
      \********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        AutoProcessor: () => (
          /* binding */
          f
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../utils/constants.js */
        "./src/utils/constants.js"
      ), r = t(
        /*! ../../utils/hub.js */
        "./src/utils/hub.js"
      ), a = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), c = t(
        /*! ../processors.js */
        "./src/models/processors.js"
      ), u = t(
        /*! ../image_processors.js */
        "./src/models/image_processors.js"
      ), l = t(
        /*! ../feature_extractors.js */
        "./src/models/feature_extractors.js"
      );
      class f {
        /** @type {typeof Processor.from_pretrained} */
        static async from_pretrained(h, p = {}) {
          const _ = await (0, r.getModelJSON)(h, i.IMAGE_PROCESSOR_NAME, !0, p), { image_processor_type: v, feature_extractor_type: S, processor_class: D } = _;
          if (D && c[D])
            return c[D].from_pretrained(h, p);
          if (!v && !S)
            throw new Error("No `image_processor_type` or `feature_extractor_type` found in the config.");
          const w = {};
          if (v) {
            const F = u[v.replace(/Fast$/, "")];
            if (!F)
              throw new Error(`Unknown image_processor_type: '${v}'.`);
            w.image_processor = new F(_);
          }
          if (S) {
            const F = u[S];
            if (F)
              w.image_processor = new F(_);
            else {
              const E = l[S];
              if (!E)
                throw new Error(`Unknown feature_extractor_type: '${S}'.`);
              w.feature_extractor = new E(_);
            }
          }
          const T = {};
          return new a.Processor(T, w, null);
        }
      }
    }
  ),
  /***/
  "./src/models/beit/image_processing_beit.js": (
    /*!**************************************************!*\
      !*** ./src/models/beit/image_processing_beit.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        BeitFeatureExtractor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/bit/image_processing_bit.js": (
    /*!************************************************!*\
      !*** ./src/models/bit/image_processing_bit.js ***!
      \************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        BitImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/chinese_clip/image_processing_chinese_clip.js": (
    /*!******************************************************************!*\
      !*** ./src/models/chinese_clip/image_processing_chinese_clip.js ***!
      \******************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ChineseCLIPFeatureExtractor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/clap/feature_extraction_clap.js": (
    /*!****************************************************!*\
      !*** ./src/models/clap/feature_extraction_clap.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ClapFeatureExtractor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      );
      t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      var r = t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      );
      class a extends i.FeatureExtractor {
        constructor(u) {
          super(u), this.mel_filters = (0, r.mel_filter_bank)(
            this.config.nb_frequency_bins,
            // num_frequency_bins
            this.config.feature_size,
            // num_mel_filters
            this.config.frequency_min,
            // min_frequency
            this.config.frequency_max,
            // max_frequency
            this.config.sampling_rate,
            // sampling_rate
            null,
            // norm
            "htk"
            // mel_scale
          ), this.mel_filters_slaney = (0, r.mel_filter_bank)(
            this.config.nb_frequency_bins,
            // num_frequency_bins
            this.config.feature_size,
            // num_mel_filters
            this.config.frequency_min,
            // min_frequency
            this.config.frequency_max,
            // max_frequency
            this.config.sampling_rate,
            // sampling_rate
            "slaney",
            // norm
            "slaney"
            // mel_scale
          ), this.window = (0, r.window_function)(this.config.fft_window_size, "hann");
        }
        /**
         * Extracts the mel spectrogram and prepares it for the mode based on the `truncation` and `padding` arguments.
         * 
         * Four different path are possible:
         *   - `truncation="fusion"` and the length of the waveform is greater than the max length: the mel spectrogram
         *     will be computed on the entire audio. 3 random crops and a dowsampled version of the full mel spectrogram
         *     are then stacked together. They will later be used for `feature_fusion`.
         *   - `truncation="rand_trunc"` and the length of the waveform is smaller than the max length: the audio is
         *     padded based on `padding`.
         *   - `truncation="fusion"` and the length of the waveform is smaller than the max length: the audio is padded
         *     based on `padding`, and is repeated `4` times.
         *   - `truncation="rand_trunc"` and the length of the waveform is greater than the max length: the mel
         *     spectrogram will be computed on a random crop of the waveform.
         * 
         * @param {Float32Array|Float64Array} waveform The input waveform.
         * @param {number} max_length The maximum length of the waveform.
         * @param {string} truncation The truncation strategy to use.
         * @param {string} padding The padding strategy to use.
         * @returns {Promise<Tensor>} An object containing the mel spectrogram data as a Float32Array, its dimensions as an array of numbers, and a boolean indicating whether the waveform was longer than the max length.
         * @private
         */
        async _get_input_mel(u, l, f, m) {
          let h;
          const p = u.length - l;
          if (p > 0)
            if (f === "rand_trunc") {
              const _ = Math.floor(Math.random() * (p + 1));
              u = u.subarray(_, _ + l), h = await this._extract_fbank_features(u, this.mel_filters_slaney, this.config.nb_max_samples);
            } else
              throw new Error(`Truncation strategy "${f}" not implemented`);
          else {
            if (p < 0) {
              let _ = new Float64Array(l);
              if (_.set(u), m === "repeat")
                for (let v = u.length; v < l; v += u.length)
                  _.set(u.subarray(0, Math.min(u.length, l - v)), v);
              else if (m === "repeatpad")
                for (let v = u.length; v < -p; v += u.length)
                  _.set(u, v);
              u = _;
            }
            if (f === "fusion")
              throw new Error(`Truncation strategy "${f}" not implemented`);
            h = await this._extract_fbank_features(u, this.mel_filters_slaney, this.config.nb_max_samples);
          }
          return h.unsqueeze_(0);
        }
        /**
         * Compute the log-mel spectrogram of the provided `waveform` using the Hann window.
         * In CLAP, two different filter banks are used depending on the truncation pattern:
         *  - `self.mel_filters`: they correspond to the default parameters of `torchaudio` which can be obtained from
         *    calling `torchaudio.transforms.MelSpectrogram().mel_scale.fb`. These filters are used when `truncation`
         *    is set to `"fusion"`.
         *  - `self.mel_filteres_slaney` : they correspond to the default parameters of `librosa` which used
         *    `librosa.filters.mel` when computing the mel spectrogram. These filters were only used in the original
         *    implementation when the truncation mode is not `"fusion"`.
         * 
         * @param {Float32Array|Float64Array} waveform The audio waveform to process.
         * @param {number[][]} mel_filters The mel filters to use.
         * @param {number} [max_length=null] The maximum number of frames to return.
         * @returns {Promise<Tensor>} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
         */
        async _extract_fbank_features(u, l, f = null) {
          return (0, r.spectrogram)(
            u,
            this.window,
            // window
            this.config.fft_window_size,
            // frame_length
            this.config.hop_length,
            // hop_length
            {
              power: 2,
              mel_filters: l,
              log_mel: "dB",
              // Custom
              max_num_frames: f,
              do_pad: !1,
              transpose: !0
            }
          );
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.
         */
        async _call(u, {
          max_length: l = null
        } = {}) {
          return (0, i.validate_audio_inputs)(u, "ClapFeatureExtractor"), {
            input_features: (await this._get_input_mel(
              u,
              l ?? this.config.nb_max_samples,
              this.config.truncation,
              this.config.padding
            )).unsqueeze_(0)
          };
        }
      }
    }
  ),
  /***/
  "./src/models/clip/image_processing_clip.js": (
    /*!**************************************************!*\
      !*** ./src/models/clip/image_processing_clip.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        CLIPFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        CLIPImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/convnext/image_processing_convnext.js": (
    /*!**********************************************************!*\
      !*** ./src/models/convnext/image_processing_convnext.js ***!
      \**********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ConvNextFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        ConvNextImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        constructor(u) {
          super(u), this.crop_pct = this.config.crop_pct ?? 224 / 256;
        }
        async resize(u) {
          var f;
          const l = (f = this.size) == null ? void 0 : f.shortest_edge;
          if (l === void 0)
            throw new Error("Size dictionary must contain 'shortest_edge' key.");
          if (l < 384) {
            const m = Math.floor(l / this.crop_pct), [h, p] = this.get_resize_output_image_size(u, {
              shortest_edge: m
            });
            u = await u.resize(h, p, {
              resample: this.resample
            }), u = await u.center_crop(l, l);
          } else
            u = await u.resize(l, l, {
              resample: this.resample
            });
          return u;
        }
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/dac/feature_extraction_dac.js": (
    /*!**************************************************!*\
      !*** ./src/models/dac/feature_extraction_dac.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DacFeatureExtractor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../encodec/feature_extraction_encodec.js */
        "./src/models/encodec/feature_extraction_encodec.js"
      );
      class r extends i.EncodecFeatureExtractor {
      }
    }
  ),
  /***/
  "./src/models/deit/image_processing_deit.js": (
    /*!**************************************************!*\
      !*** ./src/models/deit/image_processing_deit.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DeiTFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        DeiTImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/detr/image_processing_detr.js": (
    /*!**************************************************!*\
      !*** ./src/models/detr/image_processing_detr.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DetrFeatureExtractor: () => (
          /* binding */
          c
        ),
        /* harmony export */
        DetrImageProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.ImageProcessor {
        /**
         * Calls the feature extraction process on an array of images, preprocesses
         * each image, and concatenates the resulting features into a single Tensor.
         * @param {import('../../utils/image.js').RawImage[]} images The image(s) to extract features from.
         * @returns {Promise<DetrFeatureExtractorResult>} An object containing the concatenated pixel values of the preprocessed images.
         */
        async _call(l) {
          const f = await super._call(l), m = [f.pixel_values.dims[0], 64, 64], h = (0, r.full)(m, 1n);
          return { ...f, pixel_mask: h };
        }
        /** @type {typeof post_process_object_detection} */
        post_process_object_detection(...l) {
          return (0, i.post_process_object_detection)(...l);
        }
        /** @type {typeof post_process_panoptic_segmentation} */
        post_process_panoptic_segmentation(...l) {
          return (0, i.post_process_panoptic_segmentation)(...l);
        }
        /** @type {typeof post_process_instance_segmentation} */
        post_process_instance_segmentation(...l) {
          return (0, i.post_process_instance_segmentation)(...l);
        }
      }
      class c extends a {
      }
    }
  ),
  /***/
  "./src/models/dinov3_vit/image_processing_dinov3_vit.js": (
    /*!**************************************************************!*\
      !*** ./src/models/dinov3_vit/image_processing_dinov3_vit.js ***!
      \**************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DINOv3ViTImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/donut/image_processing_donut.js": (
    /*!****************************************************!*\
      !*** ./src/models/donut/image_processing_donut.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DonutFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        DonutImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        pad_image(u, l, f, m = {}) {
          const [h, p, _] = l;
          let v = this.image_mean;
          Array.isArray(this.image_mean) || (v = new Array(_).fill(v));
          let S = this.image_std;
          Array.isArray(S) || (S = new Array(_).fill(v));
          const D = v.map((w, T) => -w / S[T]);
          return super.pad_image(u, l, f, {
            center: !0,
            // Since normalization is done after padding, we need to use certain constant values to ensure the same behaviour is observed.
            // For more information, see https://github.com/huggingface/transformers/blob/main/src/transformers/models/donut/image_processing_donut.py#L433-L451
            constant_values: D,
            ...m
          });
        }
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/dpt/image_processing_dpt.js": (
    /*!************************************************!*\
      !*** ./src/models/dpt/image_processing_dpt.js ***!
      \************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DPTFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        DPTImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/efficientnet/image_processing_efficientnet.js": (
    /*!******************************************************************!*\
      !*** ./src/models/efficientnet/image_processing_efficientnet.js ***!
      \******************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        EfficientNetImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        constructor(c) {
          super(c), this.include_top = this.config.include_top ?? !0, this.include_top && (this.image_std = this.image_std.map((u) => u * u));
        }
      }
    }
  ),
  /***/
  "./src/models/encodec/feature_extraction_encodec.js": (
    /*!**********************************************************!*\
      !*** ./src/models/encodec/feature_extraction_encodec.js ***!
      \**********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        EncodecFeatureExtractor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.FeatureExtractor {
        /**
         * Asynchronously extracts input values from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_values: Tensor; }>} The extracted input values.
         */
        async _call(u) {
          (0, i.validate_audio_inputs)(u, "EncodecFeatureExtractor"), u instanceof Float64Array && (u = new Float32Array(u));
          const l = this.config.feature_size;
          if (u.length % l !== 0)
            throw new Error(`The length of the audio data must be a multiple of the number of channels (${l}).`);
          const f = [
            1,
            /* batch_size */
            l,
            /* num_channels */
            u.length / l
            /* num_samples */
          ];
          return {
            input_values: new r.Tensor("float32", u, f)
          };
        }
      }
    }
  ),
  /***/
  "./src/models/feature_extractors.js": (
    /*!******************************************!*\
      !*** ./src/models/feature_extractors.js ***!
      \******************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ASTFeatureExtractor: () => (
          /* reexport safe */
          i.ASTFeatureExtractor
        ),
        /* harmony export */
        ClapFeatureExtractor: () => (
          /* reexport safe */
          a.ClapFeatureExtractor
        ),
        /* harmony export */
        DacFeatureExtractor: () => (
          /* reexport safe */
          c.DacFeatureExtractor
        ),
        /* harmony export */
        EncodecFeatureExtractor: () => (
          /* reexport safe */
          r.EncodecFeatureExtractor
        ),
        /* harmony export */
        Gemma3nAudioFeatureExtractor: () => (
          /* reexport safe */
          u.Gemma3nAudioFeatureExtractor
        ),
        /* harmony export */
        ImageFeatureExtractor: () => (
          /* reexport safe */
          w.ImageProcessor
        ),
        /* harmony export */
        MoonshineFeatureExtractor: () => (
          /* reexport safe */
          l.MoonshineFeatureExtractor
        ),
        /* harmony export */
        ParakeetFeatureExtractor: () => (
          /* reexport safe */
          f.ParakeetFeatureExtractor
        ),
        /* harmony export */
        PyAnnoteFeatureExtractor: () => (
          /* reexport safe */
          m.PyAnnoteFeatureExtractor
        ),
        /* harmony export */
        SeamlessM4TFeatureExtractor: () => (
          /* reexport safe */
          h.SeamlessM4TFeatureExtractor
        ),
        /* harmony export */
        SnacFeatureExtractor: () => (
          /* reexport safe */
          p.SnacFeatureExtractor
        ),
        /* harmony export */
        SpeechT5FeatureExtractor: () => (
          /* reexport safe */
          _.SpeechT5FeatureExtractor
        ),
        /* harmony export */
        Wav2Vec2FeatureExtractor: () => (
          /* reexport safe */
          v.Wav2Vec2FeatureExtractor
        ),
        /* harmony export */
        WeSpeakerFeatureExtractor: () => (
          /* reexport safe */
          S.WeSpeakerFeatureExtractor
        ),
        /* harmony export */
        WhisperFeatureExtractor: () => (
          /* reexport safe */
          D.WhisperFeatureExtractor
        )
        /* harmony export */
      });
      var i = t(
        /*! ./audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js */
        "./src/models/audio_spectrogram_transformer/feature_extraction_audio_spectrogram_transformer.js"
      ), r = t(
        /*! ./encodec/feature_extraction_encodec.js */
        "./src/models/encodec/feature_extraction_encodec.js"
      ), a = t(
        /*! ./clap/feature_extraction_clap.js */
        "./src/models/clap/feature_extraction_clap.js"
      ), c = t(
        /*! ./dac/feature_extraction_dac.js */
        "./src/models/dac/feature_extraction_dac.js"
      ), u = t(
        /*! ./gemma3n/feature_extraction_gemma3n.js */
        "./src/models/gemma3n/feature_extraction_gemma3n.js"
      ), l = t(
        /*! ./moonshine/feature_extraction_moonshine.js */
        "./src/models/moonshine/feature_extraction_moonshine.js"
      ), f = t(
        /*! ./parakeet/feature_extraction_parakeet.js */
        "./src/models/parakeet/feature_extraction_parakeet.js"
      ), m = t(
        /*! ./pyannote/feature_extraction_pyannote.js */
        "./src/models/pyannote/feature_extraction_pyannote.js"
      ), h = t(
        /*! ./seamless_m4t/feature_extraction_seamless_m4t.js */
        "./src/models/seamless_m4t/feature_extraction_seamless_m4t.js"
      ), p = t(
        /*! ./snac/feature_extraction_snac.js */
        "./src/models/snac/feature_extraction_snac.js"
      ), _ = t(
        /*! ./speecht5/feature_extraction_speecht5.js */
        "./src/models/speecht5/feature_extraction_speecht5.js"
      ), v = t(
        /*! ./wav2vec2/feature_extraction_wav2vec2.js */
        "./src/models/wav2vec2/feature_extraction_wav2vec2.js"
      ), S = t(
        /*! ./wespeaker/feature_extraction_wespeaker.js */
        "./src/models/wespeaker/feature_extraction_wespeaker.js"
      ), D = t(
        /*! ./whisper/feature_extraction_whisper.js */
        "./src/models/whisper/feature_extraction_whisper.js"
      ), w = t(
        /*! ../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
    }
  ),
  /***/
  "./src/models/florence2/processing_florence2.js": (
    /*!******************************************************!*\
      !*** ./src/models/florence2/processing_florence2.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Florence2Processor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      class c extends i.Processor {
        constructor(l, f, m) {
          super(l, f, m);
          const {
            // @ts-expect-error TS2339
            tasks_answer_post_processing_type: h,
            // @ts-expect-error TS2339
            task_prompts_without_inputs: p,
            // @ts-expect-error TS2339
            task_prompts_with_input: _
          } = this.image_processor.config;
          this.tasks_answer_post_processing_type = new Map(Object.entries(h ?? {})), this.task_prompts_without_inputs = new Map(Object.entries(p ?? {})), this.task_prompts_with_input = new Map(Object.entries(_ ?? {})), this.regexes = {
            quad_boxes: /(.+?)<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm,
            bboxes: /([^<]+)?<loc_(\d+)><loc_(\d+)><loc_(\d+)><loc_(\d+)>/gm
          }, this.size_per_bin = 1e3;
        }
        /**
         * Helper function to construct prompts from input texts
         * @param {string|string[]} text
         * @returns {string[]}
         */
        construct_prompts(l) {
          typeof l == "string" && (l = [l]);
          const f = [];
          for (const m of l)
            if (this.task_prompts_without_inputs.has(m))
              f.push(this.task_prompts_without_inputs.get(m));
            else {
              for (const [h, p] of this.task_prompts_with_input)
                if (m.includes(h)) {
                  f.push(p.replaceAll("{input}", m).replaceAll(h, ""));
                  break;
                }
              f.length !== l.length && f.push(m);
            }
          return f;
        }
        /**
         * Post-process the output of the model to each of the task outputs.
         * @param {string} text The text to post-process.
         * @param {string} task The task to post-process the text for.
         * @param {[number, number]} image_size The size of the image. height x width.
         */
        post_process_generation(l, f, m) {
          const h = this.tasks_answer_post_processing_type.get(f) ?? "pure_text";
          l = l.replaceAll("<s>", "").replaceAll("</s>", "");
          let p;
          switch (h) {
            case "pure_text":
              p = l;
              break;
            case "description_with_bboxes":
            case "bboxes":
            case "phrase_grounding":
            case "ocr":
              const _ = h === "ocr" ? "quad_boxes" : "bboxes", v = l.matchAll(this.regexes[_]), S = [], D = [];
              for (const [w, T, ...F] of v)
                S.push(T ? T.trim() : S.at(-1) ?? ""), D.push(
                  F.map((E, A) => (
                    // NOTE: Add 0.5 to use the center position of the bin as the coordinate.
                    (Number(E) + 0.5) / this.size_per_bin * m[A % 2]
                  ))
                );
              p = { labels: S, [_]: D };
              break;
            default:
              throw new Error(`Task "${f}" (of type "${h}") not yet implemented.`);
          }
          return { [f]: p };
        }
        // NOTE: images and text are switched from the python version
        // `images` is required, `text` is optional
        async _call(l, f = null, m = {}) {
          if (!l && !f)
            throw new Error("Either text or images must be provided");
          const h = await this.image_processor(l, m), p = f ? this.tokenizer(this.construct_prompts(f), m) : {};
          return {
            ...h,
            ...p
          };
        }
      }
      Ce(c, "tokenizer_class", a.AutoTokenizer), Ce(c, "image_processor_class", r.AutoImageProcessor);
    }
  ),
  /***/
  "./src/models/gemma3n/feature_extraction_gemma3n.js": (
    /*!**********************************************************!*\
      !*** ./src/models/gemma3n/feature_extraction_gemma3n.js ***!
      \**********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Gemma3nAudioFeatureExtractor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      ), a = t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      );
      class c extends i.FeatureExtractor {
        constructor(l) {
          super(l);
          const {
            fft_length: f,
            feature_size: m,
            min_frequency: h,
            max_frequency: p,
            sampling_rate: _,
            frame_length: v
          } = this.config, S = (0, a.mel_filter_bank)(
            Math.floor(1 + f / 2),
            // num_frequency_bins
            m,
            // num_mel_filters
            h,
            // min_frequency
            p,
            // max_frequency
            _,
            // sampling_rate
            null,
            // norm
            "htk",
            // mel_scale
            !1
            // triangularize_in_mel_space
          );
          this.mel_filters = S, this.window = (0, a.window_function)(v, "hann");
        }
        /**
         * Computes the log-Mel spectrogram of the provided audio waveform.
         * @param {Float32Array|Float64Array} waveform The audio waveform to process.
         * @param {number} max_length The maximum number of frames to return.
         * @returns {Promise<Tensor>} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
         */
        async _extract_fbank_features(l, f) {
          return (0, a.spectrogram)(
            l,
            this.window,
            // window
            this.config.frame_length,
            // frame_length
            this.config.hop_length,
            // hop_length
            {
              fft_length: this.config.fft_length,
              center: !1,
              onesided: !0,
              preemphasis: this.config.preemphasis,
              preemphasis_htk_flavor: this.config.preemphasis_htk_flavor,
              mel_filters: this.mel_filters,
              log_mel: "log",
              mel_floor: this.config.mel_floor,
              remove_dc_offset: !1,
              // Custom
              transpose: !0
            }
          );
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @param {Object} options Optional parameters for feature extraction.
         * @param {number} [options.max_length=480_000] If provided, defines the maximum length of the audio to allow.
         * Audio longer than this will be truncated if `truncation=True`.
         * @param {boolean} [options.truncation=true] Whether or not to truncate audio above `max_length`.
         * @param {boolean} [options.padding=true] Whether to pad the sequence to a multiple of `pad_to_multiple_of`.
         * @param {number} [options.pad_to_multiple_of=128] The number to pad the sequence to a multiple of.
         * @returns {Promise<{ input_features: Tensor, input_features_mask: Tensor }>} A Promise resolving to an object containing the extracted input features and attention masks as Tensors.
         */
        async _call(l, {
          max_length: f = 48e4,
          truncation: m = !0,
          padding: h = !0,
          pad_to_multiple_of: p = 128
        } = {}) {
          if ((0, i.validate_audio_inputs)(l, "Gemma3nAudioFeatureExtractor"), m && l.length > f && (l = l.slice(0, f)), h && l.length % p !== 0) {
            const S = p - l.length % p, D = new Float64Array(l.length + S);
            D.set(l), this.config.padding_value !== 0 && D.fill(this.config.padding_value, l.length), l = D;
          }
          const _ = await this._extract_fbank_features(l, this.config.max_length), v = (0, r.full)([1, _.dims[0]], !0);
          return {
            input_features: _.unsqueeze_(0),
            input_features_mask: v
          };
        }
      }
    }
  ),
  /***/
  "./src/models/gemma3n/processing_gemma3n.js": (
    /*!**************************************************!*\
      !*** ./src/models/gemma3n/processing_gemma3n.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Gemma3nProcessor: () => (
          /* binding */
          u
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      ), c = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      t(
        /*! ../../utils/image.js */
        "./src/utils/image.js"
      ), t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      );
      class u extends i.Processor {
        constructor(f, m, h) {
          super(f, m, h), this.audio_seq_length = this.config.audio_seq_length, this.image_seq_length = this.config.image_seq_length;
          const {
            // Audio tokens
            audio_token_id: p,
            boa_token: _,
            audio_token: v,
            eoa_token: S,
            // Image tokens
            image_token_id: D,
            boi_token: w,
            image_token: T,
            eoi_token: F
          } = this.tokenizer.config;
          this.audio_token_id = p, this.boa_token = _, this.audio_token = v;
          const E = v.repeat(this.audio_seq_length);
          this.full_audio_sequence = `

${_}${E}${S}

`, this.image_token_id = D, this.boi_token = w, this.image_token = T;
          const A = T.repeat(this.image_seq_length);
          this.full_image_sequence = `

${w}${A}${F}

`;
        }
        /**
         * 
         * @param {string|string[]} text 
         * @param {RawImage|RawImage[]|RawImage[][]} images
         * @param {RawAudio|RawAudio[]|RawAudio[][]} audio
         * @returns {Promise<any>}
         */
        async _call(f, m = null, h = null, p = {}) {
          typeof f == "string" && (f = [f]);
          let _;
          h && (_ = await this.feature_extractor(h, p), f = f.map((D) => D.replaceAll(this.audio_token, this.full_audio_sequence)));
          let v;
          return m && (v = await this.image_processor(m, p), f = f.map((D) => D.replaceAll(this.image_token, this.full_image_sequence))), {
            ...this.tokenizer(f, p),
            ...v,
            ..._
          };
        }
      }
      Ce(u, "image_processor_class", r.AutoImageProcessor), Ce(u, "feature_extractor_class", a.AutoFeatureExtractor), Ce(u, "tokenizer_class", c.AutoTokenizer), Ce(u, "uses_processor_config", !0), Ce(u, "uses_chat_template_file", !0);
    }
  ),
  /***/
  "./src/models/glpn/image_processing_glpn.js": (
    /*!**************************************************!*\
      !*** ./src/models/glpn/image_processing_glpn.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        GLPNFeatureExtractor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/grounding_dino/image_processing_grounding_dino.js": (
    /*!**********************************************************************!*\
      !*** ./src/models/grounding_dino/image_processing_grounding_dino.js ***!
      \**********************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        GroundingDinoImageProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.ImageProcessor {
        /**
         * Calls the feature extraction process on an array of images, preprocesses
         * each image, and concatenates the resulting features into a single Tensor.
         * @param {import('../../utils/image.js').RawImage[]} images The image(s) to extract features from.
         * @returns {Promise<GroundingDinoFeatureExtractorResult>} An object containing the concatenated pixel values of the preprocessed images.
         */
        async _call(u) {
          const l = await super._call(u), f = l.pixel_values.dims, m = (0, r.ones)([f[0], f[2], f[3]]);
          return { ...l, pixel_mask: m };
        }
      }
    }
  ),
  /***/
  "./src/models/grounding_dino/processing_grounding_dino.js": (
    /*!****************************************************************!*\
      !*** ./src/models/grounding_dino/processing_grounding_dino.js ***!
      \****************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        GroundingDinoProcessor: () => (
          /* binding */
          l
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), c = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      function u(f, m) {
        const p = f.dims.at(-1) - 1, _ = f.tolist();
        _.fill(!1, 0, 0 + 1), _.fill(!1, p);
        const v = m.tolist();
        return _.map((S, D) => S ? D : null).filter((S) => S !== null).map((S) => v[S]);
      }
      class l extends i.Processor {
        /**
         * @typedef {import('../../utils/image.js').RawImage} RawImage
         */
        /**
         * 
         * @param {RawImage|RawImage[]|RawImage[][]} images  
         * @param {string|string[]} text 
         * @returns {Promise<any>}
         */
        async _call(m, h, p = {}) {
          const _ = m ? await this.image_processor(m, p) : {};
          return {
            ...h ? this.tokenizer(h, p) : {},
            ..._
          };
        }
        post_process_grounded_object_detection(m, h, {
          box_threshold: p = 0.25,
          text_threshold: _ = 0.25,
          target_sizes: v = null
        } = {}) {
          const { logits: S, pred_boxes: D } = m, w = S.dims[0];
          if (v !== null && v.length !== w)
            throw Error("Make sure that you pass in as many target sizes as the batch dimension of the logits");
          const T = S.dims.at(1), F = S.sigmoid(), E = F.max(-1).tolist(), A = D.tolist().map((I) => I.map((R) => (0, c.center_to_corners_format)(R))), L = [];
          for (let I = 0; I < w; ++I) {
            const R = v !== null ? v[I] : null;
            R !== null && (A[I] = A[I].map((W) => W.map((te, K) => te * R[(K + 1) % 2])));
            const N = E[I], q = [], ne = [], Q = [];
            for (let W = 0; W < T; ++W) {
              const te = N[W];
              if (te <= p)
                continue;
              const K = A[I][W], pe = F[I][W];
              q.push(te), Q.push(K);
              const be = u(pe.gt(_), h[I]);
              ne.push(be);
            }
            L.push({ scores: q, boxes: Q, labels: this.batch_decode(ne) });
          }
          return L;
        }
      }
      Ce(l, "tokenizer_class", a.AutoTokenizer), Ce(l, "image_processor_class", r.AutoImageProcessor);
    }
  ),
  /***/
  "./src/models/idefics3/image_processing_idefics3.js": (
    /*!**********************************************************!*\
      !*** ./src/models/idefics3/image_processing_idefics3.js ***!
      \**********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Idefics3ImageProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.ImageProcessor {
        constructor(u) {
          super(u), this.do_image_splitting = u.do_image_splitting ?? !0, this.max_image_size = u.max_image_size;
        }
        /**
         * @typedef {import('../../utils/image.js').RawImage} RawImage
         * @typedef {import('../../utils/tensor.js').Tensor} Tensor
         */
        /**
         * Calculate size to resize images to, to be multiples of `vision_encoder_max_size` while preserving the aspect ratio.
         * @param {Tensor} pixel_values Tensor of the image to resize.
         * @param {number} vision_encoder_max_size Maximum size of the output image. If the image is larger than this size,
         * it will be split into patches of this size, and the original image will be concatenated with the patches, resized to max_size.
         */
        get_resize_for_vision_encoder(u, l) {
          let [f, m] = u.dims.slice(-2);
          const h = m / f;
          return m >= f ? (m = Math.ceil(m / l) * l, f = Math.floor(m / h), f = Math.ceil(f / l) * l) : (f = Math.ceil(f / l) * l, m = Math.floor(f * h), m = Math.ceil(m / l) * l), { height: f, width: m };
        }
        /** @param {RawImage|RawImage[]|RawImage[][]} images */
        async _call(u, {
          do_image_splitting: l = null,
          return_row_col_info: f = !1
        } = {}) {
          let m;
          if (!Array.isArray(u))
            m = [[u]];
          else {
            if (u.length === 0 || !u[0])
              throw new Error("No images provided.");
            Array.isArray(u[0]) ? m = /** @type {RawImage[][]} */
            u : m = [
              /** @type {RawImage[]} */
              u
            ];
          }
          let h = [], p = [], _ = [];
          const v = [], S = [];
          for (const I of m) {
            let R = await Promise.all(I.map((ne) => this.preprocess(ne)));
            v.push(...R.map((ne) => ne.original_size)), S.push(...R.map((ne) => ne.reshaped_input_size)), R.forEach((ne) => ne.pixel_values.unsqueeze_(0));
            const { longest_edge: N } = this.max_image_size;
            let q;
            if (l ?? this.do_image_splitting) {
              let ne = new Array(R.length), Q = new Array(R.length);
              q = await Promise.all(R.map(async (W, te) => {
                const K = this.get_resize_for_vision_encoder(W.pixel_values, N), pe = await (0, r.interpolate_4d)(W.pixel_values, {
                  size: [K.height, K.width]
                }), { frames: be, num_splits_h: Ee, num_splits_w: Ge } = await this.split_image(pe, this.max_image_size);
                return ne[te] = Ee, Q[te] = Ge, (0, r.cat)(be, 0);
              })), p.push(ne), _.push(Q);
            } else {
              const ne = [N, N];
              q = await Promise.all(
                R.map((Q) => (0, r.interpolate_4d)(Q.pixel_values, { size: ne }))
              ), p.push(new Array(R.length).fill(0)), _.push(new Array(R.length).fill(0));
            }
            h.push((0, r.cat)(q, 0));
          }
          const D = h.length, [w, T, F, E] = h[0].dims;
          let A, L;
          if (D === 1)
            A = h[0].unsqueeze_(0), L = (0, r.full)([D, w, F, E], !0);
          else {
            const I = Math.max(...h.map((q) => q.dims.at(0)));
            L = (0, r.full)([D, I, F, E], !0);
            const R = L.data, N = I * F * E;
            for (let q = 0; q < D; ++q) {
              const ne = h[q].dims[0];
              if (ne < I) {
                h[q] = (0, r.cat)([
                  h[q],
                  (0, r.full)([I - ne, T, F, E], 0)
                ], 0);
                const Q = q * N + ne * F * E, W = (q + 1) * N;
                R.fill(!1, Q, W);
              }
            }
            A = (0, r.stack)(h, 0);
          }
          return {
            pixel_values: A,
            pixel_attention_mask: L,
            original_sizes: v,
            reshaped_input_sizes: S,
            ...f ? { rows: p, cols: _ } : {}
          };
        }
        async split_image(u, { longest_edge: l }) {
          const f = l, m = l, h = [], [p, _] = u.dims.slice(-2);
          let v = 0, S = 0;
          if (p > f || _ > m) {
            v = Math.ceil(p / f), S = Math.ceil(_ / m);
            const D = Math.ceil(p / v), w = Math.ceil(_ / S);
            for (let E = 0; E < v; ++E)
              for (let A = 0; A < S; ++A) {
                let L, I, R, N;
                E === v - 1 ? (I = p - D, N = p) : (I = E * D, N = (E + 1) * D), A === S - 1 ? (L = _ - w, R = _) : (L = A * w, R = (A + 1) * w);
                const q = [I, L], ne = [N, R], Q = await (0, r.slice)(u, q, ne, [2, 3]);
                h.push(Q);
              }
            const T = f, F = m;
            (p !== T || _ !== F) && (u = await (0, r.interpolate_4d)(u, {
              size: [T, F]
            }));
          }
          return h.push(u), { frames: h, num_splits_h: v, num_splits_w: S };
        }
      }
    }
  ),
  /***/
  "./src/models/idefics3/processing_idefics3.js": (
    /*!****************************************************!*\
      !*** ./src/models/idefics3/processing_idefics3.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Idefics3Processor: () => (
          /* binding */
          m
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      t(
        /*! ../../utils/image.js */
        "./src/utils/image.js"
      );
      var c = t(
        /*! ../../utils/core.js */
        "./src/utils/core.js"
      );
      function u(h, p, _, v, S, D) {
        let w = "";
        for (let T = 0; T < p; ++T) {
          for (let F = 0; F < _; ++F)
            w += v + `<row_${T + 1}_col_${F + 1}>` + S.repeat(h);
          w += `
`;
        }
        return w += `
${v}${D}` + S.repeat(h) + `${v}`, w;
      }
      function l(h, p, _, v) {
        return `${p}${v}` + _.repeat(h) + `${p}`;
      }
      function f(h, p, _, v, S, D) {
        return h === 0 && p === 0 ? l(
          _,
          v,
          S,
          D
        ) : u(
          _,
          h,
          p,
          v,
          S,
          D
        );
      }
      class m extends i.Processor {
        constructor() {
          super(...arguments);
          Ce(this, "fake_image_token", "<fake_token_around_image>");
          Ce(this, "image_token", "<image>");
          Ce(this, "global_img_token", "<global-img>");
        }
        /**
         * 
         * @param {string|string[]} text 
         * @param {RawImage|RawImage[]|RawImage[][]} images  
         * @returns {Promise<any>}
         */
        async _call(_, v = null, S = {}) {
          S.return_row_col_info ?? (S.return_row_col_info = !0);
          let D;
          v && (D = await this.image_processor(v, S)), Array.isArray(_) || (_ = [_]);
          const w = D.rows ?? [new Array(_.length).fill(0)], T = D.cols ?? [new Array(_.length).fill(0)], F = this.config.image_seq_len, E = [], A = [];
          for (let I = 0; I < _.length; ++I) {
            const R = _[I], N = w[I], q = T[I];
            E.push((0, c.count)(R, this.image_token));
            const ne = N.map(
              (te, K) => f(
                te,
                q[K],
                F,
                this.fake_image_token,
                this.image_token,
                this.global_img_token
              )
            ), Q = R.split(this.image_token);
            if (Q.length === 0)
              throw new Error("The image token should be present in the text.");
            let W = Q[0];
            for (let te = 0; te < ne.length; ++te)
              W += ne[te] + Q[te + 1];
            A.push(W);
          }
          return {
            ...this.tokenizer(A),
            ...D
          };
        }
      }
      Ce(m, "image_processor_class", r.AutoImageProcessor), Ce(m, "tokenizer_class", a.AutoTokenizer), Ce(m, "uses_processor_config", !0);
    }
  ),
  /***/
  "./src/models/image_processors.js": (
    /*!****************************************!*\
      !*** ./src/models/image_processors.js ***!
      \****************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        BeitFeatureExtractor: () => (
          /* reexport safe */
          i.BeitFeatureExtractor
        ),
        /* harmony export */
        BitImageProcessor: () => (
          /* reexport safe */
          r.BitImageProcessor
        ),
        /* harmony export */
        CLIPFeatureExtractor: () => (
          /* reexport safe */
          c.CLIPFeatureExtractor
        ),
        /* harmony export */
        CLIPImageProcessor: () => (
          /* reexport safe */
          c.CLIPImageProcessor
        ),
        /* harmony export */
        ChineseCLIPFeatureExtractor: () => (
          /* reexport safe */
          a.ChineseCLIPFeatureExtractor
        ),
        /* harmony export */
        ConvNextFeatureExtractor: () => (
          /* reexport safe */
          u.ConvNextFeatureExtractor
        ),
        /* harmony export */
        ConvNextImageProcessor: () => (
          /* reexport safe */
          u.ConvNextImageProcessor
        ),
        /* harmony export */
        DINOv3ViTImageProcessor: () => (
          /* reexport safe */
          m.DINOv3ViTImageProcessor
        ),
        /* harmony export */
        DPTFeatureExtractor: () => (
          /* reexport safe */
          p.DPTFeatureExtractor
        ),
        /* harmony export */
        DPTImageProcessor: () => (
          /* reexport safe */
          p.DPTImageProcessor
        ),
        /* harmony export */
        DeiTFeatureExtractor: () => (
          /* reexport safe */
          l.DeiTFeatureExtractor
        ),
        /* harmony export */
        DeiTImageProcessor: () => (
          /* reexport safe */
          l.DeiTImageProcessor
        ),
        /* harmony export */
        DetrFeatureExtractor: () => (
          /* reexport safe */
          f.DetrFeatureExtractor
        ),
        /* harmony export */
        DetrImageProcessor: () => (
          /* reexport safe */
          f.DetrImageProcessor
        ),
        /* harmony export */
        DonutFeatureExtractor: () => (
          /* reexport safe */
          h.DonutFeatureExtractor
        ),
        /* harmony export */
        DonutImageProcessor: () => (
          /* reexport safe */
          h.DonutImageProcessor
        ),
        /* harmony export */
        EfficientNetImageProcessor: () => (
          /* reexport safe */
          _.EfficientNetImageProcessor
        ),
        /* harmony export */
        GLPNFeatureExtractor: () => (
          /* reexport safe */
          v.GLPNFeatureExtractor
        ),
        /* harmony export */
        GroundingDinoImageProcessor: () => (
          /* reexport safe */
          S.GroundingDinoImageProcessor
        ),
        /* harmony export */
        Idefics3ImageProcessor: () => (
          /* reexport safe */
          D.Idefics3ImageProcessor
        ),
        /* harmony export */
        JinaCLIPImageProcessor: () => (
          /* reexport safe */
          T.JinaCLIPImageProcessor
        ),
        /* harmony export */
        LlavaOnevisionImageProcessor: () => (
          /* reexport safe */
          F.LlavaOnevisionImageProcessor
        ),
        /* harmony export */
        Mask2FormerImageProcessor: () => (
          /* reexport safe */
          E.Mask2FormerImageProcessor
        ),
        /* harmony export */
        MaskFormerFeatureExtractor: () => (
          /* reexport safe */
          A.MaskFormerFeatureExtractor
        ),
        /* harmony export */
        MaskFormerImageProcessor: () => (
          /* reexport safe */
          A.MaskFormerImageProcessor
        ),
        /* harmony export */
        MobileNetV1FeatureExtractor: () => (
          /* reexport safe */
          L.MobileNetV1FeatureExtractor
        ),
        /* harmony export */
        MobileNetV1ImageProcessor: () => (
          /* reexport safe */
          L.MobileNetV1ImageProcessor
        ),
        /* harmony export */
        MobileNetV2FeatureExtractor: () => (
          /* reexport safe */
          I.MobileNetV2FeatureExtractor
        ),
        /* harmony export */
        MobileNetV2ImageProcessor: () => (
          /* reexport safe */
          I.MobileNetV2ImageProcessor
        ),
        /* harmony export */
        MobileNetV3FeatureExtractor: () => (
          /* reexport safe */
          R.MobileNetV3FeatureExtractor
        ),
        /* harmony export */
        MobileNetV3ImageProcessor: () => (
          /* reexport safe */
          R.MobileNetV3ImageProcessor
        ),
        /* harmony export */
        MobileNetV4FeatureExtractor: () => (
          /* reexport safe */
          N.MobileNetV4FeatureExtractor
        ),
        /* harmony export */
        MobileNetV4ImageProcessor: () => (
          /* reexport safe */
          N.MobileNetV4ImageProcessor
        ),
        /* harmony export */
        MobileViTFeatureExtractor: () => (
          /* reexport safe */
          q.MobileViTFeatureExtractor
        ),
        /* harmony export */
        MobileViTImageProcessor: () => (
          /* reexport safe */
          q.MobileViTImageProcessor
        ),
        /* harmony export */
        NougatImageProcessor: () => (
          /* reexport safe */
          ne.NougatImageProcessor
        ),
        /* harmony export */
        OwlViTFeatureExtractor: () => (
          /* reexport safe */
          W.OwlViTFeatureExtractor
        ),
        /* harmony export */
        OwlViTImageProcessor: () => (
          /* reexport safe */
          W.OwlViTImageProcessor
        ),
        /* harmony export */
        Owlv2ImageProcessor: () => (
          /* reexport safe */
          Q.Owlv2ImageProcessor
        ),
        /* harmony export */
        Phi3VImageProcessor: () => (
          /* reexport safe */
          te.Phi3VImageProcessor
        ),
        /* harmony export */
        PixtralImageProcessor: () => (
          /* reexport safe */
          K.PixtralImageProcessor
        ),
        /* harmony export */
        PvtImageProcessor: () => (
          /* reexport safe */
          pe.PvtImageProcessor
        ),
        /* harmony export */
        Qwen2VLImageProcessor: () => (
          /* reexport safe */
          be.Qwen2VLImageProcessor
        ),
        /* harmony export */
        RTDetrImageProcessor: () => (
          /* reexport safe */
          Ee.RTDetrImageProcessor
        ),
        /* harmony export */
        Sam2ImageProcessor: () => (
          /* reexport safe */
          _e.Sam2ImageProcessor
        ),
        /* harmony export */
        Sam3ImageProcessor: () => (
          /* reexport safe */
          De.Sam3ImageProcessor
        ),
        /* harmony export */
        SamImageProcessor: () => (
          /* reexport safe */
          Ge.SamImageProcessor
        ),
        /* harmony export */
        SegformerFeatureExtractor: () => (
          /* reexport safe */
          he.SegformerFeatureExtractor
        ),
        /* harmony export */
        SegformerImageProcessor: () => (
          /* reexport safe */
          he.SegformerImageProcessor
        ),
        /* harmony export */
        SiglipImageProcessor: () => (
          /* reexport safe */
          Z.SiglipImageProcessor
        ),
        /* harmony export */
        SmolVLMImageProcessor: () => (
          /* reexport safe */
          me.SmolVLMImageProcessor
        ),
        /* harmony export */
        Swin2SRImageProcessor: () => (
          /* reexport safe */
          we.Swin2SRImageProcessor
        ),
        /* harmony export */
        VLMImageProcessor: () => (
          /* reexport safe */
          w.VLMImageProcessor
        ),
        /* harmony export */
        ViTFeatureExtractor: () => (
          /* reexport safe */
          xe.ViTFeatureExtractor
        ),
        /* harmony export */
        ViTImageProcessor: () => (
          /* reexport safe */
          xe.ViTImageProcessor
        ),
        /* harmony export */
        VitMatteImageProcessor: () => (
          /* reexport safe */
          et.VitMatteImageProcessor
        ),
        /* harmony export */
        VitPoseImageProcessor: () => (
          /* reexport safe */
          Ve.VitPoseImageProcessor
        ),
        /* harmony export */
        YolosFeatureExtractor: () => (
          /* reexport safe */
          nt.YolosFeatureExtractor
        ),
        /* harmony export */
        YolosImageProcessor: () => (
          /* reexport safe */
          nt.YolosImageProcessor
        )
        /* harmony export */
      });
      var i = t(
        /*! ./beit/image_processing_beit.js */
        "./src/models/beit/image_processing_beit.js"
      ), r = t(
        /*! ./bit/image_processing_bit.js */
        "./src/models/bit/image_processing_bit.js"
      ), a = t(
        /*! ./chinese_clip/image_processing_chinese_clip.js */
        "./src/models/chinese_clip/image_processing_chinese_clip.js"
      ), c = t(
        /*! ./clip/image_processing_clip.js */
        "./src/models/clip/image_processing_clip.js"
      ), u = t(
        /*! ./convnext/image_processing_convnext.js */
        "./src/models/convnext/image_processing_convnext.js"
      ), l = t(
        /*! ./deit/image_processing_deit.js */
        "./src/models/deit/image_processing_deit.js"
      ), f = t(
        /*! ./detr/image_processing_detr.js */
        "./src/models/detr/image_processing_detr.js"
      ), m = t(
        /*! ./dinov3_vit/image_processing_dinov3_vit.js */
        "./src/models/dinov3_vit/image_processing_dinov3_vit.js"
      ), h = t(
        /*! ./donut/image_processing_donut.js */
        "./src/models/donut/image_processing_donut.js"
      ), p = t(
        /*! ./dpt/image_processing_dpt.js */
        "./src/models/dpt/image_processing_dpt.js"
      ), _ = t(
        /*! ./efficientnet/image_processing_efficientnet.js */
        "./src/models/efficientnet/image_processing_efficientnet.js"
      ), v = t(
        /*! ./glpn/image_processing_glpn.js */
        "./src/models/glpn/image_processing_glpn.js"
      ), S = t(
        /*! ./grounding_dino/image_processing_grounding_dino.js */
        "./src/models/grounding_dino/image_processing_grounding_dino.js"
      ), D = t(
        /*! ./idefics3/image_processing_idefics3.js */
        "./src/models/idefics3/image_processing_idefics3.js"
      ), w = t(
        /*! ./janus/image_processing_janus.js */
        "./src/models/janus/image_processing_janus.js"
      ), T = t(
        /*! ./jina_clip/image_processing_jina_clip.js */
        "./src/models/jina_clip/image_processing_jina_clip.js"
      ), F = t(
        /*! ./llava_onevision/image_processing_llava_onevision.js */
        "./src/models/llava_onevision/image_processing_llava_onevision.js"
      ), E = t(
        /*! ./mask2former/image_processing_mask2former.js */
        "./src/models/mask2former/image_processing_mask2former.js"
      ), A = t(
        /*! ./maskformer/image_processing_maskformer.js */
        "./src/models/maskformer/image_processing_maskformer.js"
      ), L = t(
        /*! ./mobilenet_v1/image_processing_mobilenet_v1.js */
        "./src/models/mobilenet_v1/image_processing_mobilenet_v1.js"
      ), I = t(
        /*! ./mobilenet_v2/image_processing_mobilenet_v2.js */
        "./src/models/mobilenet_v2/image_processing_mobilenet_v2.js"
      ), R = t(
        /*! ./mobilenet_v3/image_processing_mobilenet_v3.js */
        "./src/models/mobilenet_v3/image_processing_mobilenet_v3.js"
      ), N = t(
        /*! ./mobilenet_v4/image_processing_mobilenet_v4.js */
        "./src/models/mobilenet_v4/image_processing_mobilenet_v4.js"
      ), q = t(
        /*! ./mobilevit/image_processing_mobilevit.js */
        "./src/models/mobilevit/image_processing_mobilevit.js"
      ), ne = t(
        /*! ./nougat/image_processing_nougat.js */
        "./src/models/nougat/image_processing_nougat.js"
      ), Q = t(
        /*! ./owlv2/image_processing_owlv2.js */
        "./src/models/owlv2/image_processing_owlv2.js"
      ), W = t(
        /*! ./owlvit/image_processing_owlvit.js */
        "./src/models/owlvit/image_processing_owlvit.js"
      ), te = t(
        /*! ./phi3_v/image_processing_phi3_v.js */
        "./src/models/phi3_v/image_processing_phi3_v.js"
      ), K = t(
        /*! ./pixtral/image_processing_pixtral.js */
        "./src/models/pixtral/image_processing_pixtral.js"
      ), pe = t(
        /*! ./pvt/image_processing_pvt.js */
        "./src/models/pvt/image_processing_pvt.js"
      ), be = t(
        /*! ./qwen2_vl/image_processing_qwen2_vl.js */
        "./src/models/qwen2_vl/image_processing_qwen2_vl.js"
      ), Ee = t(
        /*! ./rt_detr/image_processing_rt_detr.js */
        "./src/models/rt_detr/image_processing_rt_detr.js"
      ), Ge = t(
        /*! ./sam/image_processing_sam.js */
        "./src/models/sam/image_processing_sam.js"
      ), _e = t(
        /*! ./sam2/image_processing_sam2.js */
        "./src/models/sam2/image_processing_sam2.js"
      ), De = t(
        /*! ./sam3/image_processing_sam3.js */
        "./src/models/sam3/image_processing_sam3.js"
      ), he = t(
        /*! ./segformer/image_processing_segformer.js */
        "./src/models/segformer/image_processing_segformer.js"
      ), Z = t(
        /*! ./siglip/image_processing_siglip.js */
        "./src/models/siglip/image_processing_siglip.js"
      ), me = t(
        /*! ./smolvlm/image_processing_smolvlm.js */
        "./src/models/smolvlm/image_processing_smolvlm.js"
      ), we = t(
        /*! ./swin2sr/image_processing_swin2sr.js */
        "./src/models/swin2sr/image_processing_swin2sr.js"
      ), xe = t(
        /*! ./vit/image_processing_vit.js */
        "./src/models/vit/image_processing_vit.js"
      ), et = t(
        /*! ./vitmatte/image_processing_vitmatte.js */
        "./src/models/vitmatte/image_processing_vitmatte.js"
      ), Ve = t(
        /*! ./vitpose/image_processing_vitpose.js */
        "./src/models/vitpose/image_processing_vitpose.js"
      ), nt = t(
        /*! ./yolos/image_processing_yolos.js */
        "./src/models/yolos/image_processing_yolos.js"
      );
    }
  ),
  /***/
  "./src/models/janus/image_processing_janus.js": (
    /*!****************************************************!*\
      !*** ./src/models/janus/image_processing_janus.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        VLMImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        constructor(c) {
          super({
            do_pad: !0,
            pad_size: {
              width: c.image_size,
              height: c.image_size
            },
            ...c
          }), this.constant_values = this.config.background_color.map((u) => u * this.rescale_factor);
        }
        pad_image(c, u, l, f) {
          return super.pad_image(c, u, l, {
            constant_values: this.constant_values,
            center: !0,
            ...f
          });
        }
      }
    }
  ),
  /***/
  "./src/models/janus/processing_janus.js": (
    /*!**********************************************!*\
      !*** ./src/models/janus/processing_janus.js ***!
      \**********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        VLChatProcessor: () => (
          /* binding */
          f
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), c = t(
        /*! ../../utils/core.js */
        "./src/utils/core.js"
      ), u = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      ), l = t(
        /*! ../../utils/image.js */
        "./src/utils/image.js"
      );
      class f extends i.Processor {
        constructor(h, p, _) {
          super(h, p, _), this.image_tag = this.config.image_tag, this.image_start_tag = this.config.image_start_tag, this.image_end_tag = this.config.image_end_tag, this.num_image_tokens = this.config.num_image_tokens;
        }
        /**
         * @typedef {Object} MultimodalMessageProperties Additional properties for multimodal messages.
         * @property {(RawImage | string | URL)[]} [images] The images in the message.
         * @typedef {(import('../../tokenizers.js').Message & MultimodalMessageProperties)[]} MultimodalConversation The conversation possibly containing multimodal inputs.
         */
        /**
         * @typedef {Object} VLCChatProcessorResult The processed input.
         * @property {Tensor} input_ids The input IDs.
         * @property {Tensor} attention_mask The attention mask.
         * @property {Tensor} images_seq_mask The image sequence mask.
         * @property {Tensor} images_emb_mask The image embedding mask.
         */
        /**
         * @param {MultimodalConversation} conversation The chat messages to process.
         * @param {Object} options Additional options for processing.
         * @param {RawImage|RawImage[]} [options.images] The images to process, if not set in the conversation.
         * @param {string} [options.chat_template="default"] The chat template to use.
         * @returns {Promise<VLCChatProcessorResult | VLCChatProcessorResult & import('../../base/image_processors_utils.js').ImageProcessorResult>} The processed input.
         */
        async _call(h, {
          images: p = null,
          chat_template: _ = "default"
        } = {}) {
          p ? Array.isArray(p) || (p = [p]) : p = await Promise.all(
            h.filter((q) => q.images).flatMap((q) => q.images).map((q) => l.RawImage.read(q))
          );
          const v = this.tokenizer, S = v.apply_chat_template(h, {
            tokenize: !1,
            add_generation_prompt: !0,
            chat_template: _
          }), D = (q) => v.encode(q, { add_special_tokens: !1 }), w = (
            /** @type {string} */
            S.split(this.image_tag)
          ), T = w.length - 1;
          if (p.length !== T)
            throw new Error(`Number of images provided (${p.length}) does not match number of "${this.image_tag}" image tags (${T})`);
          const [
            F,
            E,
            A
          ] = v.model.convert_tokens_to_ids([
            this.image_tag,
            this.image_start_tag,
            this.image_end_tag
          ]);
          let L = D(w[0]), I = new Array(L.length).fill(!1);
          for (let q = 1; q < w.length; ++q) {
            const ne = new Array(this.num_image_tokens).fill(F), Q = D(w[q]);
            L = (0, c.mergeArrays)(
              L,
              [E],
              ne,
              [A],
              Q
            );
            const W = new Array(this.num_image_tokens).fill(!0);
            I = (0, c.mergeArrays)(
              I,
              [!1],
              W,
              [!1],
              new Array(Q.length).fill(!1)
            );
          }
          const R = [1, L.length], N = {
            input_ids: new u.Tensor("int64", L, R),
            attention_mask: new u.Tensor("int64", new Array(L.length).fill(1), R),
            images_seq_mask: new u.Tensor("bool", I, R),
            images_emb_mask: new u.Tensor(
              "bool",
              new Array(T * this.num_image_tokens).fill(!0),
              [1, T, this.num_image_tokens]
            )
          };
          if (p && p.length > 0) {
            const q = await this.image_processor(p);
            return q.pixel_values.unsqueeze_(0), { ...N, ...q };
          }
          return N;
        }
      }
      Ce(f, "image_processor_class", r.AutoImageProcessor), Ce(f, "tokenizer_class", a.AutoTokenizer), Ce(f, "uses_processor_config", !0);
    }
  ),
  /***/
  "./src/models/jina_clip/image_processing_jina_clip.js": (
    /*!************************************************************!*\
      !*** ./src/models/jina_clip/image_processing_jina_clip.js ***!
      \************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        JinaCLIPImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        constructor(c) {
          const { resize_mode: u, fill_color: l, interpolation: f, size: m, ...h } = c, p = u === "squash" ? { width: m, height: m } : u === "shortest" ? { shortest_edge: m } : { longest_edge: m }, _ = f === "bicubic" ? 3 : 2;
          super({
            ...h,
            size: p,
            resample: _,
            do_center_crop: !0,
            crop_size: m,
            do_normalize: !0
          });
        }
      }
    }
  ),
  /***/
  "./src/models/jina_clip/processing_jina_clip.js": (
    /*!******************************************************!*\
      !*** ./src/models/jina_clip/processing_jina_clip.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        JinaCLIPProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      class c extends i.Processor {
        async _call(l = null, f = null, m = {}) {
          if (!l && !f)
            throw new Error("Either text or images must be provided");
          const h = l ? this.tokenizer(l, m) : {}, p = f ? await this.image_processor(f, m) : {};
          return {
            ...h,
            ...p
          };
        }
      }
      Ce(c, "tokenizer_class", a.AutoTokenizer), Ce(c, "image_processor_class", r.AutoImageProcessor);
    }
  ),
  /***/
  "./src/models/llava/processing_llava.js": (
    /*!**********************************************!*\
      !*** ./src/models/llava/processing_llava.js ***!
      \**********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        LlavaProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      class c extends i.Processor {
        /**
         * @typedef {import('../../utils/image.js').RawImage} RawImage
         */
        // `images` is required, `text` is optional
        async _call(l, f = null, m = {}) {
          const h = await this.image_processor(l, m);
          if (f) {
            const [_, v] = h.pixel_values.dims.slice(-2), { image_token: S, patch_size: D, num_additional_image_tokens: w } = this.config, T = Math.floor(
              _ / D
            ) * Math.floor(v / D) + w;
            f = structuredClone(f), Array.isArray(f) || (f = [f]);
            for (let F = 0; F < f.length; ++F)
              f[F] = f[F].replace(S, S.repeat(T));
          }
          const p = f ? this.tokenizer(f, m) : {};
          return {
            ...h,
            ...p
          };
        }
      }
      Ce(c, "tokenizer_class", a.AutoTokenizer), Ce(c, "image_processor_class", r.AutoImageProcessor), Ce(c, "uses_processor_config", !0);
    }
  ),
  /***/
  "./src/models/llava_onevision/image_processing_llava_onevision.js": (
    /*!************************************************************************!*\
      !*** ./src/models/llava_onevision/image_processing_llava_onevision.js ***!
      \************************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        LlavaOnevisionImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/mask2former/image_processing_mask2former.js": (
    /*!****************************************************************!*\
      !*** ./src/models/mask2former/image_processing_mask2former.js ***!
      \****************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Mask2FormerImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../maskformer/image_processing_maskformer.js */
        "./src/models/maskformer/image_processing_maskformer.js"
      );
      class r extends i.MaskFormerImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/maskformer/image_processing_maskformer.js": (
    /*!**************************************************************!*\
      !*** ./src/models/maskformer/image_processing_maskformer.js ***!
      \**************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MaskFormerFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        MaskFormerImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        /** @type {typeof post_process_panoptic_segmentation} */
        post_process_panoptic_segmentation(...u) {
          return (0, i.post_process_panoptic_segmentation)(...u);
        }
        /** @type {typeof post_process_instance_segmentation} */
        post_process_instance_segmentation(...u) {
          return (0, i.post_process_instance_segmentation)(...u);
        }
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/mgp_str/processing_mgp_str.js": (
    /*!**************************************************!*\
      !*** ./src/models/mgp_str/processing_mgp_str.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MgpstrProcessor: () => (
          /* binding */
          l
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), c = t(
        /*! ../../utils/maths.js */
        "./src/utils/maths.js"
      );
      const u = {
        char: ["char_decode", 1],
        bpe: ["bpe_decode", 2],
        wp: ["wp_decode", 102]
      };
      class l extends i.Processor {
        /**
         * @returns {import('../../tokenizers.js').MgpstrTokenizer} The character tokenizer.
         */
        get char_tokenizer() {
          return this.components.char_tokenizer;
        }
        /**
         * @returns {import('../../tokenizers.js').GPT2Tokenizer} The BPE tokenizer.
         */
        get bpe_tokenizer() {
          return this.components.bpe_tokenizer;
        }
        /**
         * @returns {import('../../tokenizers.js').BertTokenizer} The WordPiece tokenizer.
         */
        get wp_tokenizer() {
          return this.components.wp_tokenizer;
        }
        /**
         * Helper function to decode the model prediction logits.
         * @param {import('../../utils/tensor.js').Tensor} pred_logits Model prediction logits.
         * @param {string} format Type of model prediction. Must be one of ['char', 'bpe', 'wp'].
         * @returns {[string[], number[]]} The decoded sentences and their confidence scores.
         */
        _decode_helper(m, h) {
          if (!u.hasOwnProperty(h))
            throw new Error(`Format ${h} is not supported.`);
          const [p, _] = u[h], v = this[p].bind(this), [S, D] = m.dims, w = [], T = [], F = m.tolist();
          for (let A = 0; A < S; ++A) {
            const L = F[A], I = [], R = [];
            for (let q = 1; q < D; ++q) {
              const [ne, Q] = (0, c.max)((0, c.softmax)(L[q]));
              if (R.push(ne), Q == _)
                break;
              I.push(Q);
            }
            const N = R.length > 0 ? R.reduce((q, ne) => q * ne, 1) : 0;
            T.push(I), w.push(N);
          }
          return [v(T), w];
        }
        /**
         * Convert a list of lists of char token ids into a list of strings by calling char tokenizer.
         * @param {number[][]} sequences List of tokenized input ids.
         * @returns {string[]} The list of char decoded sentences.
         */
        char_decode(m) {
          return this.char_tokenizer.batch_decode(m).map((h) => h.replaceAll(" ", ""));
        }
        /**
         * Convert a list of lists of BPE token ids into a list of strings by calling BPE tokenizer.
         * @param {number[][]} sequences List of tokenized input ids.
         * @returns {string[]} The list of BPE decoded sentences.
         */
        bpe_decode(m) {
          return this.bpe_tokenizer.batch_decode(m);
        }
        /**
         * Convert a list of lists of word piece token ids into a list of strings by calling word piece tokenizer.
         * @param {number[][]} sequences List of tokenized input ids.
         * @returns {string[]} The list of wp decoded sentences.
         */
        wp_decode(m) {
          return this.wp_tokenizer.batch_decode(m).map((h) => h.replaceAll(" ", ""));
        }
        /**
         * Convert a list of lists of token ids into a list of strings by calling decode.
         * @param {[import('../../utils/tensor.js').Tensor, import('../../utils/tensor.js').Tensor, import('../../utils/tensor.js').Tensor]} sequences List of tokenized input ids.
         * @returns {{generated_text: string[], scores: number[], char_preds: string[], bpe_preds: string[], wp_preds: string[]}}
         * Dictionary of all the outputs of the decoded results.
         * - generated_text: The final results after fusion of char, bpe, and wp.
         * - scores: The final scores after fusion of char, bpe, and wp.
         * - char_preds: The list of character decoded sentences.
         * - bpe_preds: The list of BPE decoded sentences.
         * - wp_preds: The list of wp decoded sentences.
         */
        // @ts-expect-error The type of this method is not compatible with the one in the base class.
        batch_decode([m, h, p]) {
          const [_, v] = this._decode_helper(m, "char"), [S, D] = this._decode_helper(h, "bpe"), [w, T] = this._decode_helper(p, "wp"), F = [], E = [];
          for (let A = 0; A < _.length; ++A) {
            const [L, I] = (0, c.max)([v[A], D[A], T[A]]);
            F.push([_[A], S[A], w[A]][I]), E.push(L);
          }
          return {
            generated_text: F,
            scores: E,
            char_preds: _,
            bpe_preds: S,
            wp_preds: w
          };
        }
        /** @type {typeof Processor.from_pretrained} */
        static async from_pretrained(...m) {
          const h = await super.from_pretrained(...m), p = await a.AutoTokenizer.from_pretrained("Xenova/gpt2"), _ = await a.AutoTokenizer.from_pretrained("Xenova/bert-base-uncased");
          return h.components = {
            image_processor: h.image_processor,
            char_tokenizer: h.tokenizer,
            bpe_tokenizer: p,
            wp_tokenizer: _
          }, h;
        }
        async _call(m, h = null) {
          const p = await this.image_processor(m);
          return h && (p.labels = this.tokenizer(h).input_ids), p;
        }
      }
      Ce(l, "tokenizer_class", a.AutoTokenizer), Ce(l, "image_processor_class", r.AutoImageProcessor);
    }
  ),
  /***/
  "./src/models/mobilenet_v1/image_processing_mobilenet_v1.js": (
    /*!******************************************************************!*\
      !*** ./src/models/mobilenet_v1/image_processing_mobilenet_v1.js ***!
      \******************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MobileNetV1FeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        MobileNetV1ImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/mobilenet_v2/image_processing_mobilenet_v2.js": (
    /*!******************************************************************!*\
      !*** ./src/models/mobilenet_v2/image_processing_mobilenet_v2.js ***!
      \******************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MobileNetV2FeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        MobileNetV2ImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/mobilenet_v3/image_processing_mobilenet_v3.js": (
    /*!******************************************************************!*\
      !*** ./src/models/mobilenet_v3/image_processing_mobilenet_v3.js ***!
      \******************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MobileNetV3FeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        MobileNetV3ImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/mobilenet_v4/image_processing_mobilenet_v4.js": (
    /*!******************************************************************!*\
      !*** ./src/models/mobilenet_v4/image_processing_mobilenet_v4.js ***!
      \******************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MobileNetV4FeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        MobileNetV4ImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/mobilevit/image_processing_mobilevit.js": (
    /*!************************************************************!*\
      !*** ./src/models/mobilevit/image_processing_mobilevit.js ***!
      \************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MobileViTFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        MobileViTImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/moonshine/feature_extraction_moonshine.js": (
    /*!**************************************************************!*\
      !*** ./src/models/moonshine/feature_extraction_moonshine.js ***!
      \**************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MoonshineFeatureExtractor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.FeatureExtractor {
        /**
         * Asynchronously extracts input values from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_values: Tensor; }>} The extracted input values.
         */
        async _call(u) {
          (0, i.validate_audio_inputs)(u, "MoonshineFeatureExtractor"), u instanceof Float64Array && (u = new Float32Array(u));
          const l = [
            1,
            /* batch_size */
            u.length
            /* num_samples */
          ];
          return {
            input_values: new r.Tensor("float32", u, l)
          };
        }
      }
    }
  ),
  /***/
  "./src/models/moonshine/processing_moonshine.js": (
    /*!******************************************************!*\
      !*** ./src/models/moonshine/processing_moonshine.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MoonshineProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      ), r = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), a = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      );
      class c extends a.Processor {
        /**
         * Calls the feature_extractor function with the given audio input.
         * @param {any} audio The audio input to extract features from.
         * @returns {Promise<any>} A Promise that resolves with the extracted features.
         */
        async _call(l) {
          return await this.feature_extractor(l);
        }
      }
      Ce(c, "tokenizer_class", r.AutoTokenizer), Ce(c, "feature_extractor_class", i.AutoFeatureExtractor);
    }
  ),
  /***/
  "./src/models/nougat/image_processing_nougat.js": (
    /*!******************************************************!*\
      !*** ./src/models/nougat/image_processing_nougat.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        NougatImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../donut/image_processing_donut.js */
        "./src/models/donut/image_processing_donut.js"
      );
      class r extends i.DonutImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/owlv2/image_processing_owlv2.js": (
    /*!****************************************************!*\
      !*** ./src/models/owlv2/image_processing_owlv2.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Owlv2ImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../owlvit/image_processing_owlvit.js */
        "./src/models/owlvit/image_processing_owlvit.js"
      );
      class r extends i.OwlViTImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/owlvit/image_processing_owlvit.js": (
    /*!******************************************************!*\
      !*** ./src/models/owlvit/image_processing_owlvit.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        OwlViTFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        OwlViTImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        /** @type {typeof post_process_object_detection} */
        post_process_object_detection(...u) {
          return (0, i.post_process_object_detection)(...u);
        }
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/owlvit/processing_owlvit.js": (
    /*!************************************************!*\
      !*** ./src/models/owlvit/processing_owlvit.js ***!
      \************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        OwlViTProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      class c extends i.Processor {
      }
      Ce(c, "tokenizer_class", a.AutoTokenizer), Ce(c, "image_processor_class", r.AutoImageProcessor);
    }
  ),
  /***/
  "./src/models/paligemma/processing_paligemma.js": (
    /*!******************************************************!*\
      !*** ./src/models/paligemma/processing_paligemma.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        PaliGemmaProcessor: () => (
          /* binding */
          l
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      const c = "<image>";
      function u(f, m, h, p, _) {
        return `${p.repeat(h * _)}${m}${f}
`;
      }
      class l extends i.Processor {
        /**
         * @typedef {import('../../utils/image.js').RawImage} RawImage
         */
        // `images` is required, `text` is optional
        async _call(m, h = null, p = {}) {
          h || (console.warn(
            "You are using PaliGemma without a text prefix. It will perform as a picture-captioning model."
          ), h = ""), Array.isArray(m) || (m = [m]), Array.isArray(h) || (h = [h]);
          const _ = this.tokenizer.bos_token, v = this.image_processor.config.image_seq_length;
          let S;
          h.some((T) => T.includes(c)) ? S = h.map(
            (T) => {
              const F = T.replaceAll(c, c.repeat(v)), E = F.lastIndexOf(c), A = E === -1 ? 0 : E + c.length;
              return F.slice(0, A) + _ + F.slice(A) + `
`;
            }
          ) : (console.warn(
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text. For this call, we will infer how many images each text has and add special tokens."
          ), S = h.map(
            (T) => u(
              T,
              _,
              v,
              c,
              m.length
            )
          ));
          const D = this.tokenizer(S, p);
          return {
            ...await this.image_processor(m, p),
            ...D
          };
        }
      }
      Ce(l, "tokenizer_class", a.AutoTokenizer), Ce(l, "image_processor_class", r.AutoImageProcessor), Ce(l, "uses_processor_config", !1);
    }
  ),
  /***/
  "./src/models/parakeet/feature_extraction_parakeet.js": (
    /*!************************************************************!*\
      !*** ./src/models/parakeet/feature_extraction_parakeet.js ***!
      \************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ParakeetFeatureExtractor: () => (
          /* binding */
          u
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      ), a = t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      );
      const c = 1e-5;
      class u extends i.FeatureExtractor {
        constructor(f) {
          var p;
          super(f), (p = this.config).mel_filters ?? (p.mel_filters = (0, a.mel_filter_bank)(
            Math.floor(1 + this.config.n_fft / 2),
            // num_frequency_bins
            this.config.feature_size,
            // num_mel_filters
            0,
            // min_frequency
            this.config.sampling_rate / 2,
            // max_frequency
            this.config.sampling_rate,
            // sampling_rate
            "slaney",
            // norm
            "slaney"
            // mel_scale
          ));
          const m = (0, a.window_function)(this.config.win_length, "hann", {
            periodic: !1
          });
          this.window = new Float64Array(this.config.n_fft);
          const h = Math.floor((this.config.n_fft - this.config.win_length) / 2);
          this.window.set(m, h);
        }
        /**
         * Computes the log-Mel spectrogram of the provided audio waveform.
         * @param {Float32Array|Float64Array} waveform The audio waveform to process.
         * @returns {Promise<Tensor>} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
         */
        async _extract_fbank_features(f) {
          const m = this.config.preemphasis;
          f = new Float64Array(f);
          for (let p = f.length - 1; p >= 1; --p)
            f[p] -= m * f[p - 1];
          return await (0, a.spectrogram)(
            f,
            this.window,
            // window
            this.window.length,
            // frame_length
            this.config.hop_length,
            // hop_length
            {
              fft_length: this.config.n_fft,
              power: 2,
              mel_filters: this.config.mel_filters,
              log_mel: "log",
              mel_floor: -1 / 0,
              pad_mode: "constant",
              center: !0,
              // Custom
              transpose: !0,
              mel_offset: 2 ** -24
            }
          );
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_features: Tensor; attention_mask: Tensor; }>} A Promise resolving to an object containing the extracted input features as a Tensor.
         */
        async _call(f) {
          (0, i.validate_audio_inputs)(f, "ParakeetFeatureExtractor");
          const m = await this._extract_fbank_features(f), h = Math.floor(
            (f.length + Math.floor(this.config.n_fft / 2) * 2 - this.config.n_fft) / this.config.hop_length
          ), p = (
            /** @type {Float32Array} */
            m.data
          );
          p.fill(0, h * m.dims[1]);
          const [_, v] = m.dims, S = new Float64Array(v), D = new Float64Array(v);
          for (let F = 0; F < h; ++F) {
            const E = F * v;
            for (let A = 0; A < v; ++A) {
              const L = p[E + A];
              S[A] += L, D[A] += L * L;
            }
          }
          const w = h > 1 ? h - 1 : 1;
          for (let F = 0; F < v; ++F) {
            const E = S[F] / h, A = (D[F] - h * E * E) / w, I = 1 / (Math.sqrt(A) + c);
            for (let R = 0; R < h; ++R) {
              const N = R * v + F;
              p[N] = (p[N] - E) * I;
            }
          }
          const T = new BigInt64Array(_);
          return T.fill(1n, 0, h), {
            input_features: m.unsqueeze_(0),
            attention_mask: new r.Tensor("int64", T, [1, _])
          };
        }
      }
    }
  ),
  /***/
  "./src/models/phi3_v/image_processing_phi3_v.js": (
    /*!******************************************************!*\
      !*** ./src/models/phi3_v/image_processing_phi3_v.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Phi3VImageProcessor: () => (
          /* binding */
          m
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      const a = 336, c = [2, 3], { ceil: u, floor: l, sqrt: f } = Math;
      class m extends i.ImageProcessor {
        constructor(p) {
          super({
            ...p,
            do_normalize: !0,
            do_pad: !0,
            pad_size: "custom",
            do_convert_rgb: !0,
            do_resize: !0
            // Smart resizing "hd_transform"
          }), this._num_crops = p.num_crops;
        }
        calc_num_image_tokens_from_image_size(p, _) {
          const { num_img_tokens: v } = this.config;
          return l((l(_ / a) * l(p / a) + 1) * v + 1 + (l(_ / a) + 1) * f(v));
        }
        /** @type {ImageProcessor['get_resize_output_image_size']} */
        get_resize_output_image_size(p, _) {
          const v = this._num_crops, [S, D] = p.size;
          let w = S / D, T = 1;
          for (; T * Math.ceil(T / w) <= v; )
            T += 1;
          T -= 1;
          const F = Math.floor(T * 336), E = Math.floor(F / w);
          return [F, E];
        }
        /** @type {ImageProcessor['pad_image']} */
        pad_image(p, _, v, S = {}) {
          const [D, w] = _, T = a * u(D / a), F = a * u(w / a), E = [1, 1, 1].map((A, L) => (A - this.image_mean[L]) / this.image_std[L]);
          return super.pad_image(p, _, { width: F, height: T }, {
            center: !0,
            constant_values: E,
            ...S
          });
        }
        async _call(p, {
          num_crops: _ = null
        } = {}) {
          if (this._num_crops = _ ?? (_ = this.config.num_crops), _ < 4 || f(_) % 1 !== 0)
            throw new Error("num_crops must be a square number >= 4");
          Array.isArray(p) || (p = [p]);
          const v = p.length, S = await Promise.all(p.map((I) => this.preprocess(I))), D = S.map((I) => I.original_size), w = S.map((I) => I.reshaped_input_size), T = [];
          for (const { pixel_values: I } of S) {
            I.unsqueeze_(0);
            const [R, N] = I.dims.slice(-2), q = await (0, r.interpolate_4d)(I, {
              size: [a, a],
              mode: "bicubic"
            });
            if (_ > 0) {
              const ne = [], Q = f(_), W = l(N / Q), te = l(R / Q);
              for (let pe = 0; pe < Q; ++pe)
                for (let be = 0; be < Q; ++be) {
                  let Ee, Ge, _e, De;
                  pe === Q - 1 ? (Ge = R - te, De = R) : (Ge = pe * te, De = (pe + 1) * te), be === Q - 1 ? (Ee = N - W, _e = N) : (Ee = be * W, _e = (be + 1) * W);
                  const he = [Ge, Ee], Z = [De, _e], me = await (0, r.slice)(I, he, Z, c);
                  ne.push(me);
                }
              const K = await (0, r.interpolate_4d)((0, r.cat)(ne, 0), {
                size: [a, a],
                mode: "bicubic"
              });
              T.push((0, r.cat)([q, K], 0));
            } else
              T.push(q);
          }
          const F = (0, r.stack)(T, 0), E = w.map((I) => I.map((R) => a * u(R / a))), A = new r.Tensor(
            "int64",
            E.flat(),
            [v, 2]
          ), L = E.map(
            ([I, R]) => this.calc_num_image_tokens_from_image_size(R, I)
          );
          return { pixel_values: F, original_sizes: D, reshaped_input_sizes: w, image_sizes: A, num_img_tokens: L };
        }
      }
    }
  ),
  /***/
  "./src/models/phi3_v/processing_phi3_v.js": (
    /*!************************************************!*\
      !*** ./src/models/phi3_v/processing_phi3_v.js ***!
      \************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Phi3VProcessor: () => (
          /* binding */
          l
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      t(
        /*! ../../utils/image.js */
        "./src/utils/image.js"
      );
      const c = "<|image|>", u = /<\|image_\d+\|>/g;
      class l extends i.Processor {
        /**
         * 
         * @param {string|string[]} text 
         * @param {RawImage|RawImage[]} images 
         * @param  { { padding?: boolean, truncation?: boolean, num_crops?: number } | undefined } options
         * @returns {Promise<any>}
         */
        async _call(m, h = null, {
          padding: p = !0,
          truncation: _ = !0,
          num_crops: v = null
        } = {}) {
          Array.isArray(m) || (m = [m]);
          let S, D;
          if (h) {
            D = await this.image_processor(h, { num_crops: v });
            const { num_img_tokens: w } = D, T = m.map((E, A) => E.split(u).join(c.repeat(w[A])));
            S = this.tokenizer(T, { padding: p, truncation: _ });
            const F = this.tokenizer.model.convert_tokens_to_ids([c])[0];
            S.input_ids.map_((E) => E == F ? -E : E);
          } else
            S = this.tokenizer(m);
          return {
            ...S,
            ...D
          };
        }
      }
      Ce(l, "image_processor_class", r.AutoImageProcessor), Ce(l, "tokenizer_class", a.AutoTokenizer);
    }
  ),
  /***/
  "./src/models/pixtral/image_processing_pixtral.js": (
    /*!********************************************************!*\
      !*** ./src/models/pixtral/image_processing_pixtral.js ***!
      \********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        PixtralImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        /** @type {ImageProcessor['get_resize_output_image_size']} */
        get_resize_output_image_size(c, u) {
          const { longest_edge: l } = u;
          if (l === void 0)
            throw new Error("size must contain 'longest_edge'");
          const [f, m] = c.size, h = Math.max(f, m) / l;
          let p = f, _ = m;
          h > 1 && (p = Math.floor(f / h), _ = Math.floor(m / h));
          const { patch_size: v, spatial_merge_size: S } = this.config;
          if (!S)
            throw new Error("config must contain 'spatial_merge_size'");
          const D = v * S, w = Math.floor((p - 1) / D) + 1, T = Math.floor((_ - 1) / D) + 1;
          return [w * D, T * D];
        }
      }
    }
  ),
  /***/
  "./src/models/pixtral/processing_pixtral.js": (
    /*!**************************************************!*\
      !*** ./src/models/pixtral/processing_pixtral.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        PixtralProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      class c extends i.Processor {
        /**
         * @typedef {import('../../utils/image.js').RawImage} RawImage
         */
        // `images` is required, `text` is optional
        async _call(l, f = null, m = {}) {
          const h = await this.image_processor(l, m);
          if (f) {
            const [_, v] = h.pixel_values.dims.slice(-2), { image_token: S, image_break_token: D, image_end_token: w, patch_size: T, spatial_merge_size: F } = this.config, E = T * F, A = Math.floor(_ / E), L = Math.floor(v / E);
            f = structuredClone(f), Array.isArray(f) || (f = [f]);
            for (let I = 0; I < f.length; ++I) {
              const R = S.repeat(L), N = R + D, q = R + w, ne = N.repeat(A - 1) + q;
              f[I] = f[I].replace(S, ne);
            }
          }
          const p = f ? this.tokenizer(f, m) : {};
          return {
            ...h,
            ...p
          };
        }
      }
      Ce(c, "tokenizer_class", a.AutoTokenizer), Ce(c, "image_processor_class", r.AutoImageProcessor), Ce(c, "uses_processor_config", !0);
    }
  ),
  /***/
  "./src/models/processors.js": (
    /*!**********************************!*\
      !*** ./src/models/processors.js ***!
      \**********************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Florence2Processor: () => (
          /* reexport safe */
          i.Florence2Processor
        ),
        /* harmony export */
        Gemma3nProcessor: () => (
          /* reexport safe */
          r.Gemma3nProcessor
        ),
        /* harmony export */
        GroundingDinoProcessor: () => (
          /* reexport safe */
          a.GroundingDinoProcessor
        ),
        /* harmony export */
        Idefics3Processor: () => (
          /* reexport safe */
          c.Idefics3Processor
        ),
        /* harmony export */
        JinaCLIPProcessor: () => (
          /* reexport safe */
          l.JinaCLIPProcessor
        ),
        /* harmony export */
        LlavaProcessor: () => (
          /* reexport safe */
          f.LlavaProcessor
        ),
        /* harmony export */
        MgpstrProcessor: () => (
          /* reexport safe */
          m.MgpstrProcessor
        ),
        /* harmony export */
        MoonshineProcessor: () => (
          /* reexport safe */
          h.MoonshineProcessor
        ),
        /* harmony export */
        OwlViTProcessor: () => (
          /* reexport safe */
          p.OwlViTProcessor
        ),
        /* harmony export */
        PaliGemmaProcessor: () => (
          /* reexport safe */
          _.PaliGemmaProcessor
        ),
        /* harmony export */
        Phi3VProcessor: () => (
          /* reexport safe */
          v.Phi3VProcessor
        ),
        /* harmony export */
        PixtralProcessor: () => (
          /* reexport safe */
          S.PixtralProcessor
        ),
        /* harmony export */
        PyAnnoteProcessor: () => (
          /* reexport safe */
          D.PyAnnoteProcessor
        ),
        /* harmony export */
        Qwen2VLProcessor: () => (
          /* reexport safe */
          w.Qwen2VLProcessor
        ),
        /* harmony export */
        Sam2Processor: () => (
          /* reexport safe */
          F.Sam2Processor
        ),
        /* harmony export */
        Sam2VideoProcessor: () => (
          /* reexport safe */
          F.Sam2VideoProcessor
        ),
        /* harmony export */
        SamProcessor: () => (
          /* reexport safe */
          T.SamProcessor
        ),
        /* harmony export */
        SmolVLMProcessor: () => (
          /* reexport safe */
          E.SmolVLMProcessor
        ),
        /* harmony export */
        SpeechT5Processor: () => (
          /* reexport safe */
          A.SpeechT5Processor
        ),
        /* harmony export */
        UltravoxProcessor: () => (
          /* reexport safe */
          L.UltravoxProcessor
        ),
        /* harmony export */
        VLChatProcessor: () => (
          /* reexport safe */
          u.VLChatProcessor
        ),
        /* harmony export */
        VoxtralProcessor: () => (
          /* reexport safe */
          I.VoxtralProcessor
        ),
        /* harmony export */
        Wav2Vec2Processor: () => (
          /* reexport safe */
          R.Wav2Vec2Processor
        ),
        /* harmony export */
        Wav2Vec2ProcessorWithLM: () => (
          /* reexport safe */
          N.Wav2Vec2ProcessorWithLM
        ),
        /* harmony export */
        WhisperProcessor: () => (
          /* reexport safe */
          q.WhisperProcessor
        )
        /* harmony export */
      });
      var i = t(
        /*! ./florence2/processing_florence2.js */
        "./src/models/florence2/processing_florence2.js"
      ), r = t(
        /*! ./gemma3n/processing_gemma3n.js */
        "./src/models/gemma3n/processing_gemma3n.js"
      ), a = t(
        /*! ./grounding_dino/processing_grounding_dino.js */
        "./src/models/grounding_dino/processing_grounding_dino.js"
      ), c = t(
        /*! ./idefics3/processing_idefics3.js */
        "./src/models/idefics3/processing_idefics3.js"
      ), u = t(
        /*! ./janus/processing_janus.js */
        "./src/models/janus/processing_janus.js"
      ), l = t(
        /*! ./jina_clip/processing_jina_clip.js */
        "./src/models/jina_clip/processing_jina_clip.js"
      ), f = t(
        /*! ./llava/processing_llava.js */
        "./src/models/llava/processing_llava.js"
      ), m = t(
        /*! ./mgp_str/processing_mgp_str.js */
        "./src/models/mgp_str/processing_mgp_str.js"
      ), h = t(
        /*! ./moonshine/processing_moonshine.js */
        "./src/models/moonshine/processing_moonshine.js"
      ), p = t(
        /*! ./owlvit/processing_owlvit.js */
        "./src/models/owlvit/processing_owlvit.js"
      ), _ = t(
        /*! ./paligemma/processing_paligemma.js */
        "./src/models/paligemma/processing_paligemma.js"
      ), v = t(
        /*! ./phi3_v/processing_phi3_v.js */
        "./src/models/phi3_v/processing_phi3_v.js"
      ), S = t(
        /*! ./pixtral/processing_pixtral.js */
        "./src/models/pixtral/processing_pixtral.js"
      ), D = t(
        /*! ./pyannote/processing_pyannote.js */
        "./src/models/pyannote/processing_pyannote.js"
      ), w = t(
        /*! ./qwen2_vl/processing_qwen2_vl.js */
        "./src/models/qwen2_vl/processing_qwen2_vl.js"
      ), T = t(
        /*! ./sam/processing_sam.js */
        "./src/models/sam/processing_sam.js"
      ), F = t(
        /*! ./sam2/processing_sam2.js */
        "./src/models/sam2/processing_sam2.js"
      ), E = t(
        /*! ./smolvlm/processing_smolvlm.js */
        "./src/models/smolvlm/processing_smolvlm.js"
      ), A = t(
        /*! ./speecht5/processing_speecht5.js */
        "./src/models/speecht5/processing_speecht5.js"
      ), L = t(
        /*! ./ultravox/processing_ultravox.js */
        "./src/models/ultravox/processing_ultravox.js"
      ), I = t(
        /*! ./voxtral/processing_voxtral.js */
        "./src/models/voxtral/processing_voxtral.js"
      ), R = t(
        /*! ./wav2vec2/processing_wav2vec2.js */
        "./src/models/wav2vec2/processing_wav2vec2.js"
      ), N = t(
        /*! ./wav2vec2_with_lm/processing_wav2vec2_with_lm.js */
        "./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js"
      ), q = t(
        /*! ./whisper/processing_whisper.js */
        "./src/models/whisper/processing_whisper.js"
      );
    }
  ),
  /***/
  "./src/models/pvt/image_processing_pvt.js": (
    /*!************************************************!*\
      !*** ./src/models/pvt/image_processing_pvt.js ***!
      \************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        PvtImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/pyannote/feature_extraction_pyannote.js": (
    /*!************************************************************!*\
      !*** ./src/models/pyannote/feature_extraction_pyannote.js ***!
      \************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        PyAnnoteFeatureExtractor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      ), a = t(
        /*! ../../utils/maths.js */
        "./src/utils/maths.js"
      );
      class c extends i.FeatureExtractor {
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_values: Tensor; }>} The extracted input features.
         */
        async _call(l) {
          (0, i.validate_audio_inputs)(l, "PyAnnoteFeatureExtractor"), l instanceof Float64Array && (l = new Float32Array(l));
          const f = [
            1,
            /* batch_size */
            1,
            /* num_channels */
            l.length
            /* num_samples */
          ];
          return {
            input_values: new r.Tensor("float32", l, f)
          };
        }
        /**
         * NOTE: Can return fractional values. `Math.ceil` will ensure correct value.
         * @param {number} samples The number of frames in the audio.
         * @returns {number} The number of frames in the audio.
         */
        samples_to_frames(l) {
          return (l - this.config.offset) / this.config.step;
        }
        /**
         * Post-processes the speaker diarization logits output by the model.
         * @param {import('../../utils/tensor.js').Tensor} logits The speaker diarization logits output by the model.
         * @param {number} num_samples Number of samples in the input audio.
         * @returns {Array<Array<{ id: number, start: number, end: number, confidence: number }>>} The post-processed speaker diarization results.
         */
        post_process_speaker_diarization(l, f) {
          const m = f / this.samples_to_frames(f) / this.config.sampling_rate, h = [];
          for (const p of l.tolist()) {
            const _ = [];
            let v = -1;
            for (let S = 0; S < p.length; ++S) {
              const D = (0, a.softmax)(p[S]), [w, T] = (0, a.max)(D), [F, E] = [S, S + 1];
              T !== v ? (v = T, _.push({ id: T, start: F, end: E, score: w })) : (_.at(-1).end = E, _.at(-1).score += w);
            }
            h.push(_.map(
              // Convert frame-space to time-space
              // and compute the confidence
              ({ id: S, start: D, end: w, score: T }) => ({
                id: S,
                start: D * m,
                end: w * m,
                confidence: T / (w - D)
              })
            ));
          }
          return h;
        }
      }
    }
  ),
  /***/
  "./src/models/pyannote/processing_pyannote.js": (
    /*!****************************************************!*\
      !*** ./src/models/pyannote/processing_pyannote.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        PyAnnoteProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ./feature_extraction_pyannote.js */
        "./src/models/pyannote/feature_extraction_pyannote.js"
      );
      class a extends i.Processor {
        /**
         * Calls the feature_extractor function with the given audio input.
         * @param {any} audio The audio input to extract features from.
         * @returns {Promise<any>} A Promise that resolves with the extracted features.
         */
        async _call(u) {
          return await this.feature_extractor(u);
        }
        /** @type {PyAnnoteFeatureExtractor['post_process_speaker_diarization']} */
        post_process_speaker_diarization(...u) {
          return (
            /** @type {PyAnnoteFeatureExtractor} */
            this.feature_extractor.post_process_speaker_diarization(...u)
          );
        }
        get sampling_rate() {
          return this.feature_extractor.config.sampling_rate;
        }
      }
      Ce(a, "feature_extractor_class", r.PyAnnoteFeatureExtractor);
    }
  ),
  /***/
  "./src/models/qwen2_vl/image_processing_qwen2_vl.js": (
    /*!**********************************************************!*\
      !*** ./src/models/qwen2_vl/image_processing_qwen2_vl.js ***!
      \**********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Qwen2VLImageProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.ImageProcessor {
        async _call(u, ...l) {
          const { pixel_values: f, original_sizes: m, reshaped_input_sizes: h } = await super._call(u, ...l);
          let p = f;
          const { temporal_patch_size: _, merge_size: v, patch_size: S } = this.config;
          p.dims[0] === 1 && (p = (0, r.cat)(Array.from({ length: _ }, () => p), 0));
          const D = p.dims[0] / _, w = p.dims[1], T = Math.floor(p.dims[2] / S), F = Math.floor(p.dims[3] / S), E = p.view(
            D,
            _,
            w,
            Math.floor(T / v),
            v,
            S,
            Math.floor(F / v),
            v,
            S
          ).permute(0, 3, 6, 4, 7, 2, 1, 5, 8).view(
            D * T * F,
            w * _ * S * S
          ), A = new r.Tensor("int64", [D, T, F], [1, 3]);
          return {
            pixel_values: E,
            image_grid_thw: A,
            original_sizes: m,
            reshaped_input_sizes: h
          };
        }
      }
    }
  ),
  /***/
  "./src/models/qwen2_vl/processing_qwen2_vl.js": (
    /*!****************************************************!*\
      !*** ./src/models/qwen2_vl/processing_qwen2_vl.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Qwen2VLProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      ), a = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      );
      t(
        /*! ../../utils/image.js */
        "./src/utils/image.js"
      );
      class c extends i.Processor {
        /**
         * 
         * @param {string|string[]} text 
         * @param {RawImage|RawImage[]} images 
         * @param  {...any} args 
         * @returns {Promise<any>}
         */
        async _call(l, f = null, ...m) {
          Array.isArray(l) || (l = [l]);
          let h, p;
          if (f && (h = await this.image_processor(f), p = h.image_grid_thw), p) {
            let v = this.image_processor.config.merge_size ** 2, S = 0;
            const D = p.tolist();
            l = l.map((w) => {
              for (; w.includes("<|image_pad|>"); ) {
                const T = Number(D[S++].reduce((F, E) => F * E, 1n));
                w = w.replace("<|image_pad|>", "<|placeholder|>".repeat(Math.floor(T / v)));
              }
              return w.replaceAll("<|placeholder|>", "<|image_pad|>");
            });
          }
          return {
            ...this.tokenizer(l),
            ...h
            // TODO: ...videos_inputs,
          };
        }
      }
      Ce(c, "image_processor_class", r.AutoImageProcessor), Ce(c, "tokenizer_class", a.AutoTokenizer);
    }
  ),
  /***/
  "./src/models/rt_detr/image_processing_rt_detr.js": (
    /*!********************************************************!*\
      !*** ./src/models/rt_detr/image_processing_rt_detr.js ***!
      \********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        RTDetrImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        /** @type {typeof post_process_object_detection} */
        post_process_object_detection(...c) {
          return (0, i.post_process_object_detection)(...c);
        }
      }
    }
  ),
  /***/
  "./src/models/sam/image_processing_sam.js": (
    /*!************************************************!*\
      !*** ./src/models/sam/image_processing_sam.js ***!
      \************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SamImageProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), r = t(
        /*! ../../utils/core.js */
        "./src/utils/core.js"
      ), a = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class c extends i.ImageProcessor {
        /**
         * 
         * @param {any} input_points 
         * @param {import("../../base/image_processors_utils.js").HeightWidth[]} original_sizes 
         * @param {import("../../base/image_processors_utils.js").HeightWidth[]} reshaped_input_sizes 
         * @returns {Tensor}
         */
        reshape_input_points(l, f, m, h = !1) {
          l = structuredClone(l);
          let p = (0, r.calculateDimensions)(l);
          if (p.length === 3)
            h || (p = [1, ...p]), l = [l];
          else if (p.length !== 4)
            throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");
          for (let _ = 0; _ < l.length; ++_) {
            const [v, S] = f[_], [D, w] = m[_], T = [
              w / S,
              D / v
            ];
            for (let F = 0; F < l[_].length; ++F)
              for (let E = 0; E < l[_][F].length; ++E)
                for (let A = 0; A < l[_][F][E].length; ++A)
                  l[_][F][E][A] *= T[A % 2];
          }
          return new a.Tensor(
            "float32",
            Float32Array.from(l.flat(1 / 0)),
            p
          );
        }
        /**
         * 
         * @param {any} input_labels 
         * @param {Tensor} input_points 
         * @returns {Tensor}
         */
        add_input_labels(l, f) {
          let m = (0, r.calculateDimensions)(l);
          if (m.length === 2)
            m = [1, ...m], l = [l];
          else if (m.length !== 3)
            throw Error("The input_points must be a 4D tensor of shape `batch_size`, `point_batch_size`, `nb_points_per_image`, `2`.");
          if (m.some((h, p) => h !== f.dims[p]))
            throw Error(`The first ${m.length} dimensions of 'input_points' and 'input_labels' must be the same.`);
          return new a.Tensor(
            "int64",
            l.flat(1 / 0).map(BigInt),
            m
          );
        }
        /**
         * @param {any[]} images The URL(s) of the image(s) to extract features from.
         * @param {Object} [options] Additional options for the processor.
         * @param {any} [options.input_points=null] A 3D or 4D array, representing the input points provided by the user.
         * - 3D: `[point_batch_size, nb_points_per_image, 2]`. In this case, `batch_size` is assumed to be 1.
         * - 4D: `[batch_size, point_batch_size, nb_points_per_image, 2]`.
         * @param {any} [options.input_labels=null] A 2D or 3D array, representing the input labels for the points, used by the prompt encoder to encode the prompt.
         * - 2D: `[point_batch_size, nb_points_per_image]`. In this case, `batch_size` is assumed to be 1.
         * - 3D: `[batch_size, point_batch_size, nb_points_per_image]`.
         * @param {number[][][]} [options.input_boxes=null] A 3D array of shape `(batch_size, num_boxes, 4)`, representing the input boxes provided by the user.
         * This is used by the prompt encoder to encode the prompt. Generally yields to much better generated masks.
         * The processor will generate a tensor, with each dimension corresponding respectively to the image batch size,
         * the number of boxes per image and the coordinates of the top left and botton right point of the box.
         * In the order (`x1`, `y1`, `x2`, `y2`):
         * - `x1`: the x coordinate of the top left point of the input box
         * - `y1`: the y coordinate of the top left point of the input box
         * - `x2`: the x coordinate of the bottom right point of the input box
         * - `y2`: the y coordinate of the bottom right point of the input box
         * @returns {Promise<SamImageProcessorResult>}
         */
        async _call(l, {
          input_points: f = null,
          input_labels: m = null,
          input_boxes: h = null
        } = {}) {
          const p = await super._call(l);
          if (f && (p.input_points = this.reshape_input_points(
            f,
            p.original_sizes,
            p.reshaped_input_sizes
          )), m) {
            if (!p.input_points)
              throw Error("`input_points` must be provided if `input_labels` are provided.");
            p.input_labels = this.add_input_labels(m, p.input_points);
          }
          return h && (p.input_boxes = this.reshape_input_points(
            h,
            p.original_sizes,
            p.reshaped_input_sizes,
            !0
          )), p;
        }
        /**
         * Remove padding and upscale masks to the original image size.
         * @param {Tensor} masks Batched masks from the mask_decoder in (batch_size, num_channels, height, width) format.
         * @param {[number, number][]} original_sizes The original sizes of each image before it was resized to the model's expected input shape, in (height, width) format.
         * @param {[number, number][]} reshaped_input_sizes The size of each image as it is fed to the model, in (height, width) format. Used to remove padding.
         * @param {Object} options Optional parameters for post-processing.
         * @param {number} [options.mask_threshold] The threshold to use for binarizing the masks.
         * @param {boolean} [options.binarize] Whether to binarize the masks.
         * @param {Object} [options.pad_size] The target size the images were padded to before being passed to the model. If `null`, the target size is assumed to be the processor's `pad_size`.
         * @param {number} [options.pad_size.height] The height the images were padded to.
         * @param {number} [options.pad_size.width] The width the images were padded to.
         * @returns {Promise<Tensor[]>} Batched masks in batch_size, num_channels, height, width) format, where (height, width) is given by original_size.
         */
        async post_process_masks(l, f, m, {
          mask_threshold: h = 0,
          binarize: p = !0,
          pad_size: _ = null
        } = {}) {
          const v = [];
          _ = _ ?? this.pad_size ?? this.size;
          const S = [_.height, _.width];
          for (let D = 0; D < f.length; ++D) {
            const w = f[D], T = m[D];
            let F = await (0, a.interpolate_4d)(
              l[D],
              { mode: "bilinear", size: S }
            );
            if (F = F.slice(null, null, [0, T[0]], [0, T[1]]), F = await (0, a.interpolate_4d)(
              F,
              { mode: "bilinear", size: w }
            ), p) {
              const E = F.data, A = new Uint8Array(E.length);
              for (let L = 0; L < E.length; ++L)
                E[L] > h && (A[L] = 1);
              F = new a.Tensor(
                "bool",
                A,
                F.dims
              );
            }
            v.push(F);
          }
          return v;
        }
        /**
         * Generates a list of crop boxes of different sizes. Each layer has (2**i)**2 boxes for the ith layer.
         * @param {import("../../utils/image.js").RawImage} image Input original image
         * @param {number} target_size Target size of the resized image
         * @param {Object} options Options for generating crop boxes 
         * @param {number} [options.crop_n_layers] If >0, mask prediction will be run again on crops of the image.
         * Sets the number of layers to run, where each layer has 2**i_layer number of image crops.
         * @param {number} [options.overlap_ratio] Sets the degree to which crops overlap. In the first crop layer,
         * crops will overlap by this fraction of the image length. Later layers with more crops scale down this overlap.
         * @param {number} [options.points_per_crop] Number of points to sample from each crop.
         * @param {number} [options.crop_n_points_downscale_factor] The number of points-per-side sampled in layer n is
         * scaled down by crop_n_points_downscale_factor**n.
         * @returns {Object} An object containing the crop boxes, number of points per crop, cropped images, and input labels.
         */
        generate_crop_boxes(l, f, {
          crop_n_layers: m = 0,
          overlap_ratio: h = 512 / 1500,
          points_per_crop: p = 32,
          crop_n_points_downscale_factor: _ = 1
        } = {}) {
        }
      }
    }
  ),
  /***/
  "./src/models/sam/processing_sam.js": (
    /*!******************************************!*\
      !*** ./src/models/sam/processing_sam.js ***!
      \******************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SamProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../auto/image_processing_auto.js */
        "./src/models/auto/image_processing_auto.js"
      );
      class a extends i.Processor {
        async _call(...u) {
          return await this.image_processor(...u);
        }
        post_process_masks(...u) {
          return this.image_processor.post_process_masks(...u);
        }
        reshape_input_points(...u) {
          return this.image_processor.reshape_input_points(...u);
        }
      }
      Ce(a, "image_processor_class", r.AutoImageProcessor);
    }
  ),
  /***/
  "./src/models/sam2/image_processing_sam2.js": (
    /*!**************************************************!*\
      !*** ./src/models/sam2/image_processing_sam2.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Sam2ImageProcessor: () => (
          /* reexport safe */
          i.SamImageProcessor
        )
        /* harmony export */
      });
      var i = t(
        /*! ../sam/image_processing_sam.js */
        "./src/models/sam/image_processing_sam.js"
      );
    }
  ),
  /***/
  "./src/models/sam2/processing_sam2.js": (
    /*!********************************************!*\
      !*** ./src/models/sam2/processing_sam2.js ***!
      \********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Sam2Processor: () => (
          /* binding */
          r
        ),
        /* harmony export */
        Sam2VideoProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../sam/processing_sam.js */
        "./src/models/sam/processing_sam.js"
      );
      class r extends i.SamProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/sam3/image_processing_sam3.js": (
    /*!**************************************************!*\
      !*** ./src/models/sam3/image_processing_sam3.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Sam3ImageProcessor: () => (
          /* reexport safe */
          i.Sam2ImageProcessor
        )
        /* harmony export */
      });
      var i = t(
        /*! ../sam2/image_processing_sam2.js */
        "./src/models/sam2/image_processing_sam2.js"
      );
    }
  ),
  /***/
  "./src/models/seamless_m4t/feature_extraction_seamless_m4t.js": (
    /*!********************************************************************!*\
      !*** ./src/models/seamless_m4t/feature_extraction_seamless_m4t.js ***!
      \********************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SeamlessM4TFeatureExtractor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      ), a = t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      );
      class c extends i.FeatureExtractor {
        constructor(l) {
          super(l);
          const f = this.config.sampling_rate, m = (0, a.mel_filter_bank)(
            257,
            // num_frequency_bins
            this.config.num_mel_bins,
            // num_mel_filters
            20,
            // min_frequency
            Math.floor(f / 2),
            // max_frequency
            f,
            // sampling_rate
            null,
            // norm
            "kaldi",
            // mel_scale
            !0
            // triangularize_in_mel_space
          );
          this.mel_filters = m, this.window = (0, a.window_function)(400, "povey", {
            periodic: !1
          });
        }
        /**
         * Computes the log-Mel spectrogram of the provided audio waveform.
         * @param {Float32Array|Float64Array} waveform The audio waveform to process.
         * @param {number} max_length The maximum number of frames to return.
         * @returns {Promise<Tensor>} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
         */
        async _extract_fbank_features(l, f) {
          return l = l.map((m) => m * 32768), (0, a.spectrogram)(
            l,
            this.window,
            // window
            400,
            // frame_length
            160,
            // hop_length
            {
              fft_length: 512,
              power: 2,
              center: !1,
              preemphasis: 0.97,
              mel_filters: this.mel_filters,
              log_mel: "log",
              mel_floor: 1192092955078125e-22,
              remove_dc_offset: !0,
              // Custom
              max_num_frames: f,
              transpose: !0
            }
          );
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @param {Object} options Optional parameters for feature extraction.
         * @param {boolean} [options.padding=true] Whether to pad the sequence to a multiple of `pad_to_multiple_of`.
         * @param {number} [options.pad_to_multiple_of=2] The number to pad the sequence to a multiple of.
         * @param {boolean} [options.do_normalize_per_mel_bins=true] Whether or not to zero-mean unit-variance normalize the input per mel-channel.
         * @param {boolean} [options.return_attention_mask=true] Whether to return the attention mask.
         * @returns {Promise<{ input_features: Tensor, attention_mask?: Tensor }>} A Promise resolving to an object containing the extracted input features and attention masks as Tensors.
         */
        async _call(l, {
          padding: f = !0,
          pad_to_multiple_of: m = 2,
          do_normalize_per_mel_bins: h = !0,
          return_attention_mask: p = !0
        } = {}) {
          (0, i.validate_audio_inputs)(l, "SeamlessM4TFeatureExtractor");
          let _ = await this._extract_fbank_features(l, this.config.max_length);
          if (h) {
            const [A, L] = _.dims, I = _.data;
            for (let R = 0; R < L; ++R) {
              let N = 0;
              for (let W = 0; W < A; ++W)
                N += I[W * L + R];
              const q = N / A;
              let ne = 0;
              for (let W = 0; W < A; ++W)
                ne += (I[W * L + R] - q) ** 2;
              ne /= A - 1;
              const Q = Math.sqrt(ne + 1e-7);
              for (let W = 0; W < A; ++W) {
                const te = W * L + R;
                I[te] = (I[te] - q) / Q;
              }
            }
          }
          let v;
          if (f) {
            const [A, L] = _.dims, I = (
              /** @type {Float32Array} */
              _.data
            ), R = A % m;
            if (R > 0) {
              const N = new Float32Array(L * (A + R));
              N.set(I), N.fill(this.config.padding_value, I.length);
              const q = A + R;
              _ = new r.Tensor(
                _.type,
                N,
                [q, L]
              ), p && (v = new r.Tensor(
                "int64",
                new BigInt64Array(q),
                [1, q]
              ), v.data.fill(1n, 0, A));
            }
          }
          const [S, D] = _.dims, w = this.config.stride;
          if (S % w !== 0)
            throw new Error(`The number of frames (${S}) must be a multiple of the stride (${w}).`);
          const F = _.view(
            1,
            Math.floor(S / w),
            D * w
          ), E = { input_features: F };
          if (p) {
            const A = F.dims[1], L = new BigInt64Array(A);
            if (v) {
              const I = v.data;
              for (let R = 1, N = 0; R < S; R += w, ++N)
                L[N] = I[R];
            } else
              L.fill(1n);
            E.attention_mask = new r.Tensor(
              "int64",
              L,
              [1, A]
            );
          }
          return E;
        }
      }
    }
  ),
  /***/
  "./src/models/segformer/image_processing_segformer.js": (
    /*!************************************************************!*\
      !*** ./src/models/segformer/image_processing_segformer.js ***!
      \************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SegformerFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        SegformerImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        /** @type {typeof post_process_semantic_segmentation} */
        post_process_semantic_segmentation(...u) {
          return (0, i.post_process_semantic_segmentation)(...u);
        }
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/siglip/image_processing_siglip.js": (
    /*!******************************************************!*\
      !*** ./src/models/siglip/image_processing_siglip.js ***!
      \******************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SiglipImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
    }
  ),
  /***/
  "./src/models/smolvlm/image_processing_smolvlm.js": (
    /*!********************************************************!*\
      !*** ./src/models/smolvlm/image_processing_smolvlm.js ***!
      \********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SmolVLMImageProcessor: () => (
          /* reexport safe */
          i.Idefics3ImageProcessor
        )
        /* harmony export */
      });
      var i = t(
        /*! ../idefics3/image_processing_idefics3.js */
        "./src/models/idefics3/image_processing_idefics3.js"
      );
    }
  ),
  /***/
  "./src/models/smolvlm/processing_smolvlm.js": (
    /*!**************************************************!*\
      !*** ./src/models/smolvlm/processing_smolvlm.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SmolVLMProcessor: () => (
          /* reexport safe */
          i.Idefics3Processor
        )
        /* harmony export */
      });
      var i = t(
        /*! ../idefics3/processing_idefics3.js */
        "./src/models/idefics3/processing_idefics3.js"
      );
    }
  ),
  /***/
  "./src/models/snac/feature_extraction_snac.js": (
    /*!****************************************************!*\
      !*** ./src/models/snac/feature_extraction_snac.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SnacFeatureExtractor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../dac/feature_extraction_dac.js */
        "./src/models/dac/feature_extraction_dac.js"
      );
      class r extends i.DacFeatureExtractor {
      }
    }
  ),
  /***/
  "./src/models/speecht5/feature_extraction_speecht5.js": (
    /*!************************************************************!*\
      !*** ./src/models/speecht5/feature_extraction_speecht5.js ***!
      \************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SpeechT5FeatureExtractor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      );
      class r extends i.FeatureExtractor {
      }
    }
  ),
  /***/
  "./src/models/speecht5/processing_speecht5.js": (
    /*!****************************************************!*\
      !*** ./src/models/speecht5/processing_speecht5.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        SpeechT5Processor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), r = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), a = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      );
      class c extends i.Processor {
        /**
         * Calls the feature_extractor function with the given input.
         * @param {any} input The input to extract features from.
         * @returns {Promise<any>} A Promise that resolves with the extracted features.
         */
        async _call(l) {
          return await this.feature_extractor(l);
        }
      }
      Ce(c, "tokenizer_class", r.AutoTokenizer), Ce(c, "feature_extractor_class", a.AutoFeatureExtractor);
    }
  ),
  /***/
  "./src/models/swin2sr/image_processing_swin2sr.js": (
    /*!********************************************************!*\
      !*** ./src/models/swin2sr/image_processing_swin2sr.js ***!
      \********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Swin2SRImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        pad_image(c, u, l, f = {}) {
          const [m, h, p] = u;
          return super.pad_image(c, u, {
            // NOTE: For Swin2SR models, the original python implementation adds padding even when the image's width/height is already
            // a multiple of `pad_size`. However, this is most likely a bug (PR: https://github.com/mv-lab/swin2sr/pull/19).
            // For this reason, we only add padding when the image's width/height is not a multiple of `pad_size`.
            width: h + (l - h % l) % l,
            height: m + (l - m % l) % l
          }, {
            mode: "symmetric",
            center: !1,
            constant_values: -1,
            ...f
          });
        }
      }
    }
  ),
  /***/
  "./src/models/ultravox/processing_ultravox.js": (
    /*!****************************************************!*\
      !*** ./src/models/ultravox/processing_ultravox.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        UltravoxProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      ), r = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), a = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      );
      class c extends a.Processor {
        /**
         * @param {string} text The text input to process.
         * @param {Float32Array} audio The audio input to process.
         */
        async _call(l, f = null, m = {}) {
          if (Array.isArray(l))
            throw new Error("Batched inputs are not supported yet.");
          let h = {};
          if (f) {
            const _ = f.length, { input_features: v } = await this.feature_extractor(f, {
              ...m,
              max_length: _
            }), S = Math.round(_ / this.config.encoder_ds_factor + 1e-4), D = 1 + Math.ceil(S / this.config.stack_factor);
            h.audio_token_len = [D], h.audio_values = v;
            const w = this.config.audio_placeholder;
            if (!l.includes(w))
              throw new Error(`The input text does not contain the image token ${w}.`);
            l = l.replaceAll(w, w.repeat(D));
          }
          return {
            ...this.tokenizer(l, {
              add_special_tokens: !1,
              ...m
            }),
            ...h
          };
        }
      }
      Ce(c, "tokenizer_class", r.AutoTokenizer), Ce(c, "feature_extractor_class", i.AutoFeatureExtractor), Ce(c, "uses_processor_config", !0);
    }
  ),
  /***/
  "./src/models/vit/image_processing_vit.js": (
    /*!************************************************!*\
      !*** ./src/models/vit/image_processing_vit.js ***!
      \************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        ViTFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        ViTImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/models/vitmatte/image_processing_vitmatte.js": (
    /*!**********************************************************!*\
      !*** ./src/models/vitmatte/image_processing_vitmatte.js ***!
      \**********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        VitMatteImageProcessor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.ImageProcessor {
        /**
         * Calls the feature extraction process on an array of images, preprocesses
         * each image, and concatenates the resulting features into a single Tensor.
         * @param {import("../../utils/image.js").RawImage[]} images The image(s) to extract features from.
         * @param {import("../../utils/image.js").RawImage[]} trimaps The trimaps(s) to extract features from.
         * @returns {Promise<import("../../base/image_processors_utils.js").ImageProcessorResult>} An object containing the concatenated pixel values of the preprocessed images.
         */
        async _call(u, l) {
          Array.isArray(u) || (u = [u]), Array.isArray(l) || (l = [l]);
          const f = await Promise.all(u.map((p) => this.preprocess(p))), m = await Promise.all(l.map((p) => this.preprocess(p, {
            do_normalize: !1,
            do_convert_rgb: !1,
            do_convert_grayscale: !0
          })));
          return {
            pixel_values: (0, r.stack)(f.map(
              // Concatenate images and trimaps
              (p, _) => (0, r.cat)([p.pixel_values, m[_].pixel_values], 0)
            ), 0),
            // Original sizes of images
            original_sizes: f.map((p) => p.original_size),
            // Reshaped sizes of images, before padding or cropping
            reshaped_input_sizes: f.map((p) => p.reshaped_input_size)
          };
        }
      }
    }
  ),
  /***/
  "./src/models/vitpose/image_processing_vitpose.js": (
    /*!********************************************************!*\
      !*** ./src/models/vitpose/image_processing_vitpose.js ***!
      \********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        VitPoseImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        /**
         * Transform the heatmaps into keypoint predictions and transform them back to the image.
         * NOTE: This is a naive implementation and does not include advanced post-processing techniques,
         * so the results may not be as accurate as the original implementation.
         * @param {import('../../utils/tensor.js').Tensor} outputs The model outputs.
         * @param {[number, number, number, number][][]} boxes List or array of bounding boxes for each image.
         * Each box should be a list of 4 floats representing the bounding box coordinates in COCO format (top_left_x, top_left_y, width, height).
         * @returns {{
         *   bbox: [number, number, number, number],
         *   scores: number[],
         *   labels: number[],
         *   keypoints: [number, number][]
         * }[][]} List of keypoints predictions for each image.
         */
        post_process_pose_estimation(c, u, {
          threshold: l = null
          // TODO:
          // kernel_size = 11,
          // target_sizes = null,
        } = {}) {
          const f = c.tolist(), [m, h, p, _] = c.dims, v = [];
          for (let S = 0; S < m; ++S) {
            const D = f[S], w = u[S], T = [];
            for (let F = 0; F < w.length; ++F) {
              const E = w[F], A = [], L = [], I = [], R = E.at(-2) / _, N = E.at(-1) / p;
              for (let q = 0; q < D.length; ++q) {
                let [ne, Q] = [0, 0], W = 0, te = -1 / 0;
                const K = D[q];
                for (let be = 0; be < K.length; ++be) {
                  const Ee = K[be];
                  for (let Ge = 0; Ge < Ee.length; ++Ge) {
                    const _e = Ee[Ge];
                    W += _e, te = Math.max(te, _e), ne += (Ge + 0.5) * _e, Q += be * _e;
                  }
                }
                if (l != null && te < l)
                  continue;
                const pe = [
                  R * ne / W,
                  N * Q / W
                ];
                A.push(pe), I.push(q), L.push(te);
              }
              T.push({
                bbox: E,
                scores: L,
                labels: I,
                keypoints: A
              });
            }
            v.push(T);
          }
          return v;
        }
      }
    }
  ),
  /***/
  "./src/models/voxtral/processing_voxtral.js": (
    /*!**************************************************!*\
      !*** ./src/models/voxtral/processing_voxtral.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        VoxtralProcessor: () => (
          /* binding */
          h
        )
        /* harmony export */
      });
      var i = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      ), r = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), a = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      ), c = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      const u = "[AUDIO]", l = "[BEGIN_AUDIO]", f = 375;
      function m(p, _) {
        const v = [];
        for (let S = 0; S < p.length; S += _)
          v.push(p.subarray(S, Math.min(S + _, p.length)));
        return v;
      }
      class h extends a.Processor {
        /**
         * @param {string} text The text input to process.
         * @param {Float32Array|Float32Array[]} audio The audio input(s) to process.
         */
        async _call(_, v = null, S = {}) {
          if (Array.isArray(_))
            throw new Error("Batched inputs are not supported yet.");
          const D = {};
          if (v) {
            if (!_.includes(u))
              throw new Error(`The input text does not contain the audio token ${u}.`);
            Array.isArray(v) || (v = [v]);
            const T = _.split(u), F = T.length - 1;
            if (F !== v.length)
              throw new Error(`The number of audio inputs (${v.length}) does not match the number of audio tokens in the text (${F}).`);
            const E = this.feature_extractor.config.n_samples, A = v.map((q) => m(q, E)), L = A.map((q) => q.length), I = A.flat(), R = (await Promise.all(
              I.map((q) => this.feature_extractor(q, S))
            )).map((q) => q.input_features);
            D.audio_values = R.length > 1 ? (0, c.cat)(R, 0) : R[0];
            let N = T[0];
            for (let q = 0; q < L.length; ++q) {
              N += l;
              for (let ne = 0; ne < L[q]; ++ne)
                N += u.repeat(f);
              N += T[q + 1];
            }
            _ = N;
          }
          return {
            ...this.tokenizer(_, {
              add_special_tokens: !1,
              ...S
            }),
            ...D
          };
        }
      }
      Ce(h, "tokenizer_class", r.AutoTokenizer), Ce(h, "feature_extractor_class", i.AutoFeatureExtractor), Ce(h, "uses_processor_config", !1);
    }
  ),
  /***/
  "./src/models/wav2vec2/feature_extraction_wav2vec2.js": (
    /*!************************************************************!*\
      !*** ./src/models/wav2vec2/feature_extraction_wav2vec2.js ***!
      \************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Wav2Vec2FeatureExtractor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      ), r = t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      class a extends i.FeatureExtractor {
        /**
         * @param {Float32Array} input_values 
         * @returns {Float32Array} 
         */
        _zero_mean_unit_var_norm(u) {
          const f = u.reduce((h, p) => h + p, 0) / u.length, m = u.reduce((h, p) => h + (p - f) ** 2, 0) / u.length;
          return u.map((h) => (h - f) / Math.sqrt(m + 1e-7));
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_values: Tensor; attention_mask: Tensor }>} A Promise resolving to an object containing the extracted input features and attention mask as Tensors.
         */
        async _call(u) {
          (0, i.validate_audio_inputs)(u, "Wav2Vec2FeatureExtractor"), u instanceof Float64Array && (u = new Float32Array(u));
          let l = u;
          this.config.do_normalize && (l = this._zero_mean_unit_var_norm(l));
          const f = [1, l.length];
          return {
            input_values: new r.Tensor("float32", l, f),
            attention_mask: new r.Tensor("int64", new BigInt64Array(l.length).fill(1n), f)
          };
        }
      }
    }
  ),
  /***/
  "./src/models/wav2vec2/processing_wav2vec2.js": (
    /*!****************************************************!*\
      !*** ./src/models/wav2vec2/processing_wav2vec2.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Wav2Vec2Processor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), r = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      ), a = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      );
      class c extends a.Processor {
        /**
         * Calls the feature_extractor function with the given audio input.
         * @param {any} audio The audio input to extract features from.
         * @returns {Promise<any>} A Promise that resolves with the extracted features.
         */
        async _call(l) {
          return await this.feature_extractor(l);
        }
      }
      Ce(c, "tokenizer_class", i.AutoTokenizer), Ce(c, "feature_extractor_class", r.AutoFeatureExtractor);
    }
  ),
  /***/
  "./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js": (
    /*!********************************************************************!*\
      !*** ./src/models/wav2vec2_with_lm/processing_wav2vec2_with_lm.js ***!
      \********************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Wav2Vec2ProcessorWithLM: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), r = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      ), a = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      );
      class c extends a.Processor {
        /**
         * Calls the feature_extractor function with the given audio input.
         * @param {any} audio The audio input to extract features from.
         * @returns {Promise<any>} A Promise that resolves with the extracted features.
         */
        async _call(l) {
          return await this.feature_extractor(l);
        }
      }
      Ce(c, "tokenizer_class", i.AutoTokenizer), Ce(c, "feature_extractor_class", r.AutoFeatureExtractor);
    }
  ),
  /***/
  "./src/models/wespeaker/feature_extraction_wespeaker.js": (
    /*!**************************************************************!*\
      !*** ./src/models/wespeaker/feature_extraction_wespeaker.js ***!
      \**************************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        WeSpeakerFeatureExtractor: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      );
      t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      var r = t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      );
      class a extends i.FeatureExtractor {
        constructor(u) {
          super(u);
          const l = this.config.sampling_rate, f = (0, r.mel_filter_bank)(
            257,
            // num_frequency_bins
            this.config.num_mel_bins,
            // num_mel_filters
            20,
            // min_frequency
            Math.floor(l / 2),
            // max_frequency
            l,
            // sampling_rate
            null,
            // norm
            "kaldi",
            // mel_scale
            !0
            // triangularize_in_mel_space
          );
          this.mel_filters = f, this.window = (0, r.window_function)(400, "hamming", {
            periodic: !1
          }), this.min_num_frames = this.config.min_num_frames;
        }
        /**
         * Computes the log-Mel spectrogram of the provided audio waveform.
         * @param {Float32Array|Float64Array} waveform The audio waveform to process.
         * @returns {Promise<Tensor>} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
         */
        async _extract_fbank_features(u) {
          return u = u.map((l) => l * 32768), (0, r.spectrogram)(
            u,
            this.window,
            // window
            400,
            // frame_length
            160,
            // hop_length
            {
              fft_length: 512,
              power: 2,
              center: !1,
              preemphasis: 0.97,
              mel_filters: this.mel_filters,
              log_mel: "log",
              mel_floor: 1192092955078125e-22,
              remove_dc_offset: !0,
              // Custom
              transpose: !0,
              min_num_frames: this.min_num_frames
            }
          );
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.
         */
        async _call(u) {
          (0, i.validate_audio_inputs)(u, "WeSpeakerFeatureExtractor");
          const l = (await this._extract_fbank_features(u)).unsqueeze_(0);
          if (this.config.fbank_centering_span === null) {
            const f = (
              /** @type {Float32Array} */
              l.mean(1).data
            ), m = (
              /** @type {Float32Array} */
              l.data
            ), [h, p, _] = l.dims;
            for (let v = 0; v < h; ++v) {
              const S = v * p * _, D = v * _;
              for (let w = 0; w < p; ++w) {
                const T = S + w * _;
                for (let F = 0; F < _; ++F)
                  m[T + F] -= f[D + F];
              }
            }
          }
          return {
            input_features: l
          };
        }
      }
    }
  ),
  /***/
  "./src/models/whisper/common_whisper.js": (
    /*!**********************************************!*\
      !*** ./src/models/whisper/common_whisper.js ***!
      \**********************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        WHISPER_LANGUAGE_MAPPING: () => (
          /* binding */
          r
        ),
        /* harmony export */
        WHISPER_TO_LANGUAGE_CODE_MAPPING: () => (
          /* binding */
          a
        ),
        /* harmony export */
        whisper_language_to_code: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      const i = [
        ["en", "english"],
        ["zh", "chinese"],
        ["de", "german"],
        ["es", "spanish"],
        ["ru", "russian"],
        ["ko", "korean"],
        ["fr", "french"],
        ["ja", "japanese"],
        ["pt", "portuguese"],
        ["tr", "turkish"],
        ["pl", "polish"],
        ["ca", "catalan"],
        ["nl", "dutch"],
        ["ar", "arabic"],
        ["sv", "swedish"],
        ["it", "italian"],
        ["id", "indonesian"],
        ["hi", "hindi"],
        ["fi", "finnish"],
        ["vi", "vietnamese"],
        ["he", "hebrew"],
        ["uk", "ukrainian"],
        ["el", "greek"],
        ["ms", "malay"],
        ["cs", "czech"],
        ["ro", "romanian"],
        ["da", "danish"],
        ["hu", "hungarian"],
        ["ta", "tamil"],
        ["no", "norwegian"],
        ["th", "thai"],
        ["ur", "urdu"],
        ["hr", "croatian"],
        ["bg", "bulgarian"],
        ["lt", "lithuanian"],
        ["la", "latin"],
        ["mi", "maori"],
        ["ml", "malayalam"],
        ["cy", "welsh"],
        ["sk", "slovak"],
        ["te", "telugu"],
        ["fa", "persian"],
        ["lv", "latvian"],
        ["bn", "bengali"],
        ["sr", "serbian"],
        ["az", "azerbaijani"],
        ["sl", "slovenian"],
        ["kn", "kannada"],
        ["et", "estonian"],
        ["mk", "macedonian"],
        ["br", "breton"],
        ["eu", "basque"],
        ["is", "icelandic"],
        ["hy", "armenian"],
        ["ne", "nepali"],
        ["mn", "mongolian"],
        ["bs", "bosnian"],
        ["kk", "kazakh"],
        ["sq", "albanian"],
        ["sw", "swahili"],
        ["gl", "galician"],
        ["mr", "marathi"],
        ["pa", "punjabi"],
        ["si", "sinhala"],
        ["km", "khmer"],
        ["sn", "shona"],
        ["yo", "yoruba"],
        ["so", "somali"],
        ["af", "afrikaans"],
        ["oc", "occitan"],
        ["ka", "georgian"],
        ["be", "belarusian"],
        ["tg", "tajik"],
        ["sd", "sindhi"],
        ["gu", "gujarati"],
        ["am", "amharic"],
        ["yi", "yiddish"],
        ["lo", "lao"],
        ["uz", "uzbek"],
        ["fo", "faroese"],
        ["ht", "haitian creole"],
        ["ps", "pashto"],
        ["tk", "turkmen"],
        ["nn", "nynorsk"],
        ["mt", "maltese"],
        ["sa", "sanskrit"],
        ["lb", "luxembourgish"],
        ["my", "myanmar"],
        ["bo", "tibetan"],
        ["tl", "tagalog"],
        ["mg", "malagasy"],
        ["as", "assamese"],
        ["tt", "tatar"],
        ["haw", "hawaiian"],
        ["ln", "lingala"],
        ["ha", "hausa"],
        ["ba", "bashkir"],
        ["jw", "javanese"],
        ["su", "sundanese"]
      ], r = new Map(i), a = new Map([
        ...i.map(([u, l]) => [l, u]),
        ["burmese", "my"],
        ["valencian", "ca"],
        ["flemish", "nl"],
        ["haitian", "ht"],
        ["letzeburgesch", "lb"],
        ["pushto", "ps"],
        ["panjabi", "pa"],
        ["moldavian", "ro"],
        ["moldovan", "ro"],
        ["sinhalese", "si"],
        ["castilian", "es"]
      ]);
      function c(u) {
        u = u.toLowerCase();
        let l = a.get(u);
        if (l === void 0) {
          const f = u.match(/^<\|([a-z]{2})\|>$/);
          if (f && (u = f[1]), r.has(u))
            l = u;
          else {
            const h = u.length === 2 ? r.keys() : r.values();
            throw new Error(`Language "${u}" is not supported. Must be one of: ${JSON.stringify(Array.from(h))}`);
          }
        }
        return l;
      }
    }
  ),
  /***/
  "./src/models/whisper/feature_extraction_whisper.js": (
    /*!**********************************************************!*\
      !*** ./src/models/whisper/feature_extraction_whisper.js ***!
      \**********************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        WhisperFeatureExtractor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/feature_extraction_utils.js */
        "./src/base/feature_extraction_utils.js"
      );
      t(
        /*! ../../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      var r = t(
        /*! ../../utils/audio.js */
        "./src/utils/audio.js"
      ), a = t(
        /*! ../../utils/maths.js */
        "./src/utils/maths.js"
      );
      class c extends i.FeatureExtractor {
        constructor(l) {
          var f;
          super(l), (f = this.config).mel_filters ?? (f.mel_filters = (0, r.mel_filter_bank)(
            Math.floor(1 + this.config.n_fft / 2),
            // num_frequency_bins
            this.config.feature_size,
            // num_mel_filters
            0,
            // min_frequency
            8e3,
            // max_frequency
            this.config.sampling_rate,
            // sampling_rate
            "slaney",
            // norm
            "slaney"
            // mel_scale
          )), this.window = (0, r.window_function)(this.config.n_fft, "hann");
        }
        /**
         * Computes the log-Mel spectrogram of the provided audio waveform.
         * @param {Float32Array|Float64Array} waveform The audio waveform to process.
         * @returns {Promise<Tensor>} An object containing the log-Mel spectrogram data as a Float32Array and its dimensions as an array of numbers.
         */
        async _extract_fbank_features(l) {
          const f = await (0, r.spectrogram)(
            l,
            this.window,
            // window
            this.config.n_fft,
            // frame_length
            this.config.hop_length,
            // hop_length
            {
              power: 2,
              mel_filters: this.config.mel_filters,
              log_mel: "log10",
              // Custom
              max_num_frames: Math.min(
                Math.floor(l.length / this.config.hop_length),
                this.config.nb_max_frames
                // 3000
              )
            }
          ), m = f.data, h = (0, a.max)(
            /** @type {Float32Array} */
            m
          )[0];
          for (let p = 0; p < m.length; ++p)
            m[p] = (Math.max(m[p], h - 8) + 4) / 4;
          return f;
        }
        /**
         * Asynchronously extracts features from a given audio using the provided configuration.
         * @param {Float32Array|Float64Array} audio The audio data as a Float32Array/Float64Array.
         * @returns {Promise<{ input_features: Tensor }>} A Promise resolving to an object containing the extracted input features as a Tensor.
         */
        async _call(l, {
          max_length: f = null
        } = {}) {
          (0, i.validate_audio_inputs)(l, "WhisperFeatureExtractor");
          let m;
          const h = f ?? this.config.n_samples;
          return l.length > h ? (l.length > this.config.n_samples && console.warn(
            "Attempting to extract features for audio longer than 30 seconds. If using a pipeline to extract transcript from a long audio clip, remember to specify `chunk_length_s` and/or `stride_length_s`."
          ), m = l.slice(0, h)) : (m = new Float32Array(h), m.set(l)), {
            input_features: (await this._extract_fbank_features(m)).unsqueeze_(0)
          };
        }
      }
    }
  ),
  /***/
  "./src/models/whisper/generation_whisper.js": (
    /*!**************************************************!*\
      !*** ./src/models/whisper/generation_whisper.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        WhisperGenerationConfig: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../generation/configuration_utils.js */
        "./src/generation/configuration_utils.js"
      );
      class r extends i.GenerationConfig {
        constructor() {
          super(...arguments);
          /**
           * Whether to return the timestamps with the text. This enables the `WhisperTimestampsLogitsProcessor`.
           * @type {boolean}
           */
          Ce(this, "return_timestamps", null);
          /**
           * Whether to return token-level timestamps
           * with the text. This can be used with or without the `return_timestamps` option. To get word-level
           * timestamps, use the tokenizer to group the tokens into words.
           * @type {boolean}
           */
          Ce(this, "return_token_timestamps", null);
          /**
           * The number of audio frames available in this chunk. This is only used generating word-level timestamps.
           * @type {number}
           */
          Ce(this, "num_frames", null);
          /**
           * Alignment heads to predict word-level timestamps. This is a list of [layer, head] pairs that
           * select the cross-attention heads that are highly correlated to word-level timing.
           * @type {[number, number][]}
           */
          Ce(this, "alignment_heads", null);
          /**
           * Task to use for generation, either "translate" or "transcribe".
           * @type {string}
           */
          Ce(this, "task", null);
          /**
           * Language token to use for generation, can be either in the form of `<|en|>`, `en` or `english`.
           * You can find all the possible language tokens in the `model.generation_config.lang_to_id` dictionary.
           * @type {string}
           */
          Ce(this, "language", null);
          /**
           * The id of the `"<|notimestamps|>"` token.
           * @type {number}
           */
          Ce(this, "no_timestamps_token_id", null);
          /**
           * Rank-1 list of token IDs created by passing text to [`~WhisperProcessor.get_prompt_ids`] that is
           * provided as a prompt to each chunk. This can be used to provide or "prompt-engineer" a context for
           * transcription, e.g. custom vocabularies or proper nouns to make it more likely to predict those words
           * correctly. It cannot be used in conjunction with `decoder_start_token_id` as it overwrites this value.
           * @type {number[]}
           */
          Ce(this, "prompt_ids", null);
          /**
           * Whether the model is multilingual or not.
           * @type {boolean}
           */
          Ce(this, "is_multilingual", null);
          /**
           * (Optional) A mapping from language tokens to their corresponding IDs.
           * Only required if the model is multilingual.
           * @type {Record<string, number>|null}
           */
          Ce(this, "lang_to_id", null);
          /**
           * (Optional) A mapping from task tokens to their corresponding IDs.
           * @type {Record<string, number>|null}
           */
          Ce(this, "task_to_id", null);
          /**
           * Used to set the maximum value of the initial timestamp. This is used to prevent the model from
           * predicting timestamps that are too far in the future.
           * @type {number}
           */
          Ce(this, "max_initial_timestamp_index", 1);
        }
      }
    }
  ),
  /***/
  "./src/models/whisper/processing_whisper.js": (
    /*!**************************************************!*\
      !*** ./src/models/whisper/processing_whisper.js ***!
      \**************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        WhisperProcessor: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../auto/feature_extraction_auto.js */
        "./src/models/auto/feature_extraction_auto.js"
      ), r = t(
        /*! ../../tokenizers.js */
        "./src/tokenizers.js"
      ), a = t(
        /*! ../../base/processing_utils.js */
        "./src/base/processing_utils.js"
      );
      class c extends a.Processor {
        /**
         * Calls the feature_extractor function with the given audio input.
         * @param {any} audio The audio input to extract features from.
         * @returns {Promise<any>} A Promise that resolves with the extracted features.
         */
        async _call(l) {
          return await this.feature_extractor(l);
        }
      }
      Ce(c, "tokenizer_class", r.AutoTokenizer), Ce(c, "feature_extractor_class", i.AutoFeatureExtractor);
    }
  ),
  /***/
  "./src/models/yolos/image_processing_yolos.js": (
    /*!****************************************************!*\
      !*** ./src/models/yolos/image_processing_yolos.js ***!
      \****************************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        YolosFeatureExtractor: () => (
          /* binding */
          a
        ),
        /* harmony export */
        YolosImageProcessor: () => (
          /* binding */
          r
        )
        /* harmony export */
      });
      var i = t(
        /*! ../../base/image_processors_utils.js */
        "./src/base/image_processors_utils.js"
      );
      class r extends i.ImageProcessor {
        /** @type {typeof post_process_object_detection} */
        post_process_object_detection(...u) {
          return (0, i.post_process_object_detection)(...u);
        }
      }
      class a extends r {
      }
    }
  ),
  /***/
  "./src/ops/registry.js": (
    /*!*****************************!*\
      !*** ./src/ops/registry.js ***!
      \*****************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        TensorOpRegistry: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      var i = t(
        /*! ../backends/onnx.js */
        "./src/backends/onnx.js"
      ), r = t(
        /*! ../utils/tensor.js */
        "./src/utils/tensor.js"
      );
      const a = async (u, l, f) => {
        const m = await (0, i.createInferenceSession)(
          new Uint8Array(u),
          l
        );
        return (
          /** @type {any} */
          async (h) => {
            const p = (0, i.isONNXProxy)(), _ = Object.fromEntries(Object.entries(h).map(([S, D]) => [S, (p ? D.clone() : D).ort_tensor])), v = await (0, i.runInferenceSession)(m, _);
            return Array.isArray(f) ? f.map((S) => new r.Tensor(v[S])) : new r.Tensor(v[
              /** @type {string} */
              f
            ]);
          }
        );
      };
      class c {
        static get nearest_interpolate_4d() {
          return this._nearest_interpolate_4d || (this._nearest_interpolate_4d = a(
            [8, 10, 18, 0, 58, 129, 1, 10, 41, 10, 1, 120, 10, 0, 10, 0, 10, 1, 115, 18, 1, 121, 34, 6, 82, 101, 115, 105, 122, 101, 42, 18, 10, 4, 109, 111, 100, 101, 34, 7, 110, 101, 97, 114, 101, 115, 116, 160, 1, 3, 18, 1, 114, 90, 31, 10, 1, 120, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 90, 15, 10, 1, 115, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 4, 98, 31, 10, 1, 121, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 66, 2, 16, 21],
            this.session_options,
            "y"
          )), this._nearest_interpolate_4d;
        }
        static get bilinear_interpolate_4d() {
          return this._bilinear_interpolate_4d || (this._bilinear_interpolate_4d = a(
            [8, 9, 18, 0, 58, 128, 1, 10, 40, 10, 1, 120, 10, 0, 10, 0, 10, 1, 115, 18, 1, 121, 34, 6, 82, 101, 115, 105, 122, 101, 42, 17, 10, 4, 109, 111, 100, 101, 34, 6, 108, 105, 110, 101, 97, 114, 160, 1, 3, 18, 1, 114, 90, 31, 10, 1, 120, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 90, 15, 10, 1, 115, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 4, 98, 31, 10, 1, 121, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 66, 2, 16, 20],
            this.session_options,
            "y"
          )), this._bilinear_interpolate_4d;
        }
        static get bicubic_interpolate_4d() {
          return this._bicubic_interpolate_4d || (this._bicubic_interpolate_4d = a(
            [8, 9, 18, 0, 58, 127, 10, 39, 10, 1, 120, 10, 0, 10, 0, 10, 1, 115, 18, 1, 121, 34, 6, 82, 101, 115, 105, 122, 101, 42, 16, 10, 4, 109, 111, 100, 101, 34, 5, 99, 117, 98, 105, 99, 160, 1, 3, 18, 1, 114, 90, 31, 10, 1, 120, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 90, 15, 10, 1, 115, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 4, 98, 31, 10, 1, 121, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 99, 10, 3, 18, 1, 104, 10, 3, 18, 1, 119, 66, 2, 16, 20],
            this.session_options,
            "y"
          )), this._bicubic_interpolate_4d;
        }
        static get matmul() {
          return this._matmul || (this._matmul = a(
            [8, 9, 18, 0, 58, 55, 10, 17, 10, 1, 97, 10, 1, 98, 18, 1, 99, 34, 6, 77, 97, 116, 77, 117, 108, 18, 1, 114, 90, 9, 10, 1, 97, 18, 4, 10, 2, 8, 1, 90, 9, 10, 1, 98, 18, 4, 10, 2, 8, 1, 98, 9, 10, 1, 99, 18, 4, 10, 2, 8, 1, 66, 2, 16, 20],
            this.session_options,
            "c"
          )), this._matmul;
        }
        static get stft() {
          return this._stft || (this._stft = a(
            [8, 7, 18, 0, 58, 148, 1, 10, 38, 10, 1, 115, 10, 1, 106, 10, 1, 119, 10, 1, 108, 18, 1, 111, 34, 4, 83, 84, 70, 84, 42, 15, 10, 8, 111, 110, 101, 115, 105, 100, 101, 100, 24, 1, 160, 1, 2, 18, 1, 115, 90, 26, 10, 1, 115, 18, 21, 10, 19, 8, 1, 18, 15, 10, 3, 18, 1, 98, 10, 3, 18, 1, 115, 10, 3, 18, 1, 99, 90, 11, 10, 1, 106, 18, 6, 10, 4, 8, 7, 18, 0, 90, 16, 10, 1, 119, 18, 11, 10, 9, 8, 1, 18, 5, 10, 3, 18, 1, 119, 90, 11, 10, 1, 108, 18, 6, 10, 4, 8, 7, 18, 0, 98, 31, 10, 1, 111, 18, 26, 10, 24, 8, 1, 18, 20, 10, 3, 18, 1, 98, 10, 3, 18, 1, 102, 10, 3, 18, 1, 100, 10, 3, 18, 1, 99, 66, 2, 16, 17],
            this.session_options,
            "o"
          )), this._stft;
        }
        static get rfft() {
          return this._rfft || (this._rfft = a(
            [8, 9, 18, 0, 58, 97, 10, 33, 10, 1, 120, 10, 0, 10, 1, 97, 18, 1, 121, 34, 3, 68, 70, 84, 42, 15, 10, 8, 111, 110, 101, 115, 105, 100, 101, 100, 24, 1, 160, 1, 2, 18, 1, 100, 90, 21, 10, 1, 120, 18, 16, 10, 14, 8, 1, 18, 10, 10, 3, 18, 1, 115, 10, 3, 18, 1, 99, 90, 11, 10, 1, 97, 18, 6, 10, 4, 8, 7, 18, 0, 98, 21, 10, 1, 121, 18, 16, 10, 14, 8, 1, 18, 10, 10, 3, 18, 1, 115, 10, 3, 18, 1, 99, 66, 2, 16, 20],
            this.session_options,
            "y"
          )), this._rfft;
        }
        static get top_k() {
          return this._top_k || (this._top_k = a(
            [8, 10, 18, 0, 58, 73, 10, 18, 10, 1, 120, 10, 1, 107, 18, 1, 118, 18, 1, 105, 34, 4, 84, 111, 112, 75, 18, 1, 116, 90, 9, 10, 1, 120, 18, 4, 10, 2, 8, 1, 90, 15, 10, 1, 107, 18, 10, 10, 8, 8, 7, 18, 4, 10, 2, 8, 1, 98, 9, 10, 1, 118, 18, 4, 10, 2, 8, 1, 98, 9, 10, 1, 105, 18, 4, 10, 2, 8, 7, 66, 2, 16, 21],
            this.session_options,
            [
              /* Values */
              "v",
              /* Indices */
              "i"
            ]
          )), this._top_k;
        }
        static get slice() {
          return this._slice || (this._slice = a(
            [8, 7, 18, 0, 58, 96, 10, 25, 10, 1, 120, 10, 1, 115, 10, 1, 101, 10, 1, 97, 10, 1, 116, 18, 1, 121, 34, 5, 83, 108, 105, 99, 101, 18, 1, 114, 90, 9, 10, 1, 120, 18, 4, 10, 2, 8, 1, 90, 9, 10, 1, 115, 18, 4, 10, 2, 8, 7, 90, 9, 10, 1, 101, 18, 4, 10, 2, 8, 7, 90, 9, 10, 1, 97, 18, 4, 10, 2, 8, 7, 90, 9, 10, 1, 116, 18, 4, 10, 2, 8, 7, 98, 9, 10, 1, 121, 18, 4, 10, 2, 8, 1, 66, 2, 16, 13],
            this.session_options,
            "y"
          )), this._slice;
        }
      }
      Ce(c, "session_options", {
        // TODO: Allow for multiple execution providers
        // executionProviders: ['webgpu'],
      });
    }
  ),
  /***/
  "./src/pipelines.js": (
    /*!**************************!*\
      !*** ./src/pipelines.js ***!
      \**************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        AudioClassificationPipeline: () => (
          /* binding */
          Q
        ),
        /* harmony export */
        AutomaticSpeechRecognitionPipeline: () => (
          /* binding */
          te
        ),
        /* harmony export */
        BackgroundRemovalPipeline: () => (
          /* binding */
          Ee
        ),
        /* harmony export */
        DepthEstimationPipeline: () => (
          /* binding */
          we
        ),
        /* harmony export */
        DocumentQuestionAnsweringPipeline: () => (
          /* binding */
          he
        ),
        /* harmony export */
        FeatureExtractionPipeline: () => (
          /* binding */
          q
        ),
        /* harmony export */
        FillMaskPipeline: () => (
          /* binding */
          F
        ),
        /* harmony export */
        ImageClassificationPipeline: () => (
          /* binding */
          pe
        ),
        /* harmony export */
        ImageFeatureExtractionPipeline: () => (
          /* binding */
          ne
        ),
        /* harmony export */
        ImageSegmentationPipeline: () => (
          /* binding */
          be
        ),
        /* harmony export */
        ImageToImagePipeline: () => (
          /* binding */
          me
        ),
        /* harmony export */
        ImageToTextPipeline: () => (
          /* binding */
          K
        ),
        /* harmony export */
        ObjectDetectionPipeline: () => (
          /* binding */
          _e
        ),
        /* harmony export */
        Pipeline: () => (
          /* binding */
          S
        ),
        /* harmony export */
        QuestionAnsweringPipeline: () => (
          /* binding */
          T
        ),
        /* harmony export */
        SummarizationPipeline: () => (
          /* binding */
          A
        ),
        /* harmony export */
        Text2TextGenerationPipeline: () => (
          /* binding */
          E
        ),
        /* harmony export */
        TextClassificationPipeline: () => (
          /* binding */
          D
        ),
        /* harmony export */
        TextGenerationPipeline: () => (
          /* binding */
          R
        ),
        /* harmony export */
        TextToAudioPipeline: () => (
          /* binding */
          Z
        ),
        /* harmony export */
        TokenClassificationPipeline: () => (
          /* binding */
          w
        ),
        /* harmony export */
        TranslationPipeline: () => (
          /* binding */
          L
        ),
        /* harmony export */
        ZeroShotAudioClassificationPipeline: () => (
          /* binding */
          W
        ),
        /* harmony export */
        ZeroShotClassificationPipeline: () => (
          /* binding */
          N
        ),
        /* harmony export */
        ZeroShotImageClassificationPipeline: () => (
          /* binding */
          Ge
        ),
        /* harmony export */
        ZeroShotObjectDetectionPipeline: () => (
          /* binding */
          De
        ),
        /* harmony export */
        pipeline: () => (
          /* binding */
          Ve
        )
        /* harmony export */
      });
      var i = t(
        /*! ./tokenizers.js */
        "./src/tokenizers.js"
      ), r = t(
        /*! ./models.js */
        "./src/models.js"
      ), a = t(
        /*! ./models/auto/processing_auto.js */
        "./src/models/auto/processing_auto.js"
      );
      t(
        /*! ./base/processing_utils.js */
        "./src/base/processing_utils.js"
      );
      var c = t(
        /*! ./utils/generic.js */
        "./src/utils/generic.js"
      ), u = t(
        /*! ./utils/core.js */
        "./src/utils/core.js"
      ), l = t(
        /*! ./utils/maths.js */
        "./src/utils/maths.js"
      ), f = t(
        /*! ./utils/audio.js */
        "./src/utils/audio.js"
      ), m = t(
        /*! ./utils/tensor.js */
        "./src/utils/tensor.js"
      ), h = t(
        /*! ./utils/image.js */
        "./src/utils/image.js"
      );
      async function p(Be) {
        return Array.isArray(Be) || (Be = [Be]), await Promise.all(Be.map((ae) => h.RawImage.read(ae)));
      }
      async function _(Be, ae) {
        return Array.isArray(Be) || (Be = [Be]), await Promise.all(Be.map((U) => typeof U == "string" || U instanceof URL ? (0, f.read_audio)(U, ae) : U instanceof Float64Array ? new Float32Array(U) : U));
      }
      function v(Be, ae) {
        ae && (Be = Be.map((Ye) => Ye | 0));
        const [U, Se, ze, Oe] = Be;
        return { xmin: U, ymin: Se, xmax: ze, ymax: Oe };
      }
      class S extends c.Callable {
        /**
         * Create a new Pipeline.
         * @param {Object} options An object containing the following properties:
         * @param {string} [options.task] The task of the pipeline. Useful for specifying subtasks.
         * @param {PreTrainedModel} [options.model] The model used by the pipeline.
         * @param {PreTrainedTokenizer} [options.tokenizer=null] The tokenizer used by the pipeline (if any).
         * @param {Processor} [options.processor=null] The processor used by the pipeline (if any).
         */
        constructor({ task: ae, model: U, tokenizer: Se = null, processor: ze = null }) {
          super(), this.task = ae, this.model = U, this.tokenizer = Se, this.processor = ze;
        }
        /** @type {DisposeType} */
        async dispose() {
          await this.model.dispose();
        }
      }
      class D extends /** @type {new (options: TextPipelineConstructorArgs) => TextClassificationPipelineType} */
      S {
        /**
         * Create a new TextClassificationPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {TextClassificationPipelineCallback} */
        async _call(ae, {
          top_k: U = 1
        } = {}) {
          const Se = this.tokenizer(ae, {
            padding: !0,
            truncation: !0
          }), ze = await this.model(Se), Oe = (
            // @ts-expect-error TS2339
            this.model.config.problem_type === "multi_label_classification" ? (Y) => Y.sigmoid() : (Y) => new m.Tensor(
              "float32",
              (0, l.softmax)(Y.data),
              Y.dims
            )
          ), Ye = this.model.config.id2label, H = [];
          for (const Y of ze.logits) {
            const $e = Oe(Y), Ie = await (0, m.topk)($e, U), fe = Ie[0].tolist(), Ne = Ie[1].tolist().map((ut, de) => ({
              label: Ye ? Ye[ut] : `LABEL_${ut}`,
              score: fe[de]
            }));
            U === 1 ? H.push(...Ne) : H.push(Ne);
          }
          return Array.isArray(ae) || U === 1 ? (
            /** @type {TextClassificationOutput} */
            H
          ) : (
            /** @type {TextClassificationOutput[]} */
            H[0]
          );
        }
      }
      class w extends /** @type {new (options: TextPipelineConstructorArgs) => TokenClassificationPipelineType} */
      S {
        /**
         * Create a new TokenClassificationPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {TokenClassificationPipelineCallback} */
        async _call(ae, {
          ignore_labels: U = ["O"]
        } = {}) {
          const Se = Array.isArray(ae), ze = this.tokenizer(Se ? ae : [ae], {
            padding: !0,
            truncation: !0
          }), Ye = (await this.model(ze)).logits, H = this.model.config.id2label, Y = [];
          for (let $e = 0; $e < Ye.dims[0]; ++$e) {
            const Ie = ze.input_ids[$e], fe = Ye[$e], Qe = [];
            for (let Ne = 0; Ne < fe.dims[0]; ++Ne) {
              const ut = fe[Ne], de = (0, l.max)(ut.data)[1], qe = H ? H[de] : `LABEL_${de}`;
              if (U.includes(qe))
                continue;
              const tt = this.tokenizer.decode([Ie[Ne].item()], { skip_special_tokens: !0 });
              if (tt === "")
                continue;
              const He = (0, l.softmax)(ut.data);
              Qe.push({
                entity: qe,
                score: He[de],
                index: Ne,
                word: tt
                // TODO: Add support for start and end
                // start: null,
                // end: null,
              });
            }
            Y.push(Qe);
          }
          return Se ? Y : Y[0];
        }
      }
      class T extends /** @type {new (options: TextPipelineConstructorArgs) => QuestionAnsweringPipelineType} */
      S {
        /**
         * Create a new QuestionAnsweringPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {QuestionAnsweringPipelineCallback} */
        async _call(ae, U, {
          top_k: Se = 1
        } = {}) {
          const ze = this.tokenizer(ae, {
            text_pair: U,
            padding: !0,
            truncation: !0
          }), { start_logits: Oe, end_logits: Ye } = await this.model(ze), H = ze.input_ids.tolist(), Y = ze.attention_mask.tolist(), $e = this.tokenizer.all_special_ids, Ie = [];
          for (let fe = 0; fe < Oe.dims[0]; ++fe) {
            const Qe = H[fe], Ne = Qe.findIndex(
              (je) => (
                // We use == to match bigint with number
                // @ts-ignore
                je == this.tokenizer.sep_token_id
              )
            );
            Y[fe].map((je, lt) => je == 1 && (lt === 0 || lt > Ne && $e.findIndex((Mt) => Mt == Qe[lt]) === -1));
            const ut = Oe[fe].tolist(), de = Ye[fe].tolist();
            for (let je = 1; je < ut.length; ++je)
              (Y[fe] == 0 || je <= Ne || $e.findIndex((lt) => lt == Qe[je]) !== -1) && (ut[je] = -1 / 0, de[je] = -1 / 0);
            const qe = (0, l.softmax)(ut).map((je, lt) => [je, lt]), tt = (0, l.softmax)(de).map((je, lt) => [je, lt]);
            qe[0][0] = 0, tt[0][0] = 0;
            const He = (0, u.product)(qe, tt).filter((je) => je[0][1] <= je[1][1]).map((je) => [je[0][1], je[1][1], je[0][0] * je[1][0]]).sort((je, lt) => lt[2] - je[2]);
            for (let je = 0; je < Math.min(He.length, Se); ++je) {
              const [lt, Mt, Rt] = He[je], Kt = Qe.slice(lt, Mt + 1), vn = this.tokenizer.decode(Kt, {
                skip_special_tokens: !0
              });
              Ie.push({
                answer: vn,
                score: Rt
              });
            }
          }
          return Se === 1 ? Ie[0] : Ie;
        }
      }
      class F extends /** @type {new (options: TextPipelineConstructorArgs) => FillMaskPipelineType} */
      S {
        /**
         * Create a new FillMaskPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {FillMaskPipelineCallback} */
        async _call(ae, {
          top_k: U = 5
        } = {}) {
          const Se = this.tokenizer(ae, {
            padding: !0,
            truncation: !0
          }), { logits: ze } = await this.model(Se), Oe = [], Ye = Se.input_ids.tolist();
          for (let H = 0; H < Ye.length; ++H) {
            const Y = Ye[H], $e = Y.findIndex(
              (ut) => (
                // We use == to match bigint with number
                // @ts-ignore
                ut == this.tokenizer.mask_token_id
              )
            );
            if ($e === -1)
              throw Error(`Mask token (${this.tokenizer.mask_token}) not found in text.`);
            const Ie = ze[H][$e], fe = await (0, m.topk)(new m.Tensor(
              "float32",
              (0, l.softmax)(Ie.data),
              Ie.dims
            ), U), Qe = fe[0].tolist(), Ne = fe[1].tolist();
            Oe.push(Ne.map((ut, de) => {
              const qe = Y.slice();
              return qe[$e] = ut, {
                score: Qe[de],
                token: Number(ut),
                token_str: this.tokenizer.decode([ut]),
                sequence: this.tokenizer.decode(qe, { skip_special_tokens: !0 })
              };
            }));
          }
          return Array.isArray(ae) ? Oe : Oe[0];
        }
      }
      class E extends /** @type {new (options: TextPipelineConstructorArgs) => Text2TextGenerationPipelineType} */
      S {
        /**
         * Create a new Text2TextGenerationPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(U) {
          super(U);
          /** @type {'generated_text'} */
          Ce(this, "_key", "generated_text");
        }
        /** @type {Text2TextGenerationPipelineCallback} */
        async _call(U, Se = {}) {
          Array.isArray(U) || (U = [U]), this.model.config.prefix && (U = U.map(($e) => this.model.config.prefix + $e));
          const ze = this.model.config.task_specific_params;
          ze && ze[this.task] && ze[this.task].prefix && (U = U.map(($e) => ze[this.task].prefix + $e));
          const Oe = this.tokenizer, Ye = {
            padding: !0,
            truncation: !0
          };
          let H;
          this instanceof L && "_build_translation_inputs" in Oe ? H = Oe._build_translation_inputs(U, Ye, Se) : H = Oe(U, Ye);
          const Y = await this.model.generate({ ...H, ...Se });
          return Oe.batch_decode(
            /** @type {Tensor} */
            Y,
            {
              skip_special_tokens: !0
            }
          ).map(($e) => ({ [this._key]: $e }));
        }
      }
      class A extends /** @type {new (options: TextPipelineConstructorArgs) => SummarizationPipelineType} */
      /** @type {any} */
      E {
        /**
         * Create a new SummarizationPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(U) {
          super(U);
          /** @type {'summary_text'} */
          Ce(this, "_key", "summary_text");
        }
      }
      class L extends /** @type {new (options: TextPipelineConstructorArgs) => TranslationPipelineType} */
      /** @type {any} */
      E {
        /**
         * Create a new TranslationPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(U) {
          super(U);
          /** @type {'translation_text'} */
          Ce(this, "_key", "translation_text");
        }
      }
      function I(Be) {
        return Array.isArray(Be) && Be.every((ae) => "role" in ae && "content" in ae);
      }
      class R extends /** @type {new (options: TextPipelineConstructorArgs) => TextGenerationPipelineType} */
      S {
        /**
         * Create a new TextGenerationPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {TextGenerationPipelineCallback} */
        async _call(ae, U = {}) {
          let Se = !1, ze = !1, Oe = U.add_special_tokens ?? (this.tokenizer.add_bos_token || this.tokenizer.add_eos_token) ?? !1, Ye;
          if (typeof ae == "string")
            Ye = ae = [ae];
          else if (Array.isArray(ae) && ae.every((Ne) => typeof Ne == "string"))
            Se = !0, Ye = /** @type {string[]} */
            ae;
          else {
            if (I(ae))
              ae = [
                /** @type {Chat} */
                ae
              ];
            else if (Array.isArray(ae) && ae.every(I))
              Se = !0;
            else
              throw new Error("Input must be a string, an array of strings, a Chat, or an array of Chats");
            ze = !0, Ye = /** @type {string[]} */
            /** @type {Chat[]} */
            ae.map(
              (Ne) => this.tokenizer.apply_chat_template(Ne, {
                tokenize: !1,
                add_generation_prompt: !0
              })
            ), Oe = !1;
          }
          const H = ze ? !1 : U.return_full_text ?? !0;
          this.tokenizer.padding_side = "left";
          const Y = this.tokenizer(Ye, {
            add_special_tokens: Oe,
            padding: !0,
            truncation: !0
          }), $e = (
            /** @type {Tensor} */
            await this.model.generate({
              ...Y,
              ...U
            })
          ), Ie = this.tokenizer.batch_decode($e, {
            skip_special_tokens: !0
          });
          let fe;
          !H && Y.input_ids.dims.at(-1) > 0 && (fe = this.tokenizer.batch_decode(Y.input_ids, {
            skip_special_tokens: !0
          }).map((Ne) => Ne.length));
          const Qe = Array.from({ length: ae.length }, (Ne) => []);
          for (let Ne = 0; Ne < Ie.length; ++Ne) {
            const ut = Math.floor(Ne / $e.dims[0] * ae.length);
            fe && (Ie[Ne] = Ie[Ne].slice(fe[ut])), Qe[ut].push({
              generated_text: ze ? [
                .../** @type {Chat[]} */
                ae[ut],
                { role: "assistant", content: Ie[Ne] }
              ] : Ie[Ne]
            });
          }
          return !Se && Qe.length === 1 ? Qe[0] : Qe;
        }
      }
      class N extends /** @type {new (options: TextPipelineConstructorArgs) => ZeroShotClassificationPipelineType} */
      S {
        /**
         * Create a new ZeroShotClassificationPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae), this.label2id = Object.fromEntries(
            Object.entries(
              /** @type {any} */
              this.model.config.label2id
            ).map(
              ([U, Se]) => [U.toLowerCase(), Se]
            )
          ), this.entailment_id = this.label2id.entailment, this.entailment_id === void 0 && (console.warn("Could not find 'entailment' in label2id mapping. Using 2 as entailment_id."), this.entailment_id = 2), this.contradiction_id = this.label2id.contradiction ?? this.label2id.not_entailment, this.contradiction_id === void 0 && (console.warn("Could not find 'contradiction' in label2id mapping. Using 0 as contradiction_id."), this.contradiction_id = 0);
        }
        /** @type {ZeroShotClassificationPipelineCallback} */
        async _call(ae, U, {
          hypothesis_template: Se = "This example is {}.",
          multi_label: ze = !1
        } = {}) {
          const Oe = Array.isArray(ae);
          Oe || (ae = [
            /** @type {string} */
            ae
          ]), Array.isArray(U) || (U = [U]);
          const Ye = U.map(
            ($e) => Se.replace("{}", $e)
          ), H = ze || U.length === 1, Y = [];
          for (const $e of ae) {
            const Ie = [];
            for (const Ne of Ye) {
              const ut = this.tokenizer($e, {
                text_pair: Ne,
                padding: !0,
                truncation: !0
              }), de = await this.model(ut);
              H ? Ie.push([
                de.logits.data[this.contradiction_id],
                de.logits.data[this.entailment_id]
              ]) : Ie.push(de.logits.data[this.entailment_id]);
            }
            const Qe = (H ? Ie.map((Ne) => (0, l.softmax)(Ne)[1]) : (0, l.softmax)(Ie)).map((Ne, ut) => [Ne, ut]).sort((Ne, ut) => ut[0] - Ne[0]);
            Y.push({
              sequence: $e,
              labels: Qe.map((Ne) => U[Ne[1]]),
              scores: Qe.map((Ne) => Ne[0])
            });
          }
          return Oe ? Y : Y[0];
        }
      }
      class q extends /** @type {new (options: TextPipelineConstructorArgs) => FeatureExtractionPipelineType} */
      S {
        /**
         * Create a new FeatureExtractionPipeline.
         * @param {TextPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {FeatureExtractionPipelineCallback} */
        async _call(ae, {
          pooling: U = (
            /** @type {'none'} */
            "none"
          ),
          normalize: Se = !1,
          quantize: ze = !1,
          precision: Oe = (
            /** @type {'binary'} */
            "binary"
          )
        } = {}) {
          const Ye = this.tokenizer(ae, {
            padding: !0,
            truncation: !0
          }), H = await this.model(Ye);
          let Y = H.last_hidden_state ?? H.logits ?? H.token_embeddings;
          switch (U) {
            case "none":
              break;
            case "mean":
              Y = (0, m.mean_pooling)(Y, Ye.attention_mask);
              break;
            case "first_token":
            case "cls":
              Y = Y.slice(null, 0);
              break;
            case "last_token":
            case "eos":
              Y = Y.slice(null, -1);
              break;
            default:
              throw Error(`Pooling method '${U}' not supported.`);
          }
          return Se && (Y = Y.normalize(2, -1)), ze && (Y = (0, m.quantize_embeddings)(Y, Oe)), Y;
        }
      }
      class ne extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageFeatureExtractionPipelineType} */
      S {
        /**
         * Create a new ImageFeatureExtractionPipeline.
         * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ImageFeatureExtractionPipelineCallback} */
        async _call(ae, {
          pool: U = null
        } = {}) {
          const Se = await p(ae), { pixel_values: ze } = await this.processor(Se), Oe = await this.model({ pixel_values: ze });
          let Ye;
          if (U) {
            if (!("pooler_output" in Oe))
              throw Error("No pooled output was returned. Make sure the model has a 'pooler' layer when using the 'pool' option.");
            Ye = Oe.pooler_output;
          } else
            Ye = Oe.last_hidden_state ?? Oe.logits ?? Oe.image_embeds;
          return Ye;
        }
      }
      class Q extends /** @type {new (options: AudioPipelineConstructorArgs) => AudioClassificationPipelineType} */
      S {
        /**
         * Create a new AudioClassificationPipeline.
         * @param {AudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {AudioClassificationPipelineCallback} */
        async _call(ae, {
          top_k: U = 5
        } = {}) {
          const Se = this.processor.feature_extractor.config.sampling_rate, ze = await _(ae, Se), Oe = this.model.config.id2label, Ye = [];
          for (const H of ze) {
            const Y = await this.processor(H), Ie = (await this.model(Y)).logits[0], fe = await (0, m.topk)(new m.Tensor(
              "float32",
              (0, l.softmax)(Ie.data),
              Ie.dims
            ), U), Qe = fe[0].tolist(), ut = fe[1].tolist().map((de, qe) => ({
              label: (
                /** @type {string} */
                Oe ? Oe[de] : `LABEL_${de}`
              ),
              score: (
                /** @type {number} */
                Qe[qe]
              )
            }));
            Ye.push(ut);
          }
          return Array.isArray(ae) ? Ye : Ye[0];
        }
      }
      class W extends /** @type {new (options: TextAudioPipelineConstructorArgs) => ZeroShotAudioClassificationPipelineType} */
      S {
        /**
         * Create a new ZeroShotAudioClassificationPipeline.
         * @param {TextAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ZeroShotAudioClassificationPipelineCallback} */
        async _call(ae, U, {
          hypothesis_template: Se = "This is a sound of {}."
        } = {}) {
          const ze = !Array.isArray(ae);
          ze && (ae = [
            /** @type {AudioInput} */
            ae
          ]);
          const Oe = U.map(
            (Ie) => Se.replace("{}", Ie)
          ), Ye = this.tokenizer(Oe, {
            padding: !0,
            truncation: !0
          }), H = this.processor.feature_extractor.config.sampling_rate, Y = await _(ae, H), $e = [];
          for (const Ie of Y) {
            const fe = await this.processor(Ie), Qe = await this.model({ ...Ye, ...fe }), Ne = (0, l.softmax)(Qe.logits_per_audio.data);
            $e.push([...Ne].map((ut, de) => ({
              score: ut,
              label: U[de]
            })));
          }
          return ze ? $e[0] : $e;
        }
      }
      class te extends /** @type {new (options: TextAudioPipelineConstructorArgs) => AutomaticSpeechRecognitionPipelineType} */
      S {
        /**
         * Create a new AutomaticSpeechRecognitionPipeline.
         * @param {TextAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {AutomaticSpeechRecognitionPipelineCallback} */
        async _call(ae, U = {}) {
          switch (this.model.config.model_type) {
            case "whisper":
            case "lite-whisper":
              return this._call_whisper(ae, U);
            case "wav2vec2":
            case "wav2vec2-bert":
            case "unispeech":
            case "unispeech-sat":
            case "hubert":
            case "parakeet_ctc":
              return this._call_wav2vec2(ae, U);
            case "moonshine":
              return this._call_moonshine(ae, U);
            default:
              throw new Error(`AutomaticSpeechRecognitionPipeline does not support model type '${this.model.config.model_type}'.`);
          }
        }
        /**
         * @type {AutomaticSpeechRecognitionPipelineCallback}
         * @private
         */
        async _call_wav2vec2(ae, U) {
          U.language && console.warn('`language` parameter is not yet supported for `wav2vec2` models, defaulting to "English".'), U.task && console.warn('`task` parameter is not yet supported for `wav2vec2` models, defaulting to "transcribe".');
          const Se = !Array.isArray(ae);
          Se && (ae = [
            /** @type {AudioInput} */
            ae
          ]);
          const ze = this.processor.feature_extractor.config.sampling_rate, Oe = await _(ae, ze), Ye = [];
          for (const H of Oe) {
            const Y = await this.processor(H), Ie = (await this.model(Y)).logits[0], fe = [];
            for (const Ne of Ie)
              fe.push((0, l.max)(Ne.data)[1]);
            const Qe = this.tokenizer.decode(fe, { skip_special_tokens: !0 }).trim();
            Ye.push({ text: Qe });
          }
          return Se ? Ye[0] : Ye;
        }
        /**
         * @type {AutomaticSpeechRecognitionPipelineCallback}
         * @private
         */
        async _call_whisper(ae, U) {
          const Se = U.return_timestamps ?? !1, ze = U.chunk_length_s ?? 0, Oe = U.force_full_sequences ?? !1;
          let Ye = U.stride_length_s ?? null;
          const H = { ...U };
          Se === "word" && (H.return_token_timestamps = !0, H.return_timestamps = !1);
          const Y = !Array.isArray(ae);
          Y && (ae = [
            /** @type {AudioInput} */
            ae
          ]);
          const $e = this.processor.feature_extractor.config.chunk_length / this.model.config.max_source_positions, Ie = this.processor.feature_extractor.config.hop_length, fe = this.processor.feature_extractor.config.sampling_rate, Qe = await _(ae, fe), Ne = [];
          for (const ut of Qe) {
            let de = [];
            if (ze > 0) {
              if (Ye === null)
                Ye = ze / 6;
              else if (ze <= Ye)
                throw Error("`chunk_length_s` must be larger than `stride_length_s`.");
              const He = fe * ze, je = fe * Ye, lt = He - 2 * je;
              let Mt = 0;
              for (; ; ) {
                const Rt = Mt + He, Kt = ut.subarray(Mt, Rt), vn = await this.processor(Kt), wn = Mt === 0, ln = Rt >= ut.length;
                if (de.push({
                  stride: [
                    Kt.length,
                    wn ? 0 : je,
                    ln ? 0 : je
                  ],
                  input_features: vn.input_features,
                  is_last: ln
                }), ln)
                  break;
                Mt += lt;
              }
            } else
              de = [{
                stride: [ut.length, 0, 0],
                input_features: (await this.processor(ut)).input_features,
                is_last: !0
              }];
            for (const He of de) {
              H.num_frames = Math.floor(He.stride[0] / Ie);
              const je = await this.model.generate({
                inputs: He.input_features,
                ...H
              });
              Se === "word" ? (He.tokens = je.sequences.tolist()[0], He.token_timestamps = je.token_timestamps.tolist()[0].map(
                (lt) => (0, l.round)(lt, 2)
              )) : He.tokens = /** @type {Tensor} */
              je[0].tolist(), He.stride = He.stride.map((lt) => lt / fe);
            }
            const [qe, tt] = this.tokenizer._decode_asr(de, {
              time_precision: $e,
              return_timestamps: Se,
              force_full_sequences: Oe
            });
            Ne.push({ text: qe, ...tt });
          }
          return Y ? Ne[0] : Ne;
        }
        /**
         * @type {AutomaticSpeechRecognitionPipelineCallback}
         * @private
         */
        async _call_moonshine(ae, U) {
          const Se = !Array.isArray(ae);
          Se && (ae = [
            /** @type {AudioInput} */
            ae
          ]);
          const ze = this.processor.feature_extractor.config.sampling_rate, Oe = await _(ae, ze), Ye = [];
          for (const H of Oe) {
            const Y = await this.processor(H), $e = Math.floor(H.length / ze) * 6, Ie = await this.model.generate({ max_new_tokens: $e, ...U, ...Y }), fe = this.processor.batch_decode(
              /** @type {Tensor} */
              Ie,
              { skip_special_tokens: !0 }
            )[0];
            Ye.push({ text: fe });
          }
          return Se ? Ye[0] : Ye;
        }
      }
      class K extends /** @type {new (options: TextImagePipelineConstructorArgs) => ImageToTextPipelineType} */
      S {
        /**
         * Create a new ImageToTextPipeline.
         * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ImageToTextPipelineCallback} */
        async _call(ae, U = {}) {
          const Se = Array.isArray(ae), ze = await p(ae), { pixel_values: Oe } = await this.processor(ze), Ye = [];
          for (const H of Oe) {
            H.dims = [1, ...H.dims];
            const Y = await this.model.generate({ inputs: H, ...U }), $e = this.tokenizer.batch_decode(
              /** @type {Tensor} */
              Y,
              {
                skip_special_tokens: !0
              }
            ).map((Ie) => ({ generated_text: Ie.trim() }));
            Ye.push($e);
          }
          return Se ? Ye : Ye[0];
        }
      }
      class pe extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageClassificationPipelineType} */
      S {
        /**
         * Create a new ImageClassificationPipeline.
         * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ImageClassificationPipelineCallback} */
        async _call(ae, {
          top_k: U = 5
        } = {}) {
          const Se = await p(ae), { pixel_values: ze } = await this.processor(Se), Oe = await this.model({ pixel_values: ze }), Ye = this.model.config.id2label, H = [];
          for (const Y of Oe.logits) {
            const $e = await (0, m.topk)(new m.Tensor(
              "float32",
              (0, l.softmax)(Y.data),
              Y.dims
            ), U), Ie = $e[0].tolist(), Qe = $e[1].tolist().map((Ne, ut) => ({
              label: (
                /** @type {string} */
                Ye ? Ye[Ne] : `LABEL_${Ne}`
              ),
              score: (
                /** @type {number} */
                Ie[ut]
              )
            }));
            H.push(Qe);
          }
          return Array.isArray(ae) ? H : H[0];
        }
      }
      class be extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageSegmentationPipelineType} */
      S {
        /**
         * Create a new ImageSegmentationPipeline.
         * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae), this.subtasks_mapping = {
            // Mapping of subtasks to their corresponding post-processing function names.
            panoptic: "post_process_panoptic_segmentation",
            instance: "post_process_instance_segmentation",
            semantic: "post_process_semantic_segmentation"
          };
        }
        /** @type {ImageSegmentationPipelineCallback} */
        async _call(ae, {
          threshold: U = 0.5,
          mask_threshold: Se = 0.5,
          overlap_mask_area_threshold: ze = 0.8,
          label_ids_to_fuse: Oe = null,
          target_sizes: Ye = null,
          subtask: H = null
        } = {}) {
          if (Array.isArray(ae) && ae.length !== 1)
            throw Error("Image segmentation pipeline currently only supports a batch size of 1.");
          const $e = await p(ae), Ie = $e.map((He) => [He.height, He.width]), fe = await this.processor($e), { inputNames: Qe, outputNames: Ne } = this.model.sessions.model;
          if (!Qe.includes("pixel_values")) {
            if (Qe.length !== 1)
              throw Error(`Expected a single input name, but got ${Qe.length} inputs: ${Qe}.`);
            const He = Qe[0];
            if (He in fe)
              throw Error(`Input name ${He} already exists in the inputs.`);
            fe[He] = fe.pixel_values;
          }
          const ut = await this.model(fe);
          let de = null;
          if (H !== null)
            de = this.subtasks_mapping[H];
          else if (this.processor.image_processor) {
            for (const [He, je] of Object.entries(this.subtasks_mapping))
              if (je in this.processor.image_processor) {
                de = this.processor.image_processor[je].bind(this.processor.image_processor), H = He;
                break;
              }
          }
          const qe = this.model.config.id2label, tt = [];
          if (H)
            if (H === "panoptic" || H === "instance") {
              const He = de(
                ut,
                U,
                Se,
                ze,
                Oe,
                Ye ?? Ie
                // TODO FIX?
              )[0], je = He.segmentation;
              for (const lt of He.segments_info) {
                const Mt = new Uint8ClampedArray(je.data.length);
                for (let Kt = 0; Kt < je.data.length; ++Kt)
                  je.data[Kt] === lt.id && (Mt[Kt] = 255);
                const Rt = new h.RawImage(Mt, je.dims[1], je.dims[0], 1);
                tt.push({
                  score: lt.score,
                  label: qe[lt.label_id],
                  mask: Rt
                });
              }
            } else if (H === "semantic") {
              const { segmentation: He, labels: je } = de(ut, Ye ?? Ie)[0];
              for (const lt of je) {
                const Mt = new Uint8ClampedArray(He.data.length);
                for (let Kt = 0; Kt < He.data.length; ++Kt)
                  He.data[Kt] === lt && (Mt[Kt] = 255);
                const Rt = new h.RawImage(Mt, He.dims[1], He.dims[0], 1);
                tt.push({
                  score: null,
                  label: qe[lt],
                  mask: Rt
                });
              }
            } else
              throw Error(`Subtask ${H} not supported.`);
          else {
            const je = ut[Ne[0]];
            for (let lt = 0; lt < Ie.length; ++lt) {
              const Mt = Ie[lt], Rt = je[lt];
              Rt.data.some((vn) => vn < -1e-5 || vn > 1 + 1e-5) && Rt.sigmoid_();
              const Kt = await h.RawImage.fromTensor(Rt.mul_(255).to("uint8")).resize(Mt[1], Mt[0]);
              tt.push({
                label: null,
                score: null,
                mask: Kt
              });
            }
          }
          return tt;
        }
      }
      class Ee extends /** @type {new (options: ImagePipelineConstructorArgs) => BackgroundRemovalPipelineType} */
      /** @type {any} */
      be {
        /**
         * Create a new BackgroundRemovalPipeline.
         * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {BackgroundRemovalPipelineCallback} */
        async _call(ae, U = {}) {
          if (Array.isArray(ae) && ae.length !== 1)
            throw Error("Background removal pipeline currently only supports a batch size of 1.");
          const ze = await p(ae), Oe = await super._call(ae, U);
          return ze.map((H, Y) => {
            const $e = H.clone();
            return $e.putAlpha(Oe[Y].mask), $e;
          });
        }
      }
      class Ge extends /** @type {new (options: TextImagePipelineConstructorArgs) => ZeroShotImageClassificationPipelineType} */
      S {
        /**
         * Create a new ZeroShotImageClassificationPipeline.
         * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ZeroShotImageClassificationPipelineCallback} */
        async _call(ae, U, {
          hypothesis_template: Se = "This is a photo of {}"
        } = {}) {
          const ze = Array.isArray(ae), Oe = await p(ae), Ye = U.map(
            (Qe) => Se.replace("{}", Qe)
          ), H = this.tokenizer(Ye, {
            padding: this.model.config.model_type === "siglip" ? "max_length" : !0,
            truncation: !0
          }), { pixel_values: Y } = await this.processor(Oe), $e = await this.model({ ...H, pixel_values: Y }), Ie = this.model.config.model_type === "siglip" ? (Qe) => Qe.sigmoid().data : (Qe) => (0, l.softmax)(Qe.data), fe = [];
          for (const Qe of $e.logits_per_image) {
            const ut = [...Ie(Qe)].map((de, qe) => ({
              score: de,
              label: U[qe]
            }));
            ut.sort((de, qe) => qe.score - de.score), fe.push(ut);
          }
          return ze ? fe : fe[0];
        }
      }
      class _e extends /** @type {new (options: ImagePipelineConstructorArgs) => ObjectDetectionPipelineType} */
      S {
        /**
         * Create a new ObjectDetectionPipeline.
         * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ObjectDetectionPipelineCallback} */
        async _call(ae, {
          threshold: U = 0.9,
          percentage: Se = !1
        } = {}) {
          const ze = Array.isArray(ae);
          if (ze && ae.length !== 1)
            throw Error("Object detection pipeline currently only supports a batch size of 1.");
          const Oe = await p(ae), Ye = Se ? null : Oe.map((Ne) => [Ne.height, Ne.width]), { pixel_values: H, pixel_mask: Y } = await this.processor(Oe), $e = await this.model({ pixel_values: H, pixel_mask: Y }), Ie = this.processor.image_processor.post_process_object_detection($e, U, Ye), fe = this.model.config.id2label, Qe = Ie.map((Ne) => Ne.boxes.map((ut, de) => ({
            score: Ne.scores[de],
            label: fe[Ne.classes[de]],
            box: v(ut, !Se)
          })));
          return ze ? Qe : Qe[0];
        }
      }
      class De extends /** @type {new (options: TextImagePipelineConstructorArgs) => ZeroShotObjectDetectionPipelineType} */
      S {
        /**
         * Create a new ZeroShotObjectDetectionPipeline.
         * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ZeroShotObjectDetectionPipelineCallback} */
        async _call(ae, U, {
          threshold: Se = 0.1,
          top_k: ze = null,
          percentage: Oe = !1
        } = {}) {
          const Ye = Array.isArray(ae), H = await p(ae), Y = this.tokenizer(U, {
            padding: !0,
            truncation: !0
          }), $e = await this.processor(H), Ie = [];
          for (let fe = 0; fe < H.length; ++fe) {
            const Qe = H[fe], Ne = Oe ? null : [[Qe.height, Qe.width]], ut = $e.pixel_values[fe].unsqueeze_(0), de = await this.model({ ...Y, pixel_values: ut });
            let qe;
            if ("post_process_grounded_object_detection" in this.processor) {
              const tt = this.processor.post_process_grounded_object_detection(
                de,
                Y.input_ids,
                {
                  // TODO: support separate threshold values
                  box_threshold: Se,
                  text_threshold: Se,
                  target_sizes: Ne
                }
              )[0];
              qe = tt.boxes.map((He, je) => ({
                score: tt.scores[je],
                label: tt.labels[je],
                box: v(He, !Oe)
              }));
            } else {
              const tt = this.processor.image_processor.post_process_object_detection(de, Se, Ne, !0)[0];
              qe = tt.boxes.map((He, je) => ({
                score: tt.scores[je],
                label: U[tt.classes[je]],
                box: v(He, !Oe)
              }));
            }
            qe.sort((tt, He) => He.score - tt.score), ze !== null && (qe = qe.slice(0, ze)), Ie.push(qe);
          }
          return Ye ? Ie : Ie[0];
        }
      }
      class he extends /** @type {new (options: TextImagePipelineConstructorArgs) => DocumentQuestionAnsweringPipelineType} */
      S {
        /**
         * Create a new DocumentQuestionAnsweringPipeline.
         * @param {TextImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {DocumentQuestionAnsweringPipelineCallback} */
        async _call(ae, U, Se = {}) {
          const ze = (await p(ae))[0], { pixel_values: Oe } = await this.processor(ze), Ye = `<s_docvqa><s_question>${U}</s_question><s_answer>`, H = this.tokenizer(Ye, {
            add_special_tokens: !1,
            padding: !0,
            truncation: !0
          }).input_ids, Y = await this.model.generate({
            inputs: Oe,
            // @ts-expect-error TS2339
            max_length: this.model.config.decoder.max_position_embeddings,
            decoder_input_ids: H,
            ...Se
          }), Ie = this.tokenizer.batch_decode(
            /** @type {Tensor} */
            Y
          )[0].match(/<s_answer>(.*?)<\/s_answer>/);
          let fe = null;
          return Ie && Ie.length >= 2 && (fe = Ie[1].trim()), [{ answer: fe }];
        }
      }
      class Z extends /** @type {new (options: TextToAudioPipelineConstructorArgs) => TextToAudioPipelineType} */
      S {
        /**
         * Create a new TextToAudioPipeline.
         * @param {TextToAudioPipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(U) {
          super(U);
          Ce(this, "DEFAULT_VOCODER_ID", "Xenova/speecht5_hifigan");
          this.vocoder = U.vocoder ?? null;
        }
        async _prepare_speaker_embeddings(U) {
          if ((typeof U == "string" || U instanceof URL) && (U = new Float32Array(
            await (await fetch(U)).arrayBuffer()
          )), U instanceof Float32Array)
            U = new m.Tensor(
              "float32",
              U,
              [U.length]
            );
          else if (!(U instanceof m.Tensor))
            throw new Error("Speaker embeddings must be a `Tensor`, `Float32Array`, `string`, or `URL`.");
          return U;
        }
        /** @type {TextToAudioPipelineCallback} */
        async _call(U, {
          speaker_embeddings: Se = null,
          num_inference_steps: ze,
          speed: Oe
        } = {}) {
          return this.processor ? this._call_text_to_spectrogram(U, { speaker_embeddings: Se }) : this.model.config.model_type === "supertonic" ? this._call_supertonic(U, { speaker_embeddings: Se, num_inference_steps: ze, speed: Oe }) : this._call_text_to_waveform(U);
        }
        async _call_supertonic(U, { speaker_embeddings: Se, num_inference_steps: ze, speed: Oe }) {
          if (!Se)
            throw new Error("Speaker embeddings must be provided for Supertonic models.");
          Se = await this._prepare_speaker_embeddings(Se);
          const { sampling_rate: Ye, style_dim: H } = this.model.config;
          Se = /** @type {Tensor} */
          Se.view(1, -1, H);
          const Y = this.tokenizer(U, {
            padding: !0,
            truncation: !0
          }), { waveform: $e } = await this.model.generate_speech({
            ...Y,
            style: Se,
            num_inference_steps: ze,
            speed: Oe
          });
          return new f.RawAudio(
            $e.data,
            Ye
          );
        }
        async _call_text_to_waveform(U) {
          const Se = this.tokenizer(U, {
            padding: !0,
            truncation: !0
          }), { waveform: ze } = await this.model(Se), Oe = this.model.config.sampling_rate;
          return new f.RawAudio(
            ze.data,
            Oe
          );
        }
        async _call_text_to_spectrogram(U, { speaker_embeddings: Se }) {
          this.vocoder || (console.log("No vocoder specified, using default HifiGan vocoder."), this.vocoder = await r.AutoModel.from_pretrained(this.DEFAULT_VOCODER_ID, { dtype: "fp32" }));
          const { input_ids: ze } = this.tokenizer(U, {
            padding: !0,
            truncation: !0
          });
          Se = await this._prepare_speaker_embeddings(Se), Se = Se.view(1, -1);
          const { waveform: Oe } = await this.model.generate_speech(ze, Se, { vocoder: this.vocoder }), Ye = this.processor.feature_extractor.config.sampling_rate;
          return new f.RawAudio(
            Oe.data,
            Ye
          );
        }
      }
      class me extends /** @type {new (options: ImagePipelineConstructorArgs) => ImageToImagePipelineType} */
      S {
        /**
         * Create a new ImageToImagePipeline.
         * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {ImageToImagePipelineCallback} */
        async _call(ae) {
          const U = await p(ae), Se = await this.processor(U), ze = await this.model(Se), Oe = [];
          for (const Ye of ze.reconstruction) {
            const H = Ye.squeeze().clamp_(0, 1).mul_(255).round_().to("uint8");
            Oe.push(h.RawImage.fromTensor(H));
          }
          return Oe.length > 1 ? Oe : Oe[0];
        }
      }
      class we extends /** @type {new (options: ImagePipelineConstructorArgs) => DepthEstimationPipelineType} */
      S {
        /**
         * Create a new DepthEstimationPipeline.
         * @param {ImagePipelineConstructorArgs} options An object used to instantiate the pipeline.
         */
        constructor(ae) {
          super(ae);
        }
        /** @type {DepthEstimationPipelineCallback} */
        async _call(ae) {
          const U = await p(ae), Se = await this.processor(U), { predicted_depth: ze } = await this.model(Se), Oe = [];
          for (let Ye = 0; Ye < U.length; ++Ye) {
            const H = ze[Ye], [Y, $e] = H.dims.slice(-2), [Ie, fe] = U[Ye].size, Qe = (await (0, m.interpolate_4d)(H.view(1, 1, Y, $e), {
              size: [fe, Ie],
              mode: "bilinear"
            })).view(fe, Ie), Ne = (
              /** @type {number} */
              Qe.min().item()
            ), ut = (
              /** @type {number} */
              Qe.max().item()
            ), de = Qe.sub(Ne).div_(ut - Ne).mul_(255).to("uint8").unsqueeze(0), qe = h.RawImage.fromTensor(de);
            Oe.push({
              predicted_depth: Qe,
              depth: qe
            });
          }
          return Oe.length > 1 ? Oe : Oe[0];
        }
      }
      const xe = Object.freeze({
        "text-classification": {
          tokenizer: i.AutoTokenizer,
          pipeline: D,
          model: r.AutoModelForSequenceClassification,
          default: {
            // TODO: replace with original
            // "model": "distilbert-base-uncased-finetuned-sst-2-english",
            model: "Xenova/distilbert-base-uncased-finetuned-sst-2-english"
          },
          type: "text"
        },
        "token-classification": {
          tokenizer: i.AutoTokenizer,
          pipeline: w,
          model: r.AutoModelForTokenClassification,
          default: {
            // TODO: replace with original
            // "model": "Davlan/bert-base-multilingual-cased-ner-hrl",
            model: "Xenova/bert-base-multilingual-cased-ner-hrl"
          },
          type: "text"
        },
        "question-answering": {
          tokenizer: i.AutoTokenizer,
          pipeline: T,
          model: r.AutoModelForQuestionAnswering,
          default: {
            // TODO: replace with original
            // "model": "distilbert-base-cased-distilled-squad",
            model: "Xenova/distilbert-base-cased-distilled-squad"
          },
          type: "text"
        },
        "fill-mask": {
          tokenizer: i.AutoTokenizer,
          pipeline: F,
          model: r.AutoModelForMaskedLM,
          default: {
            // TODO: replace with original
            // "model": "bert-base-uncased",
            model: "Xenova/bert-base-uncased"
          },
          type: "text"
        },
        summarization: {
          tokenizer: i.AutoTokenizer,
          pipeline: A,
          model: r.AutoModelForSeq2SeqLM,
          default: {
            // TODO: replace with original
            // "model": "sshleifer/distilbart-cnn-6-6",
            model: "Xenova/distilbart-cnn-6-6"
          },
          type: "text"
        },
        translation: {
          tokenizer: i.AutoTokenizer,
          pipeline: L,
          model: r.AutoModelForSeq2SeqLM,
          default: {
            // TODO: replace with original
            // "model": "t5-small",
            model: "Xenova/t5-small"
          },
          type: "text"
        },
        "text2text-generation": {
          tokenizer: i.AutoTokenizer,
          pipeline: E,
          model: r.AutoModelForSeq2SeqLM,
          default: {
            // TODO: replace with original
            // "model": "google/flan-t5-small",
            model: "Xenova/flan-t5-small"
          },
          type: "text"
        },
        "text-generation": {
          tokenizer: i.AutoTokenizer,
          pipeline: R,
          model: r.AutoModelForCausalLM,
          default: {
            // TODO: replace with original
            // "model": "gpt2",
            model: "Xenova/gpt2"
          },
          type: "text"
        },
        "zero-shot-classification": {
          tokenizer: i.AutoTokenizer,
          pipeline: N,
          model: r.AutoModelForSequenceClassification,
          default: {
            // TODO: replace with original
            // "model": "typeform/distilbert-base-uncased-mnli",
            model: "Xenova/distilbert-base-uncased-mnli"
          },
          type: "text"
        },
        "audio-classification": {
          pipeline: Q,
          model: r.AutoModelForAudioClassification,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "superb/wav2vec2-base-superb-ks",
            model: "Xenova/wav2vec2-base-superb-ks"
          },
          type: "audio"
        },
        "zero-shot-audio-classification": {
          tokenizer: i.AutoTokenizer,
          pipeline: W,
          model: r.AutoModel,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "laion/clap-htsat-fused",
            model: "Xenova/clap-htsat-unfused"
          },
          type: "multimodal"
        },
        "automatic-speech-recognition": {
          tokenizer: i.AutoTokenizer,
          pipeline: te,
          model: [r.AutoModelForSpeechSeq2Seq, r.AutoModelForCTC],
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "openai/whisper-tiny.en",
            model: "Xenova/whisper-tiny.en"
          },
          type: "multimodal"
        },
        "text-to-audio": {
          tokenizer: i.AutoTokenizer,
          pipeline: Z,
          model: [r.AutoModelForTextToWaveform, r.AutoModelForTextToSpectrogram],
          processor: [
            a.AutoProcessor,
            /* Some don't use a processor */
            null
          ],
          default: {
            // TODO: replace with original
            // "model": "microsoft/speecht5_tts",
            model: "Xenova/speecht5_tts"
          },
          type: "text"
        },
        "image-to-text": {
          tokenizer: i.AutoTokenizer,
          pipeline: K,
          model: r.AutoModelForVision2Seq,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "nlpconnect/vit-gpt2-image-captioning",
            model: "Xenova/vit-gpt2-image-captioning"
          },
          type: "multimodal"
        },
        "image-classification": {
          // no tokenizer
          pipeline: pe,
          model: r.AutoModelForImageClassification,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "google/vit-base-patch16-224",
            model: "Xenova/vit-base-patch16-224"
          },
          type: "multimodal"
        },
        "image-segmentation": {
          // no tokenizer
          pipeline: be,
          model: [r.AutoModelForImageSegmentation, r.AutoModelForSemanticSegmentation, r.AutoModelForUniversalSegmentation],
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "facebook/detr-resnet-50-panoptic",
            model: "Xenova/detr-resnet-50-panoptic"
          },
          type: "multimodal"
        },
        "background-removal": {
          // no tokenizer
          pipeline: Ee,
          model: [r.AutoModelForImageSegmentation, r.AutoModelForSemanticSegmentation, r.AutoModelForUniversalSegmentation],
          processor: a.AutoProcessor,
          default: {
            model: "Xenova/modnet"
          },
          type: "image"
        },
        "zero-shot-image-classification": {
          tokenizer: i.AutoTokenizer,
          pipeline: Ge,
          model: r.AutoModel,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "openai/clip-vit-base-patch32",
            model: "Xenova/clip-vit-base-patch32"
          },
          type: "multimodal"
        },
        "object-detection": {
          // no tokenizer
          pipeline: _e,
          model: r.AutoModelForObjectDetection,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "facebook/detr-resnet-50",
            model: "Xenova/detr-resnet-50"
          },
          type: "multimodal"
        },
        "zero-shot-object-detection": {
          tokenizer: i.AutoTokenizer,
          pipeline: De,
          model: r.AutoModelForZeroShotObjectDetection,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "google/owlvit-base-patch32",
            model: "Xenova/owlvit-base-patch32"
          },
          type: "multimodal"
        },
        "document-question-answering": {
          tokenizer: i.AutoTokenizer,
          pipeline: he,
          model: r.AutoModelForDocumentQuestionAnswering,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "naver-clova-ix/donut-base-finetuned-docvqa",
            model: "Xenova/donut-base-finetuned-docvqa"
          },
          type: "multimodal"
        },
        "image-to-image": {
          // no tokenizer
          pipeline: me,
          model: r.AutoModelForImageToImage,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "caidas/swin2SR-classical-sr-x2-64",
            model: "Xenova/swin2SR-classical-sr-x2-64"
          },
          type: "image"
        },
        "depth-estimation": {
          // no tokenizer
          pipeline: we,
          model: r.AutoModelForDepthEstimation,
          processor: a.AutoProcessor,
          default: {
            // TODO: replace with original
            // "model": "Intel/dpt-large",
            model: "Xenova/dpt-large"
          },
          type: "image"
        },
        // This task serves as a useful interface for dealing with sentence-transformers (https://huggingface.co/sentence-transformers).
        "feature-extraction": {
          tokenizer: i.AutoTokenizer,
          pipeline: q,
          model: r.AutoModel,
          default: {
            // TODO: replace with original
            // "model": "sentence-transformers/all-MiniLM-L6-v2",
            model: "Xenova/all-MiniLM-L6-v2"
          },
          type: "text"
        },
        "image-feature-extraction": {
          processor: a.AutoProcessor,
          pipeline: ne,
          model: [r.AutoModelForImageFeatureExtraction, r.AutoModel],
          default: {
            // TODO: replace with original
            // "model": "google/vit-base-patch16-224",
            model: "Xenova/vit-base-patch16-224-in21k"
          },
          type: "image"
        }
      }), et = Object.freeze({
        "sentiment-analysis": "text-classification",
        ner: "token-classification",
        // "vqa": "visual-question-answering", // TODO: Add
        asr: "automatic-speech-recognition",
        "text-to-speech": "text-to-audio",
        // Add for backwards compatibility
        embeddings: "feature-extraction"
      });
      async function Ve(Be, ae = null, {
        progress_callback: U = null,
        config: Se = null,
        cache_dir: ze = null,
        local_files_only: Oe = !1,
        revision: Ye = "main",
        device: H = null,
        dtype: Y = null,
        subfolder: $e = "onnx",
        use_external_data_format: Ie = null,
        model_file_name: fe = null,
        session_options: Qe = {}
      } = {}) {
        Be = et[Be] ?? Be;
        const Ne = xe[Be.split("_", 1)[0]];
        if (!Ne)
          throw Error(`Unsupported pipeline: ${Be}. Must be one of [${Object.keys(xe)}]`);
        ae || (ae = Ne.default.model, console.log(`No model specified. Using default model: "${ae}".`));
        const ut = {
          progress_callback: U,
          config: Se,
          cache_dir: ze,
          local_files_only: Oe,
          revision: Ye,
          device: H,
          dtype: Y,
          subfolder: $e,
          use_external_data_format: Ie,
          model_file_name: fe,
          session_options: Qe
        }, de = /* @__PURE__ */ new Map([
          ["tokenizer", Ne.tokenizer],
          ["model", Ne.model],
          ["processor", Ne.processor]
        ]), qe = await nt(de, ae, ut);
        qe.task = Be, (0, u.dispatchCallback)(U, {
          status: "ready",
          task: Be,
          model: ae
        });
        const tt = Ne.pipeline;
        return new tt(qe);
      }
      async function nt(Be, ae, U) {
        const Se = /* @__PURE__ */ Object.create(null), ze = [];
        for (const [Oe, Ye] of Be.entries()) {
          if (!Ye)
            continue;
          let H;
          Array.isArray(Ye) ? H = new Promise(async (Y, $e) => {
            var fe, Qe;
            let Ie;
            for (const Ne of Ye) {
              if (Ne === null) {
                Y(null);
                return;
              }
              try {
                Y(await Ne.from_pretrained(ae, U));
                return;
              } catch (ut) {
                if ((fe = ut.message) != null && fe.includes("Unsupported model type"))
                  Ie = ut;
                else if ((Qe = ut.message) != null && Qe.includes("Could not locate file"))
                  Ie = ut;
                else {
                  $e(ut);
                  return;
                }
              }
            }
            $e(Ie);
          }) : H = Ye.from_pretrained(ae, U), Se[Oe] = H, ze.push(H);
        }
        await Promise.all(ze);
        for (const [Oe, Ye] of Object.entries(Se))
          Se[Oe] = await Ye;
        return Se;
      }
    }
  ),
  /***/
  "./src/tokenizers.js": (
    /*!***************************!*\
      !*** ./src/tokenizers.js ***!
      \***************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        AlbertTokenizer: () => (
          /* binding */
          at
        ),
        /* harmony export */
        AutoTokenizer: () => (
          /* binding */
          Br
        ),
        /* harmony export */
        BartTokenizer: () => (
          /* binding */
          Tt
        ),
        /* harmony export */
        BertTokenizer: () => (
          /* binding */
          Me
        ),
        /* harmony export */
        BlenderbotSmallTokenizer: () => (
          /* binding */
          ct
        ),
        /* harmony export */
        BlenderbotTokenizer: () => (
          /* binding */
          bt
        ),
        /* harmony export */
        BloomTokenizer: () => (
          /* binding */
          Vt
        ),
        /* harmony export */
        CLIPTokenizer: () => (
          /* binding */
          Cs
        ),
        /* harmony export */
        CamembertTokenizer: () => (
          /* binding */
          ge
        ),
        /* harmony export */
        CodeGenTokenizer: () => (
          /* binding */
          As
        ),
        /* harmony export */
        CodeLlamaTokenizer: () => (
          /* binding */
          vi
        ),
        /* harmony export */
        CohereTokenizer: () => (
          /* binding */
          it
        ),
        /* harmony export */
        ConvBertTokenizer: () => (
          /* binding */
          le
        ),
        /* harmony export */
        DebertaTokenizer: () => (
          /* binding */
          _t
        ),
        /* harmony export */
        DebertaV2Tokenizer: () => (
          /* binding */
          on
        ),
        /* harmony export */
        DistilBertTokenizer: () => (
          /* binding */
          se
        ),
        /* harmony export */
        ElectraTokenizer: () => (
          /* binding */
          Ke
        ),
        /* harmony export */
        EsmTokenizer: () => (
          /* binding */
          wi
        ),
        /* harmony export */
        FalconTokenizer: () => (
          /* binding */
          fi
        ),
        /* harmony export */
        GPT2Tokenizer: () => (
          /* binding */
          Pt
        ),
        /* harmony export */
        GPTNeoXTokenizer: () => (
          /* binding */
          Pi
        ),
        /* harmony export */
        GemmaTokenizer: () => (
          /* binding */
          fs
        ),
        /* harmony export */
        Grok1Tokenizer: () => (
          /* binding */
          Ps
        ),
        /* harmony export */
        HerbertTokenizer: () => (
          /* binding */
          B
        ),
        /* harmony export */
        LlamaTokenizer: () => (
          /* binding */
          Mn
        ),
        /* harmony export */
        M2M100Tokenizer: () => (
          /* binding */
          Ni
        ),
        /* harmony export */
        MBart50Tokenizer: () => (
          /* binding */
          Dt
        ),
        /* harmony export */
        MBartTokenizer: () => (
          /* binding */
          en
        ),
        /* harmony export */
        MPNetTokenizer: () => (
          /* binding */
          ki
        ),
        /* harmony export */
        MarianTokenizer: () => (
          /* binding */
          Ji
        ),
        /* harmony export */
        MgpstrTokenizer: () => (
          /* binding */
          ps
        ),
        /* harmony export */
        MobileBertTokenizer: () => (
          /* binding */
          rt
        ),
        /* harmony export */
        NllbTokenizer: () => (
          /* binding */
          jt
        ),
        /* harmony export */
        NougatTokenizer: () => (
          /* binding */
          yn
        ),
        /* harmony export */
        PreTrainedTokenizer: () => (
          /* binding */
          qt
        ),
        /* harmony export */
        Qwen2Tokenizer: () => (
          /* binding */
          hs
        ),
        /* harmony export */
        RoFormerTokenizer: () => (
          /* binding */
          J
        ),
        /* harmony export */
        RobertaTokenizer: () => (
          /* binding */
          tn
        ),
        /* harmony export */
        SiglipTokenizer: () => (
          /* binding */
          Is
        ),
        /* harmony export */
        SpeechT5Tokenizer: () => (
          /* binding */
          Lt
        ),
        /* harmony export */
        SqueezeBertTokenizer: () => (
          /* binding */
          mt
        ),
        /* harmony export */
        T5Tokenizer: () => (
          /* binding */
          pt
        ),
        /* harmony export */
        TokenizerModel: () => (
          /* binding */
          ne
        ),
        /* harmony export */
        VitsTokenizer: () => (
          /* binding */
          Ui
        ),
        /* harmony export */
        Wav2Vec2CTCTokenizer: () => (
          /* binding */
          pi
        ),
        /* harmony export */
        WhisperTokenizer: () => (
          /* binding */
          Ws
        ),
        /* harmony export */
        XLMRobertaTokenizer: () => (
          /* binding */
          ci
        ),
        /* harmony export */
        XLMTokenizer: () => (
          /* binding */
          Fe
        ),
        /* harmony export */
        is_chinese_char: () => (
          /* binding */
          F
        )
        /* harmony export */
      });
      var i = t(
        /*! ./utils/generic.js */
        "./src/utils/generic.js"
      ), r = t(
        /*! ./utils/core.js */
        "./src/utils/core.js"
      ), a = t(
        /*! ./utils/hub.js */
        "./src/utils/hub.js"
      ), c = t(
        /*! ./utils/maths.js */
        "./src/utils/maths.js"
      ), u = t(
        /*! ./utils/tensor.js */
        "./src/utils/tensor.js"
      ), l = t(
        /*! ./utils/data-structures.js */
        "./src/utils/data-structures.js"
      ), f = t(
        /*! @huggingface/jinja */
        "./node_modules/@huggingface/jinja/dist/index.js"
      ), m = t(
        /*! ./models/whisper/common_whisper.js */
        "./src/models/whisper/common_whisper.js"
      );
      async function h(Xe, j) {
        const ie = await Promise.all([
          (0, a.getModelJSON)(Xe, "tokenizer.json", !0, j),
          (0, a.getModelJSON)(Xe, "tokenizer_config.json", !0, j)
        ]);
        return j.legacy !== null && (ie[1].legacy = j.legacy), ie;
      }
      function p(Xe, j) {
        const ie = [];
        let Ae = 0;
        for (const Re of Xe.matchAll(j)) {
          const We = Re[0];
          Ae < Re.index && ie.push(Xe.slice(Ae, Re.index)), We.length > 0 && ie.push(We), Ae = Re.index + We.length;
        }
        return Ae < Xe.length && ie.push(Xe.slice(Ae)), ie;
      }
      function _(Xe, j = !0) {
        if (Xe.Regex !== void 0) {
          let ie = Xe.Regex.replace(/\\([#&~])/g, "$1");
          for (const [Ae, Re] of N)
            ie = ie.replaceAll(Ae, Re);
          return new RegExp(ie, "gu");
        } else if (Xe.String !== void 0) {
          const ie = (0, r.escapeRegExp)(Xe.String);
          return new RegExp(j ? ie : `(${ie})`, "gu");
        } else
          return console.warn("Unknown pattern type:", Xe), null;
      }
      function v(Xe) {
        return new Map(Object.entries(Xe));
      }
      function S(Xe) {
        const j = Xe.dims;
        switch (j.length) {
          case 1:
            return Xe.tolist();
          case 2:
            if (j[0] !== 1)
              throw new Error("Unable to decode tensor with `batch size !== 1`. Use `tokenizer.batch_decode(...)` for batched inputs.");
            return Xe.tolist()[0];
          default:
            throw new Error(`Expected tensor to have 1-2 dimensions, got ${j.length}.`);
        }
      }
      function D(Xe) {
        return Xe.replace(/ \./g, ".").replace(/ \?/g, "?").replace(/ \!/g, "!").replace(/ ,/g, ",").replace(/ \' /g, "'").replace(/ n\'t/g, "n't").replace(/ \'m/g, "'m").replace(/ \'s/g, "'s").replace(/ \'ve/g, "'ve").replace(/ \'re/g, "'re");
      }
      function w(Xe) {
        return Xe.replace(/\p{M}/gu, "");
      }
      function T(Xe) {
        return w(Xe.toLowerCase());
      }
      function F(Xe) {
        return Xe >= 19968 && Xe <= 40959 || Xe >= 13312 && Xe <= 19903 || Xe >= 131072 && Xe <= 173791 || Xe >= 173824 && Xe <= 177983 || Xe >= 177984 && Xe <= 178207 || Xe >= 178208 && Xe <= 183983 || Xe >= 63744 && Xe <= 64255 || Xe >= 194560 && Xe <= 195103;
      }
      function E(Xe, j, ie) {
        const Ae = [];
        let Re = 0;
        for (; Re < Xe.length; ) {
          if (Ae.push(Xe[Re]), (j.get(Xe[Re]) ?? ie) !== ie) {
            ++Re;
            continue;
          }
          for (; ++Re < Xe.length && (j.get(Xe[Re]) ?? ie) === ie; )
            j.get(Ae.at(-1)) !== ie && (Ae[Ae.length - 1] += Xe[Re]);
        }
        return Ae;
      }
      function A(Xe) {
        return Xe.match(/\S+/g) || [];
      }
      const L = "\\p{P}\\u0021-\\u002F\\u003A-\\u0040\\u005B-\\u0060\\u007B-\\u007E", I = new RegExp(`^[${L}]+$`, "gu"), R = ".,!?", N = /* @__PURE__ */ new Map([
        // These use the case insensitive group modifier, which is not supported in JavaScript.
        // When parsing the regex, an "Invalid group" error is thrown.
        ["(?i:'s|'t|'re|'ve|'m|'ll|'d)", "(?:'([sS]|[tT]|[rR][eE]|[vV][eE]|[mM]|[lL][lL]|[dD]))"],
        ["(?i:[sdmt]|ll|ve|re)", "(?:[sS]|[dD]|[mM]|[tT]|[lL][lL]|[vV][eE]|[rR][eE])"],
        // JS doesn't support possessive quantifiers (these are used in recent OpenAI tokenizers).
        ["[^\\r\\n\\p{L}\\p{N}]?+", "[^\\r\\n\\p{L}\\p{N}]?"],
        ["[^\\s\\p{L}\\p{N}]++", "[^\\s\\p{L}\\p{N}]+"],
        // Used to override the default (invalid) regex of the bloom pretokenizer.
        // For more information, see https://github.com/huggingface/transformers.js/issues/94
        [` ?[^(\\s|[${R}])]+`, ` ?[^\\s${R}]+`]
      ]);
      class q {
        /**
         * Creates a new instance of AddedToken.
         * @param {Object} config Added token configuration object.
         * @param {string} config.content The content of the added token.
         * @param {number} config.id The id of the added token.
         * @param {boolean} [config.single_word=false] Whether this token must be a single word or can break words.
         * @param {boolean} [config.lstrip=false] Whether this token should strip whitespaces on its left.
         * @param {boolean} [config.rstrip=false] Whether this token should strip whitespaces on its right.
         * @param {boolean} [config.normalized=false] Whether this token should be normalized.
         * @param {boolean} [config.special=false] Whether this token is special.
         */
        constructor(j) {
          this.content = j.content, this.id = j.id, this.single_word = j.single_word ?? !1, this.lstrip = j.lstrip ?? !1, this.rstrip = j.rstrip ?? !1, this.special = j.special ?? !1, this.normalized = j.normalized ?? null;
        }
      }
      class ne extends i.Callable {
        /**
         * Creates a new instance of TokenizerModel.
         * @param {Object} config The configuration object for the TokenizerModel.
         */
        constructor(j) {
          super(), this.config = j, this.vocab = [], this.tokens_to_ids = /* @__PURE__ */ new Map(), this.unk_token_id = void 0, this.unk_token = void 0, this.end_of_word_suffix = void 0, this.fuse_unk = this.config.fuse_unk ?? !1;
        }
        /**
         * Instantiates a new TokenizerModel instance based on the configuration object provided.
         * @param {Object} config The configuration object for the TokenizerModel.
         * @param {...*} args Optional arguments to pass to the specific TokenizerModel constructor.
         * @returns {TokenizerModel} A new instance of a TokenizerModel.
         * @throws Will throw an error if the TokenizerModel type in the config is not recognized.
         */
        static fromConfig(j, ...ie) {
          switch (j.type) {
            case "WordPiece":
              return new Q(j);
            case "Unigram":
              return new W(j, ...ie);
            case "BPE":
              return new pe(j);
            default:
              if (j.vocab)
                return Array.isArray(j.vocab) ? new W(j, ...ie) : Object.hasOwn(j, "continuing_subword_prefix") && Object.hasOwn(j, "unk_token") ? Object.hasOwn(j, "merges") ? new pe(j) : new Q(j) : new be(j, ...ie);
              throw new Error(`Unknown TokenizerModel type: ${j.type}`);
          }
        }
        /**
         * Internal function to call the TokenizerModel instance.
         * @param {string[]} tokens The tokens to encode.
         * @returns {string[]} The encoded tokens.
         */
        _call(j) {
          return j = this.encode(j), this.fuse_unk && (j = E(j, this.tokens_to_ids, this.unk_token_id)), j;
        }
        /**
         * Encodes a list of tokens into a list of token IDs.
         * @param {string[]} tokens The tokens to encode.
         * @returns {string[]} The encoded tokens.
         * @throws Will throw an error if not implemented in a subclass.
         */
        encode(j) {
          throw Error("encode should be implemented in subclass.");
        }
        /**
         * Converts a list of tokens into a list of token IDs.
         * @param {string[]} tokens The tokens to convert.
         * @returns {number[]} The converted token IDs.
         */
        convert_tokens_to_ids(j) {
          return j.map((ie) => this.tokens_to_ids.get(ie) ?? this.unk_token_id);
        }
        /**
         * Converts a list of token IDs into a list of tokens.
         * @param {number[]|bigint[]} ids The token IDs to convert.
         * @returns {string[]} The converted tokens.
         */
        convert_ids_to_tokens(j) {
          return j.map((ie) => this.vocab[ie] ?? this.unk_token);
        }
      }
      class Q extends ne {
        /**
         * @param {Object} config The configuration object.
         * @param {Object} config.vocab A mapping of tokens to ids.
         * @param {string} config.unk_token The unknown token string.
         * @param {string} config.continuing_subword_prefix The prefix to use for continuing subwords.
         * @param {number} [config.max_input_chars_per_word=100] The maximum number of characters per word.
         */
        constructor(j) {
          super(j), this.tokens_to_ids = v(j.vocab), this.unk_token_id = this.tokens_to_ids.get(j.unk_token), this.unk_token = j.unk_token, this.max_input_chars_per_word = j.max_input_chars_per_word ?? 100, this.vocab = new Array(this.tokens_to_ids.size);
          for (const [ie, Ae] of this.tokens_to_ids)
            this.vocab[Ae] = ie;
        }
        /**
         * Encodes an array of tokens using WordPiece encoding.
         * @param {string[]} tokens The tokens to encode.
         * @returns {string[]} An array of encoded tokens.
         */
        encode(j) {
          const ie = [];
          for (const Ae of j) {
            const Re = [...Ae];
            if (Re.length > this.max_input_chars_per_word) {
              ie.push(this.unk_token);
              continue;
            }
            let We = !1, ot = 0;
            const Et = [];
            for (; ot < Re.length; ) {
              let It = Re.length, At = null;
              for (; ot < It; ) {
                let kt = Re.slice(ot, It).join("");
                if (ot > 0 && (kt = this.config.continuing_subword_prefix + kt), this.tokens_to_ids.has(kt)) {
                  At = kt;
                  break;
                }
                --It;
              }
              if (At === null) {
                We = !0;
                break;
              }
              Et.push(At), ot = It;
            }
            We ? ie.push(this.unk_token) : ie.push(...Et);
          }
          return ie;
        }
      }
      class W extends ne {
        /**
         * Create a new Unigram tokenizer model.
         * @param {Object} config The configuration object for the Unigram model.
         * @param {number} config.unk_id The ID of the unknown token
         * @param {[string, number][]} config.vocab A 2D array representing a mapping of tokens to scores.
         * @param {Object} moreConfig Additional configuration object for the Unigram model.
         */
        constructor(j, ie) {
          super(j);
          const Ae = j.vocab.length;
          this.vocab = new Array(Ae), this.scores = new Array(Ae);
          for (let Re = 0; Re < Ae; ++Re)
            [this.vocab[Re], this.scores[Re]] = j.vocab[Re];
          this.unk_token_id = j.unk_id, this.unk_token = this.vocab[j.unk_id], this.tokens_to_ids = new Map(this.vocab.map((Re, We) => [Re, We])), this.bos_token = " ", this.bos_token_id = this.tokens_to_ids.get(this.bos_token), this.eos_token = ie.eos_token, this.eos_token_id = this.tokens_to_ids.get(this.eos_token), this.unk_token = this.vocab[this.unk_token_id], this.minScore = (0, c.min)(this.scores)[0], this.unk_score = this.minScore - 10, this.scores[this.unk_token_id] = this.unk_score, this.trie = new l.CharTrie(), this.trie.extend(this.vocab), this.fuse_unk = !0;
        }
        /**
         * Populates lattice nodes.
         * @param {TokenLattice} lattice The token lattice to populate with nodes.
         */
        populateNodes(j) {
          const ie = j.chars, Ae = 1;
          let Re = 0;
          for (; Re < ie.length; ) {
            let We = !1;
            const ot = ie.slice(Re).join(""), Et = this.trie.commonPrefixSearch(ot);
            for (const It of Et) {
              const At = this.tokens_to_ids.get(It), kt = this.scores[At], Xt = (0, r.len)(It);
              j.insert(Re, Xt, kt, At), !We && Xt === Ae && (We = !0);
            }
            We || j.insert(Re, Ae, this.unk_score, this.unk_token_id), Re += Ae;
          }
        }
        /**
         * Encodes an array of tokens into an array of subtokens using the unigram model.
         *
         * @param {string} normalized The normalized string.
         * @returns {string[]} An array of subtokens obtained by encoding the input tokens using the unigram model.
         */
        tokenize(j) {
          const ie = new l.TokenLattice(j, this.bos_token_id, this.eos_token_id);
          return this.populateNodes(ie), ie.tokens();
        }
        /**
         * Encodes an array of tokens using Unigram encoding.
         * @param {string[]} tokens The tokens to encode.
         * @returns {string[]} An array of encoded tokens.
         */
        encode(j) {
          const ie = [];
          for (const Ae of j) {
            const Re = this.tokenize(Ae);
            ie.push(...Re);
          }
          return ie;
        }
      }
      const te = (() => {
        const Xe = [
          ...Array.from({ length: "~".charCodeAt(0) - "!".charCodeAt(0) + 1 }, (Re, We) => We + "!".charCodeAt(0)),
          ...Array.from({ length: "".charCodeAt(0) - "".charCodeAt(0) + 1 }, (Re, We) => We + "".charCodeAt(0)),
          ...Array.from({ length: "".charCodeAt(0) - "".charCodeAt(0) + 1 }, (Re, We) => We + "".charCodeAt(0))
        ], j = Xe.slice();
        let ie = 0;
        for (let Re = 0; Re < 256; ++Re)
          Xe.includes(Re) || (Xe.push(Re), j.push(256 + ie), ie += 1);
        const Ae = j.map((Re) => String.fromCharCode(Re));
        return Object.fromEntries(Xe.map((Re, We) => [Re, Ae[We]]));
      })(), K = (0, r.reverseDictionary)(te);
      class pe extends ne {
        /**
         * Create a BPE instance.
         * @param {Object} config The configuration object for BPE.
         * @param {Object} config.vocab A mapping of tokens to ids.
         * @param {string[]|[string, string][]} config.merges An array of BPE merges as strings.
         * @param {string} config.unk_token The unknown token used for out of vocabulary words.
         * @param {string} config.end_of_word_suffix The suffix to place at the end of each word.
         * @param {string} [config.continuing_subword_suffix] The suffix to insert between words.
         * @param {boolean} [config.byte_fallback=false] Whether to use spm byte-fallback trick (defaults to False)
         * @param {boolean} [config.ignore_merges=false] Whether or not to match tokens with the vocab before using merges.
         */
        constructor(j) {
          super(j), this.tokens_to_ids = v(j.vocab), this.unk_token_id = this.tokens_to_ids.get(j.unk_token), this.unk_token = j.unk_token, this.vocab = new Array(this.tokens_to_ids.size);
          for (const [Ae, Re] of this.tokens_to_ids)
            this.vocab[Re] = Ae;
          const ie = Array.isArray(j.merges[0]);
          this.merges = ie ? (
            /** @type {[string, string][]} */
            j.merges
          ) : (
            /** @type {string[]} */
            j.merges.map((Ae) => (
              /** @type {[string, string]} */
              Ae.split(" ", 2)
            ))
          ), this.bpe_ranks = new Map(this.merges.map((Ae, Re) => [JSON.stringify(Ae), Re])), this.end_of_word_suffix = j.end_of_word_suffix, this.continuing_subword_suffix = j.continuing_subword_suffix ?? null, this.byte_fallback = this.config.byte_fallback ?? !1, this.byte_fallback && (this.text_encoder = new TextEncoder()), this.ignore_merges = this.config.ignore_merges ?? !1, this.max_length_to_cache = 256, this.cache_capacity = 1e4, this.cache = new l.LRUCache(this.cache_capacity);
        }
        /**
         * Clears the cache.
         */
        clear_cache() {
          this.cache.clear();
        }
        /**
         * Apply Byte-Pair-Encoding (BPE) to a given token. Efficient heap-based priority
         * queue implementation adapted from https://github.com/belladoreai/llama-tokenizer-js.
         * @param {string} token The token to encode.
         * @returns {string[]} The BPE encoded tokens.
         */
        bpe(j) {
          if (j.length === 0)
            return [];
          const ie = this.cache.get(j);
          if (ie !== void 0)
            return ie;
          const Ae = Array.from(j);
          this.end_of_word_suffix && (Ae[Ae.length - 1] += this.end_of_word_suffix);
          let Re = [];
          if (Ae.length > 1) {
            const We = new l.PriorityQueue((It, At) => It.score < At.score);
            let ot = {
              token: Ae[0],
              bias: 0,
              prev: null,
              next: null
            }, Et = ot;
            for (let It = 1; It < Ae.length; ++It) {
              const At = {
                bias: It / Ae.length,
                // Add fractional component to break ties
                token: Ae[It],
                prev: Et,
                next: null
              };
              Et.next = At, this._add_node(We, Et), Et = At;
            }
            for (; !We.isEmpty(); ) {
              const It = We.pop();
              if (It.deleted || !It.next || It.next.deleted)
                continue;
              if (It.deleted = !0, It.next.deleted = !0, It.prev) {
                const kt = { ...It.prev };
                It.prev.deleted = !0, It.prev = kt, kt.prev ? kt.prev.next = kt : ot = kt;
              }
              const At = {
                token: It.token + It.next.token,
                bias: It.bias,
                prev: It.prev,
                next: It.next.next
              };
              At.prev ? (At.prev.next = At, this._add_node(We, At.prev)) : ot = At, At.next && (At.next.prev = At, this._add_node(We, At));
            }
            for (let It = ot; It !== null; It = It.next)
              Re.push(It.token);
          } else
            Re = Ae;
          if (this.continuing_subword_suffix)
            for (let We = 0; We < Re.length - 1; ++We)
              Re[We] += this.continuing_subword_suffix;
          return j.length < this.max_length_to_cache && this.cache.put(j, Re), Re;
        }
        /**
         * Helper function to add a node to the priority queue.
         * @param {PriorityQueue} queue 
         * @param {BPENode} node
         * @private
         */
        _add_node(j, ie) {
          const Ae = this.bpe_ranks.get(JSON.stringify([ie.token, ie.next.token]));
          Ae !== void 0 && (ie.score = Ae + ie.bias, j.push(ie));
        }
        /**
         * Encodes the input sequence of tokens using the BPE algorithm and returns the resulting subword tokens.
         * @param {string[]} tokens The input sequence of tokens to encode.
         * @returns {string[]} The resulting subword tokens after applying the BPE algorithm to the input sequence of tokens.
         */
        encode(j) {
          const ie = [];
          for (const Ae of j) {
            if (this.ignore_merges && this.tokens_to_ids.has(Ae)) {
              ie.push(Ae);
              continue;
            }
            const Re = this.bpe(Ae);
            for (const We of Re)
              if (this.tokens_to_ids.has(We))
                ie.push(We);
              else if (this.byte_fallback) {
                const ot = Array.from(this.text_encoder.encode(We)).map((Et) => `<0x${Et.toString(16).toUpperCase().padStart(2, "0")}>`);
                ot.every((Et) => this.tokens_to_ids.has(Et)) ? ie.push(...ot) : ie.push(this.unk_token);
              } else
                ie.push(this.unk_token);
          }
          return ie;
        }
      }
      class be extends ne {
        /**
         * Create a LegacyTokenizerModel instance.
         * @param {Object} config The configuration object for LegacyTokenizerModel.
         * @param {Object} config.vocab A (possibly nested) mapping of tokens to ids.
         * @param {Object} moreConfig Additional configuration object for the LegacyTokenizerModel model.
         */
        constructor(j, ie) {
          super(j), this.tokens_to_ids = v(
            ie.target_lang ? j.vocab[ie.target_lang] : j.vocab
          ), this.bos_token = ie.bos_token, this.bos_token_id = this.tokens_to_ids.get(this.bos_token), this.eos_token = ie.eos_token, this.eos_token_id = this.tokens_to_ids.get(this.eos_token), this.pad_token = ie.pad_token, this.pad_token_id = this.tokens_to_ids.get(this.pad_token), this.unk_token = ie.unk_token, this.unk_token_id = this.tokens_to_ids.get(this.unk_token), this.vocab = new Array(this.tokens_to_ids.size);
          for (const [Ae, Re] of this.tokens_to_ids)
            this.vocab[Re] = Ae;
        }
        encode(j) {
          return j;
        }
      }
      class Ee extends i.Callable {
        /**
         * @param {Object} config The configuration object for the normalizer.
         */
        constructor(j) {
          super(), this.config = j;
        }
        /**
         * Factory method for creating normalizers from config objects.
         * @static
         * @param {Object} config The configuration object for the normalizer.
         * @returns {Normalizer} A Normalizer object.
         * @throws {Error} If an unknown Normalizer type is specified in the config.
         */
        static fromConfig(j) {
          if (j === null)
            return null;
          switch (j.type) {
            case "BertNormalizer":
              return new Be(j);
            case "Precompiled":
              return new ln(j);
            case "Sequence":
              return new nt(j);
            case "Replace":
              return new Ge(j);
            case "NFC":
              return new De(j);
            case "NFD":
              return new he(j);
            case "NFKC":
              return new Z(j);
            case "NFKD":
              return new me(j);
            case "Strip":
              return new we(j);
            case "StripAccents":
              return new xe(j);
            case "Lowercase":
              return new et(j);
            case "Prepend":
              return new Ve(j);
            default:
              throw new Error(`Unknown Normalizer type: ${j.type}`);
          }
        }
        /**
         * Normalize the input text.
         * @abstract
         * @param {string} text The text to normalize.
         * @returns {string} The normalized text.
         * @throws {Error} If this method is not implemented in a subclass.
         */
        normalize(j) {
          throw Error("normalize should be implemented in subclass.");
        }
        /**
         * Alias for {@link Normalizer#normalize}.
         * @param {string} text The text to normalize.
         * @returns {string} The normalized text.
         */
        _call(j) {
          return this.normalize(j);
        }
      }
      class Ge extends Ee {
        /**
         * Normalize the input text by replacing the pattern with the content.
         * @param {string} text The input text to be normalized.
         * @returns {string} The normalized text after replacing the pattern with the content.
         */
        normalize(j) {
          const ie = _(this.config.pattern);
          return ie === null ? j : j.replaceAll(ie, this.config.content);
        }
      }
      class _e extends Ee {
        constructor() {
          super(...arguments);
          /**
           * @type {string} The Unicode normalization form to apply.
           * Should be one of: 'NFC', 'NFD', 'NFKC', or 'NFKD'.
           */
          Ce(this, "form");
        }
        /**
         * Normalize the input text by applying Unicode normalization.
         * @param {string} text The input text to be normalized.
         * @returns {string} The normalized text.
         */
        normalize(ie) {
          return ie = ie.normalize(this.form), ie;
        }
      }
      class De extends _e {
        constructor() {
          super(...arguments);
          Ce(this, "form", "NFC");
        }
      }
      class he extends _e {
        constructor() {
          super(...arguments);
          Ce(this, "form", "NFD");
        }
      }
      class Z extends _e {
        constructor() {
          super(...arguments);
          Ce(this, "form", "NFKC");
        }
      }
      class me extends _e {
        constructor() {
          super(...arguments);
          Ce(this, "form", "NFKD");
        }
      }
      class we extends Ee {
        /**
         * Strip leading and/or trailing whitespace from the input text.
         * @param {string} text The input text.
         * @returns {string} The normalized text.
         */
        normalize(j) {
          return this.config.strip_left && this.config.strip_right ? j = j.trim() : (this.config.strip_left && (j = j.trimStart()), this.config.strip_right && (j = j.trimEnd())), j;
        }
      }
      class xe extends Ee {
        /**
         * Remove all accents from the text.
         * @param {string} text The input text.
         * @returns {string} The normalized text without accents.
         */
        normalize(j) {
          return j = w(j), j;
        }
      }
      class et extends Ee {
        /**
         * Lowercases the input string.
         * @param {string} text The text to normalize.
         * @returns {string} The normalized text.
         */
        normalize(j) {
          return j = j.toLowerCase(), j;
        }
      }
      class Ve extends Ee {
        /**
         * Prepends the input string.
         * @param {string} text The text to normalize.
         * @returns {string} The normalized text.
         */
        normalize(j) {
          return j = this.config.prepend + j, j;
        }
      }
      class nt extends Ee {
        /**
        * Create a new instance of NormalizerSequence.
        * @param {Object} config The configuration object.
        * @param {Object[]} config.normalizers An array of Normalizer configuration objects.
        */
        constructor(j) {
          super(j), this.normalizers = j.normalizers.map((ie) => Ee.fromConfig(ie));
        }
        /**
        * Apply a sequence of Normalizers to the input text.
        * @param {string} text The text to normalize.
        * @returns {string} The normalized text.
        */
        normalize(j) {
          return this.normalizers.reduce((ie, Ae) => Ae.normalize(ie), j);
        }
      }
      class Be extends Ee {
        /**
         * Adds whitespace around any CJK (Chinese, Japanese, or Korean) character in the input text.
         *
         * @param {string} text The input text to tokenize.
         * @returns {string} The tokenized text with whitespace added around CJK characters.
         */
        _tokenize_chinese_chars(j) {
          const ie = [];
          for (let Ae = 0; Ae < j.length; ++Ae) {
            const Re = j[Ae], We = Re.charCodeAt(0);
            F(We) ? (ie.push(" "), ie.push(Re), ie.push(" ")) : ie.push(Re);
          }
          return ie.join("");
        }
        /**
         * Strips accents from the given text.
         * @param {string} text The text to strip accents from.
         * @returns {string} The text with accents removed.
         */
        stripAccents(j) {
          return j.normalize("NFD").replace(/\p{Mn}/gu, "");
        }
        /**
         * Checks whether `char` is a control character.
         * @param {string} char The character to check.
         * @returns {boolean} Whether `char` is a control character.
         * @private
         */
        _is_control(j) {
          switch (j) {
            case "	":
            case `
`:
            case "\r":
              return !1;
            default:
              return /^\p{Cc}|\p{Cf}|\p{Co}|\p{Cs}$/u.test(j);
          }
        }
        /**
         * Performs invalid character removal and whitespace cleanup on text.
         * @param {string} text The text to clean.
         * @returns {string} The cleaned text.
         * @private
         */
        _clean_text(j) {
          const ie = [];
          for (const Ae of j) {
            const Re = Ae.charCodeAt(0);
            Re === 0 || Re === 65533 || this._is_control(Ae) || (/^\s$/.test(Ae) ? ie.push(" ") : ie.push(Ae));
          }
          return ie.join("");
        }
        /**
         * Normalizes the given text based on the configuration.
         * @param {string} text The text to normalize.
         * @returns {string} The normalized text.
         */
        normalize(j) {
          return this.config.clean_text && (j = this._clean_text(j)), this.config.handle_chinese_chars && (j = this._tokenize_chinese_chars(j)), this.config.lowercase ? (j = j.toLowerCase(), this.config.strip_accents !== !1 && (j = this.stripAccents(j))) : this.config.strip_accents && (j = this.stripAccents(j)), j;
        }
      }
      class ae extends i.Callable {
        /**
        * Factory method that returns an instance of a subclass of `PreTokenizer` based on the provided configuration.
        *
        * @static
        * @param {Object} config A configuration object for the pre-tokenizer.
        * @returns {PreTokenizer} An instance of a subclass of `PreTokenizer`.
        * @throws {Error} If the provided configuration object does not correspond to any known pre-tokenizer.
        */
        static fromConfig(j) {
          if (j === null)
            return null;
          switch (j.type) {
            case "BertPreTokenizer":
              return new U(j);
            case "Sequence":
              return new Gn(j);
            case "Whitespace":
              return new li(j);
            case "WhitespaceSplit":
              return new Yi(j);
            case "Metaspace":
              return new vn(j);
            case "ByteLevel":
              return new Se(j);
            case "Split":
              return new ze(j);
            case "Punctuation":
              return new Oe(j);
            case "Digits":
              return new Ye(j);
            case "Replace":
              return new $i(j);
            case "FixedLength":
              return new An(j);
            default:
              throw new Error(`Unknown PreTokenizer type: ${j.type}`);
          }
        }
        /**
         * Method that should be implemented by subclasses to define the specific pre-tokenization logic.
         *
         * @abstract
         * @param {string} text The text to pre-tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} The pre-tokenized text.
         * @throws {Error} If the method is not implemented in the subclass.
         */
        pre_tokenize_text(j, ie) {
          throw Error("pre_tokenize_text should be implemented in subclass.");
        }
        /**
         * Tokenizes the given text into pre-tokens.
         * @param {string|string[]} text The text or array of texts to pre-tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of pre-tokens.
         */
        pre_tokenize(j, ie) {
          return (Array.isArray(j) ? j.map((Ae) => this.pre_tokenize_text(Ae, ie)) : this.pre_tokenize_text(j, ie)).flat();
        }
        /**
         * Alias for {@link PreTokenizer#pre_tokenize}.
         * @param {string|string[]} text The text or array of texts to pre-tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of pre-tokens.
         */
        _call(j, ie) {
          return this.pre_tokenize(j, ie);
        }
      }
      class U extends ae {
        /**
         * A PreTokenizer that splits text into wordpieces using a basic tokenization scheme
         * similar to that used in the original implementation of BERT.
         * 
         * @param {Object} config The configuration object.
         */
        constructor(j) {
          super(), this.pattern = new RegExp(`[^\\s${L}]+|[${L}]`, "gu");
        }
        /**
         * Tokenizes a single text using the BERT pre-tokenization scheme.
         * 
         * @param {string} text The text to tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens.
         */
        pre_tokenize_text(j, ie) {
          return j.trim().match(this.pattern) || [];
        }
      }
      class Se extends ae {
        /**
         * Creates a new instance of the `ByteLevelPreTokenizer` class.
         * @param {Object} config The configuration object.
         */
        constructor(j) {
          super(), this.config = j, this.add_prefix_space = this.config.add_prefix_space, this.trim_offsets = this.config.trim_offsets, this.use_regex = this.config.use_regex ?? !0, this.pattern = /'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+/gu, this.byte_encoder = te, this.text_encoder = new TextEncoder();
        }
        /**
         * Tokenizes a single piece of text using byte-level tokenization.
         * @param {string} text The text to tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens.
         */
        pre_tokenize_text(j, ie) {
          return this.add_prefix_space && !j.startsWith(" ") && (j = " " + j), (this.use_regex ? j.match(this.pattern) || [] : [j]).map(
            (Re) => Array.from(this.text_encoder.encode(Re), (We) => this.byte_encoder[We]).join("")
          );
        }
      }
      class ze extends ae {
        /**
         * @param {Object} config The configuration options for the pre-tokenizer.
         * @param {Object} config.pattern The pattern used to split the text. Can be a string or a regex object.
         * @param {string|undefined} config.pattern.String The string to use for splitting. Only defined if the pattern is a string.
         * @param {string|undefined} config.pattern.Regex The regex to use for splitting. Only defined if the pattern is a regex.
         * @param {SplitDelimiterBehavior} config.behavior The behavior to use when splitting.
         * @param {boolean} config.invert Whether to split (invert=false) or match (invert=true) the pattern.
         */
        constructor(j) {
          super(), this.config = j, this.pattern = _(this.config.pattern, this.config.invert);
        }
        /**
         * Tokenizes text by splitting it using the given pattern.
         * @param {string} text The text to tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens.
         */
        pre_tokenize_text(j, ie) {
          var Ae;
          return this.pattern === null ? [] : this.config.invert ? j.match(this.pattern) || [] : ((Ae = this.config.behavior) == null ? void 0 : Ae.toLowerCase()) === "removed" ? j.split(this.pattern).filter((Re) => Re) : p(j, this.pattern);
        }
      }
      class Oe extends ae {
        /**
         * @param {Object} config The configuration options for the pre-tokenizer.
         * @param {SplitDelimiterBehavior} config.behavior The behavior to use when splitting.
         */
        constructor(j) {
          super(), this.config = j, this.pattern = new RegExp(`[^${L}]+|[${L}]+`, "gu");
        }
        /**
         * Tokenizes text by splitting it using the given pattern.
         * @param {string} text The text to tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens.
         */
        pre_tokenize_text(j, ie) {
          return j.match(this.pattern) || [];
        }
      }
      class Ye extends ae {
        /**
         * @param {Object} config The configuration options for the pre-tokenizer.
         * @param {boolean} config.individual_digits Whether to split on individual digits.
         */
        constructor(j) {
          super(), this.config = j;
          const ie = `[^\\d]+|\\d${this.config.individual_digits ? "" : "+"}`;
          this.pattern = new RegExp(ie, "gu");
        }
        /**
         * Tokenizes text by splitting it using the given pattern.
         * @param {string} text The text to tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens.
         */
        pre_tokenize_text(j, ie) {
          return j.match(this.pattern) || [];
        }
      }
      class H extends i.Callable {
        /**
         * @param {Object} config The configuration for the post-processor.
         */
        constructor(j) {
          super(), this.config = j;
        }
        /**
         * Factory method to create a PostProcessor object from a configuration object.
         *
         * @param {Object} config Configuration object representing a PostProcessor.
         * @returns {PostProcessor} A PostProcessor object created from the given configuration.
         * @throws {Error} If an unknown PostProcessor type is encountered.
         */
        static fromConfig(j) {
          if (j === null)
            return null;
          switch (j.type) {
            case "TemplateProcessing":
              return new Ie(j);
            case "ByteLevel":
              return new fe(j);
            case "RobertaProcessing":
              return new $e(j);
            case "BertProcessing":
              return new Y(j);
            case "Sequence":
              return new Qe(j);
            default:
              throw new Error(`Unknown PostProcessor type: ${j.type}`);
          }
        }
        /**
         * Method to be implemented in subclass to apply post-processing on the given tokens.
         *
         * @param {Array} tokens The input tokens to be post-processed.
         * @param {...*} args Additional arguments required by the post-processing logic.
         * @returns {PostProcessedOutput} The post-processed tokens.
         * @throws {Error} If the method is not implemented in subclass.
         */
        post_process(j, ...ie) {
          throw Error("post_process should be implemented in subclass.");
        }
        /**
         * Alias for {@link PostProcessor#post_process}.
         * @param {Array} tokens The text or array of texts to post-process.
         * @param {...*} args Additional arguments required by the post-processing logic.
         * @returns {PostProcessedOutput} The post-processed tokens.
         */
        _call(j, ...ie) {
          return this.post_process(j, ...ie);
        }
      }
      class Y extends H {
        /**
         * @param {Object} config The configuration for the post-processor.
         * @param {string[]} config.cls The special tokens to add to the beginning of the input.
         * @param {string[]} config.sep The special tokens to add to the end of the input.
         */
        constructor(j) {
          super(j), this.cls = j.cls[0], this.sep = j.sep[0];
        }
        /**
         * Adds the special tokens to the beginning and end of the input.
         * @param {string[]} tokens The input tokens.
         * @param {string[]} [tokens_pair=null] An optional second set of input tokens.
         * @returns {PostProcessedOutput} The post-processed tokens with the special tokens added to the beginning and end.
         */
        post_process(j, ie = null, {
          add_special_tokens: Ae = !0
        } = {}) {
          Ae && (j = (0, r.mergeArrays)([this.cls], j, [this.sep]));
          let Re = new Array(j.length).fill(0);
          if (ie !== null) {
            const We = Ae && this instanceof $e ? [this.sep] : [], ot = Ae ? [this.sep] : [];
            j = (0, r.mergeArrays)(j, We, ie, ot), Re = (0, r.mergeArrays)(Re, new Array(ie.length + We.length + ot.length).fill(1));
          }
          return { tokens: j, token_type_ids: Re };
        }
      }
      class $e extends Y {
      }
      class Ie extends H {
        /**
         * Creates a new instance of `TemplateProcessing`.
         * @param {Object} config The configuration options for the post processor.
         * @param {Array} config.single The template for a single sequence of tokens.
         * @param {Array} config.pair The template for a pair of sequences of tokens.
         */
        constructor(j) {
          super(j), this.single = j.single, this.pair = j.pair;
        }
        /**
         * Replaces special tokens in the template with actual tokens.
         * @param {string[]} tokens The list of tokens for the first sequence.
         * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).
         * @returns {PostProcessedOutput} An object containing the list of tokens with the special tokens replaced with actual tokens.
         */
        post_process(j, ie = null, {
          add_special_tokens: Ae = !0
        } = {}) {
          const Re = ie === null ? this.single : this.pair;
          let We = [], ot = [];
          for (const Et of Re)
            "SpecialToken" in Et ? Ae && (We.push(Et.SpecialToken.id), ot.push(Et.SpecialToken.type_id)) : "Sequence" in Et && (Et.Sequence.id === "A" ? (We = (0, r.mergeArrays)(We, j), ot = (0, r.mergeArrays)(ot, new Array(j.length).fill(Et.Sequence.type_id))) : Et.Sequence.id === "B" && (We = (0, r.mergeArrays)(We, ie), ot = (0, r.mergeArrays)(ot, new Array(ie.length).fill(Et.Sequence.type_id))));
          return { tokens: We, token_type_ids: ot };
        }
      }
      class fe extends H {
        /**
         * Post process the given tokens.
         * @param {string[]} tokens The list of tokens for the first sequence.
         * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).
         * @returns {PostProcessedOutput} An object containing the post-processed tokens.
         */
        post_process(j, ie = null) {
          return ie && (j = (0, r.mergeArrays)(j, ie)), { tokens: j };
        }
      }
      class Qe extends H {
        /**
         * Creates a new instance of PostProcessorSequence.
         * @param {Object} config The configuration object.
         * @param {Object[]} config.processors The list of post-processors to apply.
         */
        constructor(j) {
          super(j), this.processors = j.processors.map((ie) => H.fromConfig(ie));
        }
        /**
         * Post process the given tokens.
         * @param {string[]} tokens The list of tokens for the first sequence.
         * @param {string[]} [tokens_pair=null] The list of tokens for the second sequence (optional).
         * @returns {PostProcessedOutput} An object containing the post-processed tokens.
         */
        post_process(j, ie = null, Ae = {}) {
          let Re;
          for (const We of this.processors)
            if (We instanceof fe)
              j = We.post_process(j).tokens, ie && (ie = We.post_process(ie).tokens);
            else {
              const ot = We.post_process(j, ie, Ae);
              j = ot.tokens, Re = ot.token_type_ids;
            }
          return { tokens: j, token_type_ids: Re };
        }
      }
      class Ne extends i.Callable {
        /**
        * Creates an instance of `Decoder`.
        *
        * @param {Object} config The configuration object.
        */
        constructor(j) {
          super(), this.config = j, this.added_tokens = [], this.end_of_word_suffix = null, this.trim_offsets = j.trim_offsets;
        }
        /**
        * Creates a decoder instance based on the provided configuration.
        *
        * @param {Object} config The configuration object.
        * @returns {Decoder} A decoder instance.
        * @throws {Error} If an unknown decoder type is provided.
        */
        static fromConfig(j) {
          if (j === null)
            return null;
          switch (j.type) {
            case "WordPiece":
              return new He(j);
            case "Metaspace":
              return new wn(j);
            case "ByteLevel":
              return new je(j);
            case "Replace":
              return new ut(j);
            case "ByteFallback":
              return new de(j);
            case "Fuse":
              return new qe(j);
            case "Strip":
              return new tt(j);
            case "Sequence":
              return new Mt(j);
            case "CTC":
              return new lt(j);
            case "BPEDecoder":
              return new Rt(j);
            default:
              throw new Error(`Unknown Decoder type: ${j.type}`);
          }
        }
        /**
        * Calls the `decode` method.
        *
        * @param {string[]} tokens The list of tokens.
        * @returns {string} The decoded string.
        */
        _call(j) {
          return this.decode(j);
        }
        /**
        * Decodes a list of tokens.
        * @param {string[]} tokens The list of tokens.
        * @returns {string} The decoded string.
        */
        decode(j) {
          return this.decode_chain(j).join("");
        }
        /**
         * Apply the decoder to a list of tokens.
         * 
         * @param {string[]} tokens The list of tokens.
         * @returns {string[]} The decoded list of tokens.
         * @throws {Error} If the `decode_chain` method is not implemented in the subclass.
         */
        decode_chain(j) {
          throw Error("`decode_chain` should be implemented in subclass.");
        }
      }
      class ut extends Ne {
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          const ie = _(this.config.pattern);
          return ie === null ? j : j.map((Ae) => Ae.replaceAll(ie, this.config.content));
        }
      }
      class de extends Ne {
        constructor(j) {
          super(j), this.text_decoder = new TextDecoder();
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          const ie = [];
          let Ae = [];
          for (const Re of j) {
            let We = null;
            if (Re.length === 6 && Re.startsWith("<0x") && Re.endsWith(">")) {
              const ot = parseInt(Re.slice(3, 5), 16);
              isNaN(ot) || (We = ot);
            }
            if (We !== null)
              Ae.push(We);
            else {
              if (Ae.length > 0) {
                const ot = this.text_decoder.decode(Uint8Array.from(Ae));
                ie.push(ot), Ae = [];
              }
              ie.push(Re);
            }
          }
          if (Ae.length > 0) {
            const Re = this.text_decoder.decode(Uint8Array.from(Ae));
            ie.push(Re), Ae = [];
          }
          return ie;
        }
      }
      class qe extends Ne {
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          return [j.join("")];
        }
      }
      class tt extends Ne {
        constructor(j) {
          super(j), this.content = this.config.content, this.start = this.config.start, this.stop = this.config.stop;
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          return j.map((ie) => {
            let Ae = 0;
            for (let We = 0; We < this.start && ie[We] === this.content; ++We) {
              Ae = We + 1;
              continue;
            }
            let Re = ie.length;
            for (let We = 0; We < this.stop; ++We) {
              const ot = ie.length - We - 1;
              if (ie[ot] === this.content) {
                Re = ot;
                continue;
              } else
                break;
            }
            return ie.slice(Ae, Re);
          });
        }
      }
      class He extends Ne {
        /**
         * Creates a new instance of WordPieceDecoder.
         * @param {Object} config The configuration object.
         * @param {string} config.prefix The prefix used for WordPiece encoding.
         * @param {boolean} config.cleanup Whether to cleanup the decoded string.
         */
        constructor(j) {
          super(j), this.cleanup = j.cleanup;
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          return j.map((ie, Ae) => (Ae !== 0 && (ie.startsWith(this.config.prefix) ? ie = ie.replace(this.config.prefix, "") : ie = " " + ie), this.cleanup && (ie = D(ie)), ie));
        }
      }
      class je extends Ne {
        /**
         * Create a `ByteLevelDecoder` object.
         * @param {Object} config Configuration object.
         */
        constructor(j) {
          super(j), this.byte_decoder = K, this.text_decoder = new TextDecoder("utf-8", {
            fatal: !1,
            ignoreBOM: !0
          }), this.end_of_word_suffix = null;
        }
        /**
         * Convert an array of tokens to string by decoding each byte.
         * @param {string[]} tokens Array of tokens to be decoded.
         * @returns {string} The decoded string.
         */
        convert_tokens_to_string(j) {
          const ie = j.join(""), Ae = new Uint8Array([...ie].map((We) => this.byte_decoder[We]));
          return this.text_decoder.decode(Ae);
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          const ie = [];
          let Ae = [];
          for (const Re of j)
            this.added_tokens.find((We) => We.content === Re) !== void 0 ? (Ae.length > 0 && (ie.push(this.convert_tokens_to_string(Ae)), Ae = []), ie.push(Re)) : Ae.push(Re);
          return Ae.length > 0 && ie.push(this.convert_tokens_to_string(Ae)), ie;
        }
      }
      class lt extends Ne {
        constructor(j) {
          super(j), this.pad_token = this.config.pad_token, this.word_delimiter_token = this.config.word_delimiter_token, this.cleanup = this.config.cleanup;
        }
        /**
         * Converts a connectionist-temporal-classification (CTC) output tokens into a single string.
         * @param {string[]} tokens Array of tokens to be decoded.
         * @returns {string} The decoded string.
         */
        convert_tokens_to_string(j) {
          if (j.length === 0)
            return "";
          const ie = [j[0]];
          for (let We = 1; We < j.length; ++We)
            j[We] !== ie.at(-1) && ie.push(j[We]);
          let Re = ie.filter((We) => We !== this.pad_token).join("");
          return this.cleanup && (Re = D(Re).replaceAll(this.word_delimiter_token, " ").trim()), Re;
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          return [this.convert_tokens_to_string(j)];
        }
      }
      class Mt extends Ne {
        /**
         * Creates a new instance of DecoderSequence.
         * @param {Object} config The configuration object.
         * @param {Object[]} config.decoders The list of decoders to apply.
         */
        constructor(j) {
          super(j), this.decoders = j.decoders.map((ie) => Ne.fromConfig(ie));
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          return this.decoders.reduce((ie, Ae) => Ae.decode_chain(ie), j);
        }
      }
      class Rt extends Ne {
        constructor(j) {
          super(j), this.suffix = this.config.suffix;
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          return j.map((ie, Ae) => ie.replaceAll(this.suffix, Ae === j.length - 1 ? "" : " "));
        }
      }
      class Kt extends Ne {
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          let ie = "";
          for (let Ae = 1; Ae < j.length; Ae += 2)
            ie += j[Ae];
          return [ie];
        }
      }
      class vn extends ae {
        /**
         * @param {Object} config The configuration object for the MetaspacePreTokenizer.
         * @param {string} config.replacement The character to replace spaces with.
         * @param {string} [config.str_rep=config.replacement] An optional string representation of the replacement character.
         * @param {'first'|'never'|'always'} [config.prepend_scheme='always'] The metaspace prepending scheme.
         */
        constructor(j) {
          super(), this.replacement = j.replacement, this.strRep = j.str_rep || this.replacement, this.prepend_scheme = j.prepend_scheme ?? "always";
        }
        /**
         * This method takes a string, replaces spaces with the replacement character,
         * adds a prefix space if requested, and returns a new list of tokens.
         * @param {string} text The text to pre-tokenize.
         * @param {Object} [options] The options for the pre-tokenization.
         * @param {number} [options.section_index] The index of the section to pre-tokenize.
         * @returns {string[]} A new list of pre-tokenized tokens.
         */
        pre_tokenize_text(j, {
          section_index: ie = void 0
        } = {}) {
          let Ae = j.replaceAll(" ", this.strRep);
          return (
            // We add a prefix space if:
            //  (1) The normalized token does not already start with the replacement character.
            !Ae.startsWith(this.replacement) && (this.prepend_scheme === "always" || this.prepend_scheme === "first" && ie === 0) && (Ae = this.strRep + Ae), [Ae]
          );
        }
      }
      class wn extends Ne {
        /**
         * Constructs a new MetaspaceDecoder object.
         * @param {Object} config The configuration object for the MetaspaceDecoder.
         * @param {string} config.replacement The string to replace spaces with.
         */
        constructor(j) {
          super(j), this.replacement = j.replacement;
        }
        /** @type {Decoder['decode_chain']} */
        decode_chain(j) {
          const ie = [];
          for (let Ae = 0; Ae < j.length; ++Ae) {
            let Re = j[Ae].replaceAll(this.replacement, " ");
            Ae == 0 && Re.startsWith(" ") && (Re = Re.substring(1)), ie.push(Re);
          }
          return ie;
        }
      }
      class ln extends Ee {
        /**
         * Create a new instance of Precompiled normalizer.
         * @param {Object} config The configuration object.
         * @param {any} config.precompiled_charsmap Precompiled chars mapping.
         */
        constructor(j) {
          super(j), this.charsmap = j.precompiled_charsmap;
        }
        /**
         * Normalizes the given text by applying the precompiled charsmap.
         * @param {string} text The text to normalize.
         * @returns {string} The normalized text.
         */
        normalize(j) {
          return j = j.replace(/[\u0001-\u0008\u000B\u000E-\u001F\u007F\u008F\u009F]/gm, ""), j = j.replace(/[\u0009\u000A\u000C\u000D\u00A0\u1680\u2000-\u200F\u2028\u2029\u202F\u205F\u2581\u3000\uFEFF\uFFFD]/gm, " "), j.includes("") ? j = j.split("").map((Ae) => Ae.normalize("NFKC")).join("") : j = j.normalize("NFKC"), j;
        }
      }
      class Gn extends ae {
        /**
         * Creates an instance of PreTokenizerSequence.
         * @param {Object} config The configuration object for the pre-tokenizer sequence.
         * @param {Object[]} config.pretokenizers An array of pre-tokenizer configurations.
         */
        constructor(j) {
          super(), this.tokenizers = j.pretokenizers.map((ie) => ae.fromConfig(ie));
        }
        /**
         * Applies each pre-tokenizer in the sequence to the input text in turn.
         * @param {string} text The text to pre-tokenize.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} The pre-tokenized text.
         */
        pre_tokenize_text(j, ie) {
          return this.tokenizers.reduce((Ae, Re) => Re.pre_tokenize(Ae, ie), [j]);
        }
      }
      class li extends ae {
        /**
         * Creates an instance of WhitespacePreTokenizer.
         * @param {Object} config The configuration object for the pre-tokenizer.
         */
        constructor(j) {
          super();
        }
        /**
         * Pre-tokenizes the input text by splitting it on word boundaries.
         * @param {string} text The text to be pre-tokenized.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens produced by splitting the input text on whitespace.
         */
        pre_tokenize_text(j, ie) {
          return j.match(/\w+|[^\w\s]+/g) || [];
        }
      }
      class Yi extends ae {
        /**
         * Creates an instance of WhitespaceSplit.
         * @param {Object} config The configuration object for the pre-tokenizer.
         */
        constructor(j) {
          super();
        }
        /**
         * Pre-tokenizes the input text by splitting it on whitespace characters.
         * @param {string} text The text to be pre-tokenized.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens produced by splitting the input text on whitespace.
         */
        pre_tokenize_text(j, ie) {
          return A(j);
        }
      }
      class $i extends ae {
        /**
         * @param {Object} config The configuration options for the pre-tokenizer.
         * @param {Object} config.pattern The pattern used to split the text. Can be a string or a regex object.
         * @param {string} config.content What to replace the pattern with.
         */
        constructor(j) {
          super(), this.config = j, this.pattern = _(this.config.pattern), this.content = this.config.content;
        }
        /**
         * Pre-tokenizes the input text by replacing certain characters.
         * @param {string} text The text to be pre-tokenized.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens produced by replacing certain characters.
         */
        pre_tokenize_text(j, ie) {
          return this.pattern === null ? [j] : [j.replaceAll(this.pattern, this.config.content)];
        }
      }
      class An extends ae {
        /**
         * @param {Object} config The configuration options for the pre-tokenizer.
         * @param {number} config.length The fixed length to split the text into.
         */
        constructor(j) {
          super(), this._length = j.length;
        }
        /**
         * Pre-tokenizes the input text by splitting it into fixed-length tokens.
         * @param {string} text The text to be pre-tokenized.
         * @param {Object} [options] Additional options for the pre-tokenization logic.
         * @returns {string[]} An array of tokens produced by splitting the input text into fixed-length tokens.
         */
        pre_tokenize_text(j, ie) {
          const Ae = [];
          for (let Re = 0; Re < j.length; Re += this._length)
            Ae.push(j.slice(Re, Re + this._length));
          return Ae;
        }
      }
      const bn = [
        "bos_token",
        "eos_token",
        "unk_token",
        "sep_token",
        "pad_token",
        "cls_token",
        "mask_token"
        // additional_special_tokens (TODO)
      ];
      function Si(Xe, j, ie, Ae) {
        for (const Re of Object.keys(Xe)) {
          const We = j - Xe[Re].length, ot = ie(Re), Et = new Array(We).fill(ot);
          Xe[Re] = Ae === "right" ? (0, r.mergeArrays)(Xe[Re], Et) : (0, r.mergeArrays)(Et, Xe[Re]);
        }
      }
      function ds(Xe, j) {
        for (const ie of Object.keys(Xe))
          Xe[ie].length = j;
      }
      class qt extends i.Callable {
        /**
         * Create a new PreTrainedTokenizer instance.
         * @param {Object} tokenizerJSON The JSON of the tokenizer.
         * @param {Object} tokenizerConfig The config of the tokenizer.
         */
        constructor(ie, Ae) {
          super();
          Ce(this, "return_token_type_ids", !1);
          Ce(this, "padding_side", "right");
          this.config = Ae, this.normalizer = Ee.fromConfig(ie.normalizer), this.pre_tokenizer = ae.fromConfig(ie.pre_tokenizer), this.model = ne.fromConfig(ie.model, Ae), this.post_processor = H.fromConfig(ie.post_processor), this.decoder = Ne.fromConfig(ie.decoder), this.special_tokens = [], this.all_special_ids = [], this.added_tokens = [];
          for (const Re of ie.added_tokens) {
            const We = new q(Re);
            this.added_tokens.push(We), this.model.tokens_to_ids.set(We.content, We.id), this.model.vocab[We.id] = We.content, We.special && (this.special_tokens.push(We.content), this.all_special_ids.push(We.id));
          }
          if (this.additional_special_tokens = Ae.additional_special_tokens ?? [], this.special_tokens.push(...this.additional_special_tokens), this.special_tokens = [...new Set(this.special_tokens)], this.decoder && (this.decoder.added_tokens = this.added_tokens, this.decoder.end_of_word_suffix = this.model.end_of_word_suffix), this.added_tokens_splitter = new l.DictionarySplitter(
            this.added_tokens.map((Re) => Re.content)
          ), this.added_tokens_map = new Map(this.added_tokens.map((Re) => [Re.content, Re])), this.mask_token = this.getToken("mask_token"), this.mask_token_id = this.model.tokens_to_ids.get(this.mask_token), this.pad_token = this.getToken("pad_token", "eos_token"), this.pad_token_id = this.model.tokens_to_ids.get(this.pad_token), this.sep_token = this.getToken("sep_token"), this.sep_token_id = this.model.tokens_to_ids.get(this.sep_token), this.unk_token = this.getToken("unk_token"), this.unk_token_id = this.model.tokens_to_ids.get(this.unk_token), this.bos_token = this.getToken("bos_token"), this.bos_token_id = this.model.tokens_to_ids.get(this.bos_token), this.eos_token = this.getToken("eos_token"), this.eos_token_id = this.model.tokens_to_ids.get(this.eos_token), this.model_max_length = Ae.model_max_length, this.remove_space = Ae.remove_space, this.clean_up_tokenization_spaces = Ae.clean_up_tokenization_spaces ?? !0, this.do_lowercase_and_remove_accent = Ae.do_lowercase_and_remove_accent ?? !1, Ae.padding_side && (this.padding_side = Ae.padding_side), this.add_bos_token = Ae.add_bos_token, this.add_eos_token = Ae.add_eos_token, this.legacy = !1, this.chat_template = Ae.chat_template ?? null, Array.isArray(this.chat_template)) {
            const Re = /* @__PURE__ */ Object.create(null);
            for (const { name: We, template: ot } of this.chat_template) {
              if (typeof We != "string" || typeof ot != "string")
                throw new Error('Chat template must be a list of objects with "name" and "template" properties');
              Re[We] = ot;
            }
            this.chat_template = Re;
          }
          this._compiled_template_cache = /* @__PURE__ */ new Map();
        }
        /**
         * Returns the value of the first matching key in the tokenizer config object.
         * @param {...string} keys One or more keys to search for in the tokenizer config object.
         * @returns {string|null} The value associated with the first matching key, or null if no match is found.
         * @throws {Error} If an object is found for a matching key and its __type property is not "AddedToken".
         * @private
         */
        getToken(...ie) {
          for (const Ae of ie) {
            const Re = this.config[Ae];
            if (Re)
              if (typeof Re == "object") {
                if (Re.__type === "AddedToken")
                  return Re.content;
                throw Error(`Unknown token: ${Re}`);
              } else
                return Re;
          }
          return null;
        }
        /**
         * Loads a pre-trained tokenizer from the given `pretrained_model_name_or_path`. 
         * 
         * @param {string} pretrained_model_name_or_path The path to the pre-trained tokenizer.
         * @param {PretrainedTokenizerOptions} options Additional options for loading the tokenizer.
         * 
         * @throws {Error} Throws an error if the tokenizer.json or tokenizer_config.json files are not found in the `pretrained_model_name_or_path`.
         * @returns {Promise<PreTrainedTokenizer>} A new instance of the `PreTrainedTokenizer` class.
         */
        static async from_pretrained(ie, {
          progress_callback: Ae = null,
          config: Re = null,
          cache_dir: We = null,
          local_files_only: ot = !1,
          revision: Et = "main",
          legacy: It = null
        } = {}) {
          const At = await h(ie, {
            progress_callback: Ae,
            config: Re,
            cache_dir: We,
            local_files_only: ot,
            revision: Et,
            legacy: It
          });
          return new this(...At);
        }
        /**
         * @typedef {number[]|number[][]|Tensor} BatchEncodingItem
         * 
         * @typedef {Object} BatchEncoding Holds the output of the tokenizer's call function.
         * @property {BatchEncodingItem} input_ids List of token ids to be fed to a model.
         * @property {BatchEncodingItem} attention_mask List of indices specifying which tokens should be attended to by the model.
         * @property {BatchEncodingItem} [token_type_ids] List of token type ids to be fed to a model.
         */
        /**
         * Encode/tokenize the given text(s).
         * @param {string|string[]} text The text to tokenize.
         * @param {Object} options An optional object containing the following properties:
         * @param {string|string[]} [options.text_pair=null] Optional second sequence to be encoded. If set, must be the same type as text.
         * @param {boolean|'max_length'} [options.padding=false] Whether to pad the input sequences.
         * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.
         * @param {boolean} [options.truncation=null] Whether to truncate the input sequences.
         * @param {number} [options.max_length=null] Maximum length of the returned list and optionally padding length.
         * @param {boolean} [options.return_tensor=true] Whether to return the results as Tensors or arrays.
         * @param {boolean} [options.return_token_type_ids=null] Whether to return the token type ids.
         * @returns {BatchEncoding} Object to be passed to the model.
         */
        _call(ie, {
          text_pair: Ae = null,
          add_special_tokens: Re = !0,
          padding: We = !1,
          truncation: ot = null,
          max_length: Et = null,
          return_tensor: It = !0,
          // Different to HF
          return_token_type_ids: At = null
        } = {}) {
          const kt = Array.isArray(ie);
          let Xt;
          if (kt) {
            if (ie.length === 0)
              throw Error("text array must be non-empty");
            if (Ae !== null) {
              if (Array.isArray(Ae)) {
                if (ie.length !== Ae.length)
                  throw Error("text and text_pair must have the same length");
              } else
                throw Error("text_pair must also be an array");
              Xt = ie.map(
                (_n, Rn) => this._encode_plus(_n, { text_pair: Ae[Rn], add_special_tokens: Re, return_token_type_ids: At })
              );
            } else
              Xt = ie.map((_n) => this._encode_plus(_n, { add_special_tokens: Re, return_token_type_ids: At }));
          } else {
            if (ie == null)
              throw Error("text may not be null or undefined");
            if (Array.isArray(Ae))
              throw Error("When specifying `text_pair`, since `text` is a string, `text_pair` must also be a string (i.e., not an array).");
            Xt = [this._encode_plus(ie, { text_pair: Ae, add_special_tokens: Re, return_token_type_ids: At })];
          }
          if (Et === null ? Et = this.model_max_length : ot === null && (We === !0 ? (console.warn(
            "`max_length` is ignored when `padding: true` and there is no truncation strategy. To pad to max length, use `padding: 'max_length'`."
          ), Et = this.model_max_length) : We === !1 && (console.warn("Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation: true` to explicitly truncate examples to max length."), ot = !0)), We === !0 && (Et = Math.min((0, c.max)(Xt.map((_n) => _n.input_ids.length))[0], Et ?? 1 / 0)), Et = Math.min(Et, this.model_max_length ?? 1 / 0), We || ot)
            for (let _n = 0; _n < Xt.length; ++_n)
              Xt[_n].input_ids.length !== Et && (Xt[_n].input_ids.length > Et ? ot && ds(Xt[_n], Et) : We && Si(
                Xt[_n],
                Et,
                (Rn) => Rn === "input_ids" ? this.pad_token_id : 0,
                this.padding_side
              ));
          const fn = {};
          if (It) {
            if (!(We && ot) && Xt.some((Rn) => {
              var En;
              for (const Un of Object.keys(Rn))
                if (Rn[Un].length !== ((En = Xt[0][Un]) == null ? void 0 : En.length))
                  return !0;
              return !1;
            }))
              throw Error(
                "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=true' and 'truncation=true' to have batched tensors with the same length."
              );
            const _n = [Xt.length, Xt[0].input_ids.length];
            for (const Rn of Object.keys(Xt[0]))
              fn[Rn] = new u.Tensor(
                "int64",
                BigInt64Array.from(Xt.flatMap((En) => En[Rn]).map(BigInt)),
                _n
              );
          } else {
            for (const _n of Object.keys(Xt[0]))
              fn[_n] = Xt.map((Rn) => Rn[_n]);
            if (!kt)
              for (const _n of Object.keys(fn))
                fn[_n] = fn[_n][0];
          }
          return (
            /** @type {BatchEncoding} */
            fn
          );
        }
        /**
         * Encodes a single text using the preprocessor pipeline of the tokenizer.
         *
         * @param {string|null} text The text to encode.
         * @returns {string[]|null} The encoded tokens.
         */
        _encode_text(ie) {
          if (ie === null)
            return null;
          const Ae = this.added_tokens_splitter.split(ie);
          for (let We = 0; We < Ae.length; ++We) {
            const ot = this.added_tokens_map.get(Ae[We]);
            ot && (ot.lstrip && We > 0 && (Ae[We - 1] = Ae[We - 1].trimEnd()), ot.rstrip && We < Ae.length - 1 && (Ae[We + 1] = Ae[We + 1].trimStart()));
          }
          return Ae.flatMap((We, ot) => {
            if (We.length === 0)
              return [];
            if (this.added_tokens_map.has(We))
              return [We];
            if (this.remove_space === !0 && (We = We.trim().split(/\s+/).join(" ")), this.do_lowercase_and_remove_accent && (We = T(We)), this.normalizer !== null && (We = this.normalizer(We)), We.length === 0)
              return [];
            const Et = this.pre_tokenizer !== null ? this.pre_tokenizer(We, {
              section_index: ot
            }) : [We];
            return this.model(Et);
          });
        }
        /**
         * Encodes a single text or a pair of texts using the model's tokenizer.
         *
         * @param {string} text The text to encode.
         * @param {Object} options An optional object containing the following properties:
         * @param {string} [options.text_pair=null] The optional second text to encode.
         * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.
         * @param {boolean} [options.return_token_type_ids=null] Whether to return token_type_ids.
         * @returns {EncodingSingle} An object containing the encoded text.
         * @private
         */
        _encode_plus(ie, {
          text_pair: Ae = null,
          add_special_tokens: Re = !0,
          return_token_type_ids: We = null
        } = {}) {
          const { tokens: ot, token_type_ids: Et } = this._tokenize_helper(ie, { pair: Ae, add_special_tokens: Re }), It = this.model.convert_tokens_to_ids(ot), At = {
            input_ids: It,
            attention_mask: new Array(It.length).fill(1)
          };
          return (We ?? this.return_token_type_ids) && Et && (At.token_type_ids = Et), At;
        }
        /**
         * Internal helper function to tokenize a text, and optionally a pair of texts.
         * @param {string} text The text to tokenize.
         * @param {Object} options An optional object containing the following properties:
         * @param {string} [options.pair=null] The optional second text to tokenize.
         * @param {boolean} [options.add_special_tokens=false] Whether or not to add the special tokens associated with the corresponding model.
         * @returns {{tokens: string[], token_type_ids?: number[]}} An object containing the tokens and optionally the token type IDs.
         */
        _tokenize_helper(ie, {
          pair: Ae = null,
          add_special_tokens: Re = !1
        } = {}) {
          const We = this._encode_text(ie), ot = this._encode_text(Ae);
          return this.post_processor ? this.post_processor(We, ot, { add_special_tokens: Re }) : { tokens: (0, r.mergeArrays)(We ?? [], ot ?? []) };
        }
        /**
         * Converts a string into a sequence of tokens.
         * @param {string} text The sequence to be encoded.
         * @param {Object} options An optional object containing the following properties:
         * @param {string} [options.pair] A second sequence to be encoded with the first.
         * @param {boolean} [options.add_special_tokens=false] Whether or not to add the special tokens associated with the corresponding model.
         * @returns {string[]} The list of tokens.
         */
        tokenize(ie, {
          pair: Ae = null,
          add_special_tokens: Re = !1
        } = {}) {
          return this._tokenize_helper(ie, { pair: Ae, add_special_tokens: Re }).tokens;
        }
        /**
         * Encodes a single text or a pair of texts using the model's tokenizer.
         *
         * @param {string} text The text to encode.
         * @param {Object} options An optional object containing the following properties:
         * @param {string} [options.text_pair=null] The optional second text to encode.
         * @param {boolean} [options.add_special_tokens=true] Whether or not to add the special tokens associated with the corresponding model.
         * @param {boolean} [options.return_token_type_ids=null] Whether to return token_type_ids.
         * @returns {number[]} An array of token IDs representing the encoded text(s).
         */
        encode(ie, {
          text_pair: Ae = null,
          add_special_tokens: Re = !0,
          return_token_type_ids: We = null
        } = {}) {
          return this._encode_plus(ie, {
            text_pair: Ae,
            add_special_tokens: Re,
            return_token_type_ids: We
          }).input_ids;
        }
        /**
         * Decode a batch of tokenized sequences.
         * @param {number[][]|Tensor} batch List/Tensor of tokenized input sequences.
         * @param {Object} decode_args (Optional) Object with decoding arguments.
         * @returns {string[]} List of decoded sequences.
         */
        batch_decode(ie, Ae = {}) {
          return ie instanceof u.Tensor && (ie = ie.tolist()), ie.map((Re) => this.decode(Re, Ae));
        }
        /**
         * Decodes a sequence of token IDs back to a string.
         *
         * @param {number[]|bigint[]|Tensor} token_ids List/Tensor of token IDs to decode.
         * @param {Object} [decode_args={}]
         * @param {boolean} [decode_args.skip_special_tokens=false] If true, special tokens are removed from the output string.
         * @param {boolean} [decode_args.clean_up_tokenization_spaces=true] If true, spaces before punctuations and abbreviated forms are removed.
         *
         * @returns {string} The decoded string.
         * @throws {Error} If `token_ids` is not a non-empty array of integers.
         */
        decode(ie, Ae = {}) {
          if (ie instanceof u.Tensor && (ie = S(ie)), !Array.isArray(ie) || ie.length === 0 || !(0, r.isIntegralNumber)(ie[0]))
            throw Error("token_ids must be a non-empty array of integers.");
          return this.decode_single(ie, Ae);
        }
        /**
         * Decode a single list of token ids to a string.
         * @param {number[]|bigint[]} token_ids List of token ids to decode
         * @param {Object} decode_args Optional arguments for decoding
         * @param {boolean} [decode_args.skip_special_tokens=false] Whether to skip special tokens during decoding
         * @param {boolean} [decode_args.clean_up_tokenization_spaces=null] Whether to clean up tokenization spaces during decoding.
         * If null, the value is set to `this.decoder.cleanup` if it exists, falling back to `this.clean_up_tokenization_spaces` if it exists, falling back to `true`.
         * @returns {string} The decoded string
         */
        decode_single(ie, {
          skip_special_tokens: Ae = !1,
          clean_up_tokenization_spaces: Re = null
        }) {
          let We = this.model.convert_ids_to_tokens(ie);
          Ae && (We = We.filter((Et) => !this.special_tokens.includes(Et)));
          let ot = this.decoder ? this.decoder(We) : We.join(" ");
          return this.decoder && this.decoder.end_of_word_suffix && (ot = ot.replaceAll(this.decoder.end_of_word_suffix, " "), Ae && (ot = ot.trim())), (Re ?? this.clean_up_tokenization_spaces) && (ot = D(ot)), ot;
        }
        /**
         * Retrieve the chat template string used for tokenizing chat messages. This template is used
         * internally by the `apply_chat_template` method and can also be used externally to retrieve the model's chat
         * template for better generation tracking.
         * 
         * @param {Object} options An optional object containing the following properties:
         * @param {string} [options.chat_template=null]
         * A Jinja template or the name of a template to use for this conversion.
         * It is usually not necessary to pass anything to this argument,
         * as the model's template will be used by default.
         * @param {Object[]} [options.tools=null]
         * A list of tools (callable functions) that will be accessible to the model. If the template does not
         * support function calling, this argument will have no effect. Each tool should be passed as a JSON Schema,
         * giving the name, description and argument types for the tool. See our
         * [chat templating guide](https://huggingface.co/docs/transformers/main/en/chat_templating#automated-function-conversion-for-tool-use)
         * for more information.
         * @returns {string} The chat template string.
         */
        get_chat_template({
          chat_template: ie = null,
          tools: Ae = null
        } = {}) {
          if (this.chat_template && typeof this.chat_template == "object") {
            const Re = this.chat_template;
            if (ie !== null && Object.hasOwn(Re, ie))
              ie = Re[ie];
            else if (ie === null)
              if (Ae !== null && "tool_use" in Re)
                ie = Re.tool_use;
              else if ("default" in Re)
                ie = Re.default;
              else
                throw Error(
                  `This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the 'chat_template' argument. Available template names are ${Object.keys(Re).sort()}.`
                );
          } else if (ie === null)
            if (this.chat_template)
              ie = this.chat_template;
            else
              throw Error(
                "Cannot use apply_chat_template() because tokenizer.chat_template is not set and no template argument was passed! For information about writing templates and setting the tokenizer.chat_template attribute, please see the documentation at https://huggingface.co/docs/transformers/main/en/chat_templating"
              );
          return ie;
        }
        /**
         * Converts a list of message objects with `"role"` and `"content"` keys to a list of token
         * ids. This method is intended for use with chat models, and will read the tokenizer's chat_template attribute to
         * determine the format and control tokens to use when converting.
         * 
         * See [here](https://huggingface.co/docs/transformers/chat_templating) for more information.
         * 
         * **Example:** Applying a chat template to a conversation.
         * 
         * ```javascript
         * import { AutoTokenizer } from "@huggingface/transformers";
         * 
         * const tokenizer = await AutoTokenizer.from_pretrained("Xenova/mistral-tokenizer-v1");
         * 
         * const chat = [
         *   { "role": "user", "content": "Hello, how are you?" },
         *   { "role": "assistant", "content": "I'm doing great. How can I help you today?" },
         *   { "role": "user", "content": "I'd like to show off how chat templating works!" },
         * ]
         * 
         * const text = tokenizer.apply_chat_template(chat, { tokenize: false });
         * // "<s>[INST] Hello, how are you? [/INST]I'm doing great. How can I help you today?</s> [INST] I'd like to show off how chat templating works! [/INST]"
         * 
         * const input_ids = tokenizer.apply_chat_template(chat, { tokenize: true, return_tensor: false });
         * // [1, 733, 16289, 28793, 22557, 28725, 910, 460, 368, 28804, 733, 28748, 16289, 28793, 28737, 28742, 28719, 2548, 1598, 28723, 1602, 541, 315, 1316, 368, 3154, 28804, 2, 28705, 733, 16289, 28793, 315, 28742, 28715, 737, 298, 1347, 805, 910, 10706, 5752, 1077, 3791, 28808, 733, 28748, 16289, 28793]
         * ```
         * 
         * @param {Message[]} conversation A list of message objects with `"role"` and `"content"` keys,
         * representing the chat history so far.
         * @param {Object} options An optional object containing the following properties:
         * @param {string} [options.chat_template=null] A Jinja template to use for this conversion. If
         * this is not passed, the model's chat template will be used instead.
         * @param {Object[]} [options.tools=null]
         * A list of tools (callable functions) that will be accessible to the model. If the template does not
         * support function calling, this argument will have no effect. Each tool should be passed as a JSON Schema,
         * giving the name, description and argument types for the tool. See our
         * [chat templating guide](https://huggingface.co/docs/transformers/main/en/chat_templating#automated-function-conversion-for-tool-use)
         * for more information.
         * @param {Record<string, string>[]} [options.documents=null]
         * A list of dicts representing documents that will be accessible to the model if it is performing RAG
         * (retrieval-augmented generation). If the template does not support RAG, this argument will have no
         * effect. We recommend that each document should be a dict containing "title" and "text" keys. Please
         * see the RAG section of the [chat templating guide](https://huggingface.co/docs/transformers/main/en/chat_templating#arguments-for-RAG)
         * for examples of passing documents with chat templates.
         * @param {boolean} [options.add_generation_prompt=false] Whether to end the prompt with the token(s) that indicate
         * the start of an assistant message. This is useful when you want to generate a response from the model.
         * Note that this argument will be passed to the chat template, and so it must be supported in the
         * template for this argument to have any effect.
         * @param {boolean} [options.tokenize=true] Whether to tokenize the output. If false, the output will be a string.
         * @param {boolean} [options.padding=false] Whether to pad sequences to the maximum length. Has no effect if tokenize is false.
         * @param {boolean} [options.truncation=false] Whether to truncate sequences to the maximum length. Has no effect if tokenize is false.
         * @param {number} [options.max_length=null] Maximum length (in tokens) to use for padding or truncation. Has no effect if tokenize is false.
         * If not specified, the tokenizer's `max_length` attribute will be used as a default.
         * @param {boolean} [options.return_tensor=true] Whether to return the output as a Tensor or an Array. Has no effect if tokenize is false.
         * @param {boolean} [options.return_dict=true] Whether to return a dictionary with named outputs. Has no effect if tokenize is false.
         * @param {Object} [options.tokenizer_kwargs={}] Additional options to pass to the tokenizer.
         * @returns {string | Tensor | number[]| number[][]|BatchEncoding} The tokenized output.
         */
        apply_chat_template(ie, {
          tools: Ae = null,
          documents: Re = null,
          chat_template: We = null,
          add_generation_prompt: ot = !1,
          tokenize: Et = !0,
          padding: It = !1,
          truncation: At = !1,
          max_length: kt = null,
          return_tensor: Xt = !0,
          return_dict: fn = !1,
          tokenizer_kwargs: _n = {},
          ...Rn
        } = {}) {
          if (We = this.get_chat_template({ chat_template: We, tools: Ae }), typeof We != "string")
            throw Error(`chat_template must be a string, but got ${typeof We}`);
          let En = this._compiled_template_cache.get(We);
          En === void 0 && (En = new f.Template(We), this._compiled_template_cache.set(We, En));
          const Un = /* @__PURE__ */ Object.create(null);
          for (const xi of bn) {
            const ms = this.getToken(xi);
            ms && (Un[xi] = ms);
          }
          const ui = En.render({
            messages: ie,
            add_generation_prompt: ot,
            tools: Ae,
            documents: Re,
            ...Un,
            ...Rn
          });
          if (Et) {
            const xi = this._call(ui, {
              add_special_tokens: !1,
              padding: It,
              truncation: At,
              max_length: kt,
              return_tensor: Xt,
              ..._n
            });
            return fn ? xi : xi.input_ids;
          }
          return ui;
        }
      }
      class Me extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class at extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class rt extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class mt extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class _t extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class on extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class B extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class le extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class J extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class se extends qt {
      }
      class ge extends qt {
      }
      class Fe extends qt {
        constructor(ie, Ae) {
          super(ie, Ae);
          Ce(this, "return_token_type_ids", !0);
          console.warn('WARNING: `XLMTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.');
        }
      }
      class Ke extends qt {
        constructor() {
          super(...arguments);
          Ce(this, "return_token_type_ids", !0);
        }
      }
      class pt extends qt {
      }
      class Pt extends qt {
      }
      class Tt extends qt {
      }
      class en extends qt {
        constructor(j, ie) {
          super(j, ie), this.languageRegex = /^[a-z]{2}_[A-Z]{2}$/, this.language_codes = this.special_tokens.filter((Ae) => this.languageRegex.test(Ae)), this.lang_to_token = (Ae) => Ae;
        }
        /**
         * Helper function to build translation inputs for an `MBartTokenizer`.
         * @param {string|string[]} raw_inputs The text to tokenize.
         * @param {Object} tokenizer_options Options to be sent to the tokenizer
         * @param {Object} generate_kwargs Generation options.
         * @returns {Object} Object to be passed to the model.
         */
        _build_translation_inputs(j, ie, Ae) {
          return Oi(this, j, ie, Ae);
        }
      }
      class Dt extends en {
      }
      class tn extends qt {
      }
      class Vt extends qt {
      }
      const nn = "";
      class Mn extends qt {
        constructor(ie, Ae) {
          super(ie, Ae);
          Ce(this, "padding_side", "left");
          this.legacy = Ae.legacy ?? !0, this.legacy || (this.normalizer = null, this.pre_tokenizer = new vn({
            replacement: nn,
            prepend_scheme: "first"
          }));
        }
        /**
         * Helper function to handle legacy encoding of SPM tokenizers.
         * Adapted from https://github.com/huggingface/transformers/blob/e6dcf8abd6f65bb4b6dfc1831b20d9ba49ce00e2/src/transformers/models/t5/tokenization_t5.py#L374-L387
         * @param {string} text The text to encode.
         * @returns {string[]} The encoded tokens.
         */
        _encode_text(ie) {
          if (ie === null)
            return null;
          if (this.legacy || ie.length === 0)
            return super._encode_text(ie);
          let Ae = super._encode_text(nn + ie.replaceAll(nn, " "));
          return Ae.length > 1 && Ae[0] === nn && this.special_tokens.includes(Ae[1]) && (Ae = Ae.slice(1)), Ae;
        }
      }
      class vi extends qt {
      }
      class ci extends qt {
      }
      class ki extends qt {
      }
      class fi extends qt {
      }
      class Pi extends qt {
      }
      class wi extends qt {
      }
      class hs extends qt {
      }
      class fs extends qt {
      }
      class Ps extends qt {
      }
      function Oi(Xe, j, ie, Ae) {
        if (!("language_codes" in Xe) || !Array.isArray(Xe.language_codes))
          throw new Error("Tokenizer must have `language_codes` attribute set and it should be an array of language ids.");
        if (!("languageRegex" in Xe) || !(Xe.languageRegex instanceof RegExp))
          throw new Error("Tokenizer must have `languageRegex` attribute set and it should be a regular expression.");
        if (!("lang_to_token" in Xe) || typeof Xe.lang_to_token != "function")
          throw new Error("Tokenizer must have `lang_to_token` attribute set and it should be a function.");
        const Re = Ae.src_lang, We = Ae.tgt_lang;
        if (!Xe.language_codes.includes(We))
          throw new Error(`Target language code "${We}" is not valid. Must be one of: {${Xe.language_codes.join(", ")}}`);
        if (Re !== void 0) {
          if (!Xe.language_codes.includes(Re))
            throw new Error(`Source language code "${Re}" is not valid. Must be one of: {${Xe.language_codes.join(", ")}}`);
          for (const ot of Xe.post_processor.config.single)
            if ("SpecialToken" in ot && Xe.languageRegex.test(ot.SpecialToken.id)) {
              ot.SpecialToken.id = Xe.lang_to_token(Re);
              break;
            }
        }
        return Ae.forced_bos_token_id = Xe.model.convert_tokens_to_ids([Xe.lang_to_token(We)])[0], Xe._call(j, ie);
      }
      class jt extends qt {
        constructor(j, ie) {
          super(j, ie), this.languageRegex = /^[a-z]{3}_[A-Z][a-z]{3}$/, this.language_codes = this.special_tokens.filter((Ae) => this.languageRegex.test(Ae)), this.lang_to_token = (Ae) => Ae;
        }
        /**
         * Helper function to build translation inputs for an `NllbTokenizer`.
         * @param {string|string[]} raw_inputs The text to tokenize.
         * @param {Object} tokenizer_options Options to be sent to the tokenizer
         * @param {Object} generate_kwargs Generation options.
         * @returns {Object} Object to be passed to the model.
         */
        _build_translation_inputs(j, ie, Ae) {
          return Oi(this, j, ie, Ae);
        }
      }
      class Ni extends qt {
        constructor(j, ie) {
          super(j, ie), this.languageRegex = /^__[a-z]{2,3}__$/, this.language_codes = this.special_tokens.filter((Ae) => this.languageRegex.test(Ae)).map((Ae) => Ae.slice(2, -2)), this.lang_to_token = (Ae) => `__${Ae}__`;
        }
        /**
         * Helper function to build translation inputs for an `M2M100Tokenizer`.
         * @param {string|string[]} raw_inputs The text to tokenize.
         * @param {Object} tokenizer_options Options to be sent to the tokenizer
         * @param {Object} generate_kwargs Generation options.
         * @returns {Object} Object to be passed to the model.
         */
        _build_translation_inputs(j, ie, Ae) {
          return Oi(this, j, ie, Ae);
        }
      }
      class Ws extends qt {
        get timestamp_begin() {
          return this.model.convert_tokens_to_ids(["<|notimestamps|>"])[0] + 1;
        }
        /**
         * Decodes automatic speech recognition (ASR) sequences.
         * @param {Array<{tokens: bigint[], token_timestamps?: number[], stride: number[]}>} sequences The sequences to decode.
         * @param {Object} options The options to use for decoding.
         * @returns {Array<string|{chunks?: undefined|Array<{language: string|null, timestamp: Array<number|null>, text: string}>}>} The decoded sequences.
         */
        _decode_asr(j, {
          return_timestamps: ie = !1,
          return_language: Ae = !1,
          time_precision: Re = null,
          force_full_sequences: We = !0
        } = {}) {
          if (Re === null)
            throw Error("Must specify time_precision");
          let ot = null;
          const Et = ie === "word";
          function It() {
            return { language: ot, timestamp: [null, null], text: "" };
          }
          const At = [];
          let kt = It(), Xt = 0;
          const fn = this.timestamp_begin, Rn = fn + 1500;
          let En = [], Un = [], ui = !1, xi = null;
          const ms = new Set(this.all_special_ids);
          for (const Cn of j) {
            const Vn = Cn.tokens, ii = Et ? Cn.token_timestamps : null;
            let Qi = null, Zi = fn;
            if ("stride" in Cn) {
              const [Yn, jn, Wn] = Cn.stride;
              if (Xt -= jn, xi = Yn - Wn, jn && (Zi = jn / Re + fn), Wn)
                for (let Yt = Vn.length - 1; Yt >= 0; --Yt) {
                  const pn = Number(Vn[Yt]);
                  if (pn >= fn) {
                    if (Qi !== null && (pn - fn) * Re < xi)
                      break;
                    Qi = pn;
                  }
                }
            }
            let si = [], es = [];
            for (let Yn = 0; Yn < Vn.length; ++Yn) {
              const jn = Number(Vn[Yn]);
              if (ms.has(jn)) {
                const Wn = this.decode([jn]), Yt = m.WHISPER_LANGUAGE_MAPPING.get(Wn.slice(2, -2));
                if (Yt !== void 0) {
                  if (ot !== null && Yt !== ot && !ie) {
                    En.push(si);
                    const pn = this.findLongestCommonSequence(En)[0], ts = this.decode(pn);
                    kt.text = ts, At.push(kt), En = [], si = [], kt = It();
                  }
                  ot = kt.language = Yt;
                }
              } else if (jn >= fn && jn <= Rn) {
                const Wn = (jn - fn) * Re + Xt, Yt = (0, c.round)(Wn, 2);
                if (Qi !== null && jn >= Qi)
                  ui = !0;
                else if (ui || En.length > 0 && jn < Zi)
                  ui = !1;
                else if (kt.timestamp[0] === null)
                  kt.timestamp[0] = Yt;
                else if (Yt !== kt.timestamp[0]) {
                  kt.timestamp[1] = Yt, En.push(si), Et && Un.push(es);
                  const [pn, ts] = this.findLongestCommonSequence(
                    En,
                    Un
                  ), ns = this.decode(pn);
                  kt.text = ns, Et && (kt.words = this.collateWordTimestamps(
                    pn,
                    ts,
                    ot
                  )), At.push(kt), En = [], si = [], Un = [], es = [], kt = It();
                }
              } else if (si.push(jn), Et) {
                let Wn = (0, c.round)(ii[Yn] + Xt, 2), Yt;
                if (Yn + 1 < ii.length) {
                  Yt = (0, c.round)(ii[Yn + 1] + Xt, 2);
                  const pn = this.decode([jn]);
                  I.test(pn) && (Yt = (0, c.round)(Math.min(Wn + Re, Yt), 2));
                } else
                  Yt = null;
                es.push([Wn, Yt]);
              }
            }
            if ("stride" in Cn) {
              const [Yn, jn, Wn] = Cn.stride;
              Xt += Yn - Wn;
            }
            si.length > 0 ? (En.push(si), Et && Un.push(es)) : En.every((Yn) => Yn.length === 0) && (kt = It(), En = [], si = [], Un = [], es = []);
          }
          if (En.length > 0) {
            if (We && ie)
              throw new Error(
                "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation."
              );
            const [Cn, Vn] = this.findLongestCommonSequence(En, Un), ii = this.decode(Cn);
            kt.text = ii, Et && (kt.words = this.collateWordTimestamps(
              Cn,
              Vn,
              ot
            )), At.push(kt);
          }
          let ei = /* @__PURE__ */ Object.create(null);
          const gs = At.map((Cn) => Cn.text).join("");
          if (ie || Ae) {
            for (let Cn = 0; Cn < At.length; ++Cn) {
              const Vn = At[Cn];
              ie || delete Vn.timestamp, Ae || delete Vn.language;
            }
            if (Et) {
              const Cn = [];
              for (const Vn of At)
                for (const ii of Vn.words)
                  Cn.push(ii);
              ei = { chunks: Cn };
            } else
              ei = { chunks: At };
          }
          return [gs, ei];
        }
        /**
         * Finds the longest common sequence among the provided sequences.
         * @param {number[][]} sequences An array of sequences of token ids to compare.
         * @returns {number[][]} The longest common sequence found.
         * @throws {Error} If there is a bug within the function.
         * @private
         */
        findLongestCommonSequence(j, ie = null) {
          let Ae = j[0], Re = Ae.length, We = [];
          const ot = Array.isArray(ie) && ie.length > 0;
          let Et = ot ? [] : null, It = ot ? ie[0] : null;
          for (let At = 1; At < j.length; ++At) {
            const kt = j[At];
            let Xt = 0, fn = [Re, Re, 0, 0];
            const _n = kt.length;
            for (let ei = 1; ei < Re + _n; ++ei) {
              const gs = Math.max(0, Re - ei), Cn = Math.min(Re, Re + _n - ei), Vn = Ae.slice(gs, Cn), ii = Math.max(0, ei - Re), Qi = Math.min(_n, ei), Zi = kt.slice(ii, Qi);
              if (Vn.length !== Zi.length)
                throw new Error("There is a bug within whisper `decode_asr` function, please report it. Dropping to prevent bad inference.");
              let si;
              ot ? si = Vn.filter((jn, Wn) => jn === Zi[Wn] && It[gs + Wn] <= ie[At][ii + Wn]).length : si = Vn.filter((jn, Wn) => jn === Zi[Wn]).length;
              const es = ei / 1e4, Yn = si / ei + es;
              si > 1 && Yn > Xt && (Xt = Yn, fn = [gs, Cn, ii, Qi]);
            }
            const [Rn, En, Un, ui] = fn, xi = Math.floor((En + Rn) / 2), ms = Math.floor((ui + Un) / 2);
            We.push(...Ae.slice(0, xi)), Ae = kt.slice(ms), Re = Ae.length, ot && (Et.push(...It.slice(0, xi)), It = ie[At].slice(ms));
          }
          return We.push(...Ae), ot ? (Et.push(...It), [We, Et]) : [We, []];
        }
        /** @private */
        collateWordTimestamps(j, ie, Ae) {
          const [Re, We, ot] = this.combineTokensIntoWords(j, Ae), Et = [];
          for (let It = 0; It < Re.length; ++It) {
            const At = ot[It];
            Et.push({
              text: Re[It],
              timestamp: [
                ie[At.at(0)][0],
                ie[At.at(-1)][1]
              ]
            });
          }
          return Et;
        }
        /**
         * Groups tokens by word. Returns a tuple containing a list of strings with the words,
         * and a list of `token_id` sequences with the tokens making up each word.
         * @param {number[]} tokens 
         * @param {string} [language] 
         * @param {string} prepend_punctionations 
         * @param {string} append_punctuations 
         * 
         * @private
         */
        combineTokensIntoWords(j, ie, Ae = `"'([{-`, Re = `"'.,!?:)]}`) {
          ie = ie ?? "english";
          let We, ot, Et;
          return ["chinese", "japanese", "thai", "lao", "myanmar"].includes(ie) ? [We, ot, Et] = this.splitTokensOnUnicode(j) : [We, ot, Et] = this.splitTokensOnSpaces(j), this.mergePunctuations(We, ot, Et, Ae, Re);
        }
        /** @type {PreTrainedTokenizer['decode']} */
        decode(j, ie) {
          let Ae;
          return ie != null && ie.decode_with_timestamps ? (j instanceof u.Tensor && (j = S(j)), Ae = this.decodeWithTimestamps(j, ie)) : Ae = super.decode(j, ie), Ae;
        }
        /**
         * @param {number[]|bigint[]} token_ids List of token IDs to decode.
         * @param {Object} decode_args Optional arguments for decoding
         * @private
         */
        decodeWithTimestamps(j, ie) {
          const Ae = (ie == null ? void 0 : ie.time_precision) ?? 0.02, Re = Array.from(this.all_special_ids).at(-1) + 1;
          let We = [[]];
          for (let ot of j)
            if (ot = Number(ot), ot >= Re) {
              const Et = ((ot - Re) * Ae).toFixed(2);
              We.push(`<|${Et}|>`), We.push([]);
            } else
              We[We.length - 1].push(ot);
          return We = We.map(
            (ot) => typeof ot == "string" ? ot : super.decode(ot, ie)
          ), We.join("");
        }
        /**
         * Combine tokens into words by splitting at any position where the tokens are decoded as valid unicode points.
         * @param {number[]} tokens 
         * @returns {*}
         * @private
         */
        splitTokensOnUnicode(j) {
          const ie = this.decode(j, {
            // @ts-ignore
            decode_with_timestamps: !0
          }), Ae = "", Re = [], We = [], ot = [];
          let Et = [], It = [], At = 0;
          for (let kt = 0; kt < j.length; ++kt) {
            const Xt = j[kt];
            Et.push(Xt), It.push(kt);
            const fn = this.decode(Et, {
              // @ts-ignore
              decode_with_timestamps: !0
            });
            (!fn.includes(Ae) || ie[At + fn.indexOf(Ae)] === Ae) && (Re.push(fn), We.push(Et), ot.push(It), Et = [], It = [], At += fn.length);
          }
          return [Re, We, ot];
        }
        /**
         * Combine tokens into words by splitting at whitespace and punctuation tokens.
         * @param {number[]} tokens 
         * @private
         */
        splitTokensOnSpaces(j) {
          const [ie, Ae, Re] = this.splitTokensOnUnicode(j), We = [], ot = [], Et = [], It = new RegExp(`^[${L}]$`, "gu");
          for (let At = 0; At < ie.length; ++At) {
            const kt = ie[At], Xt = Ae[At], fn = Re[At], _n = Xt[0] >= this.model.tokens_to_ids.get("<|endoftext|>"), Rn = kt.startsWith(" "), En = kt.trim(), Un = It.test(En);
            if (_n || Rn || Un || We.length === 0)
              We.push(kt), ot.push(Xt), Et.push(fn);
            else {
              const ui = We.length - 1;
              We[ui] += kt, ot[ui].push(...Xt), Et[ui].push(...fn);
            }
          }
          return [We, ot, Et];
        }
        /**
         * Merges punctuation tokens with neighboring words.
         * @param {string[]} words 
         * @param {number[][]} tokens 
         * @param {number[][]} indices 
         * @param {string} prepended 
         * @param {string} appended 
         * @private
         */
        mergePunctuations(j, ie, Ae, Re, We) {
          const ot = structuredClone(j), Et = structuredClone(ie), It = structuredClone(Ae);
          let At = ot.length - 2, kt = ot.length - 1;
          for (; At >= 0; )
            ot[At].startsWith(" ") && Re.includes(ot[At].trim()) ? (ot[kt] = ot[At] + ot[kt], Et[kt] = (0, r.mergeArrays)(Et[At], Et[kt]), It[kt] = (0, r.mergeArrays)(It[At], It[kt]), ot[At] = "", Et[At] = [], It[At] = []) : kt = At, --At;
          for (At = 0, kt = 1; kt < ot.length; )
            !ot[At].endsWith(" ") && We.includes(ot[kt]) ? (ot[At] += ot[kt], Et[At] = (0, r.mergeArrays)(Et[At], Et[kt]), It[At] = (0, r.mergeArrays)(It[At], It[kt]), ot[kt] = "", Et[kt] = [], It[kt] = []) : At = kt, ++kt;
          return [
            ot.filter((Xt) => Xt),
            Et.filter((Xt) => Xt.length > 0),
            It.filter((Xt) => Xt.length > 0)
          ];
        }
      }
      class As extends qt {
      }
      class Cs extends qt {
      }
      class Is extends qt {
      }
      class Ji extends qt {
        /**
         * Create a new MarianTokenizer instance.
         * @param {Object} tokenizerJSON The JSON of the tokenizer.
         * @param {Object} tokenizerConfig The config of the tokenizer.
         */
        constructor(j, ie) {
          super(j, ie), this.languageRegex = /^(>>\w+<<)\s*/g, this.supported_language_codes = this.model.vocab.filter(
            (Ae) => this.languageRegex.test(Ae)
          ), console.warn('WARNING: `MarianTokenizer` is not yet supported by Hugging Face\'s "fast" tokenizers library. Therefore, you may experience slightly inaccurate results.');
        }
        /**
         * Encodes a single text. Overriding this method is necessary since the language codes
         * must be removed before encoding with sentencepiece model.
         * @see https://github.com/huggingface/transformers/blob/12d51db243a00726a548a43cc333390ebae731e3/src/transformers/models/marian/tokenization_marian.py#L204-L213
         *
         * @param {string|null} text The text to encode.
         * @returns {Array} The encoded tokens.
         */
        _encode_text(j) {
          if (j === null)
            return null;
          const [ie, ...Ae] = j.trim().split(this.languageRegex);
          if (Ae.length === 0)
            return super._encode_text(ie);
          if (Ae.length === 2) {
            const [Re, We] = Ae;
            return this.supported_language_codes.includes(Re) || console.warn(`Unsupported language code "${Re}" detected, which may lead to unexpected behavior. Should be one of: ${JSON.stringify(this.supported_language_codes)}`), (0, r.mergeArrays)([Re], super._encode_text(We));
          }
        }
      }
      class pi extends qt {
      }
      class bt extends qt {
      }
      class ct extends qt {
      }
      class Lt extends qt {
      }
      class yn extends qt {
      }
      class Ui extends qt {
        constructor(j, ie) {
          super(j, ie), this.decoder = new Kt({});
        }
      }
      class it extends qt {
      }
      class ps extends qt {
      }
      class Br {
        /**
         * Instantiate one of the tokenizer classes of the library from a pretrained model.
         * 
         * The tokenizer class to instantiate is selected based on the `tokenizer_class` property of the config object
         * (either passed as an argument or loaded from `pretrained_model_name_or_path` if possible)
         * 
         * @param {string} pretrained_model_name_or_path The name or path of the pretrained model. Can be either:
         * - A string, the *model id* of a pretrained tokenizer hosted inside a model repo on huggingface.co.
         *   Valid model ids can be located at the root-level, like `bert-base-uncased`, or namespaced under a
         *   user or organization name, like `dbmdz/bert-base-german-cased`.
         * - A path to a *directory* containing tokenizer files, e.g., `./my_model_directory/`.
         * @param {PretrainedTokenizerOptions} options Additional options for loading the tokenizer.
         * 
         * @returns {Promise<PreTrainedTokenizer>} A new instance of the PreTrainedTokenizer class.
         */
        static async from_pretrained(j, {
          progress_callback: ie = null,
          config: Ae = null,
          cache_dir: Re = null,
          local_files_only: We = !1,
          revision: ot = "main",
          legacy: Et = null
        } = {}) {
          var fn;
          const [It, At] = await h(j, {
            progress_callback: ie,
            config: Ae,
            cache_dir: Re,
            local_files_only: We,
            revision: ot,
            legacy: Et
          }), kt = ((fn = At.tokenizer_class) == null ? void 0 : fn.replace(/Fast$/, "")) ?? "PreTrainedTokenizer";
          let Xt = this.TOKENIZER_CLASS_MAPPING[kt];
          return Xt || (console.warn(`Unknown tokenizer class "${kt}", attempting to construct from base class.`), Xt = qt), new Xt(It, At);
        }
      }
      Ce(Br, "TOKENIZER_CLASS_MAPPING", {
        T5Tokenizer: pt,
        DistilBertTokenizer: se,
        CamembertTokenizer: ge,
        DebertaTokenizer: _t,
        DebertaV2Tokenizer: on,
        BertTokenizer: Me,
        HerbertTokenizer: B,
        ConvBertTokenizer: le,
        RoFormerTokenizer: J,
        XLMTokenizer: Fe,
        ElectraTokenizer: Ke,
        MobileBertTokenizer: rt,
        SqueezeBertTokenizer: mt,
        AlbertTokenizer: at,
        GPT2Tokenizer: Pt,
        BartTokenizer: Tt,
        MBartTokenizer: en,
        MBart50Tokenizer: Dt,
        RobertaTokenizer: tn,
        WhisperTokenizer: Ws,
        CodeGenTokenizer: As,
        CLIPTokenizer: Cs,
        SiglipTokenizer: Is,
        MarianTokenizer: Ji,
        BloomTokenizer: Vt,
        NllbTokenizer: jt,
        M2M100Tokenizer: Ni,
        LlamaTokenizer: Mn,
        CodeLlamaTokenizer: vi,
        XLMRobertaTokenizer: ci,
        MPNetTokenizer: ki,
        FalconTokenizer: fi,
        GPTNeoXTokenizer: Pi,
        EsmTokenizer: wi,
        Wav2Vec2CTCTokenizer: pi,
        BlenderbotTokenizer: bt,
        BlenderbotSmallTokenizer: ct,
        SpeechT5Tokenizer: Lt,
        NougatTokenizer: yn,
        VitsTokenizer: Ui,
        Qwen2Tokenizer: hs,
        GemmaTokenizer: fs,
        Grok1Tokenizer: Ps,
        CohereTokenizer: it,
        MgpstrTokenizer: ps,
        // Base case:
        PreTrainedTokenizer: qt
      });
    }
  ),
  /***/
  "./src/utils/audio.js": (
    /*!****************************!*\
      !*** ./src/utils/audio.js ***!
      \****************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        RawAudio: () => (
          /* binding */
          Q
        ),
        /* harmony export */
        hamming: () => (
          /* binding */
          p
        ),
        /* harmony export */
        hanning: () => (
          /* binding */
          h
        ),
        /* harmony export */
        mel_filter_bank: () => (
          /* binding */
          F
        ),
        /* harmony export */
        read_audio: () => (
          /* binding */
          f
        ),
        /* harmony export */
        spectrogram: () => (
          /* binding */
          R
        ),
        /* harmony export */
        window_function: () => (
          /* binding */
          N
        )
        /* harmony export */
      });
      var i = t(
        /*! ./hub.js */
        "./src/utils/hub.js"
      ), r = t(
        /*! ./maths.js */
        "./src/utils/maths.js"
      ), a = t(
        /*! ./core.js */
        "./src/utils/core.js"
      ), c = t(
        /*! ../env.js */
        "./src/env.js"
      ), u = t(
        /*! ./tensor.js */
        "./src/utils/tensor.js"
      ), l = t(
        /*! node:fs */
        "?7992"
      );
      async function f(W, te) {
        if (typeof AudioContext > "u")
          throw Error(
            "Unable to load audio from path/URL since `AudioContext` is not available in your environment. Instead, audio data should be passed directly to the pipeline/processor. For more information and some example code, see https://huggingface.co/docs/transformers.js/guides/node-audio-processing."
          );
        const K = await (await (0, i.getFile)(W)).arrayBuffer(), pe = new AudioContext({ sampleRate: te });
        typeof te > "u" && console.warn(`No sampling rate provided, using default of ${pe.sampleRate}Hz.`);
        const be = await pe.decodeAudioData(K);
        let Ee;
        if (be.numberOfChannels === 2) {
          const Ge = Math.sqrt(2), _e = be.getChannelData(0), De = be.getChannelData(1);
          Ee = new Float32Array(_e.length);
          for (let he = 0; he < be.length; ++he)
            Ee[he] = Ge * (_e[he] + De[he]) / 2;
        } else
          Ee = be.getChannelData(0);
        return Ee;
      }
      function m(W, te) {
        if (W < 1)
          return new Float64Array();
        if (W === 1)
          return new Float64Array([1]);
        const K = 1 - te, pe = 2 * Math.PI / (W - 1), be = new Float64Array(W);
        for (let Ee = 0; Ee < W; ++Ee)
          be[Ee] = te - K * Math.cos(Ee * pe);
        return be;
      }
      function h(W) {
        return m(W, 0.5);
      }
      function p(W) {
        return m(W, 0.54);
      }
      const _ = {
        htk: (W) => 2595 * Math.log10(1 + W / 700),
        kaldi: (W) => 1127 * Math.log(1 + W / 700),
        slaney: (W, te = 1e3, K = 15, pe = 27 / Math.log(6.4)) => W >= te ? K + Math.log(W / te) * pe : 3 * W / 200
      };
      function v(W, te = "htk") {
        const K = _[te];
        if (!K)
          throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');
        return typeof W == "number" ? K(W) : W.map((pe) => K(pe));
      }
      const S = {
        htk: (W) => 700 * (10 ** (W / 2595) - 1),
        kaldi: (W) => 700 * (Math.exp(W / 1127) - 1),
        slaney: (W, te = 1e3, K = 15, pe = Math.log(6.4) / 27) => W >= K ? te * Math.exp(pe * (W - K)) : 200 * W / 3
      };
      function D(W, te = "htk") {
        const K = S[te];
        if (!K)
          throw new Error('mel_scale should be one of "htk", "slaney" or "kaldi".');
        return typeof W == "number" ? K(W) : W.map((pe) => K(pe));
      }
      function w(W, te) {
        const K = Float64Array.from(
          { length: te.length - 1 },
          (Ge, _e) => te[_e + 1] - te[_e]
        ), pe = Array.from({
          length: W.length
        }, () => new Array(te.length));
        for (let Ge = 0; Ge < W.length; ++Ge) {
          const _e = pe[Ge];
          for (let De = 0; De < te.length; ++De)
            _e[De] = te[De] - W[Ge];
        }
        const be = te.length - 2, Ee = Array.from({ length: be }, () => new Array(W.length));
        for (let Ge = 0; Ge < W.length; ++Ge) {
          const _e = pe[Ge];
          for (let De = 0; De < be; ++De) {
            const he = -_e[De] / K[De], Z = _e[De + 2] / K[De + 1];
            Ee[De][Ge] = Math.max(0, Math.min(he, Z));
          }
        }
        return Ee;
      }
      function T(W, te, K) {
        const pe = (te - W) / (K - 1);
        return Float64Array.from({ length: K }, (be, Ee) => W + pe * Ee);
      }
      function F(W, te, K, pe, be, Ee = null, Ge = "htk", _e = !1) {
        if (Ee !== null && Ee !== "slaney")
          throw new Error('norm must be one of null or "slaney"');
        if (W < 2)
          throw new Error(`Require num_frequency_bins: ${W} >= 2`);
        if (K > pe)
          throw new Error(`Require min_frequency: ${K} <= max_frequency: ${pe}`);
        const De = v(K, Ge), he = v(pe, Ge), Z = T(De, he, te + 2);
        let me = D(Z, Ge), we;
        if (_e) {
          const et = be / ((W - 1) * 2);
          we = v(Float64Array.from({ length: W }, (Ve, nt) => nt * et), Ge), me = Z;
        } else
          we = T(0, Math.floor(be / 2), W);
        const xe = w(we, me);
        if (Ee !== null && Ee === "slaney")
          for (let et = 0; et < te; ++et) {
            const Ve = xe[et], nt = 2 / (me[et + 2] - me[et]);
            for (let Be = 0; Be < W; ++Be)
              Ve[Be] *= nt;
          }
        return xe;
      }
      function E(W, te, K) {
        const pe = new W.constructor(W.length + te + K), be = W.length - 1;
        for (let Ee = 0; Ee < W.length; ++Ee)
          pe[te + Ee] = W[Ee];
        for (let Ee = 1; Ee <= te; ++Ee)
          pe[te - Ee] = W[(0, a.calculateReflectOffset)(Ee, be)];
        for (let Ee = 1; Ee <= K; ++Ee)
          pe[be + te + Ee] = W[(0, a.calculateReflectOffset)(be - Ee, be)];
        return pe;
      }
      function A(W, te, K, pe, be) {
        if (K <= 0)
          throw new Error("reference must be greater than zero");
        if (pe <= 0)
          throw new Error("min_value must be greater than zero");
        K = Math.max(pe, K);
        const Ee = Math.log10(K);
        for (let Ge = 0; Ge < W.length; ++Ge)
          W[Ge] = te * Math.log10(Math.max(pe, W[Ge]) - Ee);
        if (be !== null) {
          if (be <= 0)
            throw new Error("db_range must be greater than zero");
          const Ge = (0, r.max)(W)[0] - be;
          for (let _e = 0; _e < W.length; ++_e)
            W[_e] = Math.max(W[_e], Ge);
        }
        return W;
      }
      function L(W, te = 1, K = 1e-5, pe = null) {
        return A(W, 20, te, K, pe);
      }
      function I(W, te = 1, K = 1e-10, pe = null) {
        return A(W, 10, te, K, pe);
      }
      async function R(W, te, K, pe, {
        fft_length: be = null,
        power: Ee = 1,
        center: Ge = !0,
        pad_mode: _e = "reflect",
        onesided: De = !0,
        preemphasis: he = null,
        preemphasis_htk_flavor: Z = !0,
        mel_filters: me = null,
        mel_floor: we = 1e-10,
        log_mel: xe = null,
        reference: et = 1,
        min_value: Ve = 1e-10,
        db_range: nt = null,
        remove_dc_offset: Be = null,
        // Custom parameters for efficiency reasons
        min_num_frames: ae = null,
        max_num_frames: U = null,
        do_pad: Se = !0,
        transpose: ze = !1,
        mel_offset: Oe = 0
      } = {}) {
        const Ye = te.length;
        if (be === null && (be = K), K > be)
          throw Error(`frame_length (${K}) may not be larger than fft_length (${be})`);
        if (Ye !== K)
          throw new Error(`Length of the window (${Ye}) must equal frame_length (${K})`);
        if (pe <= 0)
          throw new Error("hop_length must be greater than zero");
        if (Ee === null && me !== null)
          throw new Error(
            "You have provided `mel_filters` but `power` is `None`. Mel spectrogram computation is not yet supported for complex-valued spectrogram. Specify `power` to fix this issue."
          );
        if (!Z)
          throw new Error(
            "`preemphasis_htk_flavor=false` is not currently supported."
          );
        if (Ge)
          switch (_e) {
            case "reflect": {
              const He = Math.floor((be - 1) / 2) + 1;
              W = E(W, He, He);
              break;
            }
            case "constant": {
              const He = Math.floor(be / 2), je = new W.constructor(W.length + 2 * He);
              je.set(W, He), W = je;
              break;
            }
            default:
              throw new Error(`pad_mode="${_e}" not implemented yet.`);
          }
        let H = Math.floor(1 + Math.floor((W.length - K) / pe));
        ae !== null && H < ae && (H = ae);
        const Y = De ? Math.floor(be / 2) + 1 : be;
        let $e = H, Ie = H;
        U !== null && (U > H ? Se && (Ie = U) : Ie = $e = U);
        const fe = new r.FFT(be), Qe = new Float64Array(be), Ne = new Float64Array(fe.outputBufferSize), ut = new Float32Array(Y * Ie);
        for (let He = 0; He < $e; ++He) {
          const je = He * pe, lt = Math.min(W.length - je, K);
          lt !== K && Qe.fill(0, 0, K);
          for (let Mt = 0; Mt < lt; ++Mt)
            Qe[Mt] = W[je + Mt];
          if (Be) {
            let Mt = 0;
            for (let Kt = 0; Kt < lt; ++Kt)
              Mt += Qe[Kt];
            const Rt = Mt / lt;
            for (let Kt = 0; Kt < lt; ++Kt)
              Qe[Kt] -= Rt;
          }
          if (he !== null) {
            for (let Mt = lt - 1; Mt >= 1; --Mt)
              Qe[Mt] -= he * Qe[Mt - 1];
            Qe[0] *= 1 - he;
          }
          for (let Mt = 0; Mt < te.length; ++Mt)
            Qe[Mt] *= te[Mt];
          fe.realTransform(Ne, Qe);
          for (let Mt = 0; Mt < Y; ++Mt) {
            const Rt = Mt << 1;
            ut[Mt * Ie + He] = Ne[Rt] ** 2 + Ne[Rt + 1] ** 2;
          }
        }
        if (Ee !== null && Ee !== 2) {
          const He = Ee / 2;
          for (let je = 0; je < ut.length; ++je)
            ut[je] **= He;
        }
        const de = me.length;
        let qe = await (0, u.matmul)(
          // TODO: Make `mel_filters` a Tensor during initialization
          new u.Tensor("float32", me.flat(), [de, Y]),
          new u.Tensor("float32", ut, [Y, Ie])
        );
        ze && (qe = qe.transpose(1, 0));
        const tt = (
          /** @type {Float32Array} */
          qe.data
        );
        for (let He = 0; He < tt.length; ++He)
          tt[He] = Oe + Math.max(we, tt[He]);
        if (Ee !== null && xe !== null) {
          const He = Math.min(tt.length, $e * de);
          switch (xe) {
            case "log":
              for (let je = 0; je < He; ++je)
                tt[je] = Math.log(tt[je]);
              break;
            case "log10":
              for (let je = 0; je < He; ++je)
                tt[je] = Math.log10(tt[je]);
              break;
            case "dB":
              if (Ee === 1)
                L(tt, et, Ve, nt);
              else if (Ee === 2)
                I(tt, et, Ve, nt);
              else
                throw new Error(`Cannot use log_mel option '${xe}' with power ${Ee}`);
              break;
            default:
              throw new Error(`log_mel must be one of null, 'log', 'log10' or 'dB'. Got '${xe}'`);
          }
        }
        return qe;
      }
      function N(W, te, {
        periodic: K = !0,
        frame_length: pe = null,
        center: be = !0
      } = {}) {
        const Ee = K ? W + 1 : W;
        let Ge;
        switch (te) {
          case "boxcar":
            Ge = new Float64Array(Ee).fill(1);
            break;
          case "hann":
          case "hann_window":
            Ge = h(Ee);
            break;
          case "hamming":
            Ge = p(Ee);
            break;
          case "povey":
            Ge = h(Ee).map((_e) => Math.pow(_e, 0.85));
            break;
          default:
            throw new Error(`Unknown window type ${te}.`);
        }
        if (K && (Ge = Ge.subarray(0, W)), pe === null)
          return Ge;
        if (W > pe)
          throw new Error(`Length of the window (${W}) may not be larger than frame_length (${pe})`);
        return Ge;
      }
      function q(W, te) {
        let K = 44;
        const pe = new ArrayBuffer(K + W.length * 4), be = new DataView(pe);
        ne(be, 0, "RIFF"), be.setUint32(4, 36 + W.length * 4, !0), ne(be, 8, "WAVE"), ne(be, 12, "fmt "), be.setUint32(16, 16, !0), be.setUint16(20, 3, !0), be.setUint16(22, 1, !0), be.setUint32(24, te, !0), be.setUint32(28, te * 4, !0), be.setUint16(32, 4, !0), be.setUint16(34, 32, !0), ne(be, 36, "data"), be.setUint32(40, W.length * 4, !0);
        for (let Ee = 0; Ee < W.length; ++Ee, K += 4)
          be.setFloat32(K, W[Ee], !0);
        return pe;
      }
      function ne(W, te, K) {
        for (let pe = 0; pe < K.length; ++pe)
          W.setUint8(te + pe, K.charCodeAt(pe));
      }
      class Q {
        /**
         * Create a new `RawAudio` object.
         * @param {Float32Array} audio Audio data
         * @param {number} sampling_rate Sampling rate of the audio data
         */
        constructor(te, K) {
          this.audio = te, this.sampling_rate = K;
        }
        /**
         * Convert the audio to a wav file buffer.
         * @returns {ArrayBuffer} The WAV file.
         */
        toWav() {
          return q(this.audio, this.sampling_rate);
        }
        /**
         * Convert the audio to a blob.
         * @returns {Blob}
         */
        toBlob() {
          const te = this.toWav();
          return new Blob([te], { type: "audio/wav" });
        }
        /**
         * Save the audio to a wav file.
         * @param {string} path
         */
        async save(te) {
          let K;
          if (c.apis.IS_BROWSER_ENV) {
            if (c.apis.IS_WEBWORKER_ENV)
              throw new Error("Unable to save a file from a Web Worker.");
            K = a.saveBlob;
          } else if (c.apis.IS_FS_AVAILABLE)
            K = async (pe, be) => {
              let Ee = await be.arrayBuffer();
              l.writeFileSync(pe, Buffer.from(Ee));
            };
          else
            throw new Error("Unable to save because filesystem is disabled in this environment.");
          await K(te, this.toBlob());
        }
      }
    }
  ),
  /***/
  "./src/utils/constants.js": (
    /*!********************************!*\
      !*** ./src/utils/constants.js ***!
      \********************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        CHAT_TEMPLATE_NAME: () => (
          /* binding */
          l
        ),
        /* harmony export */
        CONFIG_NAME: () => (
          /* binding */
          r
        ),
        /* harmony export */
        FEATURE_EXTRACTOR_NAME: () => (
          /* binding */
          a
        ),
        /* harmony export */
        GENERATION_CONFIG_NAME: () => (
          /* binding */
          f
        ),
        /* harmony export */
        GITHUB_ISSUE_URL: () => (
          /* binding */
          i
        ),
        /* harmony export */
        IMAGE_PROCESSOR_NAME: () => (
          /* binding */
          c
        ),
        /* harmony export */
        PROCESSOR_NAME: () => (
          /* binding */
          u
        )
        /* harmony export */
      });
      const i = "https://github.com/huggingface/transformers.js/issues/new/choose", r = "config.json", a = "preprocessor_config.json", c = a, u = "processor_config.json", l = "chat_template.jinja", f = "generation_config.json";
    }
  ),
  /***/
  "./src/utils/core.js": (
    /*!***************************!*\
      !*** ./src/utils/core.js ***!
      \***************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        calculateDimensions: () => (
          /* binding */
          f
        ),
        /* harmony export */
        calculateReflectOffset: () => (
          /* binding */
          _
        ),
        /* harmony export */
        count: () => (
          /* binding */
          w
        ),
        /* harmony export */
        dispatchCallback: () => (
          /* binding */
          i
        ),
        /* harmony export */
        escapeRegExp: () => (
          /* binding */
          a
        ),
        /* harmony export */
        isIntegralNumber: () => (
          /* binding */
          u
        ),
        /* harmony export */
        isNullishDimension: () => (
          /* binding */
          l
        ),
        /* harmony export */
        isTypedArray: () => (
          /* binding */
          c
        ),
        /* harmony export */
        len: () => (
          /* binding */
          D
        ),
        /* harmony export */
        mergeArrays: () => (
          /* binding */
          h
        ),
        /* harmony export */
        pick: () => (
          /* binding */
          S
        ),
        /* harmony export */
        pop: () => (
          /* binding */
          m
        ),
        /* harmony export */
        product: () => (
          /* binding */
          p
        ),
        /* harmony export */
        reverseDictionary: () => (
          /* binding */
          r
        ),
        /* harmony export */
        saveBlob: () => (
          /* binding */
          v
        )
        /* harmony export */
      });
      function i(T, F) {
        T && T(F);
      }
      function r(T) {
        return Object.fromEntries(Object.entries(T).map(([F, E]) => [E, F]));
      }
      function a(T) {
        return T.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
      }
      function c(T) {
        var F, E, A;
        return ((A = (E = (F = T == null ? void 0 : T.prototype) == null ? void 0 : F.__proto__) == null ? void 0 : E.constructor) == null ? void 0 : A.name) === "TypedArray";
      }
      function u(T) {
        return Number.isInteger(T) || typeof T == "bigint";
      }
      function l(T) {
        return T == null || T === -1;
      }
      function f(T) {
        const F = [];
        let E = T;
        for (; Array.isArray(E); )
          F.push(E.length), E = E[0];
        return F;
      }
      function m(T, F, E = void 0) {
        const A = T[F];
        if (A !== void 0)
          return delete T[F], A;
        if (E === void 0)
          throw Error(`Key ${F} does not exist in object.`);
        return E;
      }
      function h(...T) {
        return Array.prototype.concat.apply([], T);
      }
      function p(...T) {
        return T.reduce((F, E) => F.flatMap((A) => E.map((L) => [A, L])));
      }
      function _(T, F) {
        return Math.abs((T + F) % (2 * F) - F);
      }
      function v(T, F) {
        const E = URL.createObjectURL(F), A = document.createElement("a");
        A.href = E, A.download = T, A.click(), A.remove(), URL.revokeObjectURL(E);
      }
      function S(T, F) {
        return Object.assign(
          {},
          ...F.map((E) => {
            if (T[E] !== void 0)
              return { [E]: T[E] };
          })
        );
      }
      function D(T) {
        let F = 0;
        for (const E of T)
          ++F;
        return F;
      }
      function w(T, F) {
        let E = 0;
        for (const A of T)
          A === F && ++E;
        return E;
      }
    }
  ),
  /***/
  "./src/utils/data-structures.js": (
    /*!**************************************!*\
      !*** ./src/utils/data-structures.js ***!
      \**************************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        CharTrie: () => (
          /* binding */
          r
        ),
        /* harmony export */
        DictionarySplitter: () => (
          /* binding */
          l
        ),
        /* harmony export */
        LRUCache: () => (
          /* binding */
          f
        ),
        /* harmony export */
        PriorityQueue: () => (
          /* binding */
          i
        ),
        /* harmony export */
        TokenLattice: () => (
          /* binding */
          c
        )
        /* harmony export */
      });
      class i {
        /**
         * Create a new PriorityQueue.
         * @param {function(any, any): boolean} comparator Comparator function to determine priority. Defaults to a MaxHeap.
         */
        constructor(h = (_, v) => _ > v, p = 1 / 0) {
          this._heap = [], this._comparator = h, this._maxSize = p;
        }
        /**
         * The size of the queue
         */
        get size() {
          return this._heap.length;
        }
        /**
         * Check if the queue is empty.
         * @returns {boolean} `true` if the queue is empty, `false` otherwise.
         */
        isEmpty() {
          return this.size === 0;
        }
        /**
         * Return the element with the highest priority in the queue.
         * @returns {any} The highest priority element in the queue.
         */
        peek() {
          return this._heap[0];
        }
        /**
         * Add one or more elements to the queue.
         * @param  {...any} values The values to push into the queue.
         * @returns {number} The new size of the queue.
         */
        push(...h) {
          return this.extend(h);
        }
        /**
         * Add multiple elements to the queue.
         * @param {any[]} values The values to push into the queue.
         * @returns {number} The new size of the queue.
         */
        extend(h) {
          for (const p of h)
            if (this.size < this._maxSize)
              this._heap.push(p), this._siftUp();
            else {
              const _ = this._smallest();
              this._comparator(p, this._heap[_]) && (this._heap[_] = p, this._siftUpFrom(_));
            }
          return this.size;
        }
        /**
         * Remove and return the element with the highest priority in the queue.
         * @returns {any} The element with the highest priority in the queue.
         */
        pop() {
          const h = this.peek(), p = this.size - 1;
          return p > 0 && this._swap(0, p), this._heap.pop(), this._siftDown(), h;
        }
        /**
         * Replace the element with the highest priority in the queue with a new value.
         * @param {*} value The new value.
         * @returns {*} The replaced value.
         */
        replace(h) {
          const p = this.peek();
          return this._heap[0] = h, this._siftDown(), p;
        }
        /**
         * Compute the index for the parent of the node at index `i`.
         * @param {number} i The index of the node to get the parent of.
         * @returns {number} The index of the parent node.
         * @private
         */
        _parent(h) {
          return (h + 1 >>> 1) - 1;
        }
        /**
         * Compute the index for the left child of the node at index `i`.
         * @param {number} i The index of the node to get the left child of.
         * @returns {number} The index of the left child.
         * @private
         */
        _left(h) {
          return (h << 1) + 1;
        }
        /**
         * Compute the index for the right child of the node at index `i`.
         * @param {number} i The index of the node to get the right child of.
         * @returns {number} The index of the right child.
         * @private
         */
        _right(h) {
          return h + 1 << 1;
        }
        /**
         * Check if the element at index `i` is greater than the element at index `j`.
         * @param {number} i The index of the first element to compare.
         * @param {number} j The index of the second element to compare.
         * @returns {boolean} `true` if the element at index `i` is greater than the element at index `j`, `false` otherwise.
         * @private
         */
        _greater(h, p) {
          return this._comparator(this._heap[h], this._heap[p]);
        }
        /**
         * Swap the elements at indices `i` and `j`.
         * @param {number} i The index of the first element to swap.
         * @param {number} j The index of the second element to swap.
         * @private
         */
        _swap(h, p) {
          const _ = this._heap[h];
          this._heap[h] = this._heap[p], this._heap[p] = _;
        }
        /**
         * Maintain the heap property by updating positions in the heap,
         * starting at the last element and moving up the heap.
         * @private
         */
        _siftUp() {
          this._siftUpFrom(this.size - 1);
        }
        /**
         * Helper function to sift up from a given node.
         * @param {number} node The index of the node to start sifting up from.
         */
        _siftUpFrom(h) {
          for (; h > 0 && this._greater(h, this._parent(h)); )
            this._swap(h, this._parent(h)), h = this._parent(h);
        }
        /**
         * Maintain the heap property by updating positions in the heap,
         * starting at the first element and moving down the heap.
         * @private
         */
        _siftDown() {
          let h = 0;
          for (; this._left(h) < this.size && this._greater(this._left(h), h) || this._right(h) < this.size && this._greater(this._right(h), h); ) {
            const p = this._right(h) < this.size && this._greater(this._right(h), this._left(h)) ? this._right(h) : this._left(h);
            this._swap(h, p), h = p;
          }
        }
        /**
         * Get the index of the smallest element in the heap. Since we use an array-based heap,
         * the index can be computed without needing to traverse the heap.
         * @private
         */
        _smallest() {
          return 2 ** Math.floor(Math.log2(this.size)) - 1;
        }
      }
      class r {
        constructor() {
          this.root = a.default();
        }
        /**
         * Adds one or more `texts` to the trie.
         * @param {string[]} texts The strings to add to the trie.
         */
        extend(h) {
          for (const p of h)
            this.push(p);
        }
        /**
         * Adds text to the trie.
         * @param {string} text The string to add to the trie.
         */
        push(h) {
          let p = this.root;
          for (const _ of h) {
            let v = p.children.get(_);
            v === void 0 && (v = a.default(), p.children.set(_, v)), p = v;
          }
          p.isLeaf = !0;
        }
        /**
         * Searches the trie for all strings with a common prefix of `text`.
         * @param {string} text The common prefix to search for.
         * @yields {string} Each string in the trie that has `text` as a prefix.
         */
        *commonPrefixSearch(h) {
          let p = this.root;
          if (p === void 0)
            return;
          let _ = "";
          for (const v of h) {
            if (_ += v, p = p.children.get(v), p === void 0)
              return;
            p.isLeaf && (yield _);
          }
        }
      }
      class a {
        /**
         * Create a new CharTrieNode.
         * @param {boolean} isLeaf Whether the node is a leaf node or not.
         * @param {Map<string, CharTrieNode>} children A map containing the node's children, where the key is a character and the value is a `CharTrieNode`.
         */
        constructor(h, p) {
          this.isLeaf = h, this.children = p;
        }
        /**
         * Returns a new `CharTrieNode` instance with default values.
         * @returns {CharTrieNode} A new `CharTrieNode` instance with `isLeaf` set to `false` and an empty `children` map.
         */
        static default() {
          return new a(!1, /* @__PURE__ */ new Map());
        }
      }
      class c {
        /**
         * Creates a new TokenLattice instance.
         *
         * @param {string} sentence The input sentence to be tokenized.
         * @param {number} bosTokenId The beginning-of-sequence token ID.
         * @param {number} eosTokenId The end-of-sequence token ID.
         */
        constructor(h, p, _) {
          this.chars = Array.from(h), this.len = this.chars.length, this.bosTokenId = p, this.eosTokenId = _, this.nodes = [], this.beginNodes = Array.from({ length: this.len + 1 }, () => []), this.endNodes = Array.from({ length: this.len + 1 }, () => []);
          const v = new u(this.bosTokenId, 0, 0, 0, 0), S = new u(this.eosTokenId, 1, this.len, 0, 0);
          this.nodes.push(v.clone()), this.nodes.push(S.clone()), this.beginNodes[this.len].push(S), this.endNodes[0].push(v);
        }
        /**
         * Inserts a new token node into the token lattice.
         *
         * @param {number} pos The starting position of the token.
         * @param {number} length The length of the token.
         * @param {number} score The score of the token.
         * @param {number} tokenId The token ID of the token.
         */
        insert(h, p, _, v) {
          const S = this.nodes.length, D = new u(v, S, h, p, _);
          this.beginNodes[h].push(D), this.endNodes[h + p].push(D), this.nodes.push(D);
        }
        /**
         * Implements the Viterbi algorithm to compute the most likely sequence of tokens.
         *
         * @returns {TokenLatticeNode[]} The most likely sequence of tokens.
         */
        viterbi() {
          const h = this.len;
          let p = 0;
          for (; p <= h; ) {
            if (this.beginNodes[p].length == 0)
              return [];
            for (let w of this.beginNodes[p]) {
              w.prev = null;
              let T = 0, F = null;
              for (let E of this.endNodes[p]) {
                const A = E.backtraceScore + w.score;
                (F === null || A > T) && (F = E.clone(), T = A);
              }
              if (F !== null)
                w.prev = F, w.backtraceScore = T;
              else
                return [];
            }
            ++p;
          }
          const _ = [], S = this.beginNodes[h][0].prev;
          if (S === null)
            return [];
          let D = S.clone();
          for (; D.prev !== null; )
            _.push(D.clone()), D = D.clone().prev.clone();
          return _.reverse(), _;
        }
        /**
         * @param {TokenLatticeNode} node
         * @returns {string} The array of nodes representing the most likely sequence of tokens.
         */
        piece(h) {
          return this.chars.slice(h.pos, h.pos + h.length).join("");
        }
        /**
         * @returns {string[]} The most likely sequence of tokens.
         */
        tokens() {
          return this.viterbi().map((p) => this.piece(p));
        }
        /**
         * @returns {number[]} The most likely sequence of token ids.
         */
        tokenIds() {
          return this.viterbi().map((p) => p.tokenId);
        }
      }
      class u {
        /**
         * Represents a node in a token lattice for a given sentence.
         * @param {number} tokenId The ID of the token associated with this node.
         * @param {number} nodeId The ID of this node.
         * @param {number} pos The starting position of the token in the sentence.
         * @param {number} length The length of the token.
         * @param {number} score The score associated with the token.
         */
        constructor(h, p, _, v, S) {
          this.tokenId = h, this.nodeId = p, this.pos = _, this.length = v, this.score = S, this.prev = null, this.backtraceScore = 0;
        }
        /**
         * Returns a clone of this node.
         * @returns {TokenLatticeNode} A clone of this node.
         */
        clone() {
          const h = new u(this.tokenId, this.nodeId, this.pos, this.length, this.score);
          return h.prev = this.prev, h.backtraceScore = this.backtraceScore, h;
        }
      }
      class l {
        /**
         * @param {string[]} dictionary The dictionary of words to use for splitting.
         */
        constructor(h) {
          this.trie = this._buildTrie(h);
        }
        /**
         * Builds a trie from the given dictionary.
         * @param {string[]} dictionary The dictionary of words to build the trie from.
         * @returns {Object} The root node of the trie.
         * @private
         */
        _buildTrie(h) {
          var _;
          const p = /* @__PURE__ */ Object.create(null);
          for (const v of h) {
            let S = p;
            for (let D = 0; D < v.length; ++D)
              S = S[_ = v[D]] ?? (S[_] = /* @__PURE__ */ Object.create(null));
            S.end = v;
          }
          return p;
        }
        /**
         * Splits the input text into tokens based on the dictionary.
         * @param {string} text The input text to split.
         * @returns {string[]} An array of tokens.
         */
        split(h) {
          const p = [], _ = h.length;
          let v = 0, S = 0;
          for (; S < _; ) {
            let D = this.trie, w = null, T = S;
            for (; T < _ && (D = D[h[T]]); )
              D.end && (w = D.end), ++T;
            w ? (S > v && p.push(h.slice(v, S)), p.push(w), S += w.length, v = S) : ++S;
          }
          return v < _ && p.push(h.slice(v)), p;
        }
      }
      class f {
        /**
         * Creates an LRUCache instance.
         * @param {number} capacity The maximum number of items the cache can hold.
         */
        constructor(h) {
          this.capacity = h, this.cache = /* @__PURE__ */ new Map();
        }
        /**
         * Retrieves the value associated with the given key and marks the key as recently used.
         * @param {any} key The key to retrieve.
         * @returns {any} The value associated with the key, or undefined if the key does not exist.
         */
        get(h) {
          if (!this.cache.has(h))
            return;
          const p = this.cache.get(h);
          return this.cache.delete(h), this.cache.set(h, p), p;
        }
        /**
         * Inserts or updates the key-value pair in the cache.
         * If the key already exists, it is updated and marked as recently used.
         * If the cache exceeds its capacity, the least recently used item is evicted.
         * @param {any} key The key to add or update.
         * @param {any} value The value to associate with the key.
         */
        put(h, p) {
          this.cache.has(h) && this.cache.delete(h), this.cache.set(h, p), this.cache.size > this.capacity && this.cache.delete(this.cache.keys().next().value);
        }
        /**
         * Clears the cache.
         */
        clear() {
          this.cache.clear();
        }
      }
    }
  ),
  /***/
  "./src/utils/devices.js": (
    /*!******************************!*\
      !*** ./src/utils/devices.js ***!
      \******************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DEVICE_TYPES: () => (
          /* binding */
          i
        )
        /* harmony export */
      });
      const i = Object.freeze({
        auto: "auto",
        // Auto-detect based on device and environment
        gpu: "gpu",
        // Auto-detect GPU
        cpu: "cpu",
        // CPU
        wasm: "wasm",
        // WebAssembly
        webgpu: "webgpu",
        // WebGPU
        cuda: "cuda",
        // CUDA
        dml: "dml",
        // DirectML
        webnn: "webnn",
        // WebNN (default)
        "webnn-npu": "webnn-npu",
        // WebNN NPU
        "webnn-gpu": "webnn-gpu",
        // WebNN GPU
        "webnn-cpu": "webnn-cpu"
        // WebNN CPU
      });
    }
  ),
  /***/
  "./src/utils/dtypes.js": (
    /*!*****************************!*\
      !*** ./src/utils/dtypes.js ***!
      \*****************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DATA_TYPES: () => (
          /* binding */
          c
        ),
        /* harmony export */
        DEFAULT_DEVICE_DTYPE_MAPPING: () => (
          /* binding */
          u
        ),
        /* harmony export */
        DEFAULT_DTYPE_SUFFIX_MAPPING: () => (
          /* binding */
          l
        ),
        /* harmony export */
        isWebGpuFp16Supported: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      var i = t(
        /*! ../env.js */
        "./src/env.js"
      ), r = t(
        /*! ./devices.js */
        "./src/utils/devices.js"
      );
      const a = function() {
        let f;
        return async function() {
          if (f === void 0)
            if (!i.apis.IS_WEBGPU_AVAILABLE)
              f = !1;
            else
              try {
                f = (await navigator.gpu.requestAdapter()).features.has("shader-f16");
              } catch {
                f = !1;
              }
          return f;
        };
      }(), c = Object.freeze({
        auto: "auto",
        // Auto-detect based on environment
        fp32: "fp32",
        fp16: "fp16",
        q8: "q8",
        int8: "int8",
        uint8: "uint8",
        q4: "q4",
        bnb4: "bnb4",
        q4f16: "q4f16"
        // fp16 model with int4 block weight quantization
      }), u = Object.freeze({
        // NOTE: If not specified, will default to fp32
        [r.DEVICE_TYPES.wasm]: c.q8
      }), l = Object.freeze({
        [c.fp32]: "",
        [c.fp16]: "_fp16",
        [c.int8]: "_int8",
        [c.uint8]: "_uint8",
        [c.q8]: "_quantized",
        [c.q4]: "_q4",
        [c.q4f16]: "_q4f16",
        [c.bnb4]: "_bnb4"
      });
    }
  ),
  /***/
  "./src/utils/generic.js": (
    /*!******************************!*\
      !*** ./src/utils/generic.js ***!
      \******************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        Callable: () => (
          /* binding */
          i
        )
        /* harmony export */
      });
      const i = (
        /** @type {any} */
        class {
          /**
          * Creates a new instance of the Callable class.
          */
          constructor() {
            let r = function(...a) {
              return r._call(...a);
            };
            return Object.setPrototypeOf(r, new.target.prototype);
          }
          /**
           * This method should be implemented in subclasses to provide the
           * functionality of the callable object.
           *
           * @param {any[]} args
           * @throws {Error} If the subclass does not implement the `_call` method.
           */
          _call(...r) {
            throw Error("Must implement _call method in subclass");
          }
        }
      );
    }
  ),
  /***/
  "./src/utils/hub.js": (
    /*!**************************!*\
      !*** ./src/utils/hub.js ***!
      \**************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        MAX_EXTERNAL_DATA_CHUNKS: () => (
          /* binding */
          u
        ),
        /* harmony export */
        getFile: () => (
          /* binding */
          _
        ),
        /* harmony export */
        getModelFile: () => (
          /* binding */
          T
        ),
        /* harmony export */
        getModelJSON: () => (
          /* binding */
          E
        ),
        /* harmony export */
        getModelText: () => (
          /* binding */
          F
        )
        /* harmony export */
      });
      var i = t(
        /*! node:fs */
        "?7992"
      ), r = t(
        /*! node:path */
        "?5af5"
      ), a = t(
        /*! ../env.js */
        "./src/env.js"
      ), c = t(
        /*! ./core.js */
        "./src/utils/core.js"
      );
      const u = 100, l = {
        txt: "text/plain",
        html: "text/html",
        css: "text/css",
        js: "text/javascript",
        json: "application/json",
        png: "image/png",
        jpg: "image/jpeg",
        jpeg: "image/jpeg",
        gif: "image/gif"
      };
      class f {
        /**
         * Creates a new `FileResponse` object.
         * @param {string} filePath
         */
        constructor(R) {
          if (this.filePath = R, this.headers = new Headers(), this.exists = i.existsSync(R), this.exists) {
            this.status = 200, this.statusText = "OK";
            let N = i.statSync(R);
            this.headers.set("content-length", N.size.toString()), this.updateContentType();
            const q = i.createReadStream(R);
            this.body = new ReadableStream({
              start(ne) {
                q.on("data", (Q) => ne.enqueue(Q)), q.on("end", () => ne.close()), q.on("error", (Q) => ne.error(Q));
              },
              cancel() {
                q.destroy();
              }
            });
          } else
            this.status = 404, this.statusText = "Not Found", this.body = null;
        }
        /**
         * Updates the 'content-type' header property of the response based on the extension of
         * the file specified by the filePath property of the current object.
         * @returns {void}
         */
        updateContentType() {
          const R = this.filePath.toString().split(".").pop().toLowerCase();
          this.headers.set("content-type", l[R] ?? "application/octet-stream");
        }
        /**
         * Clone the current FileResponse object.
         * @returns {FileResponse} A new FileResponse object with the same properties as the current object.
         */
        clone() {
          let R = new f(this.filePath);
          return R.exists = this.exists, R.status = this.status, R.statusText = this.statusText, R.headers = new Headers(this.headers), R;
        }
        /**
         * Reads the contents of the file specified by the filePath property and returns a Promise that
         * resolves with an ArrayBuffer containing the file's contents.
         * @returns {Promise<ArrayBuffer>} A Promise that resolves with an ArrayBuffer containing the file's contents.
         * @throws {Error} If the file cannot be read.
         */
        async arrayBuffer() {
          return (
            /** @type {ArrayBuffer} */
            (await i.promises.readFile(this.filePath)).buffer
          );
        }
        /**
         * Reads the contents of the file specified by the filePath property and returns a Promise that
         * resolves with a Blob containing the file's contents.
         * @returns {Promise<Blob>} A Promise that resolves with a Blob containing the file's contents.
         * @throws {Error} If the file cannot be read.
         */
        async blob() {
          const R = await i.promises.readFile(this.filePath);
          return new Blob([R], { type: this.headers.get("content-type") });
        }
        /**
         * Reads the contents of the file specified by the filePath property and returns a Promise that
         * resolves with a string containing the file's contents.
         * @returns {Promise<string>} A Promise that resolves with a string containing the file's contents.
         * @throws {Error} If the file cannot be read.
         */
        async text() {
          return await i.promises.readFile(this.filePath, "utf8");
        }
        /**
         * Reads the contents of the file specified by the filePath property and returns a Promise that
         * resolves with a parsed JavaScript object containing the file's contents.
         *
         * @returns {Promise<Object>} A Promise that resolves with a parsed JavaScript object containing the file's contents.
         * @throws {Error} If the file cannot be read.
         */
        async json() {
          return JSON.parse(await this.text());
        }
      }
      function m(I, R = null, N = null) {
        let q;
        try {
          q = new URL(I);
        } catch {
          return !1;
        }
        return !(R && !R.includes(q.protocol) || N && !N.includes(q.hostname));
      }
      const h = /^(\b[\w\-.]+\b\/)?\b[\w\-.]{1,96}\b$/;
      function p(I) {
        return !(!h.test(I) || I.includes("..") || I.includes("--") || I.endsWith(".git") || I.endsWith(".ipynb"));
      }
      async function _(I) {
        var R, N, q, ne;
        if (a.env.useFS && !m(I, ["http:", "https:", "blob:"]))
          return new f(
            I instanceof URL ? I.protocol === "file:" ? I.pathname : I.toString() : I
          );
        if (typeof process < "u" && ((R = process == null ? void 0 : process.release) == null ? void 0 : R.name) === "node") {
          const Q = !!((N = process.env) != null && N.TESTING_REMOTELY), W = a.env.version, te = new Headers();
          if (te.set("User-Agent", `transformers.js/${W}; is_ci/${Q};`), m(I, ["http:", "https:"], ["huggingface.co", "hf.co"])) {
            const pe = ((q = process.env) == null ? void 0 : q.HF_TOKEN) ?? ((ne = process.env) == null ? void 0 : ne.HF_ACCESS_TOKEN);
            pe && te.set("Authorization", `Bearer ${pe}`);
          }
          return fetch(I, { headers: te });
        } else
          return fetch(I);
      }
      const v = {
        // 4xx errors (https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#client_error_responses)
        400: "Bad request error occurred while trying to load file",
        401: "Unauthorized access to file",
        403: "Forbidden access to file",
        404: "Could not locate file",
        408: "Request timeout error occurred while trying to load file",
        // 5xx errors (https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses)
        500: "Internal server error error occurred while trying to load file",
        502: "Bad gateway error occurred while trying to load file",
        503: "Service unavailable error occurred while trying to load file",
        504: "Gateway timeout error occurred while trying to load file"
      };
      function S(I, R, N) {
        if (!N)
          return null;
        const q = v[I] ?? `Error (${I}) occurred while trying to load file`;
        throw Error(`${q}: "${R}".`);
      }
      class D {
        /**
         * Instantiate a `FileCache` object.
         * @param {string} path
         */
        constructor(R) {
          this.path = R;
        }
        /**
         * Checks whether the given request is in the cache.
         * @param {string} request
         * @returns {Promise<FileResponse | undefined>}
         */
        async match(R) {
          let N = r.join(this.path, R), q = new f(N);
          if (q.exists)
            return q;
        }
        /**
         * Adds the given response to the cache.
         * @param {string} request
         * @param {Response} response
         * @param {(data: {progress: number, loaded: number, total: number}) => void} [progress_callback] Optional.
         * The function to call with progress updates
         * @returns {Promise<void>}
         */
        async put(R, N, q = void 0) {
          let ne = r.join(this.path, R);
          try {
            const Q = N.headers.get("Content-Length"), W = parseInt(Q ?? "0");
            let te = 0;
            await i.promises.mkdir(r.dirname(ne), { recursive: !0 });
            const K = i.createWriteStream(ne), pe = N.body.getReader();
            for (; ; ) {
              const { done: be, value: Ee } = await pe.read();
              if (be)
                break;
              await new Promise((_e, De) => {
                K.write(Ee, (he) => {
                  if (he) {
                    De(he);
                    return;
                  }
                  _e();
                });
              }), te += Ee.length;
              const Ge = W ? te / W * 100 : 0;
              q == null || q({ progress: Ge, loaded: te, total: W });
            }
            K.close();
          } catch (Q) {
            try {
              await i.promises.unlink(ne);
            } catch {
            }
            throw Q;
          }
        }
        // TODO add the rest?
        // addAll(requests: RequestInfo[]): Promise<void>;
        // delete(request: RequestInfo | URL, options?: CacheQueryOptions): Promise<boolean>;
        // keys(request?: RequestInfo | URL, options?: CacheQueryOptions): Promise<ReadonlyArray<Request>>;
        // match(request: RequestInfo | URL, options?: CacheQueryOptions): Promise<Response | undefined>;
        // matchAll(request?: RequestInfo | URL, options?: CacheQueryOptions): Promise<ReadonlyArray<Response>>;
      }
      async function w(I, ...R) {
        for (let N of R)
          try {
            let q = await I.match(N);
            if (q)
              return q;
          } catch {
            continue;
          }
      }
      async function T(I, R, N = !0, q = {}, ne = !1) {
        if (!a.env.allowLocalModels) {
          if (q.local_files_only)
            throw Error("Invalid configuration detected: local models are disabled (`env.allowLocalModels=false`) but you have requested to only use local models (`local_files_only=true`).");
          if (!a.env.allowRemoteModels)
            throw Error("Invalid configuration detected: both local and remote models are disabled. Fix by setting `env.allowLocalModels` or `env.allowRemoteModels` to `true`.");
        }
        (0, c.dispatchCallback)(q.progress_callback, {
          status: "initiate",
          name: I,
          file: R
        });
        let Q;
        if (!Q && a.env.useCustomCache) {
          if (!a.env.customCache)
            throw Error("`env.useCustomCache=true`, but `env.customCache` is not defined.");
          if (!a.env.customCache.match || !a.env.customCache.put)
            throw new Error(
              "`env.customCache` must be an object which implements the `match` and `put` functions of the Web Cache API. For more information, see https://developer.mozilla.org/en-US/docs/Web/API/Cache"
            );
          Q = a.env.customCache;
        }
        if (!Q && a.env.useBrowserCache) {
          if (typeof caches > "u")
            throw Error("Browser cache is not available in this environment.");
          try {
            Q = await caches.open("transformers-cache");
          } catch (we) {
            console.warn("An error occurred while opening the browser cache:", we);
          }
        }
        if (!Q && a.env.useFSCache) {
          if (!a.apis.IS_FS_AVAILABLE)
            throw Error("File System Cache is not available in this environment.");
          Q = new D(q.cache_dir ?? a.env.cacheDir);
        }
        const W = q.revision ?? "main", te = L(I, R), K = p(I), pe = K ? L(a.env.localModelPath, te) : te, be = L(
          a.env.remoteHost,
          a.env.remotePathTemplate.replaceAll("{model}", I).replaceAll("{revision}", encodeURIComponent(W)),
          R
        );
        let Ee;
        const Ge = Q instanceof D ? W === "main" ? te : L(I, W, R) : be;
        let _e = !1, De;
        Q && (De = await w(Q, pe, Ge));
        const he = De !== void 0;
        if (De === void 0) {
          if (a.env.allowLocalModels)
            if (m(te, ["http:", "https:"])) {
              if (q.local_files_only)
                throw new Error(`\`local_files_only=true\`, but attempted to load a remote file from: ${te}.`);
              if (!a.env.allowRemoteModels)
                throw new Error(`\`env.allowRemoteModels=false\`, but attempted to load a remote file from: ${te}.`);
            } else
              try {
                De = await _(pe), Ee = pe;
              } catch (xe) {
                console.warn(`Unable to load from local path "${pe}": "${xe}"`);
              }
          if (De === void 0 || De.status === 404) {
            if (q.local_files_only || !a.env.allowRemoteModels) {
              if (N)
                throw Error(`\`local_files_only=true\` or \`env.allowRemoteModels=false\` and file was not found locally at "${pe}".`);
              return null;
            }
            if (!K)
              throw Error(`Local file missing at "${pe}" and download aborted due to invalid model ID "${I}".`);
            if (De = await _(be), De.status !== 200)
              return S(De.status, be, N);
            Ee = Ge;
          }
          _e = Q && typeof Response < "u" && De instanceof Response && De.status === 200;
        }
        (0, c.dispatchCallback)(q.progress_callback, {
          status: "download",
          name: I,
          file: R
        });
        let Z;
        if (!(a.apis.IS_NODE_ENV && ne)) {
          let we;
          q.progress_callback ? he && typeof navigator < "u" && /firefox/i.test(navigator.userAgent) ? (we = new Uint8Array(await De.arrayBuffer()), (0, c.dispatchCallback)(q.progress_callback, {
            status: "progress",
            name: I,
            file: R,
            progress: 100,
            loaded: we.length,
            total: we.length
          })) : we = await A(De, (xe) => {
            (0, c.dispatchCallback)(q.progress_callback, {
              status: "progress",
              name: I,
              file: R,
              ...xe
            });
          }) : we = new Uint8Array(await De.arrayBuffer()), Z = we;
        }
        if (
          // Only cache web responses
          // i.e., do not cache FileResponses (prevents duplication)
          _e && Ee && // Check again whether request is in cache. If not, we add the response to the cache
          await Q.match(Ee) === void 0
        )
          if (Z)
            await Q.put(Ee, new Response(Z, {
              headers: De.headers
            })).catch((we) => {
              console.warn(`Unable to add response to browser cache: ${we}.`);
            });
          else {
            const we = q.progress_callback ? (xe) => (0, c.dispatchCallback)(q.progress_callback, {
              status: "progress",
              name: I,
              file: R,
              ...xe
            }) : void 0;
            await Q.put(
              Ee,
              /** @type {Response} */
              De,
              we
            );
          }
        if ((0, c.dispatchCallback)(q.progress_callback, {
          status: "done",
          name: I,
          file: R
        }), Z) {
          if (!a.apis.IS_NODE_ENV && ne)
            throw new Error("Cannot return path in a browser environment.");
          return Z;
        }
        if (De instanceof f)
          return De.filePath;
        const me = await (Q == null ? void 0 : Q.match(Ee));
        if (me instanceof f)
          return me.filePath;
        if (me instanceof Response)
          return new Uint8Array(await me.arrayBuffer());
        if (typeof me == "string")
          return me;
        throw new Error("Unable to get model file path or buffer.");
      }
      async function F(I, R, N = !0, q = {}) {
        const ne = await T(I, R, N, q, !1);
        return ne === null ? null : new TextDecoder("utf-8").decode(
          /** @type {Uint8Array} */
          ne
        );
      }
      async function E(I, R, N = !0, q = {}) {
        const ne = await F(I, R, N, q);
        return ne === null ? {} : JSON.parse(ne);
      }
      async function A(I, R) {
        const N = I.headers.get("Content-Length");
        N === null && console.warn("Unable to determine content-length from response headers. Will expand buffer when needed.");
        let q = parseInt(N ?? "0"), ne = new Uint8Array(q), Q = 0;
        const W = I.body.getReader();
        async function te() {
          const { done: K, value: pe } = await W.read();
          if (K)
            return;
          const be = Q + pe.length;
          if (be > q) {
            q = be;
            const Ge = new Uint8Array(q);
            Ge.set(ne), ne = Ge;
          }
          ne.set(pe, Q), Q = be;
          const Ee = Q / q * 100;
          return R({ progress: Ee, loaded: Q, total: q }), te();
        }
        return await te(), ne;
      }
      function L(...I) {
        return I = I.map((R, N) => (N && (R = R.replace(new RegExp("^/"), "")), N !== I.length - 1 && (R = R.replace(new RegExp("/$"), "")), R)), I.join("/");
      }
    }
  ),
  /***/
  "./src/utils/image.js": (
    /*!****************************!*\
      !*** ./src/utils/image.js ***!
      \****************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        RawImage: () => (
          /* binding */
          v
        ),
        /* harmony export */
        load_image: () => (
          /* binding */
          S
        )
        /* harmony export */
      });
      var i = t(
        /*! ./core.js */
        "./src/utils/core.js"
      ), r = t(
        /*! ./hub.js */
        "./src/utils/hub.js"
      ), a = t(
        /*! ../env.js */
        "./src/env.js"
      ), c = t(
        /*! ./tensor.js */
        "./src/utils/tensor.js"
      ), u = t(
        /*! sharp */
        "?2b25"
      );
      let l, f, m;
      const h = a.apis.IS_BROWSER_ENV || a.apis.IS_WEBWORKER_ENV;
      if (h)
        l = (D, w) => {
          if (!self.OffscreenCanvas)
            throw new Error("OffscreenCanvas not supported by this browser.");
          return new self.OffscreenCanvas(D, w);
        }, m = self.createImageBitmap, f = self.ImageData;
      else if (u)
        m = async (D) => {
          const T = (await D.metadata()).channels, { data: F, info: E } = await D.rotate().raw().toBuffer({ resolveWithObject: !0 }), A = new v(new Uint8ClampedArray(F), E.width, E.height, E.channels);
          return T !== void 0 && T !== E.channels && A.convert(T), A;
        };
      else
        throw new Error("Unable to load image processing library.");
      const p = {
        0: "nearest",
        1: "lanczos",
        2: "bilinear",
        3: "bicubic",
        4: "box",
        5: "hamming"
      }, _ = /* @__PURE__ */ new Map([
        ["png", "image/png"],
        ["jpg", "image/jpeg"],
        ["jpeg", "image/jpeg"],
        ["gif", "image/gif"]
      ]);
      class v {
        /**
         * Create a new `RawImage` object.
         * @param {Uint8ClampedArray|Uint8Array} data The pixel data.
         * @param {number} width The width of the image.
         * @param {number} height The height of the image.
         * @param {1|2|3|4} channels The number of channels.
         */
        constructor(w, T, F, E) {
          this.data = w, this.width = T, this.height = F, this.channels = E;
        }
        /**
         * Returns the size of the image (width, height).
         * @returns {[number, number]} The size of the image (width, height).
         */
        get size() {
          return [this.width, this.height];
        }
        /**
         * Helper method for reading an image from a variety of input types.
         * @param {RawImage|string|URL|Blob|HTMLCanvasElement|OffscreenCanvas} input
         * @returns The image object.
         *
         * **Example:** Read image from a URL.
         * ```javascript
         * let image = await RawImage.read('https://huggingface.co/datasets/Xenova/transformers.js-docs/resolve/main/football-match.jpg');
         * // RawImage {
         * //   "data": Uint8ClampedArray [ 25, 25, 25, 19, 19, 19, ... ],
         * //   "width": 800,
         * //   "height": 533,
         * //   "channels": 3
         * // }
         * ```
         */
        static async read(w) {
          if (w instanceof v)
            return w;
          if (typeof w == "string" || w instanceof URL)
            return await this.fromURL(w);
          if (w instanceof Blob)
            return await this.fromBlob(w);
          if (typeof HTMLCanvasElement < "u" && w instanceof HTMLCanvasElement || typeof OffscreenCanvas < "u" && w instanceof OffscreenCanvas)
            return this.fromCanvas(w);
          throw new Error(`Unsupported input type: ${typeof w}`);
        }
        /**
         * Read an image from a canvas.
         * @param {HTMLCanvasElement|OffscreenCanvas} canvas The canvas to read the image from.
         * @returns {RawImage} The image object.
         */
        static fromCanvas(w) {
          if (!h)
            throw new Error("fromCanvas() is only supported in browser environments.");
          const F = /** @type {CanvasRenderingContext2D | OffscreenCanvasRenderingContext2D} */ w.getContext("2d").getImageData(0, 0, w.width, w.height).data;
          return new v(F, w.width, w.height, 4);
        }
        /**
         * Read an image from a URL or file path.
         * @param {string|URL} url The URL or file path to read the image from.
         * @returns {Promise<RawImage>} The image object.
         */
        static async fromURL(w) {
          const T = await (0, r.getFile)(w);
          if (T.status !== 200)
            throw new Error(`Unable to read image from "${w}" (${T.status} ${T.statusText})`);
          const F = await T.blob();
          return this.fromBlob(F);
        }
        /**
         * Helper method to create a new Image from a blob.
         * @param {Blob} blob The blob to read the image from.
         * @returns {Promise<RawImage>} The image object.
         */
        static async fromBlob(w) {
          if (h) {
            const T = await m(w), F = l(T.width, T.height).getContext("2d");
            return F.drawImage(T, 0, 0), new this(F.getImageData(0, 0, T.width, T.height).data, T.width, T.height, 4);
          } else {
            const T = u(await w.arrayBuffer());
            return await m(T);
          }
        }
        /**
         * Helper method to create a new Image from a tensor
         * @param {Tensor} tensor
         */
        static fromTensor(w, T = "CHW") {
          if (w.dims.length !== 3)
            throw new Error(`Tensor should have 3 dimensions, but has ${w.dims.length} dimensions.`);
          if (T === "CHW")
            w = w.transpose(1, 2, 0);
          else if (T !== "HWC")
            throw new Error(`Unsupported channel format: ${T}`);
          if (!(w.data instanceof Uint8ClampedArray || w.data instanceof Uint8Array))
            throw new Error(`Unsupported tensor type: ${w.type}`);
          switch (w.dims[2]) {
            case 1:
            case 2:
            case 3:
            case 4:
              return new v(w.data, w.dims[1], w.dims[0], w.dims[2]);
            default:
              throw new Error(`Unsupported number of channels: ${w.dims[2]}`);
          }
        }
        /**
         * Convert the image to grayscale format.
         * @returns {RawImage} `this` to support chaining.
         */
        grayscale() {
          if (this.channels === 1)
            return this;
          const w = new Uint8ClampedArray(this.width * this.height * 1);
          switch (this.channels) {
            case 3:
            case 4:
              for (let T = 0, F = 0; T < this.data.length; T += this.channels) {
                const E = this.data[T], A = this.data[T + 1], L = this.data[T + 2];
                w[F++] = Math.round(0.2989 * E + 0.587 * A + 0.114 * L);
              }
              break;
            default:
              throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
          }
          return this._update(w, this.width, this.height, 1);
        }
        /**
         * Convert the image to RGB format.
         * @returns {RawImage} `this` to support chaining.
         */
        rgb() {
          if (this.channels === 3)
            return this;
          const w = new Uint8ClampedArray(this.width * this.height * 3);
          switch (this.channels) {
            case 1:
              for (let T = 0, F = 0; T < this.data.length; ++T)
                w[F++] = this.data[T], w[F++] = this.data[T], w[F++] = this.data[T];
              break;
            case 4:
              for (let T = 0, F = 0; T < this.data.length; T += 4)
                w[F++] = this.data[T], w[F++] = this.data[T + 1], w[F++] = this.data[T + 2];
              break;
            default:
              throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
          }
          return this._update(w, this.width, this.height, 3);
        }
        /**
         * Convert the image to RGBA format.
         * @returns {RawImage} `this` to support chaining.
         */
        rgba() {
          if (this.channels === 4)
            return this;
          const w = new Uint8ClampedArray(this.width * this.height * 4);
          switch (this.channels) {
            case 1:
              for (let T = 0, F = 0; T < this.data.length; ++T)
                w[F++] = this.data[T], w[F++] = this.data[T], w[F++] = this.data[T], w[F++] = 255;
              break;
            case 3:
              for (let T = 0, F = 0; T < this.data.length; T += 3)
                w[F++] = this.data[T], w[F++] = this.data[T + 1], w[F++] = this.data[T + 2], w[F++] = 255;
              break;
            default:
              throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
          }
          return this._update(w, this.width, this.height, 4);
        }
        /**
         * Apply an alpha mask to the image. Operates in place.
         * @param {RawImage} mask The mask to apply. It should have a single channel.
         * @returns {RawImage} The masked image.
         * @throws {Error} If the mask is not the same size as the image.
         * @throws {Error} If the image does not have 4 channels.
         * @throws {Error} If the mask is not a single channel.
         */
        putAlpha(w) {
          if (w.width !== this.width || w.height !== this.height)
            throw new Error(`Expected mask size to be ${this.width}x${this.height}, but got ${w.width}x${w.height}`);
          if (w.channels !== 1)
            throw new Error(`Expected mask to have 1 channel, but got ${w.channels}`);
          const T = this.data, F = w.data, E = this.width * this.height;
          if (this.channels === 3) {
            const A = new Uint8ClampedArray(E * 4);
            for (let L = 0, I = 0, R = 0; L < E; ++L)
              A[R++] = T[I++], A[R++] = T[I++], A[R++] = T[I++], A[R++] = F[L];
            return this._update(A, this.width, this.height, 4);
          } else if (this.channels === 4) {
            for (let A = 0; A < E; ++A)
              T[4 * A + 3] = F[A];
            return this;
          }
          throw new Error(`Expected image to have 3 or 4 channels, but got ${this.channels}`);
        }
        /**
         * Resize the image to the given dimensions. This method uses the canvas API to perform the resizing.
         * @param {number} width The width of the new image. `null` or `-1` will preserve the aspect ratio.
         * @param {number} height The height of the new image. `null` or `-1` will preserve the aspect ratio.
         * @param {Object} options Additional options for resizing.
         * @param {0|1|2|3|4|5|string} [options.resample] The resampling method to use.
         * @returns {Promise<RawImage>} `this` to support chaining.
         */
        async resize(w, T, {
          resample: F = 2
        } = {}) {
          if (this.width === w && this.height === T)
            return this;
          let E = p[F] ?? F;
          const A = (0, i.isNullishDimension)(w), L = (0, i.isNullishDimension)(T);
          if (A && L)
            return this;
          if (A ? w = T / this.height * this.width : L && (T = w / this.width * this.height), h) {
            const I = this.channels, R = this.toCanvas(), N = l(w, T).getContext("2d");
            return N.drawImage(R, 0, 0, w, T), new v(N.getImageData(0, 0, w, T).data, w, T, 4).convert(I);
          } else {
            let I = this.toSharp();
            switch (E) {
              case "box":
              case "hamming":
                (E === "box" || E === "hamming") && (console.warn(`Resampling method ${E} is not yet supported. Using bilinear instead.`), E = "bilinear");
              case "nearest":
              case "bilinear":
              case "bicubic":
                I = I.affine([w / this.width, 0, 0, T / this.height], {
                  interpolator: E
                });
                break;
              case "lanczos":
                I = I.resize({
                  width: w,
                  height: T,
                  fit: "fill",
                  kernel: "lanczos3"
                  // PIL Lanczos uses a kernel size of 3
                });
                break;
              default:
                throw new Error(`Resampling method ${E} is not supported.`);
            }
            return await m(I);
          }
        }
        async pad([w, T, F, E]) {
          if (w = Math.max(w, 0), T = Math.max(T, 0), F = Math.max(F, 0), E = Math.max(E, 0), w === 0 && T === 0 && F === 0 && E === 0)
            return this;
          if (h) {
            const A = this.channels, L = this.toCanvas(), I = this.width + w + T, R = this.height + F + E, N = l(I, R).getContext("2d");
            return N.drawImage(
              L,
              0,
              0,
              this.width,
              this.height,
              w,
              F,
              this.width,
              this.height
            ), new v(
              N.getImageData(0, 0, I, R).data,
              I,
              R,
              4
            ).convert(A);
          } else {
            const A = this.toSharp().extend({ left: w, right: T, top: F, bottom: E });
            return await m(A);
          }
        }
        async crop([w, T, F, E]) {
          if (w = Math.max(w, 0), T = Math.max(T, 0), F = Math.min(F, this.width - 1), E = Math.min(E, this.height - 1), w === 0 && T === 0 && F === this.width - 1 && E === this.height - 1)
            return this;
          const A = F - w + 1, L = E - T + 1;
          if (h) {
            const I = this.channels, R = this.toCanvas(), N = l(A, L).getContext("2d");
            return N.drawImage(
              R,
              w,
              T,
              A,
              L,
              0,
              0,
              A,
              L
            ), new v(N.getImageData(0, 0, A, L).data, A, L, 4).convert(I);
          } else {
            const I = this.toSharp().extract({
              left: w,
              top: T,
              width: A,
              height: L
            });
            return await m(I);
          }
        }
        async center_crop(w, T) {
          if (this.width === w && this.height === T)
            return this;
          const F = (this.width - w) / 2, E = (this.height - T) / 2;
          if (h) {
            const A = this.channels, L = this.toCanvas(), I = l(w, T).getContext("2d");
            let R = 0, N = 0, q = 0, ne = 0;
            return F >= 0 ? R = F : q = -F, E >= 0 ? N = E : ne = -E, I.drawImage(
              L,
              R,
              N,
              w,
              T,
              q,
              ne,
              w,
              T
            ), new v(I.getImageData(0, 0, w, T).data, w, T, 4).convert(A);
          } else {
            let A = this.toSharp();
            if (F >= 0 && E >= 0)
              A = A.extract({
                left: Math.floor(F),
                top: Math.floor(E),
                width: w,
                height: T
              });
            else if (F <= 0 && E <= 0) {
              const L = Math.floor(-E), I = Math.floor(-F);
              A = A.extend({
                top: L,
                left: I,
                // Ensures the resulting image has the desired dimensions
                right: w - this.width - I,
                bottom: T - this.height - L
              });
            } else {
              let L = [0, 0], I = 0;
              E < 0 ? (L[0] = Math.floor(-E), L[1] = T - this.height - L[0]) : I = Math.floor(E);
              let R = [0, 0], N = 0;
              F < 0 ? (R[0] = Math.floor(-F), R[1] = w - this.width - R[0]) : N = Math.floor(F), A = A.extend({
                top: L[0],
                bottom: L[1],
                left: R[0],
                right: R[1]
              }).extract({
                left: N,
                top: I,
                width: w,
                height: T
              });
            }
            return await m(A);
          }
        }
        async toBlob(w = "image/png", T = 1) {
          if (!h)
            throw new Error("toBlob() is only supported in browser environments.");
          return await this.toCanvas().convertToBlob({ type: w, quality: T });
        }
        toTensor(w = "CHW") {
          let T = new c.Tensor(
            "uint8",
            new Uint8Array(this.data),
            [this.height, this.width, this.channels]
          );
          if (w !== "HWC")
            if (w === "CHW")
              T = T.permute(2, 0, 1);
            else
              throw new Error(`Unsupported channel format: ${w}`);
          return T;
        }
        toCanvas() {
          if (!h)
            throw new Error("toCanvas() is only supported in browser environments.");
          const w = this.clone().rgba(), T = l(w.width, w.height), F = new f(w.data, w.width, w.height);
          return T.getContext("2d").putImageData(F, 0, 0), T;
        }
        /**
         * Split this image into individual bands. This method returns an array of individual image bands from an image.
         * For example, splitting an "RGB" image creates three new images each containing a copy of one of the original bands (red, green, blue).
         * 
         * Inspired by PIL's `Image.split()` [function](https://pillow.readthedocs.io/en/latest/reference/Image.html#PIL.Image.Image.split).
         * @returns {RawImage[]} An array containing bands.
         */
        split() {
          const { data: w, width: T, height: F, channels: E } = this, A = (
            /** @type {any} */
            w.constructor
          ), L = w.length / E, I = Array.from(
            { length: E },
            () => new A(L)
          );
          for (let R = 0; R < L; ++R) {
            const N = E * R;
            for (let q = 0; q < E; ++q)
              I[q][R] = w[N + q];
          }
          return I.map((R) => new v(R, T, F, 1));
        }
        /**
         * Helper method to update the image data.
         * @param {Uint8ClampedArray} data The new image data.
         * @param {number} width The new width of the image.
         * @param {number} height The new height of the image.
         * @param {1|2|3|4|null} [channels] The new number of channels of the image.
         * @private
         */
        _update(w, T, F, E = null) {
          return this.data = w, this.width = T, this.height = F, E !== null && (this.channels = E), this;
        }
        /**
         * Clone the image
         * @returns {RawImage} The cloned image
         */
        clone() {
          return new v(this.data.slice(), this.width, this.height, this.channels);
        }
        /**
         * Helper method for converting image to have a certain number of channels
         * @param {number} numChannels The number of channels. Must be 1, 3, or 4.
         * @returns {RawImage} `this` to support chaining.
         */
        convert(w) {
          if (this.channels === w)
            return this;
          switch (w) {
            case 1:
              this.grayscale();
              break;
            case 3:
              this.rgb();
              break;
            case 4:
              this.rgba();
              break;
            default:
              throw new Error(`Conversion failed due to unsupported number of channels: ${this.channels}`);
          }
          return this;
        }
        /**
         * Save the image to the given path.
         * @param {string} path The path to save the image to.
         */
        async save(w) {
          if (h) {
            if (a.apis.IS_WEBWORKER_ENV)
              throw new Error("Unable to save an image from a Web Worker.");
            const T = w.split(".").pop().toLowerCase(), F = _.get(T) ?? "image/png", E = await this.toBlob(F);
            (0, i.saveBlob)(w, E);
          } else {
            if (a.apis.IS_FS_AVAILABLE)
              return await this.toSharp().toFile(w);
            throw new Error("Unable to save the image because filesystem is disabled in this environment.");
          }
        }
        toSharp() {
          if (h)
            throw new Error("toSharp() is only supported in server-side environments.");
          return u(this.data, {
            raw: {
              width: this.width,
              height: this.height,
              channels: this.channels
            }
          });
        }
      }
      const S = v.read.bind(v);
    }
  ),
  /***/
  "./src/utils/maths.js": (
    /*!****************************!*\
      !*** ./src/utils/maths.js ***!
      \****************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        FFT: () => (
          /* binding */
          S
        ),
        /* harmony export */
        bankers_round: () => (
          /* binding */
          T
        ),
        /* harmony export */
        cos_sim: () => (
          /* binding */
          l
        ),
        /* harmony export */
        dot: () => (
          /* binding */
          u
        ),
        /* harmony export */
        dynamic_time_warping: () => (
          /* binding */
          F
        ),
        /* harmony export */
        interpolate_data: () => (
          /* binding */
          i
        ),
        /* harmony export */
        log_softmax: () => (
          /* binding */
          c
        ),
        /* harmony export */
        magnitude: () => (
          /* binding */
          f
        ),
        /* harmony export */
        max: () => (
          /* binding */
          h
        ),
        /* harmony export */
        medianFilter: () => (
          /* binding */
          D
        ),
        /* harmony export */
        min: () => (
          /* binding */
          m
        ),
        /* harmony export */
        permute_data: () => (
          /* binding */
          r
        ),
        /* harmony export */
        round: () => (
          /* binding */
          w
        ),
        /* harmony export */
        softmax: () => (
          /* binding */
          a
        )
        /* harmony export */
      });
      function i(E, [A, L, I], [R, N], q = "bilinear", ne = !1) {
        const Q = N / I, W = R / L, te = new E.constructor(R * N * A), K = L * I, pe = R * N;
        for (let be = 0; be < R; ++be)
          for (let Ee = 0; Ee < N; ++Ee) {
            const Ge = be * N + Ee, _e = (Ee + 0.5) / Q - 0.5, De = (be + 0.5) / W - 0.5;
            let he = Math.floor(_e), Z = Math.floor(De);
            const me = Math.min(he + 1, I - 1), we = Math.min(Z + 1, L - 1);
            he = Math.max(he, 0), Z = Math.max(Z, 0);
            const xe = _e - he, et = De - Z, Ve = (1 - xe) * (1 - et), nt = xe * (1 - et), Be = (1 - xe) * et, ae = xe * et, U = Z * I, Se = we * I, ze = U + he, Oe = U + me, Ye = Se + he, H = Se + me;
            for (let Y = 0; Y < A; ++Y) {
              const $e = Y * K;
              te[Y * pe + Ge] = Ve * E[$e + ze] + nt * E[$e + Oe] + Be * E[$e + Ye] + ae * E[$e + H];
            }
          }
        return te;
      }
      function r(E, A, L) {
        const I = new Array(L.length), R = new Array(L.length);
        for (let ne = L.length - 1, Q = 1; ne >= 0; --ne)
          R[ne] = Q, I[ne] = A[L[ne]], Q *= I[ne];
        const N = L.map((ne, Q) => R[L.indexOf(Q)]), q = new E.constructor(E.length);
        for (let ne = 0; ne < E.length; ++ne) {
          let Q = 0;
          for (let W = A.length - 1, te = ne; W >= 0; --W)
            Q += te % A[W] * N[W], te = Math.floor(te / A[W]);
          q[Q] = E[ne];
        }
        return [q, I];
      }
      function a(E) {
        const A = h(E)[0], L = E.map((N) => Math.exp(N - A)), I = L.reduce((N, q) => N + q, 0);
        return L.map((N) => N / I);
      }
      function c(E) {
        const A = h(E)[0];
        let L = 0;
        for (let N = 0; N < E.length; ++N)
          L += Math.exp(E[N] - A);
        const I = Math.log(L);
        return E.map((N) => N - A - I);
      }
      function u(E, A) {
        let L = 0;
        for (let I = 0; I < E.length; ++I)
          L += E[I] * A[I];
        return L;
      }
      function l(E, A) {
        const L = u(E, A), I = f(E), R = f(A);
        return L / (I * R);
      }
      function f(E) {
        return Math.sqrt(E.reduce((A, L) => A + L * L, 0));
      }
      function m(E) {
        if (E.length === 0)
          throw Error("Array must not be empty");
        let A = E[0], L = 0;
        for (let I = 1; I < E.length; ++I)
          E[I] < A && (A = E[I], L = I);
        return (
          /** @type {T extends bigint[]|BigTypedArray ? [bigint, number] : [number, number]} */
          [A, L]
        );
      }
      function h(E) {
        if (E.length === 0)
          throw Error("Array must not be empty");
        let A = E[0], L = 0;
        for (let I = 1; I < E.length; ++I)
          E[I] > A && (A = E[I], L = I);
        return (
          /** @type {T extends bigint[]|BigTypedArray ? [bigint, number] : [number, number]} */
          [A, L]
        );
      }
      function p(E) {
        return E > 0 && (E & E - 1) === 0;
      }
      class _ {
        /**
         * @param {number} size The size of the input array. Must be a power of two larger than 1.
         * @throws {Error} FFT size must be a power of two larger than 1.
         */
        constructor(A) {
          if (this.size = A | 0, this.size <= 1 || !p(this.size))
            throw new Error("FFT size must be a power of two larger than 1");
          this._csize = A << 1, this.table = new Float64Array(this.size * 2);
          for (let I = 0; I < this.table.length; I += 2) {
            const R = Math.PI * I / this.size;
            this.table[I] = Math.cos(R), this.table[I + 1] = -Math.sin(R);
          }
          let L = 0;
          for (let I = 1; this.size > I; I <<= 1)
            ++L;
          this._width = L % 2 === 0 ? L - 1 : L, this._bitrev = new Int32Array(1 << this._width);
          for (let I = 0; I < this._bitrev.length; ++I) {
            this._bitrev[I] = 0;
            for (let R = 0; R < this._width; R += 2) {
              const N = this._width - R - 2;
              this._bitrev[I] |= (I >>> R & 3) << N;
            }
          }
        }
        /**
         * Create a complex number array with size `2 * size`
         *
         * @returns {Float64Array} A complex number array with size `2 * size`
         */
        createComplexArray() {
          return new Float64Array(this._csize);
        }
        /**
         * Converts a complex number representation stored in a Float64Array to an array of real numbers.
         * 
         * @param {Float64Array} complex The complex number representation to be converted.
         * @param {number[]} [storage] An optional array to store the result in.
         * @returns {number[]} An array of real numbers representing the input complex number representation.
         */
        fromComplexArray(A, L) {
          const I = L || new Array(A.length >>> 1);
          for (let R = 0; R < A.length; R += 2)
            I[R >>> 1] = A[R];
          return I;
        }
        /**
         * Convert a real-valued input array to a complex-valued output array.
         * @param {Float64Array} input The real-valued input array.
         * @param {Float64Array} [storage] Optional buffer to store the output array.
         * @returns {Float64Array} The complex-valued output array.
         */
        toComplexArray(A, L) {
          const I = L || this.createComplexArray();
          for (let R = 0; R < I.length; R += 2)
            I[R] = A[R >>> 1], I[R + 1] = 0;
          return I;
        }
        /**
         * Performs a Fast Fourier Transform (FFT) on the given input data and stores the result in the output buffer.
         * 
         * @param {Float64Array} out The output buffer to store the result.
         * @param {Float64Array} data The input data to transform.
         * 
         * @throws {Error} Input and output buffers must be different.
         * 
         * @returns {void}
         */
        transform(A, L) {
          if (A === L)
            throw new Error("Input and output buffers must be different");
          this._transform4(
            A,
            L,
            1
            /* DONE */
          );
        }
        /**
         * Performs a real-valued forward FFT on the given input buffer and stores the result in the given output buffer.
         * The input buffer must contain real values only, while the output buffer will contain complex values. The input and
         * output buffers must be different.
         *
         * @param {Float64Array} out The output buffer.
         * @param {Float64Array} data The input buffer containing real values.
         *
         * @throws {Error} If the input and output buffers are the same.
         */
        realTransform(A, L) {
          if (A === L)
            throw new Error("Input and output buffers must be different");
          this._realTransform4(
            A,
            L,
            1
            /* DONE */
          );
        }
        /**
         * Performs an inverse FFT transformation on the given `data` array, and stores the result in `out`.
         * The `out` array must be a different buffer than the `data` array. The `out` array will contain the
         * result of the transformation. The `data` array will not be modified.
         * 
         * @param {Float64Array} out The output buffer for the transformed data.
         * @param {Float64Array} data The input data to transform.
         * @throws {Error} If `out` and `data` refer to the same buffer.
         * @returns {void}
         */
        inverseTransform(A, L) {
          if (A === L)
            throw new Error("Input and output buffers must be different");
          this._transform4(
            A,
            L,
            -1
            /* DONE */
          );
          for (let I = 0; I < A.length; ++I)
            A[I] /= this.size;
        }
        /**
         * Performs a radix-4 implementation of a discrete Fourier transform on a given set of data.
         *
         * @param {Float64Array} out The output buffer for the transformed data.
         * @param {Float64Array} data The input buffer of data to be transformed.
         * @param {number} inv A scaling factor to apply to the transform.
         * @returns {void}
         */
        _transform4(A, L, I) {
          const R = this._csize;
          let q = 1 << this._width, ne = R / q << 1, Q, W;
          const te = this._bitrev;
          if (ne === 4)
            for (Q = 0, W = 0; Q < R; Q += ne, ++W) {
              const pe = te[W];
              this._singleTransform2(L, A, Q, pe, q);
            }
          else
            for (Q = 0, W = 0; Q < R; Q += ne, ++W) {
              const pe = te[W];
              this._singleTransform4(L, A, Q, pe, q, I);
            }
          const K = this.table;
          for (q >>= 2; q >= 2; q >>= 2) {
            ne = R / q << 1;
            const pe = ne >>> 2;
            for (Q = 0; Q < R; Q += ne) {
              const be = Q + pe - 1;
              for (let Ee = Q, Ge = 0; Ee < be; Ee += 2, Ge += q) {
                const _e = Ee, De = _e + pe, he = De + pe, Z = he + pe, me = A[_e], we = A[_e + 1], xe = A[De], et = A[De + 1], Ve = A[he], nt = A[he + 1], Be = A[Z], ae = A[Z + 1], U = K[Ge], Se = I * K[Ge + 1], ze = xe * U - et * Se, Oe = xe * Se + et * U, Ye = K[2 * Ge], H = I * K[2 * Ge + 1], Y = Ve * Ye - nt * H, $e = Ve * H + nt * Ye, Ie = K[3 * Ge], fe = I * K[3 * Ge + 1], Qe = Be * Ie - ae * fe, Ne = Be * fe + ae * Ie, ut = me + Y, de = we + $e, qe = me - Y, tt = we - $e, He = ze + Qe, je = Oe + Ne, lt = I * (ze - Qe), Mt = I * (Oe - Ne);
                A[_e] = ut + He, A[_e + 1] = de + je, A[De] = qe + Mt, A[De + 1] = tt - lt, A[he] = ut - He, A[he + 1] = de - je, A[Z] = qe - Mt, A[Z + 1] = tt + lt;
              }
            }
          }
        }
        /**
         * Performs a radix-2 implementation of a discrete Fourier transform on a given set of data.
         *
         * @param {Float64Array} data The input buffer of data to be transformed.
         * @param {Float64Array} out The output buffer for the transformed data.
         * @param {number} outOff The offset at which to write the output data.
         * @param {number} off The offset at which to begin reading the input data.
         * @param {number} step The step size for indexing the input data.
         * @returns {void}
         */
        _singleTransform2(A, L, I, R, N) {
          const q = A[R], ne = A[R + 1], Q = A[R + N], W = A[R + N + 1];
          L[I] = q + Q, L[I + 1] = ne + W, L[I + 2] = q - Q, L[I + 3] = ne - W;
        }
        /**
         * Performs radix-4 transformation on input data of length 8
         *
         * @param {Float64Array} data Input data array of length 8
         * @param {Float64Array} out Output data array of length 8
         * @param {number} outOff Index of output array to start writing from
         * @param {number} off Index of input array to start reading from
         * @param {number} step Step size between elements in input array
         * @param {number} inv Scaling factor for inverse transform
         * 
         * @returns {void}
         */
        _singleTransform4(A, L, I, R, N, q) {
          const ne = N * 2, Q = N * 3, W = A[R], te = A[R + 1], K = A[R + N], pe = A[R + N + 1], be = A[R + ne], Ee = A[R + ne + 1], Ge = A[R + Q], _e = A[R + Q + 1], De = W + be, he = te + Ee, Z = W - be, me = te - Ee, we = K + Ge, xe = pe + _e, et = q * (K - Ge), Ve = q * (pe - _e);
          L[I] = De + we, L[I + 1] = he + xe, L[I + 2] = Z + Ve, L[I + 3] = me - et, L[I + 4] = De - we, L[I + 5] = he - xe, L[I + 6] = Z - Ve, L[I + 7] = me + et;
        }
        /**
         * Real input radix-4 implementation
         * @param {Float64Array} out Output array for the transformed data
         * @param {Float64Array} data Input array of real data to be transformed
         * @param {number} inv The scale factor used to normalize the inverse transform
         */
        _realTransform4(A, L, I) {
          const R = this._csize;
          let q = 1 << this._width, ne = R / q << 1, Q, W;
          const te = this._bitrev;
          if (ne === 4)
            for (Q = 0, W = 0; Q < R; Q += ne, ++W) {
              const be = te[W];
              this._singleRealTransform2(L, A, Q, be >>> 1, q >>> 1);
            }
          else
            for (Q = 0, W = 0; Q < R; Q += ne, ++W) {
              const be = te[W];
              this._singleRealTransform4(L, A, Q, be >>> 1, q >>> 1, I);
            }
          const K = this.table;
          for (q >>= 2; q >= 2; q >>= 2) {
            ne = R / q << 1;
            const be = ne >>> 1, Ee = be >>> 1, Ge = Ee >>> 1;
            for (Q = 0; Q < R; Q += ne)
              for (let _e = 0, De = 0; _e <= Ge; _e += 2, De += q) {
                const he = Q + _e, Z = he + Ee, me = Z + Ee, we = me + Ee, xe = A[he], et = A[he + 1], Ve = A[Z], nt = A[Z + 1], Be = A[me], ae = A[me + 1], U = A[we], Se = A[we + 1], ze = xe, Oe = et, Ye = K[De], H = I * K[De + 1], Y = Ve * Ye - nt * H, $e = Ve * H + nt * Ye, Ie = K[2 * De], fe = I * K[2 * De + 1], Qe = Be * Ie - ae * fe, Ne = Be * fe + ae * Ie, ut = K[3 * De], de = I * K[3 * De + 1], qe = U * ut - Se * de, tt = U * de + Se * ut, He = ze + Qe, je = Oe + Ne, lt = ze - Qe, Mt = Oe - Ne, Rt = Y + qe, Kt = $e + tt, vn = I * (Y - qe), wn = I * ($e - tt);
                if (A[he] = He + Rt, A[he + 1] = je + Kt, A[Z] = lt + wn, A[Z + 1] = Mt - vn, _e === 0) {
                  A[me] = He - Rt, A[me + 1] = je - Kt;
                  continue;
                }
                if (_e === Ge)
                  continue;
                const ln = Q + Ee - _e, Gn = Q + be - _e;
                A[ln] = lt - I * wn, A[ln + 1] = -Mt - I * vn, A[Gn] = He - I * Rt, A[Gn + 1] = -je + I * Kt;
              }
          }
          const pe = R >>> 1;
          for (let be = 2; be < pe; be += 2)
            A[R - be] = A[be], A[R - be + 1] = -A[be + 1];
        }
        /**
         * Performs a single real input radix-2 transformation on the provided data
         * 
         * @param {Float64Array} data The input data array
         * @param {Float64Array} out The output data array
         * @param {number} outOff The output offset
         * @param {number} off The input offset
         * @param {number} step The step
         * 
         * @returns {void}
         */
        _singleRealTransform2(A, L, I, R, N) {
          const q = A[R], ne = A[R + N];
          L[I] = q + ne, L[I + 1] = 0, L[I + 2] = q - ne, L[I + 3] = 0;
        }
        /**
         * Computes a single real-valued transform using radix-4 algorithm.
         * This method is only called for len=8.
         *
         * @param {Float64Array} data The input data array.
         * @param {Float64Array} out The output data array.
         * @param {number} outOff The offset into the output array.
         * @param {number} off The offset into the input array.
         * @param {number} step The step size for the input array.
         * @param {number} inv The value of inverse.
         */
        _singleRealTransform4(A, L, I, R, N, q) {
          const ne = N * 2, Q = N * 3, W = A[R], te = A[R + N], K = A[R + ne], pe = A[R + Q], be = W + K, Ee = W - K, Ge = te + pe, _e = q * (te - pe);
          L[I] = be + Ge, L[I + 1] = 0, L[I + 2] = Ee, L[I + 3] = -_e, L[I + 4] = be - Ge, L[I + 5] = 0, L[I + 6] = Ee, L[I + 7] = _e;
        }
      }
      class v {
        /**
         * Constructs a new NP2FFT object.
         * @param {number} fft_length The length of the FFT
         */
        constructor(A) {
          const L = 2 * (A - 1), I = 2 * (2 * A - 1), R = 2 ** Math.ceil(Math.log2(I));
          this.bufferSize = R, this._a = L;
          const N = new Float64Array(I), q = new Float64Array(R);
          this._chirpBuffer = new Float64Array(R), this._buffer1 = new Float64Array(R), this._buffer2 = new Float64Array(R), this._outBuffer1 = new Float64Array(R), this._outBuffer2 = new Float64Array(R);
          const ne = -2 * Math.PI / A, Q = Math.cos(ne), W = Math.sin(ne);
          for (let te = 0; te < I >> 1; ++te) {
            const K = (te + 1 - A) ** 2 / 2, pe = Math.sqrt(Q ** 2 + W ** 2) ** K, be = K * Math.atan2(W, Q), Ee = 2 * te;
            N[Ee] = pe * Math.cos(be), N[Ee + 1] = pe * Math.sin(be), q[Ee] = N[Ee], q[Ee + 1] = -N[Ee + 1];
          }
          this._slicedChirpBuffer = N.subarray(L, I), this._f = new _(R >> 1), this._f.transform(this._chirpBuffer, q);
        }
        _transform(A, L, I) {
          const R = this._buffer1, N = this._buffer2, q = this._outBuffer1, ne = this._outBuffer2, Q = this._chirpBuffer, W = this._slicedChirpBuffer, te = this._a;
          if (I)
            for (let K = 0; K < W.length; K += 2) {
              const pe = K + 1, be = K >> 1, Ee = L[be];
              R[K] = Ee * W[K], R[pe] = Ee * W[pe];
            }
          else
            for (let K = 0; K < W.length; K += 2) {
              const pe = K + 1;
              R[K] = L[K] * W[K] - L[pe] * W[pe], R[pe] = L[K] * W[pe] + L[pe] * W[K];
            }
          this._f.transform(q, R);
          for (let K = 0; K < Q.length; K += 2) {
            const pe = K + 1;
            N[K] = q[K] * Q[K] - q[pe] * Q[pe], N[pe] = q[K] * Q[pe] + q[pe] * Q[K];
          }
          this._f.inverseTransform(ne, N);
          for (let K = 0; K < ne.length; K += 2) {
            const pe = ne[K + te], be = ne[K + te + 1], Ee = W[K], Ge = W[K + 1];
            A[K] = pe * Ee - be * Ge, A[K + 1] = pe * Ge + be * Ee;
          }
        }
        transform(A, L) {
          this._transform(A, L, !1);
        }
        realTransform(A, L) {
          this._transform(A, L, !0);
        }
      }
      class S {
        constructor(A) {
          this.fft_length = A, this.isPowerOfTwo = p(A), this.isPowerOfTwo ? (this.fft = new _(A), this.outputBufferSize = 2 * A) : (this.fft = new v(A), this.outputBufferSize = this.fft.bufferSize);
        }
        realTransform(A, L) {
          this.fft.realTransform(A, L);
        }
        transform(A, L) {
          this.fft.transform(A, L);
        }
      }
      function D(E, A) {
        if (A % 2 === 0 || A <= 0)
          throw new Error("Window size must be a positive odd number");
        const L = new E.constructor(E.length), I = new E.constructor(A), R = Math.floor(A / 2);
        for (let N = 0; N < E.length; ++N) {
          let q = 0;
          for (let ne = -R; ne <= R; ++ne) {
            let Q = N + ne;
            Q < 0 ? Q = Math.abs(Q) : Q >= E.length && (Q = 2 * (E.length - 1) - Q), I[q++] = E[Q];
          }
          I.sort(), L[N] = I[R];
        }
        return L;
      }
      function w(E, A) {
        const L = Math.pow(10, A);
        return Math.round(E * L) / L;
      }
      function T(E) {
        const A = Math.round(E);
        return Math.abs(E) % 1 === 0.5 ? A % 2 === 0 ? A : A - 1 : A;
      }
      function F(E) {
        const A = E.length, L = E[0].length, I = [A + 1, L + 1], R = Array.from(
          { length: I[0] },
          () => Array(I[1]).fill(1 / 0)
        );
        R[0][0] = 0;
        const N = Array.from(
          { length: I[0] },
          () => Array(I[1]).fill(-1)
        );
        for (let te = 1; te < I[1]; ++te)
          for (let K = 1; K < I[0]; ++K) {
            const pe = R[K - 1][te - 1], be = R[K - 1][te], Ee = R[K][te - 1];
            let Ge, _e;
            pe < be && pe < Ee ? (Ge = pe, _e = 0) : be < pe && be < Ee ? (Ge = be, _e = 1) : (Ge = Ee, _e = 2), R[K][te] = E[K - 1][te - 1] + Ge, N[K][te] = _e;
          }
        for (let te = 0; te < I[1]; ++te)
          N[0][te] = 2;
        for (let te = 0; te < I[0]; ++te)
          N[te][0] = 1;
        let q = A, ne = L, Q = [], W = [];
        for (; q > 0 || ne > 0; )
          switch (Q.push(q - 1), W.push(ne - 1), N[q][ne]) {
            case 0:
              --q, --ne;
              break;
            case 1:
              --q;
              break;
            case 2:
              --ne;
              break;
            default:
              throw new Error(
                `Internal error in dynamic time warping. Unexpected trace[${q}, ${ne}]. Please file a bug report.`
              );
          }
        return Q.reverse(), W.reverse(), [Q, W];
      }
    }
  ),
  /***/
  "./src/utils/tensor.js": (
    /*!*****************************!*\
      !*** ./src/utils/tensor.js ***!
      \*****************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        DataTypeMap: () => (
          /* binding */
          c
        ),
        /* harmony export */
        Tensor: () => (
          /* binding */
          u
        ),
        /* harmony export */
        cat: () => (
          /* binding */
          L
        ),
        /* harmony export */
        full: () => (
          /* binding */
          W
        ),
        /* harmony export */
        full_like: () => (
          /* binding */
          te
        ),
        /* harmony export */
        interpolate: () => (
          /* binding */
          m
        ),
        /* harmony export */
        interpolate_4d: () => (
          /* binding */
          h
        ),
        /* harmony export */
        layer_norm: () => (
          /* binding */
          T
        ),
        /* harmony export */
        matmul: () => (
          /* binding */
          p
        ),
        /* harmony export */
        mean: () => (
          /* binding */
          q
        ),
        /* harmony export */
        mean_pooling: () => (
          /* binding */
          w
        ),
        /* harmony export */
        ones: () => (
          /* binding */
          K
        ),
        /* harmony export */
        ones_like: () => (
          /* binding */
          pe
        ),
        /* harmony export */
        permute: () => (
          /* binding */
          f
        ),
        /* harmony export */
        quantize_embeddings: () => (
          /* binding */
          De
        ),
        /* harmony export */
        rand: () => (
          /* binding */
          Ge
        ),
        /* harmony export */
        randn: () => (
          /* binding */
          _e
        ),
        /* harmony export */
        rfft: () => (
          /* binding */
          _
        ),
        /* harmony export */
        slice: () => (
          /* binding */
          D
        ),
        /* harmony export */
        stack: () => (
          /* binding */
          I
        ),
        /* harmony export */
        std_mean: () => (
          /* binding */
          N
        ),
        /* harmony export */
        topk: () => (
          /* binding */
          v
        ),
        /* harmony export */
        zeros: () => (
          /* binding */
          be
        ),
        /* harmony export */
        zeros_like: () => (
          /* binding */
          Ee
        )
        /* harmony export */
      });
      var i = t(
        /*! ./maths.js */
        "./src/utils/maths.js"
      ), r = t(
        /*! ../backends/onnx.js */
        "./src/backends/onnx.js"
      ), a = t(
        /*! ../ops/registry.js */
        "./src/ops/registry.js"
      );
      const c = Object.freeze({
        float32: Float32Array,
        // @ts-ignore ts(2552) Limited availability of Float16Array across browsers:
        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float16Array
        float16: typeof Float16Array < "u" ? Float16Array : Uint16Array,
        float64: Float64Array,
        string: Array,
        // string[]
        int8: Int8Array,
        uint8: Uint8Array,
        int16: Int16Array,
        uint16: Uint16Array,
        int32: Int32Array,
        uint32: Uint32Array,
        int64: BigInt64Array,
        uint64: BigUint64Array,
        bool: Uint8Array,
        uint4: Uint8Array,
        int4: Int8Array
      });
      class u {
        /**
         * Create a new Tensor or copy an existing Tensor.
         * @param {[DataType, DataArray, number[]]|[ONNXTensor]} args
         */
        constructor(...Z) {
          Ce(this, "ort_tensor");
          return (0, r.isONNXTensor)(Z[0]) ? this.ort_tensor = /** @type {ONNXTensor} */
          Z[0] : this.ort_tensor = new r.Tensor(
            /** @type {DataType} */
            Z[0],
            // @ts-expect-error ts(2769) Type 'number' is not assignable to type 'bigint'.
            /** @type {Exclude<import('./maths.js').AnyTypedArray, Uint8ClampedArray>} */
            Z[1],
            Z[2]
          ), new Proxy(this, {
            get: (me, we) => {
              if (typeof we == "string") {
                let xe = Number(we);
                if (Number.isInteger(xe))
                  return me._getitem(xe);
              }
              return me[we];
            },
            set: (me, we, xe) => me[we] = xe
          });
        }
        /** @type {number[]} Dimensions of the tensor. */
        get dims() {
          return this.ort_tensor.dims;
        }
        set dims(Z) {
          this.ort_tensor.dims = Z;
        }
        /** @type {DataType} Type of the tensor. */
        get type() {
          return this.ort_tensor.type;
        }
        /** @type {DataArray} The data stored in the tensor. */
        get data() {
          return this.ort_tensor.data;
        }
        /** @type {number} The number of elements in the tensor. */
        get size() {
          return this.ort_tensor.size;
        }
        /** @type {string} The location of the tensor data. */
        get location() {
          return this.ort_tensor.location;
        }
        dispose() {
          this.ort_tensor.dispose();
        }
        /**
         * Returns an iterator object for iterating over the tensor data in row-major order.
         * If the tensor has more than one dimension, the iterator will yield subarrays.
         * @returns {Iterator} An iterator object for iterating over the tensor data in row-major order.
         */
        *[Symbol.iterator]() {
          const [Z, ...me] = this.dims;
          if (me.length > 0) {
            const we = me.reduce((xe, et) => xe * et);
            for (let xe = 0; xe < Z; ++xe)
              yield this._subarray(xe, we, me);
          } else
            yield* this.data;
        }
        /**
         * Index into a Tensor object.
         * @param {number} index The index to access.
         * @returns {Tensor} The data at the specified index.
         */
        _getitem(Z) {
          const [me, ...we] = this.dims;
          if (Z = A(Z, me), we.length > 0) {
            const xe = we.reduce((et, Ve) => et * Ve);
            return this._subarray(Z, xe, we);
          } else
            return new u(this.type, [this.data[Z]], we);
        }
        /**
         * @param {number|bigint} item The item to search for in the tensor
         * @returns {number} The index of the first occurrence of item in the tensor data.
         */
        indexOf(Z) {
          const me = this.data;
          for (let we = 0; we < me.length; ++we)
            if (me[we] == Z)
              return we;
          return -1;
        }
        /**
         * @param {number} index
         * @param {number} iterSize
         * @param {any} iterDims
         * @returns {Tensor}
         */
        _subarray(Z, me, we) {
          const xe = Z * me, et = (Z + 1) * me, Ve = "subarray" in this.data ? this.data.subarray(xe, et) : this.data.slice(xe, et);
          return new u(this.type, Ve, we);
        }
        /**
         * Returns the value of this tensor as a standard JavaScript Number. This only works
         * for tensors with one element. For other cases, see `Tensor.tolist()`.
         * @returns {number|bigint} The value of this tensor as a standard JavaScript Number.
         * @throws {Error} If the tensor has more than one element.
         */
        item() {
          const Z = this.data;
          if (Z.length !== 1)
            throw new Error(`a Tensor with ${Z.length} elements cannot be converted to Scalar`);
          return Z[0];
        }
        /**
         * Convert tensor data to a n-dimensional JS list
         * @returns {Array}
         */
        tolist() {
          return l(this.data, this.dims);
        }
        /**
         * Return a new Tensor with the sigmoid function applied to each element.
         * @returns {Tensor} The tensor with the sigmoid function applied.
         */
        sigmoid() {
          return this.clone().sigmoid_();
        }
        /**
         * Applies the sigmoid function to the tensor in place.
         * @returns {Tensor} Returns `this`.
         */
        sigmoid_() {
          const Z = this.data;
          for (let me = 0; me < Z.length; ++me)
            Z[me] = 1 / (1 + Math.exp(-Z[me]));
          return this;
        }
        /**
         * Return a new Tensor with a callback function applied to each element.
         * @param {Function} callback - The function to apply to each element. It should take three arguments:
         *                              the current element, its index, and the tensor's data array.
         * @returns {Tensor} A new Tensor with the callback function applied to each element.
         */
        map(Z) {
          return this.clone().map_(Z);
        }
        /**
         * Apply a callback function to each element of the tensor in place.
         * @param {Function} callback - The function to apply to each element. It should take three arguments:
         *                              the current element, its index, and the tensor's data array.
         * @returns {Tensor} Returns `this`.
         */
        map_(Z) {
          const me = this.data;
          for (let we = 0; we < me.length; ++we)
            me[we] = Z(me[we], we, me);
          return this;
        }
        /**
         * Return a new Tensor with every element multiplied by a constant.
         * @param {number} val The value to multiply by.
         * @returns {Tensor} The new tensor.
         */
        mul(Z) {
          return this.clone().mul_(Z);
        }
        /**
         * Multiply the tensor by a constant in place.
         * @param {number} val The value to multiply by.
         * @returns {Tensor} Returns `this`.
         */
        mul_(Z) {
          const me = this.data;
          for (let we = 0; we < me.length; ++we)
            me[we] *= Z;
          return this;
        }
        /**
         * Return a new Tensor with every element divided by a constant.
         * @param {number} val The value to divide by.
         * @returns {Tensor} The new tensor.
         */
        div(Z) {
          return this.clone().div_(Z);
        }
        /**
         * Divide the tensor by a constant in place.
         * @param {number} val The value to divide by.
         * @returns {Tensor} Returns `this`.
         */
        div_(Z) {
          const me = this.data;
          for (let we = 0; we < me.length; ++we)
            me[we] /= Z;
          return this;
        }
        /**
         * Return a new Tensor with every element added by a constant.
         * @param {number} val The value to add by.
         * @returns {Tensor} The new tensor.
         */
        add(Z) {
          return this.clone().add_(Z);
        }
        /**
         * Add the tensor by a constant in place.
         * @param {number} val The value to add by.
         * @returns {Tensor} Returns `this`.
         */
        add_(Z) {
          const me = this.data;
          for (let we = 0; we < me.length; ++we)
            me[we] += Z;
          return this;
        }
        /**
         * Return a new Tensor with every element subtracted by a constant.
         * @param {number} val The value to subtract by.
         * @returns {Tensor} The new tensor.
         */
        sub(Z) {
          return this.clone().sub_(Z);
        }
        /**
         * Subtract the tensor by a constant in place.
         * @param {number} val The value to subtract by.
         * @returns {Tensor} Returns `this`.
         */
        sub_(Z) {
          const me = this.data;
          for (let we = 0; we < me.length; ++we)
            me[we] -= Z;
          return this;
        }
        /**
         * Creates a deep copy of the current Tensor.
         * @returns {Tensor} A new Tensor with the same type, data, and dimensions as the original.
         */
        clone() {
          return new u(this.type, this.data.slice(), this.dims.slice());
        }
        /**
         * Performs a slice operation on the Tensor along specified dimensions.
         *
         * Consider a Tensor that has a dimension of [4, 7]:
         * ```
         * [ 1,  2,  3,  4,  5,  6,  7]
         * [ 8,  9, 10, 11, 12, 13, 14]
         * [15, 16, 17, 18, 19, 20, 21]
         * [22, 23, 24, 25, 26, 27, 28]
         * ```
         * We can slice against the two dims of row and column, for instance in this
         * case we can start at the second element, and return to the second last,
         * like this:
         * ```
         * tensor.slice([1, -1], [1, -1]);
         * ```
         * which would return:
         * ```
         * [  9, 10, 11, 12, 13 ]
         * [ 16, 17, 18, 19, 20 ]
         * ```
         *
         * @param {...(number|number[]|null)} slices The slice specifications for each dimension.
         * - If a number is given, then a single element is selected.
         * - If an array of two numbers is given, then a range of elements [start, end (exclusive)] is selected.
         * - If null is given, then the entire dimension is selected.
         * @returns {Tensor} A new Tensor containing the selected elements.
         * @throws {Error} If the slice input is invalid.
         */
        slice(...Z) {
          const me = [], we = [];
          for (let U = 0; U < this.dims.length; ++U) {
            let Se = Z[U];
            if (Se == null)
              we.push([0, this.dims[U]]), me.push(this.dims[U]);
            else if (typeof Se == "number")
              Se = A(Se, this.dims[U], U), we.push([Se, Se + 1]);
            else if (Array.isArray(Se) && Se.length === 2) {
              let [ze, Oe] = Se;
              if (ze = ze === null ? 0 : A(ze, this.dims[U], U, !1), Oe = Oe === null ? this.dims[U] : A(Oe, this.dims[U], U, !1), ze > Oe)
                throw new Error(`Invalid slice: ${Se}`);
              const Ye = [
                Math.max(ze, 0),
                Math.min(Oe, this.dims[U])
              ];
              we.push(Ye), me.push(Ye[1] - Ye[0]);
            } else
              throw new Error(`Invalid slice: ${Se}`);
          }
          const xe = we.map(([U, Se]) => Se - U), et = xe.reduce((U, Se) => U * Se), Ve = this.data, nt = new Ve.constructor(et), Be = this.stride();
          let ae = !0;
          for (let U = 1; U < xe.length; ++U)
            if (we[U][0] !== 0 || we[U][1] !== this.dims[U]) {
              ae = !1;
              break;
            }
          if (ae) {
            const U = we[0][0] * Be[0], Se = we[0][1] * Be[0];
            if (ArrayBuffer.isView(Ve))
              nt.set(Ve.subarray(U, Se));
            else if (Array.isArray(Ve)) {
              const ze = Ve.slice(U, Se);
              for (let Oe = 0; Oe < ze.length; ++Oe)
                nt[Oe] = ze[Oe];
            } else
              throw new Error("Unsupported data type for slicing");
          } else
            for (let U = 0; U < et; ++U) {
              let Se = 0;
              for (let ze = xe.length - 1, Oe = U; ze >= 0; --ze) {
                const Ye = xe[ze];
                Se += (Oe % Ye + we[ze][0]) * Be[ze], Oe = Math.floor(Oe / Ye);
              }
              nt[U] = Ve[Se];
            }
          return new u(this.type, nt, me);
        }
        /**
         * Return a permuted version of this Tensor, according to the provided dimensions.
         * @param  {...number} dims Dimensions to permute.
         * @returns {Tensor} The permuted tensor.
         */
        permute(...Z) {
          return f(this, Z);
        }
        // TODO: implement transpose. For now (backwards compatibility), it's just an alias for permute()
        transpose(...Z) {
          return this.permute(...Z);
        }
        /**
         * Returns the sum of each row of the input tensor in the given dimension dim.
         *
         * @param {number} [dim=null] The dimension or dimensions to reduce. If `null`, all dimensions are reduced.
         * @param {boolean} keepdim Whether the output tensor has `dim` retained or not.
         * @returns The summed tensor
         */
        sum(Z = null, me = !1) {
          return this.norm(1, Z, me);
        }
        /**
         * Returns the matrix norm or vector norm of a given tensor.
         * @param {number|string} [p='fro'] The order of norm
         * @param {number} [dim=null] Specifies which dimension of the tensor to calculate the norm across.
         * If dim is None, the norm will be calculated across all dimensions of input.
         * @param {boolean} [keepdim=false] Whether the output tensors have dim retained or not.
         * @returns {Tensor} The norm of the tensor.
         */
        norm(Z = "fro", me = null, we = !1) {
          if (Z === "fro")
            Z = 2;
          else if (typeof Z == "string")
            throw Error(`Unsupported norm: ${Z}`);
          const xe = this.data, et = (ae, U) => ae + U ** Z;
          if (me === null) {
            const ae = xe.reduce(et, 0) ** (1 / Z);
            return new u(this.type, [ae], []);
          }
          const [Ve, nt, Be] = R(et, this, me, we);
          if (Z !== 1)
            for (let ae = 0; ae < nt.length; ++ae)
              nt[ae] = nt[ae] ** (1 / Z);
          return new u(Ve, nt, Be);
        }
        /**
         * Performs `L_p` normalization of inputs over specified dimension. Operates in place.
         * @param {number} [p=2] The exponent value in the norm formulation
         * @param {number} [dim=1] The dimension to reduce
         * @returns {Tensor} `this` for operation chaining.
         */
        normalize_(Z = 2, me = 1) {
          me = A(me, this.dims.length);
          const we = this.norm(Z, me, !0), xe = this.data, et = we.data;
          for (let Ve = 0; Ve < xe.length; ++Ve) {
            let nt = 0;
            for (let Be = this.dims.length - 1, ae = Ve, U = 1; Be >= 0; --Be) {
              const Se = this.dims[Be];
              if (Be !== me) {
                const ze = ae % Se;
                nt += ze * U, U *= this.dims[Be];
              }
              ae = Math.floor(ae / Se);
            }
            xe[Ve] /= et[nt];
          }
          return this;
        }
        /**
         * Performs `L_p` normalization of inputs over specified dimension.
         * @param {number} [p=2] The exponent value in the norm formulation
         * @param {number} [dim=1] The dimension to reduce
         * @returns {Tensor} The normalized tensor.
         */
        normalize(Z = 2, me = 1) {
          return this.clone().normalize_(Z, me);
        }
        /**
         * Compute and return the stride of this tensor.
         * Stride is the jump necessary to go from one element to the next one in the specified dimension dim.
         * @returns {number[]} The stride of this tensor.
         */
        stride() {
          return ne(this.dims);
        }
        /**
         * Returns a tensor with all specified dimensions of input of size 1 removed.
         *
         * NOTE: The returned tensor shares the storage with the input tensor, so changing the contents of one will change the contents of the other.
         * If you would like a copy, use `tensor.clone()` before squeezing.
         *
         * @param {number|number[]} [dim=null] If given, the input will be squeezed only in the specified dimensions.
         * @returns {Tensor} The squeezed tensor
         */
        squeeze(Z = null) {
          return new u(
            this.type,
            this.data,
            F(this.dims, Z)
          );
        }
        /**
         * In-place version of @see {@link Tensor.squeeze}
         */
        squeeze_(Z = null) {
          return this.dims = F(this.dims, Z), this;
        }
        /**
         * Returns a new tensor with a dimension of size one inserted at the specified position.
         *
         * NOTE: The returned tensor shares the same underlying data with this tensor.
         *
         * @param {number} dim The index at which to insert the singleton dimension
         * @returns {Tensor} The unsqueezed tensor
         */
        unsqueeze(Z = null) {
          return new u(
            this.type,
            this.data,
            E(this.dims, Z)
          );
        }
        /**
         * In-place version of @see {@link Tensor.unsqueeze}
         */
        unsqueeze_(Z = null) {
          return this.dims = E(this.dims, Z), this;
        }
        /**
         * In-place version of @see {@link Tensor.flatten}
         */
        flatten_(Z = 0, me = -1) {
          me = (me + this.dims.length) % this.dims.length;
          let we = this.dims.slice(0, Z), xe = this.dims.slice(Z, me + 1), et = this.dims.slice(me + 1);
          return this.dims = [...we, xe.reduce((Ve, nt) => Ve * nt, 1), ...et], this;
        }
        /**
         * Flattens input by reshaping it into a one-dimensional tensor.
         * If `start_dim` or `end_dim` are passed, only dimensions starting with `start_dim`
         * and ending with `end_dim` are flattened. The order of elements in input is unchanged.
         * @param {number} start_dim the first dim to flatten
         * @param {number} end_dim the last dim to flatten
         * @returns {Tensor} The flattened tensor.
         */
        flatten(Z = 0, me = -1) {
          return this.clone().flatten_(Z, me);
        }
        /**
         * Returns a new tensor with the same data as the `self` tensor but of a different `shape`.
         * @param  {...number} dims the desired size
         * @returns {Tensor} The tensor with the same data but different shape
         */
        view(...Z) {
          let me = -1;
          for (let xe = 0; xe < Z.length; ++xe)
            if (Z[xe] === -1) {
              if (me !== -1)
                throw new Error("Only one dimension can be inferred");
              me = xe;
            }
          const we = this.data;
          if (me !== -1) {
            const xe = Z.reduce((et, Ve, nt) => nt !== me ? et * Ve : et, 1);
            Z[me] = we.length / xe;
          }
          return new u(this.type, we, Z);
        }
        neg_() {
          const Z = this.data;
          for (let me = 0; me < Z.length; ++me)
            Z[me] = -Z[me];
          return this;
        }
        neg() {
          return this.clone().neg_();
        }
        /**
         * Computes input > val element-wise.
         * @param {number} val The value to compare with.
         * @returns {Tensor} A boolean tensor that is `true` where input is greater than other and `false` elsewhere.
         */
        gt(Z) {
          const me = new Uint8Array(this.data.length), we = this.data;
          for (let xe = 0; xe < we.length; ++xe)
            me[xe] = we[xe] > Z ? 1 : 0;
          return new u("bool", me, this.dims);
        }
        /**
         * Computes input < val element-wise.
         * @param {number} val The value to compare with.
         * @returns {Tensor} A boolean tensor that is `true` where input is less than other and `false` elsewhere.
         */
        lt(Z) {
          const me = new Uint8Array(this.data.length), we = this.data;
          for (let xe = 0; xe < we.length; ++xe)
            me[xe] = we[xe] < Z ? 1 : 0;
          return new u("bool", me, this.dims);
        }
        /**
         * In-place version of @see {@link Tensor.clamp}
         */
        clamp_(Z, me) {
          const we = this.data;
          for (let xe = 0; xe < we.length; ++xe)
            we[xe] = Math.min(Math.max(we[xe], Z), me);
          return this;
        }
        /**
         * Clamps all elements in input into the range [ min, max ]
         * @param {number} min lower-bound of the range to be clamped to
         * @param {number} max upper-bound of the range to be clamped to
         * @returns {Tensor} the output tensor.
         */
        clamp(Z, me) {
          return this.clone().clamp_(Z, me);
        }
        /**
         * In-place version of @see {@link Tensor.round}
         */
        round_() {
          const Z = this.data;
          for (let me = 0; me < Z.length; ++me)
            Z[me] = Math.round(Z[me]);
          return this;
        }
        /**
         * Rounds elements of input to the nearest integer.
         * @returns {Tensor} the output tensor.
         */
        round() {
          return this.clone().round_();
        }
        mean(Z = null, me = !1) {
          return q(this, Z, me);
        }
        min(Z = null, me = !1) {
          if (Z === null) {
            const Ve = (0, i.min)(this.data)[0];
            return new u(this.type, [Ve], [
              /* scalar */
            ]);
          }
          const [we, xe, et] = R((Ve, nt) => Math.min(Ve, nt), this, Z, me, 1 / 0);
          return new u(we, xe, et);
        }
        max(Z = null, me = !1) {
          if (Z === null) {
            const Ve = (0, i.max)(this.data)[0];
            return new u(this.type, [Ve], [
              /* scalar */
            ]);
          }
          const [we, xe, et] = R((Ve, nt) => Math.max(Ve, nt), this, Z, me, -1 / 0);
          return new u(we, xe, et);
        }
        argmin(Z = null, me = !1) {
          if (Z !== null)
            throw new Error("`dim !== null` not yet implemented.");
          const we = (0, i.min)(this.data)[1];
          return new u("int64", [BigInt(we)], []);
        }
        argmax(Z = null, me = !1) {
          if (Z !== null)
            throw new Error("`dim !== null` not yet implemented.");
          const we = (0, i.max)(this.data)[1];
          return new u("int64", [BigInt(we)], []);
        }
        /**
         * Performs Tensor dtype conversion.
         * @param {DataType} type The desired data type.
         * @returns {Tensor} The converted tensor.
         */
        to(Z) {
          if (this.type === Z)
            return this;
          if (!c.hasOwnProperty(Z))
            throw new Error(`Unsupported type: ${Z}`);
          let me;
          const we = ["int64", "uint64"].includes(this.type), xe = ["int64", "uint64"].includes(Z);
          return we && !xe ? me = Number : !we && xe && (["float16", "float32", "float64"].includes(this.type) ? me = (et) => BigInt(Math.floor(et)) : me = BigInt), new u(Z, c[Z].from(this.data, me), this.dims);
        }
      }
      function l(he, Z) {
        const me = he.length, we = Z.reduce((et, Ve) => et * Ve);
        if (me !== we)
          throw Error(`cannot reshape array of size ${me} into shape (${Z})`);
        let xe = he;
        for (let et = Z.length - 1; et >= 0; et--)
          xe = xe.reduce((Ve, nt) => {
            let Be = Ve[Ve.length - 1];
            return Be.length < Z[et] ? Be.push(nt) : Ve.push([nt]), Ve;
          }, [[]]);
        return xe[0];
      }
      function f(he, Z) {
        const [me, we] = (0, i.permute_data)(he.data, he.dims, Z);
        return new u(he.type, me, we);
      }
      function m(he, [Z, me], we = "bilinear", xe = !1) {
        const et = he.dims.at(-3) ?? 1, Ve = he.dims.at(-2), nt = he.dims.at(-1);
        let Be = (0, i.interpolate_data)(
          /** @type {import('./maths.js').TypedArray}*/
          he.data,
          [et, Ve, nt],
          [Z, me],
          we,
          xe
        );
        return new u(he.type, Be, [et, Z, me]);
      }
      async function h(he, {
        size: Z = null,
        mode: me = "bilinear"
      } = {}) {
        if (he.dims.length !== 4)
          throw new Error("`interpolate_4d` currently only supports 4D input.");
        if (!Z)
          throw new Error("`interpolate_4d` requires a `size` argument.");
        let we;
        if (Z.length === 2)
          we = [...he.dims.slice(0, 2), ...Z];
        else if (Z.length === 3)
          we = [he.dims[0], ...Z];
        else if (Z.length === 4)
          we = Z;
        else
          throw new Error("`size` must be of length 2, 3, or 4.");
        let xe;
        if (me === "nearest")
          xe = await a.TensorOpRegistry.nearest_interpolate_4d;
        else if (me === "bilinear")
          xe = await a.TensorOpRegistry.bilinear_interpolate_4d;
        else if (me === "bicubic")
          xe = await a.TensorOpRegistry.bicubic_interpolate_4d;
        else
          throw new Error(`Unsupported mode: ${me}`);
        const et = new u("int64", new BigInt64Array(we.map(BigInt)), [we.length]);
        return await xe({ x: he, s: et });
      }
      async function p(he, Z) {
        return await (await a.TensorOpRegistry.matmul)({ a: he, b: Z });
      }
      async function _(he, Z) {
        return await (await a.TensorOpRegistry.rfft)({ x: he, a: Z });
      }
      async function v(he, Z) {
        const me = await a.TensorOpRegistry.top_k;
        return Z == null ? Z = he.dims.at(-1) : Z = Math.min(Z, he.dims.at(-1)), await me({
          x: he,
          k: new u(
            "int64",
            [BigInt(Z)],
            [1]
          )
        });
      }
      const S = (he) => new u("int64", he, [he.length]);
      async function D(he, Z, me, we, xe) {
        return await (await a.TensorOpRegistry.slice)({
          x: he,
          s: S(Z),
          e: S(me),
          a: S(we),
          t: S(xe ?? new Array(we.length).fill(1))
        });
      }
      function w(he, Z) {
        const me = he.data, we = Z.data, xe = [he.dims[0], he.dims[2]], et = new me.constructor(xe[0] * xe[1]), [Ve, nt, Be] = he.dims;
        let ae = 0;
        for (let U = 0; U < Ve; ++U) {
          const Se = U * Be * nt;
          for (let ze = 0; ze < Be; ++ze) {
            let Oe = 0, Ye = 0;
            const H = U * nt, Y = Se + ze;
            for (let Ie = 0; Ie < nt; ++Ie) {
              const fe = Number(we[H + Ie]);
              Ye += fe, Oe += me[Y + Ie * Be] * fe;
            }
            const $e = Oe / Ye;
            et[ae++] = $e;
          }
        }
        return new u(
          he.type,
          et,
          xe
        );
      }
      function T(he, Z, {
        eps: me = 1e-5
      } = {}) {
        if (he.dims.length !== 2)
          throw new Error("`layer_norm` currently only supports 2D input.");
        const [we, xe] = he.dims;
        if (Z.length !== 1 && Z[0] !== xe)
          throw new Error("`normalized_shape` must be a 1D array with shape `[input.dims[1]]`.");
        const [et, Ve] = N(he, 1, 0, !0), nt = (
          /** @type {Float32Array} */
          et.data
        ), Be = (
          /** @type {Float32Array} */
          Ve.data
        ), ae = (
          /** @type {Float32Array} */
          he.data
        ), U = new ae.constructor(ae.length);
        for (let Se = 0; Se < we; ++Se) {
          const ze = Se * xe;
          for (let Oe = 0; Oe < xe; ++Oe) {
            const Ye = ze + Oe;
            U[Ye] = (ae[Ye] - Be[Se]) / (nt[Se] + me);
          }
        }
        return new u(he.type, U, he.dims);
      }
      function F(he, Z) {
        return he = he.slice(), Z === null ? he = he.filter((me) => me !== 1) : typeof Z == "number" ? he[Z] === 1 && he.splice(Z, 1) : Array.isArray(Z) && (he = he.filter((me, we) => me !== 1 || !Z.includes(we))), he;
      }
      function E(he, Z) {
        return Z = A(Z, he.length + 1), he = he.slice(), he.splice(Z, 0, 1), he;
      }
      function A(he, Z, me = null, we = !0) {
        if (he < -Z || he >= Z) {
          if (we)
            throw new Error(`IndexError: index ${he} is out of bounds for dimension${me === null ? "" : " " + me} with size ${Z}`);
          return he < -Z ? 0 : Z;
        }
        return he < 0 && (he = (he % Z + Z) % Z), he;
      }
      function L(he, Z = 0) {
        Z = A(Z, he[0].dims.length);
        const me = he[0].dims.slice();
        me[Z] = he.reduce((Ve, nt) => Ve + nt.dims[Z], 0);
        const we = me.reduce((Ve, nt) => Ve * nt, 1), xe = new he[0].data.constructor(we), et = he[0].type;
        if (Z === 0) {
          let Ve = 0;
          for (const nt of he) {
            const Be = nt.data;
            xe.set(Be, Ve), Ve += Be.length;
          }
        } else {
          let Ve = 0;
          for (let nt = 0; nt < he.length; ++nt) {
            const { data: Be, dims: ae } = he[nt];
            for (let U = 0; U < Be.length; ++U) {
              let Se = 0;
              for (let ze = ae.length - 1, Oe = U, Ye = 1; ze >= 0; --ze) {
                const H = ae[ze];
                let Y = Oe % H;
                ze === Z && (Y += Ve), Se += Y * Ye, Ye *= me[ze], Oe = Math.floor(Oe / H);
              }
              xe[Se] = Be[U];
            }
            Ve += ae[Z];
          }
        }
        return new u(et, xe, me);
      }
      function I(he, Z = 0) {
        return L(he.map((me) => me.unsqueeze(Z)), Z);
      }
      function R(he, Z, me = null, we = !1, xe = null) {
        const et = Z.data, Ve = Z.dims;
        me = A(me, Ve.length);
        const nt = Ve.slice();
        nt[me] = 1;
        const Be = new et.constructor(et.length / Ve[me]);
        xe !== null && Be.fill(xe);
        for (let ae = 0; ae < et.length; ++ae) {
          let U = 0;
          for (let Se = Ve.length - 1, ze = ae, Oe = 1; Se >= 0; --Se) {
            const Ye = Ve[Se];
            if (Se !== me) {
              const H = ze % Ye;
              U += H * Oe, Oe *= nt[Se];
            }
            ze = Math.floor(ze / Ye);
          }
          Be[U] = he(Be[U], et[ae], ae, U);
        }
        return we || nt.splice(me, 1), [Z.type, Be, nt];
      }
      function N(he, Z = null, me = 1, we = !1) {
        const xe = (
          /** @type {Float32Array} */
          he.data
        ), et = he.dims;
        if (Z === null) {
          const Oe = xe.reduce(($e, Ie) => $e + Ie, 0) / xe.length, Ye = Math.sqrt(xe.reduce(($e, Ie) => $e + (Ie - Oe) ** 2, 0) / (xe.length - me)), H = new u(he.type, [Oe], [
            /* scalar */
          ]);
          return [new u(he.type, [Ye], [
            /* scalar */
          ]), H];
        }
        Z = A(Z, et.length);
        const Ve = q(he, Z, we), nt = Ve.data, [Be, ae, U] = R((ze, Oe, Ye, H) => ze + (Oe - nt[H]) ** 2, he, Z, we);
        for (let ze = 0; ze < ae.length; ++ze)
          ae[ze] = Math.sqrt(ae[ze] / (et[Z] - me));
        return [new u(Be, ae, U), Ve];
      }
      function q(he, Z = null, me = !1) {
        const we = he.dims, xe = (
          /** @type {Float32Array} */
          he.data
        );
        if (Z === null) {
          const Be = xe.reduce((ae, U) => ae + U, 0);
          return new u(he.type, [Be / xe.length], [
            /* scalar */
          ]);
        }
        Z = A(Z, we.length);
        const [et, Ve, nt] = R((Be, ae) => Be + ae, he, Z, me);
        if (we[Z] !== 1)
          for (let Be = 0; Be < Ve.length; ++Be)
            Ve[Be] /= we[Z];
        return new u(et, Ve, nt);
      }
      function ne(he) {
        const Z = new Array(he.length);
        for (let me = he.length - 1, we = 1; me >= 0; --me)
          Z[me] = we, we *= he[me];
        return Z;
      }
      function Q(he, Z, me, we) {
        const xe = he.reduce((et, Ve) => et * Ve, 1);
        return new u(
          me,
          new we(xe).fill(Z),
          he
        );
      }
      function W(he, Z) {
        let me, we;
        if (typeof Z == "number")
          me = "float32", we = Float32Array;
        else if (typeof Z == "bigint")
          me = "int64", we = BigInt64Array;
        else if (typeof Z == "boolean")
          me = "bool", we = Uint8Array;
        else
          throw new Error(`Unsupported data type: ${typeof Z}`);
        return Q(he, Z, me, we);
      }
      function te(he, Z) {
        return W(he.dims, Z);
      }
      function K(he) {
        return Q(he, 1n, "int64", BigInt64Array);
      }
      function pe(he) {
        return K(he.dims);
      }
      function be(he) {
        return Q(he, 0n, "int64", BigInt64Array);
      }
      function Ee(he) {
        return be(he.dims);
      }
      function Ge(he) {
        const Z = he.reduce((me, we) => me * we, 1);
        return new u(
          "float32",
          Float32Array.from({ length: Z }, () => Math.random()),
          he
        );
      }
      function _e(he) {
        const Z = he.reduce((we, xe) => we * xe, 1);
        function me() {
          const we = 1 - Math.random(), xe = 1 - Math.random();
          return Math.sqrt(-2 * Math.log(we)) * Math.cos(2 * Math.PI * xe);
        }
        return new u(
          "float32",
          Float32Array.from({ length: Z }, () => me()),
          he
        );
      }
      function De(he, Z) {
        if (he.dims.length !== 2)
          throw new Error("The tensor must have 2 dimensions");
        if (he.dims.at(-1) % 8 !== 0)
          throw new Error("The last dimension of the tensor must be a multiple of 8");
        if (!["binary", "ubinary"].includes(Z))
          throw new Error("The precision must be either 'binary' or 'ubinary'");
        const me = Z === "binary", we = me ? "int8" : "uint8", xe = me ? Int8Array : Uint8Array, et = he.data, Ve = new xe(et.length / 8);
        for (let nt = 0; nt < et.length; ++nt) {
          const Be = et[nt] > 0 ? 1 : 0, ae = Math.floor(nt / 8), U = nt % 8;
          Ve[ae] |= Be << 7 - U, me && U === 0 && (Ve[ae] -= 128);
        }
        return new u(we, Ve, [he.dims[0], he.dims[1] / 8]);
      }
    }
  ),
  /***/
  "./src/utils/video.js": (
    /*!****************************!*\
      !*** ./src/utils/video.js ***!
      \****************************/
    /***/
    (e, n, t) => {
      t.r(n), t.d(n, {
        /* harmony export */
        RawVideo: () => (
          /* binding */
          c
        ),
        /* harmony export */
        RawVideoFrame: () => (
          /* binding */
          a
        ),
        /* harmony export */
        load_video: () => (
          /* binding */
          u
        )
        /* harmony export */
      });
      var i = t(
        /*! ./image.js */
        "./src/utils/image.js"
      ), r = t(
        /*! ../env.js */
        "./src/env.js"
      );
      class a {
        /**
         * @param {RawImage} image
         * @param {number} timestamp
         */
        constructor(f, m) {
          this.image = f, this.timestamp = m;
        }
      }
      class c {
        /**
         * @param {RawVideoFrame[]|RawImage[]} frames
         * @param {number} duration
         */
        constructor(f, m) {
          f.length > 0 && f[0] instanceof i.RawImage && (f = f.map((h, p) => new a(h, (p + 1) / (f.length + 1) * m))), this.frames = /** @type {RawVideoFrame[]} */
          f, this.duration = m;
        }
        get width() {
          return this.frames[0].image.width;
        }
        get height() {
          return this.frames[0].image.height;
        }
        get fps() {
          return this.frames.length / this.duration;
        }
      }
      async function u(l, { num_frames: f = null, fps: m = null } = {}) {
        if (!r.apis.IS_BROWSER_ENV)
          throw new Error("`load_video` is currently only supported in browser environments.");
        if (f == null && m == null)
          throw new Error("Either num_frames or fps must be provided.");
        const h = [], p = document.createElement("video");
        if (p.crossOrigin = "anonymous", p.muted = !0, typeof l == "string")
          p.src = l;
        else if (l instanceof Blob)
          p.src = URL.createObjectURL(l);
        else if (l instanceof HTMLVideoElement)
          p.src = l.src;
        else
          throw new Error("Invalid URL or video element provided.");
        if (await new Promise((F) => p.onloadedmetadata = F), p.seekable.start(0) === p.seekable.end(0)) {
          const E = await (await fetch(p.src)).blob();
          p.src = URL.createObjectURL(E), await new Promise((A) => p.onloadedmetadata = A);
        }
        const _ = p.duration;
        let v, S;
        f != null ? (v = f, S = f === 1 ? 0 : _ / (f - 1)) : (S = 1 / m, v = Math.floor(_ / S));
        let D = [];
        for (let F = 0; F < v; ++F)
          D.push(f === 1 ? _ / 2 : F * S);
        const w = document.createElement("canvas");
        w.width = p.videoWidth, w.height = p.videoHeight;
        const T = w.getContext("2d", { willReadFrequently: !0 });
        for (const F of D) {
          p.currentTime = F, await new Promise((I) => {
            p.onseeked = I;
          }), T.drawImage(p, 0, 0, w.width, w.height);
          const E = T.getImageData(0, 0, w.width, w.height), A = new i.RawImage(E.data, w.width, w.height, 4), L = new a(A, F);
          h.push(L);
        }
        return p.remove(), new c(h, _);
      }
    }
  )
  /******/
}, Ix = {};
function xn(e) {
  var n = Ix[e];
  if (n !== void 0)
    return n.exports;
  var t = Ix[e] = {
    /******/
    // no module.id needed
    /******/
    // no module.loaded needed
    /******/
    exports: {}
    /******/
  };
  return QP[e](t, t.exports, xn), t.exports;
}
(() => {
  var e = Object.getPrototypeOf ? (t) => Object.getPrototypeOf(t) : (t) => t.__proto__, n;
  xn.t = function(t, i) {
    if (i & 1 && (t = this(t)), i & 8 || typeof t == "object" && t && (i & 4 && t.__esModule || i & 16 && typeof t.then == "function"))
      return t;
    var r = /* @__PURE__ */ Object.create(null);
    xn.r(r);
    var a = {};
    n = n || [null, e({}), e([]), e(e)];
    for (var c = i & 2 && t; typeof c == "object" && !~n.indexOf(c); c = e(c))
      Object.getOwnPropertyNames(c).forEach((u) => a[u] = () => t[u]);
    return a.default = () => t, xn.d(r, a), r;
  };
})();
xn.d = (e, n) => {
  for (var t in n)
    xn.o(n, t) && !xn.o(e, t) && Object.defineProperty(e, t, { enumerable: !0, get: n[t] });
};
xn.o = (e, n) => Object.prototype.hasOwnProperty.call(e, n);
xn.r = (e) => {
  typeof Symbol < "u" && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, { value: "Module" }), Object.defineProperty(e, "__esModule", { value: !0 });
};
var Oy = {};
(() => {
  /*!*****************************!*\
    !*** ./src/transformers.js ***!
    \*****************************/
  xn.r(Oy), xn.d(Oy, {
    /* harmony export */
    ASTFeatureExtractor: () => (
      /* reexport safe */
      h.ASTFeatureExtractor
    ),
    /* harmony export */
    ASTForAudioClassification: () => (
      /* reexport safe */
      t.ASTForAudioClassification
    ),
    /* harmony export */
    ASTModel: () => (
      /* reexport safe */
      t.ASTModel
    ),
    /* harmony export */
    ASTPreTrainedModel: () => (
      /* reexport safe */
      t.ASTPreTrainedModel
    ),
    /* harmony export */
    AlbertForMaskedLM: () => (
      /* reexport safe */
      t.AlbertForMaskedLM
    ),
    /* harmony export */
    AlbertForQuestionAnswering: () => (
      /* reexport safe */
      t.AlbertForQuestionAnswering
    ),
    /* harmony export */
    AlbertForSequenceClassification: () => (
      /* reexport safe */
      t.AlbertForSequenceClassification
    ),
    /* harmony export */
    AlbertModel: () => (
      /* reexport safe */
      t.AlbertModel
    ),
    /* harmony export */
    AlbertPreTrainedModel: () => (
      /* reexport safe */
      t.AlbertPreTrainedModel
    ),
    /* harmony export */
    AlbertTokenizer: () => (
      /* reexport safe */
      i.AlbertTokenizer
    ),
    /* harmony export */
    ArceeForCausalLM: () => (
      /* reexport safe */
      t.ArceeForCausalLM
    ),
    /* harmony export */
    ArceeModel: () => (
      /* reexport safe */
      t.ArceeModel
    ),
    /* harmony export */
    ArceePreTrainedModel: () => (
      /* reexport safe */
      t.ArceePreTrainedModel
    ),
    /* harmony export */
    AudioClassificationPipeline: () => (
      /* reexport safe */
      n.AudioClassificationPipeline
    ),
    /* harmony export */
    AutoConfig: () => (
      /* reexport safe */
      r.AutoConfig
    ),
    /* harmony export */
    AutoFeatureExtractor: () => (
      /* reexport safe */
      p.AutoFeatureExtractor
    ),
    /* harmony export */
    AutoImageProcessor: () => (
      /* reexport safe */
      S.AutoImageProcessor
    ),
    /* harmony export */
    AutoModel: () => (
      /* reexport safe */
      t.AutoModel
    ),
    /* harmony export */
    AutoModelForAudioClassification: () => (
      /* reexport safe */
      t.AutoModelForAudioClassification
    ),
    /* harmony export */
    AutoModelForAudioFrameClassification: () => (
      /* reexport safe */
      t.AutoModelForAudioFrameClassification
    ),
    /* harmony export */
    AutoModelForAudioTextToText: () => (
      /* reexport safe */
      t.AutoModelForAudioTextToText
    ),
    /* harmony export */
    AutoModelForCTC: () => (
      /* reexport safe */
      t.AutoModelForCTC
    ),
    /* harmony export */
    AutoModelForCausalLM: () => (
      /* reexport safe */
      t.AutoModelForCausalLM
    ),
    /* harmony export */
    AutoModelForDepthEstimation: () => (
      /* reexport safe */
      t.AutoModelForDepthEstimation
    ),
    /* harmony export */
    AutoModelForDocumentQuestionAnswering: () => (
      /* reexport safe */
      t.AutoModelForDocumentQuestionAnswering
    ),
    /* harmony export */
    AutoModelForImageClassification: () => (
      /* reexport safe */
      t.AutoModelForImageClassification
    ),
    /* harmony export */
    AutoModelForImageFeatureExtraction: () => (
      /* reexport safe */
      t.AutoModelForImageFeatureExtraction
    ),
    /* harmony export */
    AutoModelForImageMatting: () => (
      /* reexport safe */
      t.AutoModelForImageMatting
    ),
    /* harmony export */
    AutoModelForImageSegmentation: () => (
      /* reexport safe */
      t.AutoModelForImageSegmentation
    ),
    /* harmony export */
    AutoModelForImageTextToText: () => (
      /* reexport safe */
      t.AutoModelForImageTextToText
    ),
    /* harmony export */
    AutoModelForImageToImage: () => (
      /* reexport safe */
      t.AutoModelForImageToImage
    ),
    /* harmony export */
    AutoModelForMaskGeneration: () => (
      /* reexport safe */
      t.AutoModelForMaskGeneration
    ),
    /* harmony export */
    AutoModelForMaskedLM: () => (
      /* reexport safe */
      t.AutoModelForMaskedLM
    ),
    /* harmony export */
    AutoModelForNormalEstimation: () => (
      /* reexport safe */
      t.AutoModelForNormalEstimation
    ),
    /* harmony export */
    AutoModelForObjectDetection: () => (
      /* reexport safe */
      t.AutoModelForObjectDetection
    ),
    /* harmony export */
    AutoModelForPoseEstimation: () => (
      /* reexport safe */
      t.AutoModelForPoseEstimation
    ),
    /* harmony export */
    AutoModelForQuestionAnswering: () => (
      /* reexport safe */
      t.AutoModelForQuestionAnswering
    ),
    /* harmony export */
    AutoModelForSemanticSegmentation: () => (
      /* reexport safe */
      t.AutoModelForSemanticSegmentation
    ),
    /* harmony export */
    AutoModelForSeq2SeqLM: () => (
      /* reexport safe */
      t.AutoModelForSeq2SeqLM
    ),
    /* harmony export */
    AutoModelForSequenceClassification: () => (
      /* reexport safe */
      t.AutoModelForSequenceClassification
    ),
    /* harmony export */
    AutoModelForSpeechSeq2Seq: () => (
      /* reexport safe */
      t.AutoModelForSpeechSeq2Seq
    ),
    /* harmony export */
    AutoModelForTextToSpectrogram: () => (
      /* reexport safe */
      t.AutoModelForTextToSpectrogram
    ),
    /* harmony export */
    AutoModelForTextToWaveform: () => (
      /* reexport safe */
      t.AutoModelForTextToWaveform
    ),
    /* harmony export */
    AutoModelForTokenClassification: () => (
      /* reexport safe */
      t.AutoModelForTokenClassification
    ),
    /* harmony export */
    AutoModelForUniversalSegmentation: () => (
      /* reexport safe */
      t.AutoModelForUniversalSegmentation
    ),
    /* harmony export */
    AutoModelForVision2Seq: () => (
      /* reexport safe */
      t.AutoModelForVision2Seq
    ),
    /* harmony export */
    AutoModelForXVector: () => (
      /* reexport safe */
      t.AutoModelForXVector
    ),
    /* harmony export */
    AutoModelForZeroShotObjectDetection: () => (
      /* reexport safe */
      t.AutoModelForZeroShotObjectDetection
    ),
    /* harmony export */
    AutoProcessor: () => (
      /* reexport safe */
      T.AutoProcessor
    ),
    /* harmony export */
    AutoTokenizer: () => (
      /* reexport safe */
      i.AutoTokenizer
    ),
    /* harmony export */
    AutomaticSpeechRecognitionPipeline: () => (
      /* reexport safe */
      n.AutomaticSpeechRecognitionPipeline
    ),
    /* harmony export */
    BackgroundRemovalPipeline: () => (
      /* reexport safe */
      n.BackgroundRemovalPipeline
    ),
    /* harmony export */
    BartForConditionalGeneration: () => (
      /* reexport safe */
      t.BartForConditionalGeneration
    ),
    /* harmony export */
    BartForSequenceClassification: () => (
      /* reexport safe */
      t.BartForSequenceClassification
    ),
    /* harmony export */
    BartModel: () => (
      /* reexport safe */
      t.BartModel
    ),
    /* harmony export */
    BartPretrainedModel: () => (
      /* reexport safe */
      t.BartPretrainedModel
    ),
    /* harmony export */
    BartTokenizer: () => (
      /* reexport safe */
      i.BartTokenizer
    ),
    /* harmony export */
    BaseModelOutput: () => (
      /* reexport safe */
      t.BaseModelOutput
    ),
    /* harmony export */
    BaseStreamer: () => (
      /* reexport safe */
      F.BaseStreamer
    ),
    /* harmony export */
    BeitFeatureExtractor: () => (
      /* reexport safe */
      v.BeitFeatureExtractor
    ),
    /* harmony export */
    BeitForImageClassification: () => (
      /* reexport safe */
      t.BeitForImageClassification
    ),
    /* harmony export */
    BeitModel: () => (
      /* reexport safe */
      t.BeitModel
    ),
    /* harmony export */
    BeitPreTrainedModel: () => (
      /* reexport safe */
      t.BeitPreTrainedModel
    ),
    /* harmony export */
    BertForMaskedLM: () => (
      /* reexport safe */
      t.BertForMaskedLM
    ),
    /* harmony export */
    BertForQuestionAnswering: () => (
      /* reexport safe */
      t.BertForQuestionAnswering
    ),
    /* harmony export */
    BertForSequenceClassification: () => (
      /* reexport safe */
      t.BertForSequenceClassification
    ),
    /* harmony export */
    BertForTokenClassification: () => (
      /* reexport safe */
      t.BertForTokenClassification
    ),
    /* harmony export */
    BertModel: () => (
      /* reexport safe */
      t.BertModel
    ),
    /* harmony export */
    BertPreTrainedModel: () => (
      /* reexport safe */
      t.BertPreTrainedModel
    ),
    /* harmony export */
    BertTokenizer: () => (
      /* reexport safe */
      i.BertTokenizer
    ),
    /* harmony export */
    BitImageProcessor: () => (
      /* reexport safe */
      v.BitImageProcessor
    ),
    /* harmony export */
    BlenderbotForConditionalGeneration: () => (
      /* reexport safe */
      t.BlenderbotForConditionalGeneration
    ),
    /* harmony export */
    BlenderbotModel: () => (
      /* reexport safe */
      t.BlenderbotModel
    ),
    /* harmony export */
    BlenderbotPreTrainedModel: () => (
      /* reexport safe */
      t.BlenderbotPreTrainedModel
    ),
    /* harmony export */
    BlenderbotSmallForConditionalGeneration: () => (
      /* reexport safe */
      t.BlenderbotSmallForConditionalGeneration
    ),
    /* harmony export */
    BlenderbotSmallModel: () => (
      /* reexport safe */
      t.BlenderbotSmallModel
    ),
    /* harmony export */
    BlenderbotSmallPreTrainedModel: () => (
      /* reexport safe */
      t.BlenderbotSmallPreTrainedModel
    ),
    /* harmony export */
    BlenderbotSmallTokenizer: () => (
      /* reexport safe */
      i.BlenderbotSmallTokenizer
    ),
    /* harmony export */
    BlenderbotTokenizer: () => (
      /* reexport safe */
      i.BlenderbotTokenizer
    ),
    /* harmony export */
    BloomForCausalLM: () => (
      /* reexport safe */
      t.BloomForCausalLM
    ),
    /* harmony export */
    BloomModel: () => (
      /* reexport safe */
      t.BloomModel
    ),
    /* harmony export */
    BloomPreTrainedModel: () => (
      /* reexport safe */
      t.BloomPreTrainedModel
    ),
    /* harmony export */
    BloomTokenizer: () => (
      /* reexport safe */
      i.BloomTokenizer
    ),
    /* harmony export */
    CLIPFeatureExtractor: () => (
      /* reexport safe */
      v.CLIPFeatureExtractor
    ),
    /* harmony export */
    CLIPImageProcessor: () => (
      /* reexport safe */
      v.CLIPImageProcessor
    ),
    /* harmony export */
    CLIPModel: () => (
      /* reexport safe */
      t.CLIPModel
    ),
    /* harmony export */
    CLIPPreTrainedModel: () => (
      /* reexport safe */
      t.CLIPPreTrainedModel
    ),
    /* harmony export */
    CLIPSegForImageSegmentation: () => (
      /* reexport safe */
      t.CLIPSegForImageSegmentation
    ),
    /* harmony export */
    CLIPSegModel: () => (
      /* reexport safe */
      t.CLIPSegModel
    ),
    /* harmony export */
    CLIPSegPreTrainedModel: () => (
      /* reexport safe */
      t.CLIPSegPreTrainedModel
    ),
    /* harmony export */
    CLIPTextModel: () => (
      /* reexport safe */
      t.CLIPTextModel
    ),
    /* harmony export */
    CLIPTextModelWithProjection: () => (
      /* reexport safe */
      t.CLIPTextModelWithProjection
    ),
    /* harmony export */
    CLIPTokenizer: () => (
      /* reexport safe */
      i.CLIPTokenizer
    ),
    /* harmony export */
    CLIPVisionModel: () => (
      /* reexport safe */
      t.CLIPVisionModel
    ),
    /* harmony export */
    CLIPVisionModelWithProjection: () => (
      /* reexport safe */
      t.CLIPVisionModelWithProjection
    ),
    /* harmony export */
    CamembertForMaskedLM: () => (
      /* reexport safe */
      t.CamembertForMaskedLM
    ),
    /* harmony export */
    CamembertForQuestionAnswering: () => (
      /* reexport safe */
      t.CamembertForQuestionAnswering
    ),
    /* harmony export */
    CamembertForSequenceClassification: () => (
      /* reexport safe */
      t.CamembertForSequenceClassification
    ),
    /* harmony export */
    CamembertForTokenClassification: () => (
      /* reexport safe */
      t.CamembertForTokenClassification
    ),
    /* harmony export */
    CamembertModel: () => (
      /* reexport safe */
      t.CamembertModel
    ),
    /* harmony export */
    CamembertPreTrainedModel: () => (
      /* reexport safe */
      t.CamembertPreTrainedModel
    ),
    /* harmony export */
    CamembertTokenizer: () => (
      /* reexport safe */
      i.CamembertTokenizer
    ),
    /* harmony export */
    CausalLMOutput: () => (
      /* reexport safe */
      t.CausalLMOutput
    ),
    /* harmony export */
    CausalLMOutputWithPast: () => (
      /* reexport safe */
      t.CausalLMOutputWithPast
    ),
    /* harmony export */
    ChineseCLIPFeatureExtractor: () => (
      /* reexport safe */
      v.ChineseCLIPFeatureExtractor
    ),
    /* harmony export */
    ChineseCLIPModel: () => (
      /* reexport safe */
      t.ChineseCLIPModel
    ),
    /* harmony export */
    ChineseCLIPPreTrainedModel: () => (
      /* reexport safe */
      t.ChineseCLIPPreTrainedModel
    ),
    /* harmony export */
    ClapAudioModelWithProjection: () => (
      /* reexport safe */
      t.ClapAudioModelWithProjection
    ),
    /* harmony export */
    ClapFeatureExtractor: () => (
      /* reexport safe */
      h.ClapFeatureExtractor
    ),
    /* harmony export */
    ClapModel: () => (
      /* reexport safe */
      t.ClapModel
    ),
    /* harmony export */
    ClapPreTrainedModel: () => (
      /* reexport safe */
      t.ClapPreTrainedModel
    ),
    /* harmony export */
    ClapTextModelWithProjection: () => (
      /* reexport safe */
      t.ClapTextModelWithProjection
    ),
    /* harmony export */
    ClassifierFreeGuidanceLogitsProcessor: () => (
      /* reexport safe */
      A.ClassifierFreeGuidanceLogitsProcessor
    ),
    /* harmony export */
    CodeGenForCausalLM: () => (
      /* reexport safe */
      t.CodeGenForCausalLM
    ),
    /* harmony export */
    CodeGenModel: () => (
      /* reexport safe */
      t.CodeGenModel
    ),
    /* harmony export */
    CodeGenPreTrainedModel: () => (
      /* reexport safe */
      t.CodeGenPreTrainedModel
    ),
    /* harmony export */
    CodeGenTokenizer: () => (
      /* reexport safe */
      i.CodeGenTokenizer
    ),
    /* harmony export */
    CodeLlamaTokenizer: () => (
      /* reexport safe */
      i.CodeLlamaTokenizer
    ),
    /* harmony export */
    CohereForCausalLM: () => (
      /* reexport safe */
      t.CohereForCausalLM
    ),
    /* harmony export */
    CohereModel: () => (
      /* reexport safe */
      t.CohereModel
    ),
    /* harmony export */
    CoherePreTrainedModel: () => (
      /* reexport safe */
      t.CoherePreTrainedModel
    ),
    /* harmony export */
    CohereTokenizer: () => (
      /* reexport safe */
      i.CohereTokenizer
    ),
    /* harmony export */
    ConvBertForMaskedLM: () => (
      /* reexport safe */
      t.ConvBertForMaskedLM
    ),
    /* harmony export */
    ConvBertForQuestionAnswering: () => (
      /* reexport safe */
      t.ConvBertForQuestionAnswering
    ),
    /* harmony export */
    ConvBertForSequenceClassification: () => (
      /* reexport safe */
      t.ConvBertForSequenceClassification
    ),
    /* harmony export */
    ConvBertForTokenClassification: () => (
      /* reexport safe */
      t.ConvBertForTokenClassification
    ),
    /* harmony export */
    ConvBertModel: () => (
      /* reexport safe */
      t.ConvBertModel
    ),
    /* harmony export */
    ConvBertPreTrainedModel: () => (
      /* reexport safe */
      t.ConvBertPreTrainedModel
    ),
    /* harmony export */
    ConvBertTokenizer: () => (
      /* reexport safe */
      i.ConvBertTokenizer
    ),
    /* harmony export */
    ConvNextFeatureExtractor: () => (
      /* reexport safe */
      v.ConvNextFeatureExtractor
    ),
    /* harmony export */
    ConvNextForImageClassification: () => (
      /* reexport safe */
      t.ConvNextForImageClassification
    ),
    /* harmony export */
    ConvNextImageProcessor: () => (
      /* reexport safe */
      v.ConvNextImageProcessor
    ),
    /* harmony export */
    ConvNextModel: () => (
      /* reexport safe */
      t.ConvNextModel
    ),
    /* harmony export */
    ConvNextPreTrainedModel: () => (
      /* reexport safe */
      t.ConvNextPreTrainedModel
    ),
    /* harmony export */
    ConvNextV2ForImageClassification: () => (
      /* reexport safe */
      t.ConvNextV2ForImageClassification
    ),
    /* harmony export */
    ConvNextV2Model: () => (
      /* reexport safe */
      t.ConvNextV2Model
    ),
    /* harmony export */
    ConvNextV2PreTrainedModel: () => (
      /* reexport safe */
      t.ConvNextV2PreTrainedModel
    ),
    /* harmony export */
    DFineForObjectDetection: () => (
      /* reexport safe */
      t.DFineForObjectDetection
    ),
    /* harmony export */
    DFineModel: () => (
      /* reexport safe */
      t.DFineModel
    ),
    /* harmony export */
    DFinePreTrainedModel: () => (
      /* reexport safe */
      t.DFinePreTrainedModel
    ),
    /* harmony export */
    DINOv3ConvNextModel: () => (
      /* reexport safe */
      t.DINOv3ConvNextModel
    ),
    /* harmony export */
    DINOv3ConvNextPreTrainedModel: () => (
      /* reexport safe */
      t.DINOv3ConvNextPreTrainedModel
    ),
    /* harmony export */
    DINOv3ViTImageProcessor: () => (
      /* reexport safe */
      v.DINOv3ViTImageProcessor
    ),
    /* harmony export */
    DINOv3ViTModel: () => (
      /* reexport safe */
      t.DINOv3ViTModel
    ),
    /* harmony export */
    DINOv3ViTPreTrainedModel: () => (
      /* reexport safe */
      t.DINOv3ViTPreTrainedModel
    ),
    /* harmony export */
    DPTFeatureExtractor: () => (
      /* reexport safe */
      v.DPTFeatureExtractor
    ),
    /* harmony export */
    DPTForDepthEstimation: () => (
      /* reexport safe */
      t.DPTForDepthEstimation
    ),
    /* harmony export */
    DPTImageProcessor: () => (
      /* reexport safe */
      v.DPTImageProcessor
    ),
    /* harmony export */
    DPTModel: () => (
      /* reexport safe */
      t.DPTModel
    ),
    /* harmony export */
    DPTPreTrainedModel: () => (
      /* reexport safe */
      t.DPTPreTrainedModel
    ),
    /* harmony export */
    DacDecoderModel: () => (
      /* reexport safe */
      t.DacDecoderModel
    ),
    /* harmony export */
    DacDecoderOutput: () => (
      /* reexport safe */
      t.DacDecoderOutput
    ),
    /* harmony export */
    DacEncoderModel: () => (
      /* reexport safe */
      t.DacEncoderModel
    ),
    /* harmony export */
    DacEncoderOutput: () => (
      /* reexport safe */
      t.DacEncoderOutput
    ),
    /* harmony export */
    DacFeatureExtractor: () => (
      /* reexport safe */
      h.DacFeatureExtractor
    ),
    /* harmony export */
    DacModel: () => (
      /* reexport safe */
      t.DacModel
    ),
    /* harmony export */
    DacPreTrainedModel: () => (
      /* reexport safe */
      t.DacPreTrainedModel
    ),
    /* harmony export */
    DataTypeMap: () => (
      /* reexport safe */
      l.DataTypeMap
    ),
    /* harmony export */
    DebertaForMaskedLM: () => (
      /* reexport safe */
      t.DebertaForMaskedLM
    ),
    /* harmony export */
    DebertaForQuestionAnswering: () => (
      /* reexport safe */
      t.DebertaForQuestionAnswering
    ),
    /* harmony export */
    DebertaForSequenceClassification: () => (
      /* reexport safe */
      t.DebertaForSequenceClassification
    ),
    /* harmony export */
    DebertaForTokenClassification: () => (
      /* reexport safe */
      t.DebertaForTokenClassification
    ),
    /* harmony export */
    DebertaModel: () => (
      /* reexport safe */
      t.DebertaModel
    ),
    /* harmony export */
    DebertaPreTrainedModel: () => (
      /* reexport safe */
      t.DebertaPreTrainedModel
    ),
    /* harmony export */
    DebertaTokenizer: () => (
      /* reexport safe */
      i.DebertaTokenizer
    ),
    /* harmony export */
    DebertaV2ForMaskedLM: () => (
      /* reexport safe */
      t.DebertaV2ForMaskedLM
    ),
    /* harmony export */
    DebertaV2ForQuestionAnswering: () => (
      /* reexport safe */
      t.DebertaV2ForQuestionAnswering
    ),
    /* harmony export */
    DebertaV2ForSequenceClassification: () => (
      /* reexport safe */
      t.DebertaV2ForSequenceClassification
    ),
    /* harmony export */
    DebertaV2ForTokenClassification: () => (
      /* reexport safe */
      t.DebertaV2ForTokenClassification
    ),
    /* harmony export */
    DebertaV2Model: () => (
      /* reexport safe */
      t.DebertaV2Model
    ),
    /* harmony export */
    DebertaV2PreTrainedModel: () => (
      /* reexport safe */
      t.DebertaV2PreTrainedModel
    ),
    /* harmony export */
    DebertaV2Tokenizer: () => (
      /* reexport safe */
      i.DebertaV2Tokenizer
    ),
    /* harmony export */
    DecisionTransformerModel: () => (
      /* reexport safe */
      t.DecisionTransformerModel
    ),
    /* harmony export */
    DecisionTransformerPreTrainedModel: () => (
      /* reexport safe */
      t.DecisionTransformerPreTrainedModel
    ),
    /* harmony export */
    DeiTFeatureExtractor: () => (
      /* reexport safe */
      v.DeiTFeatureExtractor
    ),
    /* harmony export */
    DeiTForImageClassification: () => (
      /* reexport safe */
      t.DeiTForImageClassification
    ),
    /* harmony export */
    DeiTImageProcessor: () => (
      /* reexport safe */
      v.DeiTImageProcessor
    ),
    /* harmony export */
    DeiTModel: () => (
      /* reexport safe */
      t.DeiTModel
    ),
    /* harmony export */
    DeiTPreTrainedModel: () => (
      /* reexport safe */
      t.DeiTPreTrainedModel
    ),
    /* harmony export */
    DepthAnythingForDepthEstimation: () => (
      /* reexport safe */
      t.DepthAnythingForDepthEstimation
    ),
    /* harmony export */
    DepthAnythingPreTrainedModel: () => (
      /* reexport safe */
      t.DepthAnythingPreTrainedModel
    ),
    /* harmony export */
    DepthEstimationPipeline: () => (
      /* reexport safe */
      n.DepthEstimationPipeline
    ),
    /* harmony export */
    DepthProForDepthEstimation: () => (
      /* reexport safe */
      t.DepthProForDepthEstimation
    ),
    /* harmony export */
    DepthProPreTrainedModel: () => (
      /* reexport safe */
      t.DepthProPreTrainedModel
    ),
    /* harmony export */
    DetrFeatureExtractor: () => (
      /* reexport safe */
      v.DetrFeatureExtractor
    ),
    /* harmony export */
    DetrForObjectDetection: () => (
      /* reexport safe */
      t.DetrForObjectDetection
    ),
    /* harmony export */
    DetrForSegmentation: () => (
      /* reexport safe */
      t.DetrForSegmentation
    ),
    /* harmony export */
    DetrImageProcessor: () => (
      /* reexport safe */
      v.DetrImageProcessor
    ),
    /* harmony export */
    DetrModel: () => (
      /* reexport safe */
      t.DetrModel
    ),
    /* harmony export */
    DetrObjectDetectionOutput: () => (
      /* reexport safe */
      t.DetrObjectDetectionOutput
    ),
    /* harmony export */
    DetrPreTrainedModel: () => (
      /* reexport safe */
      t.DetrPreTrainedModel
    ),
    /* harmony export */
    DetrSegmentationOutput: () => (
      /* reexport safe */
      t.DetrSegmentationOutput
    ),
    /* harmony export */
    Dinov2ForImageClassification: () => (
      /* reexport safe */
      t.Dinov2ForImageClassification
    ),
    /* harmony export */
    Dinov2Model: () => (
      /* reexport safe */
      t.Dinov2Model
    ),
    /* harmony export */
    Dinov2PreTrainedModel: () => (
      /* reexport safe */
      t.Dinov2PreTrainedModel
    ),
    /* harmony export */
    Dinov2WithRegistersForImageClassification: () => (
      /* reexport safe */
      t.Dinov2WithRegistersForImageClassification
    ),
    /* harmony export */
    Dinov2WithRegistersModel: () => (
      /* reexport safe */
      t.Dinov2WithRegistersModel
    ),
    /* harmony export */
    Dinov2WithRegistersPreTrainedModel: () => (
      /* reexport safe */
      t.Dinov2WithRegistersPreTrainedModel
    ),
    /* harmony export */
    DistilBertForMaskedLM: () => (
      /* reexport safe */
      t.DistilBertForMaskedLM
    ),
    /* harmony export */
    DistilBertForQuestionAnswering: () => (
      /* reexport safe */
      t.DistilBertForQuestionAnswering
    ),
    /* harmony export */
    DistilBertForSequenceClassification: () => (
      /* reexport safe */
      t.DistilBertForSequenceClassification
    ),
    /* harmony export */
    DistilBertForTokenClassification: () => (
      /* reexport safe */
      t.DistilBertForTokenClassification
    ),
    /* harmony export */
    DistilBertModel: () => (
      /* reexport safe */
      t.DistilBertModel
    ),
    /* harmony export */
    DistilBertPreTrainedModel: () => (
      /* reexport safe */
      t.DistilBertPreTrainedModel
    ),
    /* harmony export */
    DistilBertTokenizer: () => (
      /* reexport safe */
      i.DistilBertTokenizer
    ),
    /* harmony export */
    DocumentQuestionAnsweringPipeline: () => (
      /* reexport safe */
      n.DocumentQuestionAnsweringPipeline
    ),
    /* harmony export */
    DonutFeatureExtractor: () => (
      /* reexport safe */
      v.DonutFeatureExtractor
    ),
    /* harmony export */
    DonutImageProcessor: () => (
      /* reexport safe */
      v.DonutImageProcessor
    ),
    /* harmony export */
    DonutSwinModel: () => (
      /* reexport safe */
      t.DonutSwinModel
    ),
    /* harmony export */
    DonutSwinPreTrainedModel: () => (
      /* reexport safe */
      t.DonutSwinPreTrainedModel
    ),
    /* harmony export */
    EdgeTamModel: () => (
      /* reexport safe */
      t.EdgeTamModel
    ),
    /* harmony export */
    EfficientNetForImageClassification: () => (
      /* reexport safe */
      t.EfficientNetForImageClassification
    ),
    /* harmony export */
    EfficientNetImageProcessor: () => (
      /* reexport safe */
      v.EfficientNetImageProcessor
    ),
    /* harmony export */
    EfficientNetModel: () => (
      /* reexport safe */
      t.EfficientNetModel
    ),
    /* harmony export */
    EfficientNetPreTrainedModel: () => (
      /* reexport safe */
      t.EfficientNetPreTrainedModel
    ),
    /* harmony export */
    ElectraForMaskedLM: () => (
      /* reexport safe */
      t.ElectraForMaskedLM
    ),
    /* harmony export */
    ElectraForQuestionAnswering: () => (
      /* reexport safe */
      t.ElectraForQuestionAnswering
    ),
    /* harmony export */
    ElectraForSequenceClassification: () => (
      /* reexport safe */
      t.ElectraForSequenceClassification
    ),
    /* harmony export */
    ElectraForTokenClassification: () => (
      /* reexport safe */
      t.ElectraForTokenClassification
    ),
    /* harmony export */
    ElectraModel: () => (
      /* reexport safe */
      t.ElectraModel
    ),
    /* harmony export */
    ElectraPreTrainedModel: () => (
      /* reexport safe */
      t.ElectraPreTrainedModel
    ),
    /* harmony export */
    ElectraTokenizer: () => (
      /* reexport safe */
      i.ElectraTokenizer
    ),
    /* harmony export */
    EncodecFeatureExtractor: () => (
      /* reexport safe */
      h.EncodecFeatureExtractor
    ),
    /* harmony export */
    EosTokenCriteria: () => (
      /* reexport safe */
      E.EosTokenCriteria
    ),
    /* harmony export */
    Ernie4_5ForCausalLM: () => (
      /* reexport safe */
      t.Ernie4_5ForCausalLM
    ),
    /* harmony export */
    Ernie4_5Model: () => (
      /* reexport safe */
      t.Ernie4_5Model
    ),
    /* harmony export */
    Ernie4_5PreTrainedModel: () => (
      /* reexport safe */
      t.Ernie4_5PreTrainedModel
    ),
    /* harmony export */
    EsmForMaskedLM: () => (
      /* reexport safe */
      t.EsmForMaskedLM
    ),
    /* harmony export */
    EsmForSequenceClassification: () => (
      /* reexport safe */
      t.EsmForSequenceClassification
    ),
    /* harmony export */
    EsmForTokenClassification: () => (
      /* reexport safe */
      t.EsmForTokenClassification
    ),
    /* harmony export */
    EsmModel: () => (
      /* reexport safe */
      t.EsmModel
    ),
    /* harmony export */
    EsmPreTrainedModel: () => (
      /* reexport safe */
      t.EsmPreTrainedModel
    ),
    /* harmony export */
    EsmTokenizer: () => (
      /* reexport safe */
      i.EsmTokenizer
    ),
    /* harmony export */
    ExaoneForCausalLM: () => (
      /* reexport safe */
      t.ExaoneForCausalLM
    ),
    /* harmony export */
    ExaoneModel: () => (
      /* reexport safe */
      t.ExaoneModel
    ),
    /* harmony export */
    ExaonePreTrainedModel: () => (
      /* reexport safe */
      t.ExaonePreTrainedModel
    ),
    /* harmony export */
    FFT: () => (
      /* reexport safe */
      f.FFT
    ),
    /* harmony export */
    FalconForCausalLM: () => (
      /* reexport safe */
      t.FalconForCausalLM
    ),
    /* harmony export */
    FalconModel: () => (
      /* reexport safe */
      t.FalconModel
    ),
    /* harmony export */
    FalconPreTrainedModel: () => (
      /* reexport safe */
      t.FalconPreTrainedModel
    ),
    /* harmony export */
    FalconTokenizer: () => (
      /* reexport safe */
      i.FalconTokenizer
    ),
    /* harmony export */
    FastViTForImageClassification: () => (
      /* reexport safe */
      t.FastViTForImageClassification
    ),
    /* harmony export */
    FastViTModel: () => (
      /* reexport safe */
      t.FastViTModel
    ),
    /* harmony export */
    FastViTPreTrainedModel: () => (
      /* reexport safe */
      t.FastViTPreTrainedModel
    ),
    /* harmony export */
    FeatureExtractionPipeline: () => (
      /* reexport safe */
      n.FeatureExtractionPipeline
    ),
    /* harmony export */
    FeatureExtractor: () => (
      /* reexport safe */
      m.FeatureExtractor
    ),
    /* harmony export */
    FillMaskPipeline: () => (
      /* reexport safe */
      n.FillMaskPipeline
    ),
    /* harmony export */
    Florence2ForConditionalGeneration: () => (
      /* reexport safe */
      t.Florence2ForConditionalGeneration
    ),
    /* harmony export */
    Florence2PreTrainedModel: () => (
      /* reexport safe */
      t.Florence2PreTrainedModel
    ),
    /* harmony export */
    Florence2Processor: () => (
      /* reexport safe */
      w.Florence2Processor
    ),
    /* harmony export */
    ForcedBOSTokenLogitsProcessor: () => (
      /* reexport safe */
      A.ForcedBOSTokenLogitsProcessor
    ),
    /* harmony export */
    ForcedEOSTokenLogitsProcessor: () => (
      /* reexport safe */
      A.ForcedEOSTokenLogitsProcessor
    ),
    /* harmony export */
    GLPNFeatureExtractor: () => (
      /* reexport safe */
      v.GLPNFeatureExtractor
    ),
    /* harmony export */
    GLPNForDepthEstimation: () => (
      /* reexport safe */
      t.GLPNForDepthEstimation
    ),
    /* harmony export */
    GLPNModel: () => (
      /* reexport safe */
      t.GLPNModel
    ),
    /* harmony export */
    GLPNPreTrainedModel: () => (
      /* reexport safe */
      t.GLPNPreTrainedModel
    ),
    /* harmony export */
    GPT2LMHeadModel: () => (
      /* reexport safe */
      t.GPT2LMHeadModel
    ),
    /* harmony export */
    GPT2Model: () => (
      /* reexport safe */
      t.GPT2Model
    ),
    /* harmony export */
    GPT2PreTrainedModel: () => (
      /* reexport safe */
      t.GPT2PreTrainedModel
    ),
    /* harmony export */
    GPT2Tokenizer: () => (
      /* reexport safe */
      i.GPT2Tokenizer
    ),
    /* harmony export */
    GPTBigCodeForCausalLM: () => (
      /* reexport safe */
      t.GPTBigCodeForCausalLM
    ),
    /* harmony export */
    GPTBigCodeModel: () => (
      /* reexport safe */
      t.GPTBigCodeModel
    ),
    /* harmony export */
    GPTBigCodePreTrainedModel: () => (
      /* reexport safe */
      t.GPTBigCodePreTrainedModel
    ),
    /* harmony export */
    GPTJForCausalLM: () => (
      /* reexport safe */
      t.GPTJForCausalLM
    ),
    /* harmony export */
    GPTJModel: () => (
      /* reexport safe */
      t.GPTJModel
    ),
    /* harmony export */
    GPTJPreTrainedModel: () => (
      /* reexport safe */
      t.GPTJPreTrainedModel
    ),
    /* harmony export */
    GPTNeoForCausalLM: () => (
      /* reexport safe */
      t.GPTNeoForCausalLM
    ),
    /* harmony export */
    GPTNeoModel: () => (
      /* reexport safe */
      t.GPTNeoModel
    ),
    /* harmony export */
    GPTNeoPreTrainedModel: () => (
      /* reexport safe */
      t.GPTNeoPreTrainedModel
    ),
    /* harmony export */
    GPTNeoXForCausalLM: () => (
      /* reexport safe */
      t.GPTNeoXForCausalLM
    ),
    /* harmony export */
    GPTNeoXModel: () => (
      /* reexport safe */
      t.GPTNeoXModel
    ),
    /* harmony export */
    GPTNeoXPreTrainedModel: () => (
      /* reexport safe */
      t.GPTNeoXPreTrainedModel
    ),
    /* harmony export */
    GPTNeoXTokenizer: () => (
      /* reexport safe */
      i.GPTNeoXTokenizer
    ),
    /* harmony export */
    Gemma2ForCausalLM: () => (
      /* reexport safe */
      t.Gemma2ForCausalLM
    ),
    /* harmony export */
    Gemma2Model: () => (
      /* reexport safe */
      t.Gemma2Model
    ),
    /* harmony export */
    Gemma2PreTrainedModel: () => (
      /* reexport safe */
      t.Gemma2PreTrainedModel
    ),
    /* harmony export */
    Gemma3ForCausalLM: () => (
      /* reexport safe */
      t.Gemma3ForCausalLM
    ),
    /* harmony export */
    Gemma3Model: () => (
      /* reexport safe */
      t.Gemma3Model
    ),
    /* harmony export */
    Gemma3PreTrainedModel: () => (
      /* reexport safe */
      t.Gemma3PreTrainedModel
    ),
    /* harmony export */
    Gemma3nAudioFeatureExtractor: () => (
      /* reexport safe */
      h.Gemma3nAudioFeatureExtractor
    ),
    /* harmony export */
    Gemma3nForConditionalGeneration: () => (
      /* reexport safe */
      t.Gemma3nForConditionalGeneration
    ),
    /* harmony export */
    Gemma3nPreTrainedModel: () => (
      /* reexport safe */
      t.Gemma3nPreTrainedModel
    ),
    /* harmony export */
    Gemma3nProcessor: () => (
      /* reexport safe */
      w.Gemma3nProcessor
    ),
    /* harmony export */
    GemmaForCausalLM: () => (
      /* reexport safe */
      t.GemmaForCausalLM
    ),
    /* harmony export */
    GemmaModel: () => (
      /* reexport safe */
      t.GemmaModel
    ),
    /* harmony export */
    GemmaPreTrainedModel: () => (
      /* reexport safe */
      t.GemmaPreTrainedModel
    ),
    /* harmony export */
    GemmaTokenizer: () => (
      /* reexport safe */
      i.GemmaTokenizer
    ),
    /* harmony export */
    GlmForCausalLM: () => (
      /* reexport safe */
      t.GlmForCausalLM
    ),
    /* harmony export */
    GlmModel: () => (
      /* reexport safe */
      t.GlmModel
    ),
    /* harmony export */
    GlmPreTrainedModel: () => (
      /* reexport safe */
      t.GlmPreTrainedModel
    ),
    /* harmony export */
    GraniteForCausalLM: () => (
      /* reexport safe */
      t.GraniteForCausalLM
    ),
    /* harmony export */
    GraniteModel: () => (
      /* reexport safe */
      t.GraniteModel
    ),
    /* harmony export */
    GraniteMoeHybridForCausalLM: () => (
      /* reexport safe */
      t.GraniteMoeHybridForCausalLM
    ),
    /* harmony export */
    GraniteMoeHybridModel: () => (
      /* reexport safe */
      t.GraniteMoeHybridModel
    ),
    /* harmony export */
    GraniteMoeHybridPreTrainedModel: () => (
      /* reexport safe */
      t.GraniteMoeHybridPreTrainedModel
    ),
    /* harmony export */
    GranitePreTrainedModel: () => (
      /* reexport safe */
      t.GranitePreTrainedModel
    ),
    /* harmony export */
    Grok1Tokenizer: () => (
      /* reexport safe */
      i.Grok1Tokenizer
    ),
    /* harmony export */
    GroundingDinoForObjectDetection: () => (
      /* reexport safe */
      t.GroundingDinoForObjectDetection
    ),
    /* harmony export */
    GroundingDinoImageProcessor: () => (
      /* reexport safe */
      v.GroundingDinoImageProcessor
    ),
    /* harmony export */
    GroundingDinoPreTrainedModel: () => (
      /* reexport safe */
      t.GroundingDinoPreTrainedModel
    ),
    /* harmony export */
    GroundingDinoProcessor: () => (
      /* reexport safe */
      w.GroundingDinoProcessor
    ),
    /* harmony export */
    GroupViTModel: () => (
      /* reexport safe */
      t.GroupViTModel
    ),
    /* harmony export */
    GroupViTPreTrainedModel: () => (
      /* reexport safe */
      t.GroupViTPreTrainedModel
    ),
    /* harmony export */
    HeliumForCausalLM: () => (
      /* reexport safe */
      t.HeliumForCausalLM
    ),
    /* harmony export */
    HeliumModel: () => (
      /* reexport safe */
      t.HeliumModel
    ),
    /* harmony export */
    HeliumPreTrainedModel: () => (
      /* reexport safe */
      t.HeliumPreTrainedModel
    ),
    /* harmony export */
    HerbertTokenizer: () => (
      /* reexport safe */
      i.HerbertTokenizer
    ),
    /* harmony export */
    HieraForImageClassification: () => (
      /* reexport safe */
      t.HieraForImageClassification
    ),
    /* harmony export */
    HieraModel: () => (
      /* reexport safe */
      t.HieraModel
    ),
    /* harmony export */
    HieraPreTrainedModel: () => (
      /* reexport safe */
      t.HieraPreTrainedModel
    ),
    /* harmony export */
    HubertForCTC: () => (
      /* reexport safe */
      t.HubertForCTC
    ),
    /* harmony export */
    HubertForSequenceClassification: () => (
      /* reexport safe */
      t.HubertForSequenceClassification
    ),
    /* harmony export */
    HubertModel: () => (
      /* reexport safe */
      t.HubertModel
    ),
    /* harmony export */
    HubertPreTrainedModel: () => (
      /* reexport safe */
      t.HubertPreTrainedModel
    ),
    /* harmony export */
    IJepaForImageClassification: () => (
      /* reexport safe */
      t.IJepaForImageClassification
    ),
    /* harmony export */
    IJepaModel: () => (
      /* reexport safe */
      t.IJepaModel
    ),
    /* harmony export */
    IJepaPreTrainedModel: () => (
      /* reexport safe */
      t.IJepaPreTrainedModel
    ),
    /* harmony export */
    Idefics3ForConditionalGeneration: () => (
      /* reexport safe */
      t.Idefics3ForConditionalGeneration
    ),
    /* harmony export */
    Idefics3ImageProcessor: () => (
      /* reexport safe */
      v.Idefics3ImageProcessor
    ),
    /* harmony export */
    Idefics3PreTrainedModel: () => (
      /* reexport safe */
      t.Idefics3PreTrainedModel
    ),
    /* harmony export */
    Idefics3Processor: () => (
      /* reexport safe */
      w.Idefics3Processor
    ),
    /* harmony export */
    ImageClassificationPipeline: () => (
      /* reexport safe */
      n.ImageClassificationPipeline
    ),
    /* harmony export */
    ImageFeatureExtractionPipeline: () => (
      /* reexport safe */
      n.ImageFeatureExtractionPipeline
    ),
    /* harmony export */
    ImageFeatureExtractor: () => (
      /* reexport safe */
      h.ImageFeatureExtractor
    ),
    /* harmony export */
    ImageMattingOutput: () => (
      /* reexport safe */
      t.ImageMattingOutput
    ),
    /* harmony export */
    ImageProcessor: () => (
      /* reexport safe */
      _.ImageProcessor
    ),
    /* harmony export */
    ImageSegmentationPipeline: () => (
      /* reexport safe */
      n.ImageSegmentationPipeline
    ),
    /* harmony export */
    ImageToImagePipeline: () => (
      /* reexport safe */
      n.ImageToImagePipeline
    ),
    /* harmony export */
    ImageToTextPipeline: () => (
      /* reexport safe */
      n.ImageToTextPipeline
    ),
    /* harmony export */
    InterruptableStoppingCriteria: () => (
      /* reexport safe */
      E.InterruptableStoppingCriteria
    ),
    /* harmony export */
    JAISLMHeadModel: () => (
      /* reexport safe */
      t.JAISLMHeadModel
    ),
    /* harmony export */
    JAISModel: () => (
      /* reexport safe */
      t.JAISModel
    ),
    /* harmony export */
    JAISPreTrainedModel: () => (
      /* reexport safe */
      t.JAISPreTrainedModel
    ),
    /* harmony export */
    JinaCLIPImageProcessor: () => (
      /* reexport safe */
      v.JinaCLIPImageProcessor
    ),
    /* harmony export */
    JinaCLIPModel: () => (
      /* reexport safe */
      t.JinaCLIPModel
    ),
    /* harmony export */
    JinaCLIPPreTrainedModel: () => (
      /* reexport safe */
      t.JinaCLIPPreTrainedModel
    ),
    /* harmony export */
    JinaCLIPProcessor: () => (
      /* reexport safe */
      w.JinaCLIPProcessor
    ),
    /* harmony export */
    JinaCLIPTextModel: () => (
      /* reexport safe */
      t.JinaCLIPTextModel
    ),
    /* harmony export */
    JinaCLIPVisionModel: () => (
      /* reexport safe */
      t.JinaCLIPVisionModel
    ),
    /* harmony export */
    Lfm2ForCausalLM: () => (
      /* reexport safe */
      t.Lfm2ForCausalLM
    ),
    /* harmony export */
    Lfm2Model: () => (
      /* reexport safe */
      t.Lfm2Model
    ),
    /* harmony export */
    Lfm2PreTrainedModel: () => (
      /* reexport safe */
      t.Lfm2PreTrainedModel
    ),
    /* harmony export */
    LiteWhisperForConditionalGeneration: () => (
      /* reexport safe */
      t.LiteWhisperForConditionalGeneration
    ),
    /* harmony export */
    Llama4ForCausalLM: () => (
      /* reexport safe */
      t.Llama4ForCausalLM
    ),
    /* harmony export */
    Llama4PreTrainedModel: () => (
      /* reexport safe */
      t.Llama4PreTrainedModel
    ),
    /* harmony export */
    LlamaForCausalLM: () => (
      /* reexport safe */
      t.LlamaForCausalLM
    ),
    /* harmony export */
    LlamaModel: () => (
      /* reexport safe */
      t.LlamaModel
    ),
    /* harmony export */
    LlamaPreTrainedModel: () => (
      /* reexport safe */
      t.LlamaPreTrainedModel
    ),
    /* harmony export */
    LlamaTokenizer: () => (
      /* reexport safe */
      i.LlamaTokenizer
    ),
    /* harmony export */
    LlavaForConditionalGeneration: () => (
      /* reexport safe */
      t.LlavaForConditionalGeneration
    ),
    /* harmony export */
    LlavaOnevisionForConditionalGeneration: () => (
      /* reexport safe */
      t.LlavaOnevisionForConditionalGeneration
    ),
    /* harmony export */
    LlavaOnevisionImageProcessor: () => (
      /* reexport safe */
      v.LlavaOnevisionImageProcessor
    ),
    /* harmony export */
    LlavaPreTrainedModel: () => (
      /* reexport safe */
      t.LlavaPreTrainedModel
    ),
    /* harmony export */
    LlavaProcessor: () => (
      /* reexport safe */
      w.LlavaProcessor
    ),
    /* harmony export */
    LlavaQwen2ForCausalLM: () => (
      /* reexport safe */
      t.LlavaQwen2ForCausalLM
    ),
    /* harmony export */
    LogitsProcessor: () => (
      /* reexport safe */
      A.LogitsProcessor
    ),
    /* harmony export */
    LogitsProcessorList: () => (
      /* reexport safe */
      A.LogitsProcessorList
    ),
    /* harmony export */
    LogitsWarper: () => (
      /* reexport safe */
      A.LogitsWarper
    ),
    /* harmony export */
    LongT5ForConditionalGeneration: () => (
      /* reexport safe */
      t.LongT5ForConditionalGeneration
    ),
    /* harmony export */
    LongT5Model: () => (
      /* reexport safe */
      t.LongT5Model
    ),
    /* harmony export */
    LongT5PreTrainedModel: () => (
      /* reexport safe */
      t.LongT5PreTrainedModel
    ),
    /* harmony export */
    M2M100ForConditionalGeneration: () => (
      /* reexport safe */
      t.M2M100ForConditionalGeneration
    ),
    /* harmony export */
    M2M100Model: () => (
      /* reexport safe */
      t.M2M100Model
    ),
    /* harmony export */
    M2M100PreTrainedModel: () => (
      /* reexport safe */
      t.M2M100PreTrainedModel
    ),
    /* harmony export */
    M2M100Tokenizer: () => (
      /* reexport safe */
      i.M2M100Tokenizer
    ),
    /* harmony export */
    MBart50Tokenizer: () => (
      /* reexport safe */
      i.MBart50Tokenizer
    ),
    /* harmony export */
    MBartForCausalLM: () => (
      /* reexport safe */
      t.MBartForCausalLM
    ),
    /* harmony export */
    MBartForConditionalGeneration: () => (
      /* reexport safe */
      t.MBartForConditionalGeneration
    ),
    /* harmony export */
    MBartForSequenceClassification: () => (
      /* reexport safe */
      t.MBartForSequenceClassification
    ),
    /* harmony export */
    MBartModel: () => (
      /* reexport safe */
      t.MBartModel
    ),
    /* harmony export */
    MBartPreTrainedModel: () => (
      /* reexport safe */
      t.MBartPreTrainedModel
    ),
    /* harmony export */
    MBartTokenizer: () => (
      /* reexport safe */
      i.MBartTokenizer
    ),
    /* harmony export */
    MPNetForMaskedLM: () => (
      /* reexport safe */
      t.MPNetForMaskedLM
    ),
    /* harmony export */
    MPNetForQuestionAnswering: () => (
      /* reexport safe */
      t.MPNetForQuestionAnswering
    ),
    /* harmony export */
    MPNetForSequenceClassification: () => (
      /* reexport safe */
      t.MPNetForSequenceClassification
    ),
    /* harmony export */
    MPNetForTokenClassification: () => (
      /* reexport safe */
      t.MPNetForTokenClassification
    ),
    /* harmony export */
    MPNetModel: () => (
      /* reexport safe */
      t.MPNetModel
    ),
    /* harmony export */
    MPNetPreTrainedModel: () => (
      /* reexport safe */
      t.MPNetPreTrainedModel
    ),
    /* harmony export */
    MPNetTokenizer: () => (
      /* reexport safe */
      i.MPNetTokenizer
    ),
    /* harmony export */
    MT5ForConditionalGeneration: () => (
      /* reexport safe */
      t.MT5ForConditionalGeneration
    ),
    /* harmony export */
    MT5Model: () => (
      /* reexport safe */
      t.MT5Model
    ),
    /* harmony export */
    MT5PreTrainedModel: () => (
      /* reexport safe */
      t.MT5PreTrainedModel
    ),
    /* harmony export */
    MarianMTModel: () => (
      /* reexport safe */
      t.MarianMTModel
    ),
    /* harmony export */
    MarianModel: () => (
      /* reexport safe */
      t.MarianModel
    ),
    /* harmony export */
    MarianPreTrainedModel: () => (
      /* reexport safe */
      t.MarianPreTrainedModel
    ),
    /* harmony export */
    MarianTokenizer: () => (
      /* reexport safe */
      i.MarianTokenizer
    ),
    /* harmony export */
    Mask2FormerImageProcessor: () => (
      /* reexport safe */
      v.Mask2FormerImageProcessor
    ),
    /* harmony export */
    MaskFormerFeatureExtractor: () => (
      /* reexport safe */
      v.MaskFormerFeatureExtractor
    ),
    /* harmony export */
    MaskFormerForInstanceSegmentation: () => (
      /* reexport safe */
      t.MaskFormerForInstanceSegmentation
    ),
    /* harmony export */
    MaskFormerImageProcessor: () => (
      /* reexport safe */
      v.MaskFormerImageProcessor
    ),
    /* harmony export */
    MaskFormerModel: () => (
      /* reexport safe */
      t.MaskFormerModel
    ),
    /* harmony export */
    MaskFormerPreTrainedModel: () => (
      /* reexport safe */
      t.MaskFormerPreTrainedModel
    ),
    /* harmony export */
    MaskedLMOutput: () => (
      /* reexport safe */
      t.MaskedLMOutput
    ),
    /* harmony export */
    MaxLengthCriteria: () => (
      /* reexport safe */
      E.MaxLengthCriteria
    ),
    /* harmony export */
    Metric3DForDepthEstimation: () => (
      /* reexport safe */
      t.Metric3DForDepthEstimation
    ),
    /* harmony export */
    Metric3DPreTrainedModel: () => (
      /* reexport safe */
      t.Metric3DPreTrainedModel
    ),
    /* harmony export */
    Metric3Dv2ForDepthEstimation: () => (
      /* reexport safe */
      t.Metric3Dv2ForDepthEstimation
    ),
    /* harmony export */
    Metric3Dv2PreTrainedModel: () => (
      /* reexport safe */
      t.Metric3Dv2PreTrainedModel
    ),
    /* harmony export */
    MgpstrForSceneTextRecognition: () => (
      /* reexport safe */
      t.MgpstrForSceneTextRecognition
    ),
    /* harmony export */
    MgpstrModelOutput: () => (
      /* reexport safe */
      t.MgpstrModelOutput
    ),
    /* harmony export */
    MgpstrPreTrainedModel: () => (
      /* reexport safe */
      t.MgpstrPreTrainedModel
    ),
    /* harmony export */
    MgpstrProcessor: () => (
      /* reexport safe */
      w.MgpstrProcessor
    ),
    /* harmony export */
    MgpstrTokenizer: () => (
      /* reexport safe */
      i.MgpstrTokenizer
    ),
    /* harmony export */
    MimiDecoderModel: () => (
      /* reexport safe */
      t.MimiDecoderModel
    ),
    /* harmony export */
    MimiDecoderOutput: () => (
      /* reexport safe */
      t.MimiDecoderOutput
    ),
    /* harmony export */
    MimiEncoderModel: () => (
      /* reexport safe */
      t.MimiEncoderModel
    ),
    /* harmony export */
    MimiEncoderOutput: () => (
      /* reexport safe */
      t.MimiEncoderOutput
    ),
    /* harmony export */
    MimiModel: () => (
      /* reexport safe */
      t.MimiModel
    ),
    /* harmony export */
    MimiPreTrainedModel: () => (
      /* reexport safe */
      t.MimiPreTrainedModel
    ),
    /* harmony export */
    MinLengthLogitsProcessor: () => (
      /* reexport safe */
      A.MinLengthLogitsProcessor
    ),
    /* harmony export */
    MinNewTokensLengthLogitsProcessor: () => (
      /* reexport safe */
      A.MinNewTokensLengthLogitsProcessor
    ),
    /* harmony export */
    Ministral3ForCausalLM: () => (
      /* reexport safe */
      t.Ministral3ForCausalLM
    ),
    /* harmony export */
    Ministral3Model: () => (
      /* reexport safe */
      t.Ministral3Model
    ),
    /* harmony export */
    Ministral3PreTrainedModel: () => (
      /* reexport safe */
      t.Ministral3PreTrainedModel
    ),
    /* harmony export */
    MinistralForCausalLM: () => (
      /* reexport safe */
      t.MinistralForCausalLM
    ),
    /* harmony export */
    MinistralModel: () => (
      /* reexport safe */
      t.MinistralModel
    ),
    /* harmony export */
    MinistralPreTrainedModel: () => (
      /* reexport safe */
      t.MinistralPreTrainedModel
    ),
    /* harmony export */
    Mistral3ForConditionalGeneration: () => (
      /* reexport safe */
      t.Mistral3ForConditionalGeneration
    ),
    /* harmony export */
    MistralForCausalLM: () => (
      /* reexport safe */
      t.MistralForCausalLM
    ),
    /* harmony export */
    MistralModel: () => (
      /* reexport safe */
      t.MistralModel
    ),
    /* harmony export */
    MistralPreTrainedModel: () => (
      /* reexport safe */
      t.MistralPreTrainedModel
    ),
    /* harmony export */
    MobileBertForMaskedLM: () => (
      /* reexport safe */
      t.MobileBertForMaskedLM
    ),
    /* harmony export */
    MobileBertForQuestionAnswering: () => (
      /* reexport safe */
      t.MobileBertForQuestionAnswering
    ),
    /* harmony export */
    MobileBertForSequenceClassification: () => (
      /* reexport safe */
      t.MobileBertForSequenceClassification
    ),
    /* harmony export */
    MobileBertModel: () => (
      /* reexport safe */
      t.MobileBertModel
    ),
    /* harmony export */
    MobileBertPreTrainedModel: () => (
      /* reexport safe */
      t.MobileBertPreTrainedModel
    ),
    /* harmony export */
    MobileBertTokenizer: () => (
      /* reexport safe */
      i.MobileBertTokenizer
    ),
    /* harmony export */
    MobileLLMForCausalLM: () => (
      /* reexport safe */
      t.MobileLLMForCausalLM
    ),
    /* harmony export */
    MobileLLMModel: () => (
      /* reexport safe */
      t.MobileLLMModel
    ),
    /* harmony export */
    MobileLLMPreTrainedModel: () => (
      /* reexport safe */
      t.MobileLLMPreTrainedModel
    ),
    /* harmony export */
    MobileNetV1FeatureExtractor: () => (
      /* reexport safe */
      v.MobileNetV1FeatureExtractor
    ),
    /* harmony export */
    MobileNetV1ForImageClassification: () => (
      /* reexport safe */
      t.MobileNetV1ForImageClassification
    ),
    /* harmony export */
    MobileNetV1ForSemanticSegmentation: () => (
      /* reexport safe */
      t.MobileNetV1ForSemanticSegmentation
    ),
    /* harmony export */
    MobileNetV1ImageProcessor: () => (
      /* reexport safe */
      v.MobileNetV1ImageProcessor
    ),
    /* harmony export */
    MobileNetV1Model: () => (
      /* reexport safe */
      t.MobileNetV1Model
    ),
    /* harmony export */
    MobileNetV1PreTrainedModel: () => (
      /* reexport safe */
      t.MobileNetV1PreTrainedModel
    ),
    /* harmony export */
    MobileNetV2FeatureExtractor: () => (
      /* reexport safe */
      v.MobileNetV2FeatureExtractor
    ),
    /* harmony export */
    MobileNetV2ForImageClassification: () => (
      /* reexport safe */
      t.MobileNetV2ForImageClassification
    ),
    /* harmony export */
    MobileNetV2ForSemanticSegmentation: () => (
      /* reexport safe */
      t.MobileNetV2ForSemanticSegmentation
    ),
    /* harmony export */
    MobileNetV2ImageProcessor: () => (
      /* reexport safe */
      v.MobileNetV2ImageProcessor
    ),
    /* harmony export */
    MobileNetV2Model: () => (
      /* reexport safe */
      t.MobileNetV2Model
    ),
    /* harmony export */
    MobileNetV2PreTrainedModel: () => (
      /* reexport safe */
      t.MobileNetV2PreTrainedModel
    ),
    /* harmony export */
    MobileNetV3FeatureExtractor: () => (
      /* reexport safe */
      v.MobileNetV3FeatureExtractor
    ),
    /* harmony export */
    MobileNetV3ForImageClassification: () => (
      /* reexport safe */
      t.MobileNetV3ForImageClassification
    ),
    /* harmony export */
    MobileNetV3ForSemanticSegmentation: () => (
      /* reexport safe */
      t.MobileNetV3ForSemanticSegmentation
    ),
    /* harmony export */
    MobileNetV3ImageProcessor: () => (
      /* reexport safe */
      v.MobileNetV3ImageProcessor
    ),
    /* harmony export */
    MobileNetV3Model: () => (
      /* reexport safe */
      t.MobileNetV3Model
    ),
    /* harmony export */
    MobileNetV3PreTrainedModel: () => (
      /* reexport safe */
      t.MobileNetV3PreTrainedModel
    ),
    /* harmony export */
    MobileNetV4FeatureExtractor: () => (
      /* reexport safe */
      v.MobileNetV4FeatureExtractor
    ),
    /* harmony export */
    MobileNetV4ForImageClassification: () => (
      /* reexport safe */
      t.MobileNetV4ForImageClassification
    ),
    /* harmony export */
    MobileNetV4ForSemanticSegmentation: () => (
      /* reexport safe */
      t.MobileNetV4ForSemanticSegmentation
    ),
    /* harmony export */
    MobileNetV4ImageProcessor: () => (
      /* reexport safe */
      v.MobileNetV4ImageProcessor
    ),
    /* harmony export */
    MobileNetV4Model: () => (
      /* reexport safe */
      t.MobileNetV4Model
    ),
    /* harmony export */
    MobileNetV4PreTrainedModel: () => (
      /* reexport safe */
      t.MobileNetV4PreTrainedModel
    ),
    /* harmony export */
    MobileViTFeatureExtractor: () => (
      /* reexport safe */
      v.MobileViTFeatureExtractor
    ),
    /* harmony export */
    MobileViTForImageClassification: () => (
      /* reexport safe */
      t.MobileViTForImageClassification
    ),
    /* harmony export */
    MobileViTImageProcessor: () => (
      /* reexport safe */
      v.MobileViTImageProcessor
    ),
    /* harmony export */
    MobileViTModel: () => (
      /* reexport safe */
      t.MobileViTModel
    ),
    /* harmony export */
    MobileViTPreTrainedModel: () => (
      /* reexport safe */
      t.MobileViTPreTrainedModel
    ),
    /* harmony export */
    MobileViTV2ForImageClassification: () => (
      /* reexport safe */
      t.MobileViTV2ForImageClassification
    ),
    /* harmony export */
    MobileViTV2Model: () => (
      /* reexport safe */
      t.MobileViTV2Model
    ),
    /* harmony export */
    MobileViTV2PreTrainedModel: () => (
      /* reexport safe */
      t.MobileViTV2PreTrainedModel
    ),
    /* harmony export */
    ModelOutput: () => (
      /* reexport safe */
      t.ModelOutput
    ),
    /* harmony export */
    ModernBertDecoderForCausalLM: () => (
      /* reexport safe */
      t.ModernBertDecoderForCausalLM
    ),
    /* harmony export */
    ModernBertDecoderModel: () => (
      /* reexport safe */
      t.ModernBertDecoderModel
    ),
    /* harmony export */
    ModernBertDecoderPreTrainedModel: () => (
      /* reexport safe */
      t.ModernBertDecoderPreTrainedModel
    ),
    /* harmony export */
    ModernBertForMaskedLM: () => (
      /* reexport safe */
      t.ModernBertForMaskedLM
    ),
    /* harmony export */
    ModernBertForSequenceClassification: () => (
      /* reexport safe */
      t.ModernBertForSequenceClassification
    ),
    /* harmony export */
    ModernBertForTokenClassification: () => (
      /* reexport safe */
      t.ModernBertForTokenClassification
    ),
    /* harmony export */
    ModernBertModel: () => (
      /* reexport safe */
      t.ModernBertModel
    ),
    /* harmony export */
    ModernBertPreTrainedModel: () => (
      /* reexport safe */
      t.ModernBertPreTrainedModel
    ),
    /* harmony export */
    Moondream1ForConditionalGeneration: () => (
      /* reexport safe */
      t.Moondream1ForConditionalGeneration
    ),
    /* harmony export */
    MoonshineFeatureExtractor: () => (
      /* reexport safe */
      h.MoonshineFeatureExtractor
    ),
    /* harmony export */
    MoonshineForConditionalGeneration: () => (
      /* reexport safe */
      t.MoonshineForConditionalGeneration
    ),
    /* harmony export */
    MoonshineModel: () => (
      /* reexport safe */
      t.MoonshineModel
    ),
    /* harmony export */
    MoonshinePreTrainedModel: () => (
      /* reexport safe */
      t.MoonshinePreTrainedModel
    ),
    /* harmony export */
    MoonshineProcessor: () => (
      /* reexport safe */
      w.MoonshineProcessor
    ),
    /* harmony export */
    MptForCausalLM: () => (
      /* reexport safe */
      t.MptForCausalLM
    ),
    /* harmony export */
    MptModel: () => (
      /* reexport safe */
      t.MptModel
    ),
    /* harmony export */
    MptPreTrainedModel: () => (
      /* reexport safe */
      t.MptPreTrainedModel
    ),
    /* harmony export */
    MultiModalityCausalLM: () => (
      /* reexport safe */
      t.MultiModalityCausalLM
    ),
    /* harmony export */
    MultiModalityPreTrainedModel: () => (
      /* reexport safe */
      t.MultiModalityPreTrainedModel
    ),
    /* harmony export */
    MusicgenForCausalLM: () => (
      /* reexport safe */
      t.MusicgenForCausalLM
    ),
    /* harmony export */
    MusicgenForConditionalGeneration: () => (
      /* reexport safe */
      t.MusicgenForConditionalGeneration
    ),
    /* harmony export */
    MusicgenModel: () => (
      /* reexport safe */
      t.MusicgenModel
    ),
    /* harmony export */
    MusicgenPreTrainedModel: () => (
      /* reexport safe */
      t.MusicgenPreTrainedModel
    ),
    /* harmony export */
    NanoChatForCausalLM: () => (
      /* reexport safe */
      t.NanoChatForCausalLM
    ),
    /* harmony export */
    NanoChatModel: () => (
      /* reexport safe */
      t.NanoChatModel
    ),
    /* harmony export */
    NanoChatPreTrainedModel: () => (
      /* reexport safe */
      t.NanoChatPreTrainedModel
    ),
    /* harmony export */
    NeoBertForMaskedLM: () => (
      /* reexport safe */
      t.NeoBertForMaskedLM
    ),
    /* harmony export */
    NeoBertForQuestionAnswering: () => (
      /* reexport safe */
      t.NeoBertForQuestionAnswering
    ),
    /* harmony export */
    NeoBertForSequenceClassification: () => (
      /* reexport safe */
      t.NeoBertForSequenceClassification
    ),
    /* harmony export */
    NeoBertForTokenClassification: () => (
      /* reexport safe */
      t.NeoBertForTokenClassification
    ),
    /* harmony export */
    NeoBertModel: () => (
      /* reexport safe */
      t.NeoBertModel
    ),
    /* harmony export */
    NeoBertPreTrainedModel: () => (
      /* reexport safe */
      t.NeoBertPreTrainedModel
    ),
    /* harmony export */
    NllbTokenizer: () => (
      /* reexport safe */
      i.NllbTokenizer
    ),
    /* harmony export */
    NoBadWordsLogitsProcessor: () => (
      /* reexport safe */
      A.NoBadWordsLogitsProcessor
    ),
    /* harmony export */
    NoRepeatNGramLogitsProcessor: () => (
      /* reexport safe */
      A.NoRepeatNGramLogitsProcessor
    ),
    /* harmony export */
    NomicBertModel: () => (
      /* reexport safe */
      t.NomicBertModel
    ),
    /* harmony export */
    NomicBertPreTrainedModel: () => (
      /* reexport safe */
      t.NomicBertPreTrainedModel
    ),
    /* harmony export */
    NougatImageProcessor: () => (
      /* reexport safe */
      v.NougatImageProcessor
    ),
    /* harmony export */
    NougatTokenizer: () => (
      /* reexport safe */
      i.NougatTokenizer
    ),
    /* harmony export */
    OPTForCausalLM: () => (
      /* reexport safe */
      t.OPTForCausalLM
    ),
    /* harmony export */
    OPTModel: () => (
      /* reexport safe */
      t.OPTModel
    ),
    /* harmony export */
    OPTPreTrainedModel: () => (
      /* reexport safe */
      t.OPTPreTrainedModel
    ),
    /* harmony export */
    ObjectDetectionPipeline: () => (
      /* reexport safe */
      n.ObjectDetectionPipeline
    ),
    /* harmony export */
    Olmo2ForCausalLM: () => (
      /* reexport safe */
      t.Olmo2ForCausalLM
    ),
    /* harmony export */
    Olmo2Model: () => (
      /* reexport safe */
      t.Olmo2Model
    ),
    /* harmony export */
    Olmo2PreTrainedModel: () => (
      /* reexport safe */
      t.Olmo2PreTrainedModel
    ),
    /* harmony export */
    OlmoForCausalLM: () => (
      /* reexport safe */
      t.OlmoForCausalLM
    ),
    /* harmony export */
    OlmoModel: () => (
      /* reexport safe */
      t.OlmoModel
    ),
    /* harmony export */
    OlmoPreTrainedModel: () => (
      /* reexport safe */
      t.OlmoPreTrainedModel
    ),
    /* harmony export */
    OpenELMForCausalLM: () => (
      /* reexport safe */
      t.OpenELMForCausalLM
    ),
    /* harmony export */
    OpenELMModel: () => (
      /* reexport safe */
      t.OpenELMModel
    ),
    /* harmony export */
    OpenELMPreTrainedModel: () => (
      /* reexport safe */
      t.OpenELMPreTrainedModel
    ),
    /* harmony export */
    OwlViTFeatureExtractor: () => (
      /* reexport safe */
      v.OwlViTFeatureExtractor
    ),
    /* harmony export */
    OwlViTForObjectDetection: () => (
      /* reexport safe */
      t.OwlViTForObjectDetection
    ),
    /* harmony export */
    OwlViTImageProcessor: () => (
      /* reexport safe */
      v.OwlViTImageProcessor
    ),
    /* harmony export */
    OwlViTModel: () => (
      /* reexport safe */
      t.OwlViTModel
    ),
    /* harmony export */
    OwlViTPreTrainedModel: () => (
      /* reexport safe */
      t.OwlViTPreTrainedModel
    ),
    /* harmony export */
    OwlViTProcessor: () => (
      /* reexport safe */
      w.OwlViTProcessor
    ),
    /* harmony export */
    Owlv2ForObjectDetection: () => (
      /* reexport safe */
      t.Owlv2ForObjectDetection
    ),
    /* harmony export */
    Owlv2ImageProcessor: () => (
      /* reexport safe */
      v.Owlv2ImageProcessor
    ),
    /* harmony export */
    Owlv2Model: () => (
      /* reexport safe */
      t.Owlv2Model
    ),
    /* harmony export */
    Owlv2PreTrainedModel: () => (
      /* reexport safe */
      t.Owlv2PreTrainedModel
    ),
    /* harmony export */
    PaliGemmaForConditionalGeneration: () => (
      /* reexport safe */
      t.PaliGemmaForConditionalGeneration
    ),
    /* harmony export */
    PaliGemmaPreTrainedModel: () => (
      /* reexport safe */
      t.PaliGemmaPreTrainedModel
    ),
    /* harmony export */
    PaliGemmaProcessor: () => (
      /* reexport safe */
      w.PaliGemmaProcessor
    ),
    /* harmony export */
    ParakeetFeatureExtractor: () => (
      /* reexport safe */
      h.ParakeetFeatureExtractor
    ),
    /* harmony export */
    ParakeetForCTC: () => (
      /* reexport safe */
      t.ParakeetForCTC
    ),
    /* harmony export */
    ParakeetPreTrainedModel: () => (
      /* reexport safe */
      t.ParakeetPreTrainedModel
    ),
    /* harmony export */
    PatchTSMixerForPrediction: () => (
      /* reexport safe */
      t.PatchTSMixerForPrediction
    ),
    /* harmony export */
    PatchTSMixerModel: () => (
      /* reexport safe */
      t.PatchTSMixerModel
    ),
    /* harmony export */
    PatchTSMixerPreTrainedModel: () => (
      /* reexport safe */
      t.PatchTSMixerPreTrainedModel
    ),
    /* harmony export */
    PatchTSTForPrediction: () => (
      /* reexport safe */
      t.PatchTSTForPrediction
    ),
    /* harmony export */
    PatchTSTModel: () => (
      /* reexport safe */
      t.PatchTSTModel
    ),
    /* harmony export */
    PatchTSTPreTrainedModel: () => (
      /* reexport safe */
      t.PatchTSTPreTrainedModel
    ),
    /* harmony export */
    Phi3ForCausalLM: () => (
      /* reexport safe */
      t.Phi3ForCausalLM
    ),
    /* harmony export */
    Phi3Model: () => (
      /* reexport safe */
      t.Phi3Model
    ),
    /* harmony export */
    Phi3PreTrainedModel: () => (
      /* reexport safe */
      t.Phi3PreTrainedModel
    ),
    /* harmony export */
    Phi3VForCausalLM: () => (
      /* reexport safe */
      t.Phi3VForCausalLM
    ),
    /* harmony export */
    Phi3VImageProcessor: () => (
      /* reexport safe */
      v.Phi3VImageProcessor
    ),
    /* harmony export */
    Phi3VPreTrainedModel: () => (
      /* reexport safe */
      t.Phi3VPreTrainedModel
    ),
    /* harmony export */
    Phi3VProcessor: () => (
      /* reexport safe */
      w.Phi3VProcessor
    ),
    /* harmony export */
    PhiForCausalLM: () => (
      /* reexport safe */
      t.PhiForCausalLM
    ),
    /* harmony export */
    PhiModel: () => (
      /* reexport safe */
      t.PhiModel
    ),
    /* harmony export */
    PhiPreTrainedModel: () => (
      /* reexport safe */
      t.PhiPreTrainedModel
    ),
    /* harmony export */
    Pipeline: () => (
      /* reexport safe */
      n.Pipeline
    ),
    /* harmony export */
    PixtralImageProcessor: () => (
      /* reexport safe */
      v.PixtralImageProcessor
    ),
    /* harmony export */
    PixtralProcessor: () => (
      /* reexport safe */
      w.PixtralProcessor
    ),
    /* harmony export */
    PreTrainedModel: () => (
      /* reexport safe */
      t.PreTrainedModel
    ),
    /* harmony export */
    PreTrainedTokenizer: () => (
      /* reexport safe */
      i.PreTrainedTokenizer
    ),
    /* harmony export */
    PretrainedConfig: () => (
      /* reexport safe */
      r.PretrainedConfig
    ),
    /* harmony export */
    PretrainedMixin: () => (
      /* reexport safe */
      t.PretrainedMixin
    ),
    /* harmony export */
    Processor: () => (
      /* reexport safe */
      D.Processor
    ),
    /* harmony export */
    PvtForImageClassification: () => (
      /* reexport safe */
      t.PvtForImageClassification
    ),
    /* harmony export */
    PvtImageProcessor: () => (
      /* reexport safe */
      v.PvtImageProcessor
    ),
    /* harmony export */
    PvtModel: () => (
      /* reexport safe */
      t.PvtModel
    ),
    /* harmony export */
    PvtPreTrainedModel: () => (
      /* reexport safe */
      t.PvtPreTrainedModel
    ),
    /* harmony export */
    PyAnnoteFeatureExtractor: () => (
      /* reexport safe */
      h.PyAnnoteFeatureExtractor
    ),
    /* harmony export */
    PyAnnoteForAudioFrameClassification: () => (
      /* reexport safe */
      t.PyAnnoteForAudioFrameClassification
    ),
    /* harmony export */
    PyAnnoteModel: () => (
      /* reexport safe */
      t.PyAnnoteModel
    ),
    /* harmony export */
    PyAnnotePreTrainedModel: () => (
      /* reexport safe */
      t.PyAnnotePreTrainedModel
    ),
    /* harmony export */
    PyAnnoteProcessor: () => (
      /* reexport safe */
      w.PyAnnoteProcessor
    ),
    /* harmony export */
    QuestionAnsweringModelOutput: () => (
      /* reexport safe */
      t.QuestionAnsweringModelOutput
    ),
    /* harmony export */
    QuestionAnsweringPipeline: () => (
      /* reexport safe */
      n.QuestionAnsweringPipeline
    ),
    /* harmony export */
    Qwen2ForCausalLM: () => (
      /* reexport safe */
      t.Qwen2ForCausalLM
    ),
    /* harmony export */
    Qwen2Model: () => (
      /* reexport safe */
      t.Qwen2Model
    ),
    /* harmony export */
    Qwen2PreTrainedModel: () => (
      /* reexport safe */
      t.Qwen2PreTrainedModel
    ),
    /* harmony export */
    Qwen2Tokenizer: () => (
      /* reexport safe */
      i.Qwen2Tokenizer
    ),
    /* harmony export */
    Qwen2VLForConditionalGeneration: () => (
      /* reexport safe */
      t.Qwen2VLForConditionalGeneration
    ),
    /* harmony export */
    Qwen2VLImageProcessor: () => (
      /* reexport safe */
      v.Qwen2VLImageProcessor
    ),
    /* harmony export */
    Qwen2VLPreTrainedModel: () => (
      /* reexport safe */
      t.Qwen2VLPreTrainedModel
    ),
    /* harmony export */
    Qwen2VLProcessor: () => (
      /* reexport safe */
      w.Qwen2VLProcessor
    ),
    /* harmony export */
    Qwen3ForCausalLM: () => (
      /* reexport safe */
      t.Qwen3ForCausalLM
    ),
    /* harmony export */
    Qwen3Model: () => (
      /* reexport safe */
      t.Qwen3Model
    ),
    /* harmony export */
    Qwen3PreTrainedModel: () => (
      /* reexport safe */
      t.Qwen3PreTrainedModel
    ),
    /* harmony export */
    RFDetrForObjectDetection: () => (
      /* reexport safe */
      t.RFDetrForObjectDetection
    ),
    /* harmony export */
    RFDetrModel: () => (
      /* reexport safe */
      t.RFDetrModel
    ),
    /* harmony export */
    RFDetrObjectDetectionOutput: () => (
      /* reexport safe */
      t.RFDetrObjectDetectionOutput
    ),
    /* harmony export */
    RFDetrPreTrainedModel: () => (
      /* reexport safe */
      t.RFDetrPreTrainedModel
    ),
    /* harmony export */
    RTDetrForObjectDetection: () => (
      /* reexport safe */
      t.RTDetrForObjectDetection
    ),
    /* harmony export */
    RTDetrImageProcessor: () => (
      /* reexport safe */
      v.RTDetrImageProcessor
    ),
    /* harmony export */
    RTDetrModel: () => (
      /* reexport safe */
      t.RTDetrModel
    ),
    /* harmony export */
    RTDetrObjectDetectionOutput: () => (
      /* reexport safe */
      t.RTDetrObjectDetectionOutput
    ),
    /* harmony export */
    RTDetrPreTrainedModel: () => (
      /* reexport safe */
      t.RTDetrPreTrainedModel
    ),
    /* harmony export */
    RTDetrV2ForObjectDetection: () => (
      /* reexport safe */
      t.RTDetrV2ForObjectDetection
    ),
    /* harmony export */
    RTDetrV2Model: () => (
      /* reexport safe */
      t.RTDetrV2Model
    ),
    /* harmony export */
    RTDetrV2ObjectDetectionOutput: () => (
      /* reexport safe */
      t.RTDetrV2ObjectDetectionOutput
    ),
    /* harmony export */
    RTDetrV2PreTrainedModel: () => (
      /* reexport safe */
      t.RTDetrV2PreTrainedModel
    ),
    /* harmony export */
    RawAudio: () => (
      /* reexport safe */
      a.RawAudio
    ),
    /* harmony export */
    RawImage: () => (
      /* reexport safe */
      c.RawImage
    ),
    /* harmony export */
    RawVideo: () => (
      /* reexport safe */
      u.RawVideo
    ),
    /* harmony export */
    RawVideoFrame: () => (
      /* reexport safe */
      u.RawVideoFrame
    ),
    /* harmony export */
    RepetitionPenaltyLogitsProcessor: () => (
      /* reexport safe */
      A.RepetitionPenaltyLogitsProcessor
    ),
    /* harmony export */
    ResNetForImageClassification: () => (
      /* reexport safe */
      t.ResNetForImageClassification
    ),
    /* harmony export */
    ResNetModel: () => (
      /* reexport safe */
      t.ResNetModel
    ),
    /* harmony export */
    ResNetPreTrainedModel: () => (
      /* reexport safe */
      t.ResNetPreTrainedModel
    ),
    /* harmony export */
    RoFormerForMaskedLM: () => (
      /* reexport safe */
      t.RoFormerForMaskedLM
    ),
    /* harmony export */
    RoFormerForQuestionAnswering: () => (
      /* reexport safe */
      t.RoFormerForQuestionAnswering
    ),
    /* harmony export */
    RoFormerForSequenceClassification: () => (
      /* reexport safe */
      t.RoFormerForSequenceClassification
    ),
    /* harmony export */
    RoFormerForTokenClassification: () => (
      /* reexport safe */
      t.RoFormerForTokenClassification
    ),
    /* harmony export */
    RoFormerModel: () => (
      /* reexport safe */
      t.RoFormerModel
    ),
    /* harmony export */
    RoFormerPreTrainedModel: () => (
      /* reexport safe */
      t.RoFormerPreTrainedModel
    ),
    /* harmony export */
    RoFormerTokenizer: () => (
      /* reexport safe */
      i.RoFormerTokenizer
    ),
    /* harmony export */
    RobertaForMaskedLM: () => (
      /* reexport safe */
      t.RobertaForMaskedLM
    ),
    /* harmony export */
    RobertaForQuestionAnswering: () => (
      /* reexport safe */
      t.RobertaForQuestionAnswering
    ),
    /* harmony export */
    RobertaForSequenceClassification: () => (
      /* reexport safe */
      t.RobertaForSequenceClassification
    ),
    /* harmony export */
    RobertaForTokenClassification: () => (
      /* reexport safe */
      t.RobertaForTokenClassification
    ),
    /* harmony export */
    RobertaModel: () => (
      /* reexport safe */
      t.RobertaModel
    ),
    /* harmony export */
    RobertaPreTrainedModel: () => (
      /* reexport safe */
      t.RobertaPreTrainedModel
    ),
    /* harmony export */
    RobertaTokenizer: () => (
      /* reexport safe */
      i.RobertaTokenizer
    ),
    /* harmony export */
    Sam2ImageProcessor: () => (
      /* reexport safe */
      v.Sam2ImageProcessor
    ),
    /* harmony export */
    Sam2ImageSegmentationOutput: () => (
      /* reexport safe */
      t.Sam2ImageSegmentationOutput
    ),
    /* harmony export */
    Sam2Model: () => (
      /* reexport safe */
      t.Sam2Model
    ),
    /* harmony export */
    Sam2PreTrainedModel: () => (
      /* reexport safe */
      t.Sam2PreTrainedModel
    ),
    /* harmony export */
    Sam2Processor: () => (
      /* reexport safe */
      w.Sam2Processor
    ),
    /* harmony export */
    Sam2VideoProcessor: () => (
      /* reexport safe */
      w.Sam2VideoProcessor
    ),
    /* harmony export */
    Sam3ImageProcessor: () => (
      /* reexport safe */
      v.Sam3ImageProcessor
    ),
    /* harmony export */
    Sam3TrackerModel: () => (
      /* reexport safe */
      t.Sam3TrackerModel
    ),
    /* harmony export */
    SamImageProcessor: () => (
      /* reexport safe */
      v.SamImageProcessor
    ),
    /* harmony export */
    SamImageSegmentationOutput: () => (
      /* reexport safe */
      t.SamImageSegmentationOutput
    ),
    /* harmony export */
    SamModel: () => (
      /* reexport safe */
      t.SamModel
    ),
    /* harmony export */
    SamPreTrainedModel: () => (
      /* reexport safe */
      t.SamPreTrainedModel
    ),
    /* harmony export */
    SamProcessor: () => (
      /* reexport safe */
      w.SamProcessor
    ),
    /* harmony export */
    SapiensForDepthEstimation: () => (
      /* reexport safe */
      t.SapiensForDepthEstimation
    ),
    /* harmony export */
    SapiensForNormalEstimation: () => (
      /* reexport safe */
      t.SapiensForNormalEstimation
    ),
    /* harmony export */
    SapiensForSemanticSegmentation: () => (
      /* reexport safe */
      t.SapiensForSemanticSegmentation
    ),
    /* harmony export */
    SapiensPreTrainedModel: () => (
      /* reexport safe */
      t.SapiensPreTrainedModel
    ),
    /* harmony export */
    SeamlessM4TFeatureExtractor: () => (
      /* reexport safe */
      h.SeamlessM4TFeatureExtractor
    ),
    /* harmony export */
    SegformerFeatureExtractor: () => (
      /* reexport safe */
      v.SegformerFeatureExtractor
    ),
    /* harmony export */
    SegformerForImageClassification: () => (
      /* reexport safe */
      t.SegformerForImageClassification
    ),
    /* harmony export */
    SegformerForSemanticSegmentation: () => (
      /* reexport safe */
      t.SegformerForSemanticSegmentation
    ),
    /* harmony export */
    SegformerImageProcessor: () => (
      /* reexport safe */
      v.SegformerImageProcessor
    ),
    /* harmony export */
    SegformerModel: () => (
      /* reexport safe */
      t.SegformerModel
    ),
    /* harmony export */
    SegformerPreTrainedModel: () => (
      /* reexport safe */
      t.SegformerPreTrainedModel
    ),
    /* harmony export */
    Seq2SeqLMOutput: () => (
      /* reexport safe */
      t.Seq2SeqLMOutput
    ),
    /* harmony export */
    SequenceClassifierOutput: () => (
      /* reexport safe */
      t.SequenceClassifierOutput
    ),
    /* harmony export */
    SiglipImageProcessor: () => (
      /* reexport safe */
      v.SiglipImageProcessor
    ),
    /* harmony export */
    SiglipModel: () => (
      /* reexport safe */
      t.SiglipModel
    ),
    /* harmony export */
    SiglipPreTrainedModel: () => (
      /* reexport safe */
      t.SiglipPreTrainedModel
    ),
    /* harmony export */
    SiglipTextModel: () => (
      /* reexport safe */
      t.SiglipTextModel
    ),
    /* harmony export */
    SiglipTokenizer: () => (
      /* reexport safe */
      i.SiglipTokenizer
    ),
    /* harmony export */
    SiglipVisionModel: () => (
      /* reexport safe */
      t.SiglipVisionModel
    ),
    /* harmony export */
    SmolLM3ForCausalLM: () => (
      /* reexport safe */
      t.SmolLM3ForCausalLM
    ),
    /* harmony export */
    SmolLM3Model: () => (
      /* reexport safe */
      t.SmolLM3Model
    ),
    /* harmony export */
    SmolLM3PreTrainedModel: () => (
      /* reexport safe */
      t.SmolLM3PreTrainedModel
    ),
    /* harmony export */
    SmolVLMForConditionalGeneration: () => (
      /* reexport safe */
      t.SmolVLMForConditionalGeneration
    ),
    /* harmony export */
    SmolVLMImageProcessor: () => (
      /* reexport safe */
      v.SmolVLMImageProcessor
    ),
    /* harmony export */
    SmolVLMProcessor: () => (
      /* reexport safe */
      w.SmolVLMProcessor
    ),
    /* harmony export */
    SnacDecoderModel: () => (
      /* reexport safe */
      t.SnacDecoderModel
    ),
    /* harmony export */
    SnacEncoderModel: () => (
      /* reexport safe */
      t.SnacEncoderModel
    ),
    /* harmony export */
    SnacFeatureExtractor: () => (
      /* reexport safe */
      h.SnacFeatureExtractor
    ),
    /* harmony export */
    SnacModel: () => (
      /* reexport safe */
      t.SnacModel
    ),
    /* harmony export */
    SnacPreTrainedModel: () => (
      /* reexport safe */
      t.SnacPreTrainedModel
    ),
    /* harmony export */
    SpeechT5FeatureExtractor: () => (
      /* reexport safe */
      h.SpeechT5FeatureExtractor
    ),
    /* harmony export */
    SpeechT5ForSpeechToText: () => (
      /* reexport safe */
      t.SpeechT5ForSpeechToText
    ),
    /* harmony export */
    SpeechT5ForTextToSpeech: () => (
      /* reexport safe */
      t.SpeechT5ForTextToSpeech
    ),
    /* harmony export */
    SpeechT5HifiGan: () => (
      /* reexport safe */
      t.SpeechT5HifiGan
    ),
    /* harmony export */
    SpeechT5Model: () => (
      /* reexport safe */
      t.SpeechT5Model
    ),
    /* harmony export */
    SpeechT5PreTrainedModel: () => (
      /* reexport safe */
      t.SpeechT5PreTrainedModel
    ),
    /* harmony export */
    SpeechT5Processor: () => (
      /* reexport safe */
      w.SpeechT5Processor
    ),
    /* harmony export */
    SpeechT5Tokenizer: () => (
      /* reexport safe */
      i.SpeechT5Tokenizer
    ),
    /* harmony export */
    SqueezeBertForMaskedLM: () => (
      /* reexport safe */
      t.SqueezeBertForMaskedLM
    ),
    /* harmony export */
    SqueezeBertForQuestionAnswering: () => (
      /* reexport safe */
      t.SqueezeBertForQuestionAnswering
    ),
    /* harmony export */
    SqueezeBertForSequenceClassification: () => (
      /* reexport safe */
      t.SqueezeBertForSequenceClassification
    ),
    /* harmony export */
    SqueezeBertModel: () => (
      /* reexport safe */
      t.SqueezeBertModel
    ),
    /* harmony export */
    SqueezeBertPreTrainedModel: () => (
      /* reexport safe */
      t.SqueezeBertPreTrainedModel
    ),
    /* harmony export */
    SqueezeBertTokenizer: () => (
      /* reexport safe */
      i.SqueezeBertTokenizer
    ),
    /* harmony export */
    StableLmForCausalLM: () => (
      /* reexport safe */
      t.StableLmForCausalLM
    ),
    /* harmony export */
    StableLmModel: () => (
      /* reexport safe */
      t.StableLmModel
    ),
    /* harmony export */
    StableLmPreTrainedModel: () => (
      /* reexport safe */
      t.StableLmPreTrainedModel
    ),
    /* harmony export */
    Starcoder2ForCausalLM: () => (
      /* reexport safe */
      t.Starcoder2ForCausalLM
    ),
    /* harmony export */
    Starcoder2Model: () => (
      /* reexport safe */
      t.Starcoder2Model
    ),
    /* harmony export */
    Starcoder2PreTrainedModel: () => (
      /* reexport safe */
      t.Starcoder2PreTrainedModel
    ),
    /* harmony export */
    StoppingCriteria: () => (
      /* reexport safe */
      E.StoppingCriteria
    ),
    /* harmony export */
    StoppingCriteriaList: () => (
      /* reexport safe */
      E.StoppingCriteriaList
    ),
    /* harmony export */
    StyleTextToSpeech2Model: () => (
      /* reexport safe */
      t.StyleTextToSpeech2Model
    ),
    /* harmony export */
    StyleTextToSpeech2PreTrainedModel: () => (
      /* reexport safe */
      t.StyleTextToSpeech2PreTrainedModel
    ),
    /* harmony export */
    SummarizationPipeline: () => (
      /* reexport safe */
      n.SummarizationPipeline
    ),
    /* harmony export */
    SupertonicForConditionalGeneration: () => (
      /* reexport safe */
      t.SupertonicForConditionalGeneration
    ),
    /* harmony export */
    SupertonicPreTrainedModel: () => (
      /* reexport safe */
      t.SupertonicPreTrainedModel
    ),
    /* harmony export */
    SuppressTokensAtBeginLogitsProcessor: () => (
      /* reexport safe */
      A.SuppressTokensAtBeginLogitsProcessor
    ),
    /* harmony export */
    Swin2SRForImageSuperResolution: () => (
      /* reexport safe */
      t.Swin2SRForImageSuperResolution
    ),
    /* harmony export */
    Swin2SRImageProcessor: () => (
      /* reexport safe */
      v.Swin2SRImageProcessor
    ),
    /* harmony export */
    Swin2SRModel: () => (
      /* reexport safe */
      t.Swin2SRModel
    ),
    /* harmony export */
    Swin2SRPreTrainedModel: () => (
      /* reexport safe */
      t.Swin2SRPreTrainedModel
    ),
    /* harmony export */
    SwinForImageClassification: () => (
      /* reexport safe */
      t.SwinForImageClassification
    ),
    /* harmony export */
    SwinForSemanticSegmentation: () => (
      /* reexport safe */
      t.SwinForSemanticSegmentation
    ),
    /* harmony export */
    SwinModel: () => (
      /* reexport safe */
      t.SwinModel
    ),
    /* harmony export */
    SwinPreTrainedModel: () => (
      /* reexport safe */
      t.SwinPreTrainedModel
    ),
    /* harmony export */
    T5ForConditionalGeneration: () => (
      /* reexport safe */
      t.T5ForConditionalGeneration
    ),
    /* harmony export */
    T5Model: () => (
      /* reexport safe */
      t.T5Model
    ),
    /* harmony export */
    T5PreTrainedModel: () => (
      /* reexport safe */
      t.T5PreTrainedModel
    ),
    /* harmony export */
    T5Tokenizer: () => (
      /* reexport safe */
      i.T5Tokenizer
    ),
    /* harmony export */
    TableTransformerForObjectDetection: () => (
      /* reexport safe */
      t.TableTransformerForObjectDetection
    ),
    /* harmony export */
    TableTransformerModel: () => (
      /* reexport safe */
      t.TableTransformerModel
    ),
    /* harmony export */
    TableTransformerObjectDetectionOutput: () => (
      /* reexport safe */
      t.TableTransformerObjectDetectionOutput
    ),
    /* harmony export */
    TableTransformerPreTrainedModel: () => (
      /* reexport safe */
      t.TableTransformerPreTrainedModel
    ),
    /* harmony export */
    TemperatureLogitsWarper: () => (
      /* reexport safe */
      A.TemperatureLogitsWarper
    ),
    /* harmony export */
    Tensor: () => (
      /* reexport safe */
      l.Tensor
    ),
    /* harmony export */
    Text2TextGenerationPipeline: () => (
      /* reexport safe */
      n.Text2TextGenerationPipeline
    ),
    /* harmony export */
    TextClassificationPipeline: () => (
      /* reexport safe */
      n.TextClassificationPipeline
    ),
    /* harmony export */
    TextGenerationPipeline: () => (
      /* reexport safe */
      n.TextGenerationPipeline
    ),
    /* harmony export */
    TextStreamer: () => (
      /* reexport safe */
      F.TextStreamer
    ),
    /* harmony export */
    TextToAudioPipeline: () => (
      /* reexport safe */
      n.TextToAudioPipeline
    ),
    /* harmony export */
    TokenClassificationPipeline: () => (
      /* reexport safe */
      n.TokenClassificationPipeline
    ),
    /* harmony export */
    TokenClassifierOutput: () => (
      /* reexport safe */
      t.TokenClassifierOutput
    ),
    /* harmony export */
    TokenizerModel: () => (
      /* reexport safe */
      i.TokenizerModel
    ),
    /* harmony export */
    TopKLogitsWarper: () => (
      /* reexport safe */
      A.TopKLogitsWarper
    ),
    /* harmony export */
    TopPLogitsWarper: () => (
      /* reexport safe */
      A.TopPLogitsWarper
    ),
    /* harmony export */
    TrOCRForCausalLM: () => (
      /* reexport safe */
      t.TrOCRForCausalLM
    ),
    /* harmony export */
    TrOCRPreTrainedModel: () => (
      /* reexport safe */
      t.TrOCRPreTrainedModel
    ),
    /* harmony export */
    TranslationPipeline: () => (
      /* reexport safe */
      n.TranslationPipeline
    ),
    /* harmony export */
    UltravoxModel: () => (
      /* reexport safe */
      t.UltravoxModel
    ),
    /* harmony export */
    UltravoxPreTrainedModel: () => (
      /* reexport safe */
      t.UltravoxPreTrainedModel
    ),
    /* harmony export */
    UltravoxProcessor: () => (
      /* reexport safe */
      w.UltravoxProcessor
    ),
    /* harmony export */
    UniSpeechForCTC: () => (
      /* reexport safe */
      t.UniSpeechForCTC
    ),
    /* harmony export */
    UniSpeechForSequenceClassification: () => (
      /* reexport safe */
      t.UniSpeechForSequenceClassification
    ),
    /* harmony export */
    UniSpeechModel: () => (
      /* reexport safe */
      t.UniSpeechModel
    ),
    /* harmony export */
    UniSpeechPreTrainedModel: () => (
      /* reexport safe */
      t.UniSpeechPreTrainedModel
    ),
    /* harmony export */
    UniSpeechSatForAudioFrameClassification: () => (
      /* reexport safe */
      t.UniSpeechSatForAudioFrameClassification
    ),
    /* harmony export */
    UniSpeechSatForCTC: () => (
      /* reexport safe */
      t.UniSpeechSatForCTC
    ),
    /* harmony export */
    UniSpeechSatForSequenceClassification: () => (
      /* reexport safe */
      t.UniSpeechSatForSequenceClassification
    ),
    /* harmony export */
    UniSpeechSatModel: () => (
      /* reexport safe */
      t.UniSpeechSatModel
    ),
    /* harmony export */
    UniSpeechSatPreTrainedModel: () => (
      /* reexport safe */
      t.UniSpeechSatPreTrainedModel
    ),
    /* harmony export */
    VLChatProcessor: () => (
      /* reexport safe */
      w.VLChatProcessor
    ),
    /* harmony export */
    VLMImageProcessor: () => (
      /* reexport safe */
      v.VLMImageProcessor
    ),
    /* harmony export */
    VaultGemmaForCausalLM: () => (
      /* reexport safe */
      t.VaultGemmaForCausalLM
    ),
    /* harmony export */
    VaultGemmaModel: () => (
      /* reexport safe */
      t.VaultGemmaModel
    ),
    /* harmony export */
    VaultGemmaPreTrainedModel: () => (
      /* reexport safe */
      t.VaultGemmaPreTrainedModel
    ),
    /* harmony export */
    ViTFeatureExtractor: () => (
      /* reexport safe */
      v.ViTFeatureExtractor
    ),
    /* harmony export */
    ViTForImageClassification: () => (
      /* reexport safe */
      t.ViTForImageClassification
    ),
    /* harmony export */
    ViTImageProcessor: () => (
      /* reexport safe */
      v.ViTImageProcessor
    ),
    /* harmony export */
    ViTMAEModel: () => (
      /* reexport safe */
      t.ViTMAEModel
    ),
    /* harmony export */
    ViTMAEPreTrainedModel: () => (
      /* reexport safe */
      t.ViTMAEPreTrainedModel
    ),
    /* harmony export */
    ViTMSNForImageClassification: () => (
      /* reexport safe */
      t.ViTMSNForImageClassification
    ),
    /* harmony export */
    ViTMSNModel: () => (
      /* reexport safe */
      t.ViTMSNModel
    ),
    /* harmony export */
    ViTMSNPreTrainedModel: () => (
      /* reexport safe */
      t.ViTMSNPreTrainedModel
    ),
    /* harmony export */
    ViTModel: () => (
      /* reexport safe */
      t.ViTModel
    ),
    /* harmony export */
    ViTPreTrainedModel: () => (
      /* reexport safe */
      t.ViTPreTrainedModel
    ),
    /* harmony export */
    VisionEncoderDecoderModel: () => (
      /* reexport safe */
      t.VisionEncoderDecoderModel
    ),
    /* harmony export */
    VitMatteForImageMatting: () => (
      /* reexport safe */
      t.VitMatteForImageMatting
    ),
    /* harmony export */
    VitMatteImageProcessor: () => (
      /* reexport safe */
      v.VitMatteImageProcessor
    ),
    /* harmony export */
    VitMattePreTrainedModel: () => (
      /* reexport safe */
      t.VitMattePreTrainedModel
    ),
    /* harmony export */
    VitPoseForPoseEstimation: () => (
      /* reexport safe */
      t.VitPoseForPoseEstimation
    ),
    /* harmony export */
    VitPoseImageProcessor: () => (
      /* reexport safe */
      v.VitPoseImageProcessor
    ),
    /* harmony export */
    VitPosePreTrainedModel: () => (
      /* reexport safe */
      t.VitPosePreTrainedModel
    ),
    /* harmony export */
    VitsModel: () => (
      /* reexport safe */
      t.VitsModel
    ),
    /* harmony export */
    VitsModelOutput: () => (
      /* reexport safe */
      t.VitsModelOutput
    ),
    /* harmony export */
    VitsPreTrainedModel: () => (
      /* reexport safe */
      t.VitsPreTrainedModel
    ),
    /* harmony export */
    VitsTokenizer: () => (
      /* reexport safe */
      i.VitsTokenizer
    ),
    /* harmony export */
    VoxtralForConditionalGeneration: () => (
      /* reexport safe */
      t.VoxtralForConditionalGeneration
    ),
    /* harmony export */
    VoxtralProcessor: () => (
      /* reexport safe */
      w.VoxtralProcessor
    ),
    /* harmony export */
    Wav2Vec2BertForCTC: () => (
      /* reexport safe */
      t.Wav2Vec2BertForCTC
    ),
    /* harmony export */
    Wav2Vec2BertForSequenceClassification: () => (
      /* reexport safe */
      t.Wav2Vec2BertForSequenceClassification
    ),
    /* harmony export */
    Wav2Vec2BertModel: () => (
      /* reexport safe */
      t.Wav2Vec2BertModel
    ),
    /* harmony export */
    Wav2Vec2BertPreTrainedModel: () => (
      /* reexport safe */
      t.Wav2Vec2BertPreTrainedModel
    ),
    /* harmony export */
    Wav2Vec2CTCTokenizer: () => (
      /* reexport safe */
      i.Wav2Vec2CTCTokenizer
    ),
    /* harmony export */
    Wav2Vec2FeatureExtractor: () => (
      /* reexport safe */
      h.Wav2Vec2FeatureExtractor
    ),
    /* harmony export */
    Wav2Vec2ForAudioFrameClassification: () => (
      /* reexport safe */
      t.Wav2Vec2ForAudioFrameClassification
    ),
    /* harmony export */
    Wav2Vec2ForCTC: () => (
      /* reexport safe */
      t.Wav2Vec2ForCTC
    ),
    /* harmony export */
    Wav2Vec2ForSequenceClassification: () => (
      /* reexport safe */
      t.Wav2Vec2ForSequenceClassification
    ),
    /* harmony export */
    Wav2Vec2Model: () => (
      /* reexport safe */
      t.Wav2Vec2Model
    ),
    /* harmony export */
    Wav2Vec2PreTrainedModel: () => (
      /* reexport safe */
      t.Wav2Vec2PreTrainedModel
    ),
    /* harmony export */
    Wav2Vec2Processor: () => (
      /* reexport safe */
      w.Wav2Vec2Processor
    ),
    /* harmony export */
    Wav2Vec2ProcessorWithLM: () => (
      /* reexport safe */
      w.Wav2Vec2ProcessorWithLM
    ),
    /* harmony export */
    WavLMForAudioFrameClassification: () => (
      /* reexport safe */
      t.WavLMForAudioFrameClassification
    ),
    /* harmony export */
    WavLMForCTC: () => (
      /* reexport safe */
      t.WavLMForCTC
    ),
    /* harmony export */
    WavLMForSequenceClassification: () => (
      /* reexport safe */
      t.WavLMForSequenceClassification
    ),
    /* harmony export */
    WavLMForXVector: () => (
      /* reexport safe */
      t.WavLMForXVector
    ),
    /* harmony export */
    WavLMModel: () => (
      /* reexport safe */
      t.WavLMModel
    ),
    /* harmony export */
    WavLMPreTrainedModel: () => (
      /* reexport safe */
      t.WavLMPreTrainedModel
    ),
    /* harmony export */
    WeSpeakerFeatureExtractor: () => (
      /* reexport safe */
      h.WeSpeakerFeatureExtractor
    ),
    /* harmony export */
    WeSpeakerResNetModel: () => (
      /* reexport safe */
      t.WeSpeakerResNetModel
    ),
    /* harmony export */
    WeSpeakerResNetPreTrainedModel: () => (
      /* reexport safe */
      t.WeSpeakerResNetPreTrainedModel
    ),
    /* harmony export */
    WhisperFeatureExtractor: () => (
      /* reexport safe */
      h.WhisperFeatureExtractor
    ),
    /* harmony export */
    WhisperForConditionalGeneration: () => (
      /* reexport safe */
      t.WhisperForConditionalGeneration
    ),
    /* harmony export */
    WhisperModel: () => (
      /* reexport safe */
      t.WhisperModel
    ),
    /* harmony export */
    WhisperPreTrainedModel: () => (
      /* reexport safe */
      t.WhisperPreTrainedModel
    ),
    /* harmony export */
    WhisperProcessor: () => (
      /* reexport safe */
      w.WhisperProcessor
    ),
    /* harmony export */
    WhisperTextStreamer: () => (
      /* reexport safe */
      F.WhisperTextStreamer
    ),
    /* harmony export */
    WhisperTimeStampLogitsProcessor: () => (
      /* reexport safe */
      A.WhisperTimeStampLogitsProcessor
    ),
    /* harmony export */
    WhisperTokenizer: () => (
      /* reexport safe */
      i.WhisperTokenizer
    ),
    /* harmony export */
    XLMForQuestionAnswering: () => (
      /* reexport safe */
      t.XLMForQuestionAnswering
    ),
    /* harmony export */
    XLMForSequenceClassification: () => (
      /* reexport safe */
      t.XLMForSequenceClassification
    ),
    /* harmony export */
    XLMForTokenClassification: () => (
      /* reexport safe */
      t.XLMForTokenClassification
    ),
    /* harmony export */
    XLMModel: () => (
      /* reexport safe */
      t.XLMModel
    ),
    /* harmony export */
    XLMPreTrainedModel: () => (
      /* reexport safe */
      t.XLMPreTrainedModel
    ),
    /* harmony export */
    XLMRobertaForMaskedLM: () => (
      /* reexport safe */
      t.XLMRobertaForMaskedLM
    ),
    /* harmony export */
    XLMRobertaForQuestionAnswering: () => (
      /* reexport safe */
      t.XLMRobertaForQuestionAnswering
    ),
    /* harmony export */
    XLMRobertaForSequenceClassification: () => (
      /* reexport safe */
      t.XLMRobertaForSequenceClassification
    ),
    /* harmony export */
    XLMRobertaForTokenClassification: () => (
      /* reexport safe */
      t.XLMRobertaForTokenClassification
    ),
    /* harmony export */
    XLMRobertaModel: () => (
      /* reexport safe */
      t.XLMRobertaModel
    ),
    /* harmony export */
    XLMRobertaPreTrainedModel: () => (
      /* reexport safe */
      t.XLMRobertaPreTrainedModel
    ),
    /* harmony export */
    XLMRobertaTokenizer: () => (
      /* reexport safe */
      i.XLMRobertaTokenizer
    ),
    /* harmony export */
    XLMTokenizer: () => (
      /* reexport safe */
      i.XLMTokenizer
    ),
    /* harmony export */
    XLMWithLMHeadModel: () => (
      /* reexport safe */
      t.XLMWithLMHeadModel
    ),
    /* harmony export */
    XVectorOutput: () => (
      /* reexport safe */
      t.XVectorOutput
    ),
    /* harmony export */
    YolosFeatureExtractor: () => (
      /* reexport safe */
      v.YolosFeatureExtractor
    ),
    /* harmony export */
    YolosForObjectDetection: () => (
      /* reexport safe */
      t.YolosForObjectDetection
    ),
    /* harmony export */
    YolosImageProcessor: () => (
      /* reexport safe */
      v.YolosImageProcessor
    ),
    /* harmony export */
    YolosModel: () => (
      /* reexport safe */
      t.YolosModel
    ),
    /* harmony export */
    YolosObjectDetectionOutput: () => (
      /* reexport safe */
      t.YolosObjectDetectionOutput
    ),
    /* harmony export */
    YolosPreTrainedModel: () => (
      /* reexport safe */
      t.YolosPreTrainedModel
    ),
    /* harmony export */
    ZeroShotAudioClassificationPipeline: () => (
      /* reexport safe */
      n.ZeroShotAudioClassificationPipeline
    ),
    /* harmony export */
    ZeroShotClassificationPipeline: () => (
      /* reexport safe */
      n.ZeroShotClassificationPipeline
    ),
    /* harmony export */
    ZeroShotImageClassificationPipeline: () => (
      /* reexport safe */
      n.ZeroShotImageClassificationPipeline
    ),
    /* harmony export */
    ZeroShotObjectDetectionPipeline: () => (
      /* reexport safe */
      n.ZeroShotObjectDetectionPipeline
    ),
    /* harmony export */
    bankers_round: () => (
      /* reexport safe */
      f.bankers_round
    ),
    /* harmony export */
    cat: () => (
      /* reexport safe */
      l.cat
    ),
    /* harmony export */
    cos_sim: () => (
      /* reexport safe */
      f.cos_sim
    ),
    /* harmony export */
    dot: () => (
      /* reexport safe */
      f.dot
    ),
    /* harmony export */
    dynamic_time_warping: () => (
      /* reexport safe */
      f.dynamic_time_warping
    ),
    /* harmony export */
    env: () => (
      /* reexport safe */
      e.env
    ),
    /* harmony export */
    full: () => (
      /* reexport safe */
      l.full
    ),
    /* harmony export */
    full_like: () => (
      /* reexport safe */
      l.full_like
    ),
    /* harmony export */
    getCacheShapes: () => (
      /* reexport safe */
      r.getCacheShapes
    ),
    /* harmony export */
    hamming: () => (
      /* reexport safe */
      a.hamming
    ),
    /* harmony export */
    hanning: () => (
      /* reexport safe */
      a.hanning
    ),
    /* harmony export */
    interpolate: () => (
      /* reexport safe */
      l.interpolate
    ),
    /* harmony export */
    interpolate_4d: () => (
      /* reexport safe */
      l.interpolate_4d
    ),
    /* harmony export */
    interpolate_data: () => (
      /* reexport safe */
      f.interpolate_data
    ),
    /* harmony export */
    is_chinese_char: () => (
      /* reexport safe */
      i.is_chinese_char
    ),
    /* harmony export */
    layer_norm: () => (
      /* reexport safe */
      l.layer_norm
    ),
    /* harmony export */
    load_image: () => (
      /* reexport safe */
      c.load_image
    ),
    /* harmony export */
    load_video: () => (
      /* reexport safe */
      u.load_video
    ),
    /* harmony export */
    log_softmax: () => (
      /* reexport safe */
      f.log_softmax
    ),
    /* harmony export */
    magnitude: () => (
      /* reexport safe */
      f.magnitude
    ),
    /* harmony export */
    matmul: () => (
      /* reexport safe */
      l.matmul
    ),
    /* harmony export */
    max: () => (
      /* reexport safe */
      f.max
    ),
    /* harmony export */
    mean: () => (
      /* reexport safe */
      l.mean
    ),
    /* harmony export */
    mean_pooling: () => (
      /* reexport safe */
      l.mean_pooling
    ),
    /* harmony export */
    medianFilter: () => (
      /* reexport safe */
      f.medianFilter
    ),
    /* harmony export */
    mel_filter_bank: () => (
      /* reexport safe */
      a.mel_filter_bank
    ),
    /* harmony export */
    min: () => (
      /* reexport safe */
      f.min
    ),
    /* harmony export */
    ones: () => (
      /* reexport safe */
      l.ones
    ),
    /* harmony export */
    ones_like: () => (
      /* reexport safe */
      l.ones_like
    ),
    /* harmony export */
    permute: () => (
      /* reexport safe */
      l.permute
    ),
    /* harmony export */
    permute_data: () => (
      /* reexport safe */
      f.permute_data
    ),
    /* harmony export */
    pipeline: () => (
      /* reexport safe */
      n.pipeline
    ),
    /* harmony export */
    quantize_embeddings: () => (
      /* reexport safe */
      l.quantize_embeddings
    ),
    /* harmony export */
    rand: () => (
      /* reexport safe */
      l.rand
    ),
    /* harmony export */
    randn: () => (
      /* reexport safe */
      l.randn
    ),
    /* harmony export */
    read_audio: () => (
      /* reexport safe */
      a.read_audio
    ),
    /* harmony export */
    rfft: () => (
      /* reexport safe */
      l.rfft
    ),
    /* harmony export */
    round: () => (
      /* reexport safe */
      f.round
    ),
    /* harmony export */
    slice: () => (
      /* reexport safe */
      l.slice
    ),
    /* harmony export */
    softmax: () => (
      /* reexport safe */
      f.softmax
    ),
    /* harmony export */
    spectrogram: () => (
      /* reexport safe */
      a.spectrogram
    ),
    /* harmony export */
    stack: () => (
      /* reexport safe */
      l.stack
    ),
    /* harmony export */
    std_mean: () => (
      /* reexport safe */
      l.std_mean
    ),
    /* harmony export */
    topk: () => (
      /* reexport safe */
      l.topk
    ),
    /* harmony export */
    window_function: () => (
      /* reexport safe */
      a.window_function
    ),
    /* harmony export */
    zeros: () => (
      /* reexport safe */
      l.zeros
    ),
    /* harmony export */
    zeros_like: () => (
      /* reexport safe */
      l.zeros_like
    )
    /* harmony export */
  });
  var e = xn(
    /*! ./env.js */
    "./src/env.js"
  ), n = xn(
    /*! ./pipelines.js */
    "./src/pipelines.js"
  ), t = xn(
    /*! ./models.js */
    "./src/models.js"
  ), i = xn(
    /*! ./tokenizers.js */
    "./src/tokenizers.js"
  ), r = xn(
    /*! ./configs.js */
    "./src/configs.js"
  ), a = xn(
    /*! ./utils/audio.js */
    "./src/utils/audio.js"
  ), c = xn(
    /*! ./utils/image.js */
    "./src/utils/image.js"
  ), u = xn(
    /*! ./utils/video.js */
    "./src/utils/video.js"
  ), l = xn(
    /*! ./utils/tensor.js */
    "./src/utils/tensor.js"
  ), f = xn(
    /*! ./utils/maths.js */
    "./src/utils/maths.js"
  ), m = xn(
    /*! ./base/feature_extraction_utils.js */
    "./src/base/feature_extraction_utils.js"
  ), h = xn(
    /*! ./models/feature_extractors.js */
    "./src/models/feature_extractors.js"
  ), p = xn(
    /*! ./models/auto/feature_extraction_auto.js */
    "./src/models/auto/feature_extraction_auto.js"
  ), _ = xn(
    /*! ./base/image_processors_utils.js */
    "./src/base/image_processors_utils.js"
  ), v = xn(
    /*! ./models/image_processors.js */
    "./src/models/image_processors.js"
  ), S = xn(
    /*! ./models/auto/image_processing_auto.js */
    "./src/models/auto/image_processing_auto.js"
  ), D = xn(
    /*! ./base/processing_utils.js */
    "./src/base/processing_utils.js"
  ), w = xn(
    /*! ./models/processors.js */
    "./src/models/processors.js"
  ), T = xn(
    /*! ./models/auto/processing_auto.js */
    "./src/models/auto/processing_auto.js"
  ), F = xn(
    /*! ./generation/streamers.js */
    "./src/generation/streamers.js"
  ), E = xn(
    /*! ./generation/stopping_criteria.js */
    "./src/generation/stopping_criteria.js"
  ), A = xn(
    /*! ./generation/logits_process.js */
    "./src/generation/logits_process.js"
  );
})();
var Ib = Oy.env, ZP = Oy.pipeline;
Ib.allowLocalModels = !0;
Ib.useBrowserCache = !0;
class Lb {
  constructor(n = {}) {
    this.modelId = n.modelId || "onnx-community/depth-anything-v2-small", this.device = n.device || "webgpu", this.pipeline = null, this.isLoading = !1, this.isReady = !1, this.depthCache = /* @__PURE__ */ new Map(), this.onProgress = n.onProgress || null, this.onReady = n.onReady || null, this.onError = n.onError || null;
  }
  /**
   * Initialize the depth estimation pipeline
   */
  async initialize() {
    if (this.isReady)
      return !0;
    if (this.isLoading)
      return new Promise((n) => {
        const t = setInterval(() => {
          this.isReady && (clearInterval(t), n(!0));
        }, 100);
      });
    this.isLoading = !0;
    try {
      return console.log(`[DepthEstimator] Loading model: ${this.modelId} on ${this.device}`), this.pipeline = await ZP("depth-estimation", this.modelId, {
        device: this.device,
        progress_callback: (n) => {
          this.onProgress && this.onProgress(n), console.log(`[DepthEstimator] Loading: ${n.status}`, n);
        }
      }), this.isReady = !0, this.isLoading = !1, console.log("[DepthEstimator] Model loaded successfully"), this.onReady && this.onReady(), !0;
    } catch (n) {
      if (this.isLoading = !1, console.error("[DepthEstimator] Failed to load model:", n), this.device === "webgpu")
        return console.log("[DepthEstimator] Falling back to WASM..."), this.device = "wasm", this.initialize();
      throw this.onError && this.onError(n), n;
    }
  }
  /**
   * Estimate depth for an image
   * @param {string|HTMLImageElement|HTMLCanvasElement} image - Image URL or element
   * @param {string} cacheKey - Optional cache key (defaults to image URL if string)
   * @returns {Promise<DepthResult>} Depth estimation result
   */
  async estimateDepth(n, t = null) {
    this.isReady || await this.initialize();
    const i = t || (typeof n == "string" ? n : null);
    if (i && this.depthCache.has(i))
      return console.log("[DepthEstimator] Returning cached depth map for:", i), this.depthCache.get(i);
    console.log("[DepthEstimator] Estimating depth for:", i || "image element");
    try {
      const r = await this.pipeline(n), a = new eA(r, n);
      return i && this.depthCache.set(i, a), a;
    } catch (r) {
      throw console.error("[DepthEstimator] Depth estimation failed:", r), r;
    }
  }
  /**
   * Clear the depth cache
   */
  clearCache() {
    this.depthCache.clear();
  }
  /**
   * Remove a specific entry from cache
   */
  removeFromCache(n) {
    this.depthCache.delete(n);
  }
  /**
   * Dispose of the pipeline and free resources
   */
  async dispose() {
    this.pipeline && (this.pipeline = null), this.depthCache.clear(), this.isReady = !1;
  }
}
class eA {
  constructor(n, t) {
    this.raw = n, this.depthTensor = n.depth, this.width = this.depthTensor.width, this.height = this.depthTensor.height, this.data = this.depthTensor.data, this.sourceImage = t, this.minDepth = 1 / 0, this.maxDepth = -1 / 0;
    for (let i = 0; i < this.data.length; i++)
      this.data[i] < this.minDepth && (this.minDepth = this.data[i]), this.data[i] > this.maxDepth && (this.maxDepth = this.data[i]);
  }
  /**
   * Get depth value at a specific pixel coordinate
   * @param {number} x - X coordinate (0 to width-1)
   * @param {number} y - Y coordinate (0 to height-1)
   * @returns {number} Raw depth value
   */
  getDepthAt(n, t) {
    const i = Math.round(n), r = Math.round(t);
    if (i < 0 || i >= this.width || r < 0 || r >= this.height)
      return null;
    const a = r * this.width + i;
    return this.data[a];
  }
  /**
   * Get normalized depth value (0-1 range)
   * @param {number} x - X coordinate
   * @param {number} y - Y coordinate
   * @returns {number} Normalized depth (0 = near, 1 = far)
   */
  getNormalizedDepthAt(n, t) {
    const i = this.getDepthAt(n, t);
    return i === null ? null : (i - this.minDepth) / (this.maxDepth - this.minDepth);
  }
  /**
   * Get depth at UV coordinates (0-1 range)
   * @param {number} u - U coordinate (0-1)
   * @param {number} v - V coordinate (0-1)
   * @returns {number} Raw depth value
   */
  getDepthAtUV(n, t) {
    const i = n * (this.width - 1), r = t * (this.height - 1);
    return this.getDepthAt(i, r);
  }
  /**
   * Sample depth with bilinear interpolation
   * @param {number} x - X coordinate (can be fractional)
   * @param {number} y - Y coordinate (can be fractional)
   * @returns {number} Interpolated depth value
   */
  sampleDepth(n, t) {
    const i = Math.floor(n), r = Math.floor(t), a = Math.min(i + 1, this.width - 1), c = Math.min(r + 1, this.height - 1), u = n - i, l = t - r, f = this.getDepthAt(i, r) || 0, m = this.getDepthAt(a, r) || 0, h = this.getDepthAt(i, c) || 0, p = this.getDepthAt(a, c) || 0, _ = f * (1 - u) + m * u, v = h * (1 - u) + p * u;
    return _ * (1 - l) + v * l;
  }
  /**
   * Create a canvas visualization of the depth map
   * @returns {HTMLCanvasElement} Canvas with depth visualization
   */
  toCanvas() {
    const n = document.createElement("canvas");
    n.width = this.width, n.height = this.height;
    const t = n.getContext("2d"), i = t.createImageData(this.width, this.height);
    for (let r = 0; r < this.data.length; r++) {
      const a = (this.data[r] - this.minDepth) / (this.maxDepth - this.minDepth), c = Math.round(a * 255);
      i.data[r * 4] = c, i.data[r * 4 + 1] = c, i.data[r * 4 + 2] = c, i.data[r * 4 + 3] = 255;
    }
    return t.putImageData(i, 0, 0), n;
  }
  /**
   * Get depth map as ImageData
   * @returns {ImageData}
   */
  toImageData() {
    const n = new ImageData(this.width, this.height);
    for (let t = 0; t < this.data.length; t++) {
      const i = (this.data[t] - this.minDepth) / (this.maxDepth - this.minDepth), r = Math.round(i * 255);
      n.data[t * 4] = r, n.data[t * 4 + 1] = r, n.data[t * 4 + 2] = r, n.data[t * 4 + 3] = 255;
    }
    return n;
  }
}
let kv = null;
function rA(e = {}) {
  return kv || (kv = new Lb(e)), kv;
}
const tA = `
  .point-tagger-marker {
    position: absolute;
    width: 20px;
    height: 20px;
    margin-left: -10px;
    margin-top: -10px;
    border: 2px solid #ff4444;
    border-radius: 50%;
    background: rgba(255, 68, 68, 0.3);
    cursor: pointer;
    pointer-events: auto;
    z-index: 100;
    transition: transform 0.1s;
  }

  .point-tagger-marker:hover {
    transform: scale(1.2);
    background: rgba(255, 68, 68, 0.5);
  }

  .point-tagger-marker.selected {
    border-color: #44ff44;
    background: rgba(68, 255, 68, 0.3);
  }

  .point-tagger-marker-label {
    position: absolute;
    top: -24px;
    left: 50%;
    transform: translateX(-50%);
    background: rgba(0, 0, 0, 0.7);
    color: white;
    padding: 2px 6px;
    border-radius: 3px;
    font-size: 11px;
    white-space: nowrap;
    pointer-events: none;
  }

  .point-tagger-crosshair {
    position: absolute;
    pointer-events: none;
    z-index: 99;
  }

  .point-tagger-crosshair-h,
  .point-tagger-crosshair-v {
    position: absolute;
    background: rgba(255, 255, 255, 0.5);
  }

  .point-tagger-crosshair-h {
    width: 100%;
    height: 1px;
    top: 50%;
  }

  .point-tagger-crosshair-v {
    width: 1px;
    height: 100%;
    left: 50%;
  }

  .point-tagger-info {
    position: absolute;
    bottom: 16px;
    left: 16px;
    background: rgba(0, 0, 0, 0.7);
    color: white;
    padding: 8px 12px;
    border-radius: 4px;
    font-size: 12px;
    font-family: monospace;
    pointer-events: none;
    z-index: 101;
  }

  .point-tagger-toolbar {
    display: flex;
    gap: 8px;
  }

  .point-tagger-btn {
    background: rgba(255, 255, 255, 0.9);
    border: 1px solid #666;
    border-radius: 4px;
    padding: 4px 8px;
    cursor: pointer;
    font-size: 12px;
  }

  .point-tagger-btn:hover {
    background: rgba(255, 255, 255, 1);
  }

  .point-tagger-btn.active {
    background: #4CAF50;
    color: white;
    border-color: #45a049;
  }
`, oA = function(e = {}) {
  let n = null, t = null, i = /* @__PURE__ */ new Map(), r = /* @__PURE__ */ new Map(), a = !1, c = null, u = null, l = null, f = null, m = null, h = null, p = !1;
  const _ = e.onPointTagged || null, v = e.onTriangulated || null, S = e.onDepthReady || null, D = () => {
    if (p)
      return;
    const _e = document.createElement("style");
    _e.textContent = tA, document.head.appendChild(_e), p = !0;
  }, w = () => "pt_" + Date.now().toString(36) + Math.random().toString(36).substr(2, 5), T = (_e, De) => {
    const Z = n.renderer.domElement.getBoundingClientRect(), me = (_e - Z.left) / Z.width * 2 - 1, we = -((De - Z.top) / Z.height) * 2 + 1, xe = new G0();
    xe.setFromCamera(new vt(me, we), n.camera);
    const et = xe.ray.direction.clone(), Ve = (Math.atan2(et.x, et.y) * 180 / Math.PI + 360) % 360, nt = Math.asin(et.z) * 180 / Math.PI;
    return {
      normalizedX: me,
      normalizedY: we,
      azimuth: Ve,
      elevation: nt,
      direction: et.toArray()
    };
  }, F = (_e, De) => {
    const he = _e * Math.PI / 180, Z = De * Math.PI / 180, me = Math.cos(Z), we = new ve(
      Math.sin(he) * me,
      Math.cos(he) * me,
      Math.sin(Z)
    );
    we.project(n.camera);
    const et = n.renderer.domElement.getBoundingClientRect(), Ve = (we.x + 1) / 2 * et.width + et.left, nt = (-we.y + 1) / 2 * et.height + et.top, Be = new ve();
    n.camera.getWorldDirection(Be);
    const U = new ve(
      Math.sin(he) * me,
      Math.cos(he) * me,
      Math.sin(Z)
    ).dot(Be) > 0;
    return { screenX: Ve, screenY: nt, isVisible: U };
  }, E = async (_e, De) => {
    if (!m)
      return console.warn("[PointTagger] No depth data available"), null;
    const Z = n.renderer.domElement.getBoundingClientRect(), me = (_e - Z.left) / Z.width, we = (De - Z.top) / Z.height, xe = m.getDepthAtUV(me, we), et = m.getNormalizedDepthAt(
      me * m.width,
      we * m.height
    );
    return { depth: xe, normalizedDepth: et };
  }, A = (_e) => {
    const De = document.createElement("div");
    De.className = "point-tagger-marker", De.dataset.pointId = _e.id;
    const he = document.createElement("div");
    return he.className = "point-tagger-marker-label", he.textContent = _e.name, De.appendChild(he), De.addEventListener("click", (Z) => {
      Z.stopPropagation(), R(_e.id);
    }), De.addEventListener("contextmenu", (Z) => {
      Z.preventDefault(), N(_e.id);
    }), De;
  }, L = () => {
    if (!f)
      return;
    const _e = f.querySelectorAll(".point-tagger-marker"), De = /* @__PURE__ */ new Map();
    _e.forEach((he) => De.set(he.dataset.pointId, he)), i.forEach((he, Z) => {
      if (he.imageUrl !== h)
        return;
      const { screenX: me, screenY: we, isVisible: xe } = F(he.azimuth, he.elevation);
      let et = De.get(Z);
      if (et || (et = A(he), f.appendChild(et)), xe) {
        const nt = n.renderer.domElement.getBoundingClientRect();
        et.style.display = "block", et.style.left = `${me - nt.left}px`, et.style.top = `${we - nt.top}px`, et.classList.toggle("selected", Z === c);
      } else
        et.style.display = "none";
      De.delete(Z);
    }), De.forEach((he) => he.remove());
  }, I = async (_e) => {
    var xe, et, Ve, nt, Be, ae, U, Se, ze, Oe, Ye, H;
    if (!a)
      return;
    const he = n.renderer.domElement.getBoundingClientRect();
    if (_e.clientX < he.left || _e.clientX > he.right || _e.clientY < he.top || _e.clientY > he.bottom)
      return;
    const Z = T(_e.clientX, _e.clientY), me = await E(_e.clientX, _e.clientY), we = {
      id: w(),
      name: `Point ${i.size + 1}`,
      screenX: _e.clientX - he.left,
      screenY: _e.clientY - he.top,
      normalizedX: Z.normalizedX,
      normalizedY: Z.normalizedY,
      azimuth: Z.azimuth,
      elevation: Z.elevation,
      direction: Z.direction,
      depth: (me == null ? void 0 : me.depth) || null,
      normalizedDepth: (me == null ? void 0 : me.normalizedDepth) || null,
      imageUrl: h,
      shotMetadata: {
        shot: (et = (xe = n.stores).shot) == null ? void 0 : et.call(xe),
        capture: (nt = (Ve = n.stores).capture) == null ? void 0 : nt.call(Ve),
        facing: (ae = (Be = n.stores).facing) == null ? void 0 : ae.call(Be),
        horizon: (Se = (U = n.stores).horizon) == null ? void 0 : Se.call(U),
        rotation: (Oe = (ze = n.stores).rotation) == null ? void 0 : Oe.call(ze),
        yaw: (H = (Ye = n.stores).yaw) == null ? void 0 : H.call(Ye)
      }
    };
    return i.set(we.id, we), L(), console.log("[PointTagger] Tagged point:", we), _ && _(we), we;
  }, R = (_e) => {
    c = _e, L();
    const De = i.get(_e);
    De && q(De);
  }, N = (_e) => {
    i.delete(_e), c === _e && (c = null), L();
  }, q = (_e) => {
    var De, he;
    if (l) {
      if (!_e) {
        l.style.display = "none";
        return;
      }
      l.style.display = "block", l.innerHTML = `
      <strong>${_e.name}</strong><br>
      Azimuth: ${_e.azimuth.toFixed(2)}&deg;<br>
      Elevation: ${_e.elevation.toFixed(2)}&deg;<br>
      Depth: ${((De = _e.depth) == null ? void 0 : De.toFixed(4)) || "N/A"}<br>
      Normalized: ${((he = _e.normalizedDepth) == null ? void 0 : he.toFixed(4)) || "N/A"}
    `;
    }
  }, ne = (_e, De, he) => {
    var me, we;
    r.has(_e) || r.set(_e, {
      pointName: _e,
      views: []
    });
    const Z = r.get(_e);
    return Z.views.push({
      point: { ...De },
      cameraPosition: he || [0, 0, 0],
      rotation: ((me = De.shotMetadata) == null ? void 0 : me.rotation) || [],
      yaw: ((we = De.shotMetadata) == null ? void 0 : we.yaw) || 0
    }), console.log(`[PointTagger] Added view to set "${_e}". Total views: ${Z.views.length}`), Z;
  }, Q = (_e) => {
    const De = r.get(_e);
    if (!De || De.views.length < 2)
      return console.warn("[PointTagger] Need at least 2 views for triangulation"), null;
    console.log(`[PointTagger] Triangulating "${_e}" with ${De.views.length} views`);
    const he = De.views.map((me) => {
      const { point: we, cameraPosition: xe } = me, et = we.azimuth * Math.PI / 180, Ve = we.elevation * Math.PI / 180, nt = Math.cos(Ve), Be = [
        Math.sin(et) * nt,
        Math.cos(et) * nt,
        Math.sin(Ve)
      ];
      if (me.rotation && me.rotation.length === 9) {
        const ae = me.rotation, U = [
          ae[0] * Be[0] + ae[1] * Be[1] + ae[2] * Be[2],
          ae[3] * Be[0] + ae[4] * Be[1] + ae[5] * Be[2],
          ae[6] * Be[0] + ae[7] * Be[1] + ae[8] * Be[2]
        ];
        Be[0] = U[0], Be[1] = U[1], Be[2] = U[2];
      }
      return {
        origin: xe,
        direction: Be,
        depth: we.depth,
        normalizedDepth: we.normalizedDepth
      };
    }), Z = W(he);
    return v && v(_e, Z), Z;
  }, W = (_e) => {
    if (_e.length < 2)
      return null;
    let De = _e.map((we) => {
      const xe = we.depth || 1;
      return [
        we.origin[0] + we.direction[0] * xe,
        we.origin[1] + we.direction[1] * xe,
        we.origin[2] + we.direction[2] * xe
      ];
    }), he = [0, 0, 0];
    De.forEach((we) => {
      he[0] += we[0] / De.length, he[1] += we[1] / De.length, he[2] += we[2] / De.length;
    });
    for (let we = 0; we < 10; we++) {
      let xe = [0, 0, 0], et = 0;
      _e.forEach((Ve) => {
        const nt = [
          he[0] - Ve.origin[0],
          he[1] - Ve.origin[1],
          he[2] - Ve.origin[2]
        ], Be = nt[0] * Ve.direction[0] + nt[1] * Ve.direction[1] + nt[2] * Ve.direction[2], ae = [
          Ve.origin[0] + Ve.direction[0] * Be,
          Ve.origin[1] + Ve.direction[1] * Be,
          Ve.origin[2] + Ve.direction[2] * Be
        ], U = Ve.normalizedDepth !== null ? 1 - Ve.normalizedDepth * 0.5 : 1;
        xe[0] += ae[0] * U, xe[1] += ae[1] * U, xe[2] += ae[2] * U, et += U;
      }), he = [
        xe[0] / et,
        xe[1] / et,
        xe[2] / et
      ];
    }
    let Z = 0;
    const me = _e.map((we) => {
      const xe = [
        he[0] - we.origin[0],
        he[1] - we.origin[1],
        he[2] - we.origin[2]
      ], et = xe[0] * we.direction[0] + xe[1] * we.direction[1] + xe[2] * we.direction[2], Ve = [
        we.origin[0] + we.direction[0] * et,
        we.origin[1] + we.direction[1] * et,
        we.origin[2] + we.direction[2] * et
      ], nt = Math.sqrt(
        Math.pow(he[0] - Ve[0], 2) + Math.pow(he[1] - Ve[1], 2) + Math.pow(he[2] - Ve[2], 2)
      );
      return Z += nt, nt;
    });
    return {
      position: he,
      averageError: Z / _e.length,
      maxError: Math.max(...me),
      viewCount: _e.length,
      confidence: 1 / (1 + Z / _e.length)
    };
  };
  return {
    name: "point-tagger",
    init(_e) {
      var he, Z, me, we, xe, et, Ve, nt;
      n = _e, u = n.wrapper, D(), f = document.createElement("div"), f.className = "point-tagger-markers", f.style.cssText = "position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; overflow: hidden;", u.appendChild(f), l = document.createElement("div"), l.className = "point-tagger-info", l.style.display = "none", u.appendChild(l), u.addEventListener("click", I);
      const De = () => {
        requestAnimationFrame(L);
      };
      (Z = (he = n.stores).facing) == null || Z.call(he, De), (we = (me = n.stores).horizon) == null || we.call(me, De), (et = (xe = n.stores).fov) == null || et.call(xe, De), (nt = (Ve = n.stores).urls) == null || nt.call(Ve, (Be) => {
        Be && Be.length > 0 && (h = Array.isArray(Be[0]) ? Be[0][0] : Be[0], m = null);
      }), console.log("[PointTagger] Plugin initialized");
    },
    destroy() {
      u && u.removeEventListener("click", I), f && f.remove(), l && l.remove(), t && t.dispose(), i.clear(), r.clear();
    },
    // Public API
    setTaggingMode: (_e) => {
      a = _e, u && (u.style.cursor = _e ? "crosshair" : "default"), console.log("[PointTagger] Tagging mode:", _e ? "ON" : "OFF");
    },
    estimateDepth: async () => {
      var he, Z;
      t || (t = new Lb({
        onProgress: (me) => console.log("[PointTagger] Depth model loading:", me),
        onReady: () => console.log("[PointTagger] Depth model ready")
      }));
      const _e = (Z = (he = n.stores).urls) == null ? void 0 : Z.call(he);
      if (!_e || _e.length === 0)
        return console.warn("[PointTagger] No image loaded"), null;
      const De = Array.isArray(_e[0]) ? _e[0][0] : _e[0];
      h = De, console.log("[PointTagger] Estimating depth for:", De);
      try {
        return m = await t.estimateDepth(De), console.log("[PointTagger] Depth estimation complete:", {
          width: m.width,
          height: m.height,
          minDepth: m.minDepth,
          maxDepth: m.maxDepth
        }), S && S(m), m;
      } catch (me) {
        throw console.error("[PointTagger] Depth estimation failed:", me), me;
      }
    },
    getDepthEstimator: () => t,
    getDepthResult: () => m,
    tagPoint: I,
    getPoints: () => Array.from(i.values()),
    getPointsForImage: (_e) => Array.from(i.values()).filter((De) => De.imageUrl === _e),
    getPoint: (_e) => i.get(_e),
    removePoint: N,
    selectPoint: R,
    addToTriangulationSet: ne,
    triangulate: Q,
    getTriangulationSet: (_e) => r.get(_e),
    getAllTriangulationSets: () => Object.fromEntries(r),
    exportData: () => ({
      points: Array.from(i.values()),
      triangulationSets: Object.fromEntries(
        Array.from(r.entries()).map(([_e, De]) => [_e, {
          ...De,
          triangulatedPosition: Q(_e)
        }])
      )
    }),
    importData: (_e) => {
      _e.points && _e.points.forEach((De) => i.set(De.id, De)), _e.triangulationSets && Object.entries(_e.triangulationSets).forEach(([De, he]) => {
        r.set(De, he);
      }), L();
    },
    updateMarkers: L
  };
};
class nA extends HTMLElement {
  static get observedAttributes() {
    return ["fov", "facing", "horizon", "src"];
  }
  constructor() {
    super(), this.viewer = null, console.log("init");
  }
  attributeChangedCallback(n, t, i) {
    console.log("attribute changed", n, i);
    const r = this, a = function(c, u) {
      if (console.log("debouceAttrChange", c, u), r.viewer) {
        if (r.viewer[c])
          console.log("setting", c, u), r.viewer[c](u);
        else if (c == "src") {
          const [l, f] = u.split(".");
          r.viewer.show(
            [
              [`${l}/0.${f}`],
              [`${l}/1.${f}`],
              [`${l}/2.${f}`]
            ],
            0,
            [`${l}/0.obj`, `${l}/1.obj`, `${l}/2.obj`]
          );
        }
      } else
        setTimeout(() => a(c, u), 100);
    };
    a(n, i);
  }
  connectedCallback() {
    console.log("connected");
    const n = this;
    this.style.display = "block", this.viewer = new IP(n, {
      plugins: [
        // Plugins go here
      ]
    });
  }
  updateViewer() {
    console.log("updating viewer"), this.viewer.show(
      [
        [
          "https://image.geocam.xyz/gc2-2022-10-28-5985_s-Boise_driving_v-Ben1027_n-2/0/0000/00002506.jpg?bytes=8431183872-8434173007&container=https%3A%2F%2Fs3proxy.geocam.xyz%2Fgc-raw-surveys-archive%2FNIST%2FBoiseDriving%2FBen_10-27%2Fgc2-2022-10-28-5985_s-Boise_driving_v-Ben1027_n-2_0.tar"
        ],
        [
          "https://image.geocam.xyz/gc2-2022-10-28-5985_s-Boise_driving_v-Ben1027_n-2/1/0000/00002506.jpg?bytes=8022497792-8025797203&container=https%3A%2F%2Fs3proxy.geocam.xyz%2Fgc-raw-surveys-archive%2FNIST%2FBoiseDriving%2FBen_10-27%2Fgc2-2022-10-28-5985_s-Boise_driving_v-Ben1027_n-2_1.tar"
        ],
        [
          "https://image.geocam.xyz/gc2-2022-10-28-5985_s-Boise_driving_v-Ben1027_n-2/2/0000/00002506.jpg?bytes=8256700416-8259564683&container=https%3A%2F%2Fs3proxy.geocam.xyz%2Fgc-raw-surveys-archive%2FNIST%2FBoiseDriving%2FBen_10-27%2Fgc2-2022-10-28-5985_s-Boise_driving_v-Ben1027_n-2_2.tar"
        ]
      ],
      0,
      [
        "https://manager.geocam.xyz/calibration/717/hemisphere_0.obj",
        "https://manager.geocam.xyz/calibration/717/hemisphere_1.obj",
        "https://manager.geocam.xyz/calibration/717/hemisphere_2.obj"
      ]
    );
  }
  disconnectedCallback() {
    console.log("disconnected"), this.viewer = null;
  }
}
window.customElements.define("geocam-viewer", nA);
export {
  Lb as DepthEstimator,
  eA as DepthResult,
  nA as GeocamViewer,
  oA as PointTaggerPlugin,
  rA as getDepthEstimator,
  IP as viewer
};
